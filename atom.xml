<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Miracleyoo</title>
  
  
  <link href="https://www.miracleyoo.com/atom.xml" rel="self"/>
  
  <link href="https://www.miracleyoo.com/"/>
  <updated>2019-10-04T03:01:16.920Z</updated>
  <id>https://www.miracleyoo.com/</id>
  
  <author>
    <name>Miracle Yoo</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Curriculum Vitae -- Zhongyang Zhang</title>
    <link href="https://www.miracleyoo.com/2118/10/30/resume/"/>
    <id>https://www.miracleyoo.com/2118/10/30/resume/</id>
    <published>2118-10-30T19:44:20.000Z</published>
    <updated>2019-10-04T03:01:16.920Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/2118/10/30/resume/cv.png" alt="Resume_ZhongyangZhang_HUST"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;img src=&quot;/2118/10/30/resume/cv.png&quot; alt=&quot;Resume_ZhongyangZhang_HUST&quot;&gt;&lt;/p&gt;
</summary>
      
    
    
    
    
    <category term="Resume" scheme="https://www.miracleyoo.com/tags/Resume/"/>
    
  </entry>
  
  <entry>
    <title>camera-calibration</title>
    <link href="https://www.miracleyoo.com/2022/11/04/camera-calibration/"/>
    <id>https://www.miracleyoo.com/2022/11/04/camera-calibration/</id>
    <published>2022-11-05T04:34:13.000Z</published>
    <updated>2022-11-05T04:34:13.228Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ç›¸æœºæ ¡å‡†">ç›¸æœºæ ¡å‡†</h1><p>é¦–å…ˆæ˜¯å‡ å¼ éå¸¸é‡è¦çš„Slidesï¼Œåé¢éƒ½ä¼šreferåˆ°ï¼Œå¯ä»¥å…ˆè‡ªè¡Œç†Ÿæ‚‰ä¸‹ã€‚å¦å¤–ï¼Œæœ¬ç¯‡ä¸æ˜¯100%ä»é›¶å¼€å§‹çš„æ•™ç¨‹ï¼Œç¯‡å¹…é™åˆ¶å¹¶æ— æ³•å±•å¼€æ‰€æœ‰çš„ç»†èŠ‚ï¼Œè‹¥æƒ³æ·±åº¦ç†è§£ï¼Œè¯·è‡ªè¡Œç»“åˆå‡ ä¸ªå¤§å­¦ï¼ˆCMUï¼ŒStanfordï¼‰ç›¸åº”çš„Slidesä¸€èµ·å­¦ä¹ ã€‚</p><p><img src="/2022/11/04/camera-calibration/image-20221021152707045-1667622796441-1.png" alt="image-20221021152707045" style="zoom:33%;"></p><figure><img src="/2022/11/04/camera-calibration/image-20221021165722788-1667622796442-2.png" alt="image-20221021165722788"><figcaption aria-hidden="true">image-20221021165722788</figcaption></figure><h2 id="coordinates">Coordinates</h2><ul><li>åœ¨æ•´ä¸ªç›¸æœºçš„æŠ•å½±ä¸æ ¡å‡†è¿‡ç¨‹ä¸­ï¼Œä¸€å…±æ¶‰åŠ3ä¸ªåæ ‡ç³»ã€‚å®ƒä»¬åˆ†åˆ«æ˜¯ï¼š<ol type="1"><li>ä¸–ç•Œåæ ‡ç³»ï¼šä»¥ç©ºé—´ä¸­æŸç‚¹ä¸ºåŸç‚¹å»ºç«‹æ¬§æ‹‰åæ ‡ç³»ï¼Œè®¾å®šxyzæ–¹å‘åå½¢æˆçš„åæ ‡ç³»ã€‚</li><li>ç›¸æœºåæ ‡ç³»ã€‚è¯¥åæ ‡ç³»çš„åŸç‚¹æ˜¯ç›¸æœºçš„ç„¦ç‚¹ã€‚ç„¦ç‚¹ä¸€èˆ¬åœ¨ç›¸æœºå†…éƒ¨ï¼Œä¹Ÿå¯èƒ½è½åœ¨çš„ç›¸æœºå¤–éƒ¨ï¼Œè¿™å–å†³äºfocal lengthã€‚åæ ‡ç³»çš„æŒ‡å‘ï¼šxå’Œyå°±æ˜¯ç›¸å¹³é¢çš„æ¨ªçºµåæ ‡æ–¹å‘ï¼ˆç›¸æœºè§†è§’æ–¹å‘ï¼‰ï¼Œzæ˜¯ä¸xyå¹³é¢å‚ç›´çš„æ–¹å‘ï¼Œäº¦å³é•œå¤´æŒ‡å‘çš„å‰æ–¹ã€‚</li><li>å›¾åƒåæ ‡ç³»ï¼ˆä¹Ÿå¯ä»¥åˆ†æˆä¸¤ä¸ªï¼šå›¾åƒåæ ‡ç³»(m)å’Œåƒç´ åæ ‡ç³»(pixel)ï¼‰ã€‚å€¼å¾—æ³¨æ„çš„ä¸€ç‚¹æ˜¯æ¯ä¸ªåƒç´ å¹¶ä¸æ˜¯çœŸæ­£çš„ä¸€ä¸ªç‚¹ï¼Œpixelåæ ‡ç³»æ‰€ä»£è¡¨çš„æ•´æ•°å€¼æ˜¯æ¯ä¸ªåƒç´ ç‚¹çš„ä¸­å¿ƒã€‚</li></ol></li><li>è€ƒè™‘åŠŸèƒ½æ€§ï¼Œè¿˜æœ‰ä¸€ä¸ªåŒè´¨åæ ‡ç³»ï¼Œç”¨äºå®é™…è¿ç®—ã€‚</li></ul><p><img src="/2022/11/04/camera-calibration/image-20221021144051423-1667622796442-3.png" alt="image-20221021144051423" style="zoom: 25%;"></p><h2 id="intrinsic">Intrinsic</h2><ul><li><p>ç†æƒ³çŠ¶å†µä¸‹ï¼ˆæ— Skewnesså’ŒDistortionï¼‰ï¼ŒIntrinsic çŸ©é˜µEncodeçš„ä¿¡æ¯æœ‰ï¼šFocal Lengthã€Image Sensorçš„é•¿å®½ï¼ˆin pixelï¼‰ï¼Œæ¯åƒç´ ä»£è¡¨çš„ç±³æ•°(pixel/m)ï¼Œä¹Ÿå³ç›¸æœºçš„åˆ†è¾¨ç‡ã€‚</p></li><li><p>éç†æƒ³æƒ…å†µä¸‹ï¼ŒSkewnesså’ŒDistortionä¹Ÿä¼šè¢«æ”¾åˆ°Intrinsicä¸­ã€‚</p></li><li><p>å…³äºå½“æé«˜/é™ä½åˆ†è¾¨ç‡æ—¶å€™çš„Intrinsicå˜åŒ–ï¼š<span class="math inline">\(k,l,c_x,c_y\)</span>éƒ½è¦ä¹˜ä»¥åˆ†è¾¨ç‡æé«˜çš„ç³»æ•°ã€‚</p><figure><img src="/2022/11/04/camera-calibration/image-20221026155238653-1667622796442-4.png" alt="image-20221026155238653"><figcaption aria-hidden="true">image-20221026155238653</figcaption></figure></li><li><p>å‚è§Intrinsicçš„è®¡ç®—è¿‡ç¨‹ï¼Œç”±äºè®¡ç®—æ—¶å·²ç»è€ƒè™‘äº†ç›®æ ‡ç‰©ä½“æ·±åº¦å¯¹æˆåƒä½ç½®çš„å½±å“ï¼Œæ‰€ä»¥Intrinsicå…¶å®æ˜¯åŒ…å«äº†é€è§†(perspective)ä¿¡æ¯çš„ã€‚</p></li><li><p>Intrinsicå¯ä½¿ç›¸æœºåæ ‡ç³»è½¬åŒ–ä¸ºå›¾ç‰‡åæ ‡ç³»ã€‚</p></li></ul><h2 id="extrinsic">Extrinsic</h2><ul><li><p>Extrinsic å¯ä»¥çœ‹ä½œæ˜¯ä¸¤ä¸ªçŸ©é˜µå†™åœ¨äº†ä¸€èµ·ï¼šæ—‹è½¬çŸ©é˜µRå’Œå¹³ç§»çŸ©é˜µTã€‚å‰ä¸‰åˆ—æ˜¯Rï¼Œæœ€åä¸€åˆ—æ˜¯Tã€‚ å…¶å®ï¼Œè™½ç„¶ç»å¸¸å†™ä½œ<span class="math inline">\([R|T]\)</span>ï¼Œä½†äº‹å®ä¸Šè¿˜æœ‰ä¸€ä¸ªç›¸ä¼¼å˜æ¢Sï¼Œè¿™ä¸ªSæ˜¯ä¸ªå¯¹è§’çº¿çŸ©é˜µï¼Œå¯¹è§’çº¿ä¸Šçš„å€¼ä¸º<span class="math inline">\([S_x, S_y, S_z, 1]\)</span>ã€‚Sç›´æ¥å’ŒRä¹˜åœ¨ä¸€èµ·ï¼Œä¸Tæ— å…³ã€‚</p><p><img src="/2022/11/04/camera-calibration/image-20221026162455644-1667622796442-5.png" alt="image-20221026162455644" style="zoom:50%;"></p></li><li><p>Extrinsicå¯ä½¿ä¸–ç•Œåæ ‡ç³»è½¬åŒ–ä¸ºç›¸æœºåæ ‡ç³»ã€‚</p></li></ul><h2 id="skewness-and-distortion">Skewness and Distortion</h2><ul><li><p>SkewnessæŒ‡çš„æ˜¯ç›¸æœºSensorçš„ä¸¤ä¸ªè½´ä¸å‚ç›´ï¼Œå³xyä¹‹é—´æœ‰ä¸€ä¸ªå°å¤¹è§’ã€‚é€šå¸¸è¿™ä¸ä¼šå‘ç”Ÿï¼Œä½†å¦‚æœæœ‰åˆ¶é€ æ–¹é¢çš„é—®é¢˜ï¼Œè¿™ä¹Ÿæ˜¯å¯èƒ½çš„ã€‚</p></li><li><p>ç›¸æœºçš„Skewness</p></li><li><p>Skewnessçš„è§£å†³æ–¹æ³•æ˜¯æŠŠè¿™ä¸ªå¤¹è§’æ‰¾åˆ°ï¼Œå¹¶åœ¨Intrinsicä¸­åæ˜ å‡ºæ¥ã€‚</p><figure><img src="/2022/11/04/camera-calibration/image-20221026154924465-1667622796442-6.png" alt="image-20221026154924465"><figcaption aria-hidden="true">image-20221026154924465</figcaption></figure></li><li><p>DistortionåŒ…å«ï¼š</p><ul><li><em>Radial Distortion</em> (å¾„å‘ç•¸å˜)ï¼š</li><li><em>Tangential distortion</em> (åˆ‡å‘ç•¸å˜)ï¼šæœ¬è´¨ä¸Šæ˜¯ç›¸å¹³é¢å’Œç›¸æœºåæ ‡ç³»å­˜åœ¨ä¸€ä¸ªå¤¹è§’ï¼Œå³â€œå›¾åƒSensorå’Œé•œå¤´æˆªé¢ä¸å¹³è¡Œâ€ã€‚</li></ul></li><li><p>å…³äºDistortionçš„è®¡ç®—ï¼š</p><figure><img src="/2022/11/04/camera-calibration/image-20221026163826434-1667622796442-7.png" alt="image-20221026163826434"><figcaption aria-hidden="true">image-20221026163826434</figcaption></figure></li></ul><h2 id="homogeneous-coordinates">Homogeneous Coordinates</h2><ul><li>åŒè´¨åæ ‡çš„ä¸»è¦ç”¨æ„æ˜¯æŠŠæœ¬æ¥åœ¨åˆ†æ¯ä¸Šçš„zï¼ˆæ·±åº¦ï¼‰ç»™æŒªèµ°ï¼Œä»¥ä¾¿è®©æŠ•å½±è¿™ä¸ªTransformationä»non-linearå˜æˆLinearã€‚</li><li>æ³¨æ„åŒè´¨åæ ‡è™½ç„¶åœ¨è§†è§‰æ•ˆæœä¸Šæ˜¯åœ¨åŸæœ¬çš„åæ ‡(u,v)æˆ–(x,y,z)ä¸‹é¢åŠ äº†ä¸€ä¸ª1ï¼Œä½†æ˜¯å®é™…ä¸Šè¿™ä¸ª1åœ¨æ¬§å¼åæ ‡ç³»ä¸­å¹¶ä¸å­˜åœ¨ã€‚å½“æˆ‘ä»¬åé¢åˆ—å‡ºæ–¹ç¨‹æ ¡å‡†æ—¶ï¼Œåº”è¯¥å›åˆ°åŸæœ¬çš„æ¬§å¼åæ ‡ç³»è§£ã€‚</li></ul><h2 id="imu">IMU</h2><ul><li>IMUè¾“å‡ºä¸‰ä¸ªæ–¹å‘è§’é€Ÿåº¦å’Œä¸‰ä¸ªè½´å‘åŠ é€Ÿåº¦çš„å€¼ï¼Œä½¿ç”¨æ—¶ä¹Ÿéœ€è¦æ ¡å‡†ã€‚</li><li>å…·ä½“æ ¡å‡†æ–¹æ³•å‚è§Kalibrå’ŒDVï¼Œå› ä¸ºæˆ‘æ²¡ç”¨ä¸Šï¼Œæ‰€ä»¥ä¸å¤šå±•å¼€ã€‚</li></ul><h2 id="dvs">DVS</h2><ul><li>DVSçš„æ ¡å‡†ä¸»è¦åˆ†ä¸ºä¸¤ç§æ–¹æ³•ï¼š<ul><li>ä¸€ç§æ˜¯ç›´æ¥ç”¨pairedçš„RGBè¿›è¡Œæ ¡å‡†ï¼Œæ¯•ç«Ÿè¿™é‡Œçš„RGBå’ŒDVS shareåŒä¸€ç»„é€é•œã€‚</li><li>å¦‚æœæ²¡æœ‰è¿™ä¸ªRGBï¼Œå°±ç›´æ¥ç”¨accumulateçš„frameåšæ ¡å‡†ã€‚</li></ul></li></ul><h2 id="methods">Methods</h2><h3 id="è§£æ–¹ç¨‹ç›´æ¥æ ¡å‡†pçŸ©é˜µ">è§£æ–¹ç¨‹ç›´æ¥æ ¡å‡†PçŸ©é˜µ</h3><ul><li><p>åœ¨Paper <em>DHP19: Dynamic Vision Sensor 3D Human Pose Dataset</em>é‡Œï¼Œ ä»–ä»¬é‡‡ç”¨çš„æ–¹æ³•æ˜¯ï¼šç›´æ¥åœ¨ç»è¿‡Mocapæ ¡å‡†çš„ç©ºé—´ä¸­æ”¾ç½®ä¸€ç³»åˆ—Markersï¼Œç„¶ååœ¨DVSçš„RGBï¼ˆAPSï¼‰è¾“å‡ºframeä¸­ç›´æ¥è¿›è¡Œæ‰‹åŠ¨æ ‡æ³¨ï¼Œå¾—åˆ°å…¶åœ¨image planeä¸­çš„<span class="math inline">\((u, v)\)</span>åæ ‡ï¼Œ ç„¶åè§£æ–¹ç¨‹ã€‚</p><p><img src="/2022/11/04/camera-calibration/image-20221021155115039-1667622796442-8.png" alt="image-20221021155115039" style="zoom:40%;"></p></li><li><p>ä¸Šå›¾ä¸­æåˆ°äº†ä¸€ä¸ªç‚¹ï¼šä»æŠ•å½±çŸ©é˜µè®¡ç®—ç›¸æœºåæ ‡ç³»çš„åŸç‚¹ï¼Œå³ç›¸æœºçš„ç„¦ç‚¹ä½ç½®çš„æ–¹æ³•ï¼š<span class="math inline">\(C=Q^{-1}c_4\)</span>ã€‚å…·ä½“çš„æ¨ç†å…¶å®å¾ˆç®€å•ï¼Œä¸»è¦å°±é ä¸€ä¸ªæ¡ä»¶å…¬å¼ï¼š<span class="math inline">\(PC=0\)</span>ï¼Œå³åŸç‚¹çš„æŠ•å½±æ˜¯0ã€‚</p></li><li><p>ç»†èŠ‚ä¸Šï¼Œä»–ä»¬ç”¨äº†38ä¸ªMarkerï¼Œå¹¶8æ¬¡æ”¹å˜å®ƒä»¬çš„ä½ç½®ï¼Œé€šè¿‡æœ€å°å¹³æ–¹æ³•è§£å¾—æœ€æ¥è¿‘çš„11ä¸ªPä¸­å‚æ•°å€¼ã€‚è¿™é‡Œçš„æœ€å°å¹³æ–¹æ³•çš„æ„ä¹‰åœ¨äºé€šè¿‡å¢åŠ æ•°æ®ç‚¹å–å¹³å‡På€¼æ¥å‡å°è¯¯å·®ã€‚å…¶å®11ç»„å¼å­å°±å¤Ÿäº†ï¼Œä½†è¿™é‡Œè¿˜æ˜¯ç”¨äº†<span class="math inline">\(8\times38\times2\)</span>ä¸ªå…¬å¼ï¼Œå°±åœ¨äºæ­¤ã€‚</p></li><li><p>å…·ä½“çš„æœ€å°å¹³æ–¹æ³•ä»‹ç»åŠä»£ç ï¼š<a href="https://pythonnumericalmethods.berkeley.edu/notebooks/chapter16.04-Least-Squares-Regression-in-Python.html">Link</a></p></li><li><p>è¿™ä¸ªå…¨çŸ©é˜µPå…¶å®åŒ…å«äº†Camera Intrinsic <em>K</em>ï¼Œ Camera Extrinsic <em>RT</em>, ä»¥åŠCamera Skewnessã€‚</p></li><li><p>ç†è®ºï¼š</p><figure><img src="/2022/11/04/camera-calibration/image-20221026175034098-1667622796442-9.png" alt="image-20221026175034098"><figcaption aria-hidden="true">image-20221026175034098</figcaption></figure><p><img src="/2022/11/04/camera-calibration/image-20221026175051047-1667622796442-10.png" alt="image-20221026175051047" style="zoom:50%;"></p></li><li><p>ä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Least Square Calibration for Camera Projection Matrix using Numpy</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">svd_calibration</span>(<span class="params">points_3d, points_2d</span>):</span></span><br><span class="line">    <span class="comment"># points_3d: 3D points in world coordinate</span></span><br><span class="line">    <span class="comment"># points_2d: 2D points in image coordinate</span></span><br><span class="line">    <span class="comment"># return: projection matrix</span></span><br><span class="line">    <span class="keyword">assert</span> points_3d.shape[<span class="number">0</span>] == points_2d.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">assert</span> points_3d.shape[<span class="number">1</span>] == <span class="number">3</span></span><br><span class="line">    <span class="keyword">assert</span> points_2d.shape[<span class="number">1</span>] == <span class="number">2</span></span><br><span class="line">    num_points = points_3d.shape[<span class="number">0</span>]</span><br><span class="line">    A = np.zeros((<span class="number">2</span> * num_points, <span class="number">12</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_points):</span><br><span class="line">        A[<span class="number">2</span> * i, <span class="number">0</span>:<span class="number">4</span>] = *(points_3d[i, :]), <span class="number">1</span></span><br><span class="line">        A[<span class="number">2</span> * i, <span class="number">8</span>:<span class="number">12</span>] = *(-points_2d[i, <span class="number">0</span>] * points_3d[i, :]), -points_2d[i, <span class="number">0</span>]</span><br><span class="line">        A[<span class="number">2</span> * i + <span class="number">1</span>, <span class="number">4</span>:<span class="number">8</span>] = *(points_3d[i, :]), <span class="number">1</span></span><br><span class="line">        A[<span class="number">2</span> * i + <span class="number">1</span>, <span class="number">8</span>:<span class="number">12</span>] = *(-points_2d[i, <span class="number">1</span>] * points_3d[i, :]), -points_2d[i, <span class="number">0</span>]</span><br><span class="line">    U, S, V = np.linalg.svd(A)</span><br><span class="line">    P = V[:ï¼Œ-<span class="number">1</span>].reshape((<span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line">    <span class="keyword">return</span> P</span><br><span class="line"></span><br><span class="line"><span class="comment"># OR</span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># Least Square Calibration for Camera Projection Matrix</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">least_square_calibrate_camera_projection_matrix_np</span>(<span class="params">x,y,z,u,v</span>):</span></span><br><span class="line">    <span class="comment"># x,y,z: 3D points in world coordinate</span></span><br><span class="line">    <span class="comment"># u,v: 2D points in image coordinate</span></span><br><span class="line">    <span class="comment"># return: projection matrix</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(x) == <span class="built_in">len</span>(y) == <span class="built_in">len</span>(z) == <span class="built_in">len</span>(u) == <span class="built_in">len</span>(v)</span><br><span class="line">    num_points = <span class="built_in">len</span>(x)</span><br><span class="line">    A = np.zeros((<span class="number">2</span> * num_points, <span class="number">12</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_points):</span><br><span class="line">        A[<span class="number">2</span> * i, <span class="number">0</span>:<span class="number">4</span>] = x[i], y[i], z[i], <span class="number">1</span></span><br><span class="line">        A[<span class="number">2</span> * i, <span class="number">8</span>:<span class="number">12</span>] = -u[i] * x[i], -u[i] * y[i], -u[i] * z[i], -u[i]</span><br><span class="line">        A[<span class="number">2</span> * i + <span class="number">1</span>, <span class="number">4</span>:<span class="number">8</span>] = x[i], y[i], z[i], <span class="number">1</span></span><br><span class="line">        A[<span class="number">2</span> * i + <span class="number">1</span>, <span class="number">8</span>:<span class="number">12</span>] = -v[i] * x[i], -v[i] * y[i], -v[i] * z[i], -v[i]</span><br><span class="line">    U, S, V = np.linalg.svd(A)</span><br><span class="line">    P = V[:ï¼Œ-<span class="number">1</span>].reshape((<span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line">    <span class="keyword">return</span> P</span><br></pre></td></tr></table></figure></li><li><p>æ³¨æ„ï¼šSVDè¿™é‡Œæ˜¯ç”¨äºè§£å†³Least Squares Problemçš„ï¼Œå¦‚æœç›´æ¥ç”¨<code>np.linalg.lstsq</code>å‡½æ•°çš„è¯ï¼ˆbå–å…¨0ï¼‰ï¼Œä¼šè§£å¾—ä¸€ä¸ªå…¨0çŸ©é˜µï¼ˆå› ä¸º0æ°¸è¿œæ˜¯ä¸€ä¸ªè§£ï¼‰ã€‚</p></li><li><p>SVDçš„è§£æ³•ç»†èŠ‚ï¼š</p><figure><img src="/2022/11/04/camera-calibration/image-20221027230723755-1667622796442-11.png" alt="image-20221027230723755"><figcaption aria-hidden="true">image-20221027230723755</figcaption></figure></li><li><p>è§£SVDçš„æ—¶å€™å¯ä»¥é€‰æ‹©æŠŠPçŸ©é˜µå³ä¸‹è§’<span class="math inline">\(P_{(3,4)}\)</span>è®¾ä¸º1ã€‚ä¸è®¾æ˜¯homogeneousè§£æ³•ï¼Œè®¾äº†ä¹‹åæ˜¯inhomogeneousã€‚</p></li></ul><h3 id="kalibr">kalibr</h3><ul><li><p><a href="https://github.com/ethz-asl/kalibr">Link</a></p></li><li><p>Used for:</p><ol type="1"><li><strong>Multi-Camera Calibration</strong>: Intrinsic and extrinsic calibration of a camera-systems with non-globally shared overlapping fields of view</li><li><strong>Visual-Inertial Calibration (CAM-IMU)</strong>: Spatial and temporal calibration of an IMU w.r.t a camera-system along with IMU intrinsic parameters</li><li><strong>Multi-Inertial Calibration (IMU-IMU)</strong>: Spatial and temporal calibration of an IMU w.r.t a base inertial sensor along with IMU intrinsic parameters (requires 1-aiding camera sensor).</li><li><strong>Rolling Shutter Camera Calibration</strong>: Full intrinsic calibration (projection, distortion and shutter parameters) of rolling shutter cameras.</li></ol></li><li><p>ç®€å•è¯´å°±æ˜¯ä¸»æ”»å¤šç›¸æœº/IMUç³»ç»Ÿã€‚<a href="https://github.com/ethz-asl/kalibr/wiki/multiple-camera-calibration">å¤šä¸ªç›¸æœº</a>ï¼Œ<a href="https://github.com/ethz-asl/kalibr/wiki/Multi-IMU-and-IMU-intrinsic-calibration">å¤šä¸ªIMU</a>ï¼Œ<a href="https://github.com/ethz-asl/kalibr/wiki/camera-imu-calibration">ç›¸æœº+IMU</a>ç­‰ã€‚</p></li><li><p>æ ¡å‡†å‡ºæ¥çš„Extrinsicç»“æœå¹¶ä¸æ˜¯ç›¸å¯¹åŸç‚¹ç»å¯¹çš„ï¼Œè€Œæ˜¯å¤šä¸ªè®¾å¤‡é—´ç›¸å¯¹çš„ã€‚æ¯”å¦‚IMU+Camæ ¡å‡†å‡ºæ¥çš„Extrinsicå°±æ˜¯IMUç›¸å¯¹äºCamåæ ‡çš„å˜æ¢ã€‚</p><p>å¼•ç”¨ä¸€æ®µ<a href="https://github.com/ethz-asl/kalibr/wiki/yaml-formats">åŸè¯</a>ï¼š</p><blockquote><ul><li><strong>T_cn_cnm1</strong> camera extrinsic transformation, always with respect to the last camera in the chain (e.g. cam1: T_cn_cnm1 = T_c1_c0, takes cam0 to cam1 coordinates)</li><li><strong>T_cam_imu</strong> IMU extrinsics: transformation from IMU to camera coordinates (T_c_i)</li><li><strong>timeshift_cam_imu</strong> timeshift between camera and IMU timestamps in seconds (t_imu = t_cam + shift)</li></ul></blockquote></li><li><p>ç»¼ä¸Šæ‰€è¿°ï¼ŒKalibrå¹¶ä¸æ˜¯æ»¡è¶³æˆ‘ä»¬éœ€æ±‚çš„æ ¡å‡†æ–¹æ¡ˆã€‚</p></li></ul><h3 id="dv-calibration">DV Calibration</h3><ul><li><a href="https://inivation.gitlab.io/dv/dv-docs/docs/tutorial-calibration/">Tutorial Link</a>, <a href="https://gitlab.com/inivation/dv/dv-imu-cam-calibration">Code Link</a></li><li>å•ä¸ªå¤šä¸ªDVSéƒ½å¯ä»¥ã€‚</li><li>åŸºäºKalibrçš„æ–¹æ¡ˆã€‚</li><li>å¯¹äºå•ä¸ªDVSï¼Œæ ¡å‡†ä¸»è¦è¿›è¡Œçš„æ˜¯undistortionï¼Œä¸”å¯ä»¥åœ¨æ ¡å‡†åç›´æ¥åº”ç”¨äºç›¸æœºåç»­çš„å›¾åƒï¼Œè®©åé¢çš„recordéƒ½ä¸å†æœ‰å¤±çœŸã€‚</li><li>è¿™é‡Œçš„æ ¡å‡†å¯ä»¥æœ‰æ•ˆåº”å¯¹ä¹‹å‰Upalæ•™æˆæå‡ºçš„æ‰­æ›²é—®é¢˜ï¼Œåº”åœ¨åç»­æ“ä½œä¸­åº”ç”¨ã€‚</li></ul><h3 id="opencv-camera-calibration">OpenCV Camera Calibration</h3><ul><li><p>è¿™ä¸ªæ ¡å‡†ä¼šä½¿ç”¨chessboardï¼Œè€Œå…³äº3dåæ ‡ï¼Œä»–ä»¬ç”¨äº†æ£‹ç›˜ä¸Šä¸¤ä¸ªç›¸é‚»çš„ç‚¹çš„å®é™…è·ç¦»æ˜¯å·²çŸ¥çš„è¿™ä¸ªç‰¹æ€§ï¼ˆå› ä¸ºæ‰“å°çš„æ ‡å‡†æ£‹ç›˜ï¼Œé—´è·æ˜¯å›ºå®šçš„ï¼Œå¦‚30mmï¼‰ï¼Œæ¥æä¾›ç›¸åº”çš„3Dåæ ‡ä¿¡æ¯ã€‚</p></li><li><p>è¿™ä¸ªæ ¡å‡†ä¼šåˆ†åˆ«è¾“å‡ºIntrinsic matrix (mtx), rotation matrix (R, rvecs), translation matrix (T, tvecs), Distortion coefficients (dist)ã€‚è¿™äº›è¾“å‡ºå¯ä»¥ç›´æ¥è¢«ç”¨æ¥çº åã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># generate camera matrixes</span></span><br><span class="line">ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objpoints, imgpoints, gray.shape[::-<span class="number">1</span>], <span class="literal">None</span>, <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">img = cv.imread(<span class="string">&#x27;left12.jpg&#x27;</span>)</span><br><span class="line">h,  w = img.shape[:<span class="number">2</span>]</span><br><span class="line">newcameramtx, roi = cv.getOptimalNewCameraMatrix(mtx, dist, (w,h), <span class="number">1</span>, (w,h))</span><br><span class="line"></span><br><span class="line"><span class="comment"># undistort</span></span><br><span class="line">dst = cv.undistort(img, mtx, dist, <span class="literal">None</span>, newcameramtx)</span><br><span class="line"><span class="comment"># crop the image</span></span><br><span class="line">x, y, w, h = roi</span><br><span class="line">dst = dst[y:y+h, x:x+w]</span><br><span class="line">cv.imwrite(<span class="string">&#x27;calibresult.png&#x27;</span>, dst)</span><br></pre></td></tr></table></figure></li><li><p>å…³äºOpenCVæ ¡å‡†å‡ºæ¥çš„Extrinsic Matrixï¼Œç”±äºä¸–ç•Œåæ ‡ç³»å¿…å®šæœ‰ä¸€ä¸ªåŸç‚¹ï¼Œæ‰€ä»¥å®ƒä»¬ä¹Ÿæ˜¯æ¯«æ— ç–‘é—®æœ‰ä¸€ä¸ªåŸç‚¹çš„ã€‚ä½†è¿™ä¸ªä¸–ç•Œåæ ‡ç³»åŸç‚¹å®é™…ä¸Šåªæœ‰å‚è€ƒæ„ä¹‰ï¼ˆç¬¬ä¸€å¼ æ ¡å‡†å›¾çš„å·¦ä¸Šè§’æ£‹ç›˜ç‚¹ï¼‰ï¼Œå¹¶æ— æ³•ç›´æ¥ä½¿ç”¨ã€‚åŒæ—¶ï¼Œç›¸æœºåæ ‡ç³»çš„åŸç‚¹æ˜¯ç›¸æœºçš„ç„¦ç‚¹ï¼Œè€Œè¿™ä¸ªç„¦ç‚¹ä¹Ÿæ˜¯å‡ ä¹ä¸å¯é¢„çŸ¥å’Œæµ‹é‡ä½ç½®çš„ï¼ˆå®ƒå¯èƒ½åœ¨ç›¸æœºå†…éƒ¨æˆ–å¤–éƒ¨ï¼Œä½†æ ¡å‡†å¹¶ä¸ä¼šå‘Šè¯‰ä½ è¿™ä¸ªç‚¹ä½ç½®ï¼Œæ‰€ä»¥ä½ ä¹Ÿæ— æ³•é€šè¿‡ç›´æ¥æµ‹é‡ç›¸æœºOç‚¹å’Œå®é™…ä¸–ç•ŒOç‚¹ä¹‹é—´çš„ç›¸å¯¹ä½ç½®æ¥çº æ­£Extrinsicã€‚ï¼‰</p><blockquote><p><a href="https://www.appsloveworld.com/opencv/100/91/opencv-camera-calibration-world-coordinate-system-origin">Link</a>: I believe it used to be the position of the top-left corner of the checkerboard in the first calibration image, but it may have changed. You can visualized it by writing a few lines of code that project point (0,0,0) (in calibrated scene coordinates) in all the calibration images, then plotting its projected image coordinates on top of the image themselves.</p><p>You should really not depend on it being anything meaningful, and instead locate a separate feature in 3D and roto-translate the reference frame to it after calibration.</p></blockquote></li><li><p>å®é™…ä¸Šï¼Œä¸è¦æƒ³é€šè¿‡OpenCVçš„æ ¡å‡†æ¥ç›´æ¥å¾—åˆ°æœ‰å®é™…æ„ä¹‰çš„Extrinsicï¼Œè‹¥æƒ³å¾—åˆ°ï¼Œè¯·è‡ªè¡Œç”¨å‰é¢æåˆ°çš„Method 1æ¥å®é™…labelä¸€äº›å·²çŸ¥3Dåæ ‡çš„Markerså¯¹åº”çš„2Dç‚¹ï¼Œç”¨Least Squaresè§£å¾—ã€‚</p></li><li><p>ä½†æ˜¯ï¼ŒOpenCVçš„æ ¡å‡†å¯ä»¥æä¾›æœ‰æ•ˆçš„Distortion Coefficientå’ŒIntrinsicï¼Œå¹¶å¯ç›´æ¥è¢«ç”¨äºç•¸å˜è¡¥å¿ã€‚</p></li></ul><h2 id="reference">Reference</h2><h3 id="blogswebsites">Blogs/Websites</h3><ul><li><a href="****https://pythonnumericalmethods.berkeley.edu/notebooks/chapter16.04-Least-Squares-Regression-in-Python.html****">Least Squares Regression in Python</a></li><li><a href="https://math.stackexchange.com/questions/974193/why-does-svd-provide-the-least-squares-and-least-norm-solution-to-a-x-b">Why does SVD provide the least squares and least norm solution to ğ´ğ‘¥=ğ‘?</a></li><li><a href="https://math.stackexchange.com/questions/772039/how-does-the-svd-solve-the-least-squares-problem">How does the SVD solve the least squares problem?</a></li><li><a href="https://www.quora.com/What-is-the-real-world-coordinate-system-camera-calibration-refer-to-in-computer-vision">What is the "real world coordinate system" camera calibration refer to in computer vision?</a></li><li><a href="https://numpy.org/doc/stable/reference/generated/numpy.linalg.svd.html">numpy linalg svd</a></li><li><a href="https://docs.opencv.org/4.x/dc/dbb/tutorial_py_calibration.html">OpenCV Camera Calibration</a></li></ul><h3 id="slides">Slides</h3><ul><li><a href="https://s3.amazonaws.com/content.udacity-data.com/courses/ud810/slides/Unit-3/3C-L3.pdf#fromHistory">Udacity CS4495/6495 Introduction to Computer Vision 3C-L3 Calibrating cameras</a></li><li><a href="https://www.cs.cmu.edu/~16385/s17/Slides/11.1_Camera_matrix.pdf">CMU - Camera Matrix</a></li><li><a href="https://cvgl.stanford.edu/teaching/cs231a_winter1314/lectures/lecture2_camera_models.pdf">Stanford - Lecture 2</a></li><li><a href="https://cvgl.stanford.edu/teaching/cs231a_winter1314/lectures/lecture3_camera_calibration.pdf">Stanford - Lecture 3</a></li></ul><h3 id="papers">Papers</h3><ul><li><a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr98-71.pdf">A Flexible New Technique for Camera Calibration</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ç›¸æœºæ ¡å‡†&quot;&gt;ç›¸æœºæ ¡å‡†&lt;/h1&gt;
&lt;p&gt;é¦–å…ˆæ˜¯å‡ å¼ éå¸¸é‡è¦çš„Slidesï¼Œåé¢éƒ½ä¼šreferåˆ°ï¼Œå¯ä»¥å…ˆè‡ªè¡Œç†Ÿæ‚‰ä¸‹ã€‚å¦å¤–ï¼Œæœ¬ç¯‡ä¸æ˜¯100%ä»é›¶å¼€å§‹çš„æ•™ç¨‹ï¼Œç¯‡å¹…é™åˆ¶å¹¶æ— æ³•å±•å¼€æ‰€æœ‰çš„ç»†èŠ‚ï¼Œè‹¥æƒ³æ·±åº¦ç†è§£ï¼Œè¯·è‡ªè¡Œç»“åˆå‡ ä¸ªå¤§å­¦ï¼ˆCMUï¼ŒStanfordï¼‰ç›¸åº”çš„Slidesä¸€èµ·å­¦</summary>
      
    
    
    
    
    <category term="python" scheme="https://www.miracleyoo.com/tags/python/"/>
    
    <category term="CV" scheme="https://www.miracleyoo.com/tags/CV/"/>
    
    <category term="camera calibration" scheme="https://www.miracleyoo.com/tags/camera-calibration/"/>
    
    <category term="camera matrix" scheme="https://www.miracleyoo.com/tags/camera-matrix/"/>
    
  </entry>
  
  <entry>
    <title>pytorch-lightning</title>
    <link href="https://www.miracleyoo.com/2021/03/11/pytorch-lightning/"/>
    <id>https://www.miracleyoo.com/2021/03/11/pytorch-lightning/</id>
    <published>2021-03-12T01:09:57.000Z</published>
    <updated>2021-03-12T01:09:57.185Z</updated>
    
    <content type="html"><![CDATA[<h1 id="pytorch-lighting"><a class="markdownIt-Anchor" href="#pytorch-lighting"></a> Pytorch-Lighting</h1><h2 id="å†™åœ¨å‰é¢"><a class="markdownIt-Anchor" href="#å†™åœ¨å‰é¢"></a> å†™åœ¨å‰é¢</h2><p>Pytorch-Lightningè¿™ä¸ªåº“æˆ‘â€œå‘ç°â€è¿‡ä¸¤æ¬¡ã€‚ç¬¬ä¸€æ¬¡å‘ç°æ—¶ï¼Œæ„Ÿè§‰å®ƒå¾ˆé‡å¾ˆéš¾å­¦ï¼Œè€Œä¸”ä¼¼ä¹è‡ªå·±ä¹Ÿç”¨ä¸ä¸Šã€‚ä½†æ˜¯åé¢éšç€åšçš„é¡¹ç›®å¼€å§‹å‡ºç°äº†ä¸€äº›ç¨å¾®é«˜é˜¶çš„è¦æ±‚ï¼Œæˆ‘å‘ç°æˆ‘æ€»æ˜¯ä¸æ–­åœ°åœ¨ç›¸ä¼¼å·¥ç¨‹ä»£ç ä¸ŠèŠ±è´¹å¤§é‡æ—¶é—´ï¼ŒDebugä¹Ÿæ˜¯è¿™äº›ä»£ç èŠ±çš„æ—¶é—´æœ€å¤šï¼Œè€Œä¸”æ¸æ¸äº§ç”Ÿäº†ä¸€ä¸ªçŸ›ç›¾ä¹‹å¤„ï¼šå¦‚æœæƒ³è¦æ›´å¤šæ›´å¥½çš„åŠŸèƒ½ï¼Œå¦‚TensorBoardæ”¯æŒï¼ŒEarly Stopï¼ŒLR Schedulerï¼Œåˆ†å¸ƒå¼è®­ç»ƒï¼Œå¿«é€Ÿæµ‹è¯•ç­‰ï¼Œä»£ç å°±æ— å¯é¿å…åœ°å˜å¾—è¶Šæ¥è¶Šé•¿ï¼Œçœ‹èµ·æ¥ä¹Ÿè¶Šæ¥è¶Šä¹±ï¼ŒåŒæ—¶æ ¸å¿ƒçš„è®­ç»ƒé€»è¾‘ä¹Ÿæ¸æ¸è¢«è¿™äº›å·¥ç¨‹ä»£ç ç›–è¿‡ã€‚é‚£ä¹ˆæœ‰æ²¡æœ‰æ›´å¥½çš„è§£å†³æ–¹æ¡ˆï¼Œç”šè‡³èƒ½ä¸€é”®è§£å†³æ‰€æœ‰è¿™äº›é—®é¢˜å‘¢ï¼Ÿ</p><p>äºæ˜¯æˆ‘ç¬¬äºŒæ¬¡å‘ç°äº†Pytorch-Lightningã€‚</p><p>çœŸé¦™ã€‚</p><p>ä½†æ˜¯é—®é¢˜è¿˜æ˜¯æ¥äº†ã€‚è¿™ä¸ªæ¡†æ¶å¹¶æ²¡æœ‰å› ä¸ºé¦™è€Œå˜å¾—æ›´åŠ æ˜“å­¦ã€‚å®˜ç½‘çš„æ•™ç¨‹å¾ˆä¸°å¯Œï¼Œå¯ä»¥çœ‹å‡ºæ¥å¼€å‘è€…ä»¬åœ¨åŠªåŠ›åšäº†ã€‚ä½†æ˜¯å¾ˆå¤šç›¸è¿çš„çŸ¥è¯†ç‚¹éƒ½è¢«åˆ†å¸ƒåœ¨äº†ä¸åŒçš„ç‰ˆå—é‡Œï¼Œè¿˜æœ‰ä¸€äº›æ ¸å¿ƒçš„ç†è§£è¦ç‚¹å¹¶æ²¡æœ‰è¢«å¼ºè°ƒå‡ºæ¥ï¼Œè€Œæ˜¯å°å­—å¸¦è¿‡ï¼Œè¿™è®©æˆ‘æƒ³åšä¸€ä¸ªæ™®æƒ çš„æ•™ç¨‹ï¼ŒåŒ…å«æ‰€æœ‰æˆ‘åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­è®¤ä¸ºé‡è¦çš„æ¦‚å¿µï¼Œå¥½ç”¨çš„å‚æ•°ï¼Œä¸€äº›æ³¨æ„ç‚¹ã€å‘ç‚¹ï¼Œå¤§é‡çš„ç¤ºä¾‹ä»£ç æ®µå’Œä¸€äº›æ ¸å¿ƒé—®é¢˜çš„é›†ä¸­è®²è§£ã€‚</p><p>æœ€åï¼Œç¬¬ä¸‰éƒ¨åˆ†æä¾›äº†ä¸€ä¸ªæˆ‘æ€»ç»“å‡ºæ¥çš„æ˜“ç”¨äºå¤§å‹é¡¹ç›®ã€å®¹æ˜“è¿ç§»ã€æ˜“äºå¤ç”¨çš„æ¨¡æ¿ï¼Œæœ‰å…´è¶£çš„å¯ä»¥å»<a href="https://github.com/miracleyoo/pytorch-lightning-template">GitHub</a>è¯•ç”¨ã€‚</p><h2 id="crucial"><a class="markdownIt-Anchor" href="#crucial"></a> Crucial</h2><ul><li><p>Pytorch-Lighting çš„ä¸€å¤§ç‰¹ç‚¹æ˜¯æŠŠæ¨¡å‹å’Œç³»ç»Ÿåˆ†å¼€æ¥çœ‹ã€‚æ¨¡å‹æ˜¯åƒResnet18ï¼Œ RNNä¹‹ç±»çš„çº¯æ¨¡å‹ï¼Œ è€Œç³»ç»Ÿå®šä¹‰äº†ä¸€ç»„æ¨¡å‹å¦‚ä½•ç›¸äº’äº¤äº’ï¼Œå¦‚GANï¼ˆç”Ÿæˆå™¨ç½‘ç»œä¸åˆ¤åˆ«å™¨ç½‘ç»œï¼‰ã€Seq2Seqï¼ˆEncoderä¸Decoderç½‘ç»œï¼‰å’ŒBertã€‚åŒæ—¶ï¼Œæœ‰æ—¶å€™é—®é¢˜åªæ¶‰åŠä¸€ä¸ªæ¨¡å‹ï¼Œé‚£ä¹ˆè¿™ä¸ªç³»ç»Ÿåˆ™å¯ä»¥æ˜¯ä¸€ä¸ªé€šç”¨çš„ç³»ç»Ÿï¼Œç”¨äºæè¿°æ¨¡å‹å¦‚ä½•ä½¿ç”¨ï¼Œå¹¶å¯ä»¥è¢«å¤ç”¨åˆ°å¾ˆå¤šå…¶ä»–é¡¹ç›®ã€‚</p></li><li><p>Pytorch-Lighting çš„æ ¸å¿ƒè®¾è®¡æ€æƒ³æ˜¯â€œè‡ªç»™è‡ªè¶³â€ã€‚æ¯ä¸ªç½‘ç»œä¹ŸåŒæ—¶åŒ…å«äº†å¦‚ä½•è®­ç»ƒã€å¦‚ä½•æµ‹è¯•ã€ä¼˜åŒ–å™¨å®šä¹‰ç­‰å†…å®¹ã€‚</p></li></ul><p><img src="/2021/03/11/pytorch-lightning/plres.png" alt="img"></p><h2 id="æ¨èä½¿ç”¨æ–¹æ³•"><a class="markdownIt-Anchor" href="#æ¨èä½¿ç”¨æ–¹æ³•"></a> æ¨èä½¿ç”¨æ–¹æ³•</h2><p>è¿™ä¸€éƒ¨åˆ†æ”¾åœ¨æœ€å‰é¢ï¼Œå› ä¸ºå…¨æ–‡å†…å®¹å¤ªé•¿ï¼Œå¦‚æœæ”¾åé¢å®¹æ˜“å¿½ç•¥æ‰è¿™éƒ¨åˆ†ç²¾åã€‚</p><p>Pytorch-Lightning æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„åº“ï¼Œæˆ–è€…è¯´æ˜¯pytorchçš„æŠ½è±¡å’ŒåŒ…è£…ã€‚å®ƒçš„å¥½å¤„æ˜¯å¯å¤ç”¨æ€§å¼ºï¼Œæ˜“ç»´æŠ¤ï¼Œé€»è¾‘æ¸…æ™°ç­‰ã€‚ç¼ºç‚¹ä¹Ÿå¾ˆæ˜æ˜¾ï¼Œè¿™ä¸ªåŒ…éœ€è¦å­¦ä¹ å’Œç†è§£çš„å†…å®¹è¿˜æ˜¯æŒºå¤šçš„ï¼Œæˆ–è€…æ¢å¥è¯è¯´ï¼Œå¾ˆé‡ã€‚å¦‚æœç›´æ¥æŒ‰ç…§å®˜æ–¹çš„æ¨¡æ¿å†™ä»£ç ï¼Œå°å‹projectè¿˜å¥½ï¼Œå¦‚æœæ˜¯å¤§å‹é¡¹ç›®ï¼Œæœ‰å¤æ•°ä¸ªéœ€è¦è°ƒè¯•éªŒè¯çš„æ¨¡å‹å’Œæ•°æ®é›†ï¼Œé‚£å°±ä¸å¤ªå¥½åŠï¼Œç”šè‡³æ›´åŠ éº»çƒ¦äº†ã€‚ç»è¿‡å‡ å¤©çš„æ‘¸ç´¢å’Œè°ƒè¯•ï¼Œæˆ‘æ€»ç»“å‡ºäº†ä¸‹é¢è¿™æ ·ä¸€å¥—å¥½ç”¨çš„æ¨¡æ¿ï¼Œä¹Ÿå¯ä»¥è¯´æ˜¯å¯¹Pytorch-Lightningçš„è¿›ä¸€æ­¥æŠ½è±¡ã€‚</p><p>æ¬¢è¿å¤§å®¶å°è¯•è¿™ä¸€å¥—ä»£ç é£æ ¼ï¼Œå¦‚æœç”¨ä¹ æƒ¯çš„è¯è¿˜æ˜¯ç›¸å½“æ–¹ä¾¿å¤ç”¨çš„ï¼Œä¹Ÿä¸å®¹æ˜“åŠé“é€€å‘ã€‚</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">root-</span><br><span class="line">|-data</span><br><span class="line">|-__init__.py</span><br><span class="line">|-data_interface.py</span><br><span class="line">|-xxxdataset1.py</span><br><span class="line">|-xxxdataset2.py</span><br><span class="line">|-...</span><br><span class="line">|-model</span><br><span class="line">|-__init__.py</span><br><span class="line">|-model_interface.py</span><br><span class="line">|-xxxmodel1.py</span><br><span class="line">|-xxxmodel2.py</span><br><span class="line">|-...</span><br><span class="line">|-main.py</span><br></pre></td></tr></table></figure><p>å¦‚æœå¯¹æ¯ä¸ªæ¨¡å‹ç›´æ¥ä¸Šplmoduleï¼Œå¯¹äºå·²æœ‰é¡¹ç›®ã€åˆ«äººçš„ä»£ç ç­‰çš„è½¬æ¢å°†ç›¸å½“è€—æ—¶ã€‚å¦å¤–ï¼Œè¿™æ ·çš„è¯ï¼Œä½ éœ€è¦ç»™æ¯ä¸ªæ¨¡å‹éƒ½åŠ ä¸Šä¸€äº›ç›¸ä¼¼çš„ä»£ç ï¼Œå¦‚<code>training_step</code>ï¼Œ<code>validation_step</code>ã€‚æ˜¾ç„¶ï¼Œè¿™å¹¶ä¸æ˜¯æˆ‘ä»¬æƒ³è¦çš„ï¼Œå¦‚æœçœŸçš„è¿™æ ·åšï¼Œä¸ä½†ä¸æ˜“äºç»´æŠ¤ï¼Œåè€Œå¯èƒ½ä¼šæ›´åŠ æ‚ä¹±ã€‚åŒç†ï¼Œå¦‚æœæŠŠæ¯ä¸ªæ•°æ®é›†ç±»éƒ½ç›´æ¥è½¬æ¢æˆplçš„DataModuleï¼Œä¹Ÿä¼šé¢ä¸´ç›¸ä¼¼çš„é—®é¢˜ã€‚åŸºäºè¿™æ ·çš„è€ƒé‡ï¼Œæˆ‘å»ºè®®ä½¿ç”¨ä¸Šè¿°æ¶æ„ï¼š</p><ul><li><p>ä¸»ç›®å½•ä¸‹åªæ”¾ä¸€ä¸ª<code>main.py</code>æ–‡ä»¶ã€‚</p></li><li><p><code>data</code>å’Œ<code>modle</code>ä¸¤ä¸ªæ–‡ä»¶å¤¹ä¸­æ”¾å…¥<code>__init__.py</code>æ–‡ä»¶ï¼ŒåšæˆåŒ…ã€‚è¿™æ ·æ–¹ä¾¿å¯¼å…¥ã€‚ä¸¤ä¸ª<code>init</code>æ–‡ä»¶åˆ†åˆ«æ˜¯ï¼š</p><ul><li><code>from .data_interface import DInterface</code></li><li><code>from .model_interface import MInterface</code></li></ul></li><li><p>åœ¨<code>data_interface</code>ä¸­å»ºç«‹ä¸€ä¸ª<code>class DInterface(pl.LightningDataModule):</code>ç”¨ä½œæ‰€æœ‰æ•°æ®é›†æ–‡ä»¶çš„æ¥å£ã€‚<code>__init__()</code>å‡½æ•°ä¸­importç›¸åº”Datasetç±»ï¼Œ<code>setup()</code>è¿›è¡Œå®ä¾‹åŒ–ï¼Œå¹¶è€è€å®å®åŠ å…¥æ‰€éœ€è¦çš„çš„<code>train_dataloader</code>, <code>val_dataloader</code>, <code>test_dataloader</code>å‡½æ•°ã€‚è¿™äº›å‡½æ•°å¾€å¾€éƒ½æ˜¯ç›¸ä¼¼çš„ï¼Œå¯ä»¥ç”¨å‡ ä¸ªè¾“å…¥argsæ§åˆ¶ä¸åŒçš„éƒ¨åˆ†ã€‚</p></li><li><p>åŒç†ï¼Œåœ¨<code>model_interface</code>ä¸­å»ºç«‹<code>class MInterface(pl.LightningModule):</code>ç±»ï¼Œä½œä¸ºæ¨¡å‹çš„ä¸­é—´æ¥å£ã€‚<code>__init__()</code>å‡½æ•°ä¸­importç›¸åº”æ¨¡å‹ç±»ï¼Œç„¶åè€è€å®å®åŠ å…¥<code>configure_optimizers</code>, <code>training_step</code>, <code>validation_step</code>ç­‰å‡½æ•°ï¼Œç”¨ä¸€ä¸ªæ¥å£ç±»æ§åˆ¶æ‰€æœ‰æ¨¡å‹ã€‚ä¸åŒéƒ¨åˆ†ä½¿ç”¨è¾“å…¥å‚æ•°æ§åˆ¶ã€‚</p></li><li><p><code>main.py</code>å‡½æ•°åªè´Ÿè´£ï¼š</p><ul><li>å®šä¹‰parserï¼Œæ·»åŠ parseé¡¹ã€‚</li><li>é€‰å¥½éœ€è¦çš„<code>callback</code>å‡½æ•°ä»¬ã€‚</li><li>å®ä¾‹åŒ–<code>MInterface</code>, <code>DInterface</code>, <code>Trainer</code>ã€‚</li></ul><p>å®Œäº‹ã€‚</p></li></ul><h2 id="lightning-module"><a class="markdownIt-Anchor" href="#lightning-module"></a> Lightning Module</h2><h3 id="ç®€ä»‹"><a class="markdownIt-Anchor" href="#ç®€ä»‹"></a> ç®€ä»‹</h3><p><a href="https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html">ä¸»é¡µé¢</a></p><ul><li><p>ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶ï¼š</p><ul><li>æ¨¡å‹</li><li>ä¼˜åŒ–å™¨</li><li>Train/Val/Testæ­¥éª¤</li></ul></li><li><p>æ•°æ®æµä¼ªä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">outs = []</span><br><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> data:</span><br><span class="line">    out = training_step(batch)</span><br><span class="line">    outs.append(out)</span><br><span class="line">training_epoch_end(outs)</span><br></pre></td></tr></table></figure><p>ç­‰ä»·Lightningä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">training_step</span>(<span class="params">self, batch, batch_idx</span>):</span></span><br><span class="line">    prediction = ...</span><br><span class="line">    <span class="keyword">return</span> prediction</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">training_epoch_end</span>(<span class="params">self, training_step_outputs</span>):</span></span><br><span class="line">    <span class="keyword">for</span> prediction <span class="keyword">in</span> predictions:</span><br><span class="line">        <span class="comment"># do something with these</span></span><br></pre></td></tr></table></figure><p>æˆ‘ä»¬éœ€è¦åšçš„ï¼Œå°±æ˜¯åƒå¡«ç©ºä¸€æ ·ï¼Œå¡«è¿™äº›å‡½æ•°ã€‚</p></li></ul><h3 id="ç»„ä»¶ä¸å‡½æ•°"><a class="markdownIt-Anchor" href="#ç»„ä»¶ä¸å‡½æ•°"></a> ç»„ä»¶ä¸å‡½æ•°</h3><p><a href="https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html#lightningmodule-api">APIé¡µé¢</a></p><ul><li><p>ä¸€ä¸ªPytorch-Lighting æ¨¡å‹å¿…é¡»å«æœ‰çš„éƒ¨ä»¶æ˜¯ï¼š</p><ul><li><p><code>init</code>: åˆå§‹åŒ–ï¼ŒåŒ…æ‹¬æ¨¡å‹å’Œç³»ç»Ÿçš„å®šä¹‰ã€‚</p></li><li><p><a href="https://pytorch-lightning.readthedocs.io/en/latest/api/pytorch_lightning.core.lightning.html#pytorch_lightning.core.lightning.LightningModule.training_step"><code>training_step(self, batch, batch_idx)</code></a>: å³æ¯ä¸ªbatchçš„å¤„ç†å‡½æ•°ã€‚</p><blockquote><p>å‚æ•°ï¼š</p><ul><li><strong>batch</strong> (<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor"><code>Tensor</code></a> | (<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor"><code>Tensor</code></a>, â€¦) | [<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor"><code>Tensor</code></a>, â€¦]) â€“ The output of your <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader"><code>DataLoader</code></a>. A tensor, tuple or list.</li><li><strong>batch_idx</strong> (<a href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a>) â€“ Integer displaying index of this batch</li><li><strong>optimizer_idx</strong> (<a href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a>) â€“ When using multiple optimizers, this argument will also be present.</li><li><strong>hiddens</strong> (<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor"><code>Tensor</code></a>) â€“ Passed in if <a href="https://pytorch-lightning.readthedocs.io/en/latest/api/pytorch_lightning.trainer.trainer.html#pytorch_lightning.trainer.trainer.Trainer.params.truncated_bptt_steps"><code>truncated_bptt_steps</code></a> &gt; 0.</li></ul><p>è¿”å›å€¼ï¼šAny of.</p><ul><li><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor"><code>Tensor</code></a> - The loss tensor</li><li><code>dict</code> - A dictionary. Can include any keys, but must include the key <code>'loss'</code></li><li><code>None</code> - Training will skip to the next batch</li></ul></blockquote><p>è¿”å›å€¼æ— è®ºå¦‚ä½•ä¹Ÿéœ€è¦æœ‰ä¸€ä¸ªlossé‡ã€‚å¦‚æœæ˜¯å­—å…¸ï¼Œè¦æœ‰è¿™ä¸ªkeyã€‚æ²¡lossè¿™ä¸ªbatchå°±è¢«è·³è¿‡äº†ã€‚ä¾‹ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">training_step</span>(<span class="params">self, batch, batch_idx</span>):</span></span><br><span class="line">    x, y, z = batch</span><br><span class="line">    out = self.encoder(x)</span><br><span class="line">    loss = self.loss(out, x)</span><br><span class="line">    <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"><span class="comment"># Multiple optimizers (e.g.: GANs)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">training_step</span>(<span class="params">self, batch, batch_idx, optimizer_idx</span>):</span></span><br><span class="line">    <span class="keyword">if</span> optimizer_idx == <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># do training_step with encoder</span></span><br><span class="line">    <span class="keyword">if</span> optimizer_idx == <span class="number">1</span>:</span><br><span class="line">        <span class="comment"># do training_step with decoder</span></span><br><span class="line">        </span><br><span class="line"><span class="comment"># Truncated back-propagation through time</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">training_step</span>(<span class="params">self, batch, batch_idx, hiddens</span>):</span></span><br><span class="line">    <span class="comment"># hiddens are the hidden states from the previous truncated backprop step</span></span><br><span class="line">    ...</span><br><span class="line">    out, hiddens = self.lstm(data, hiddens)</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&#x27;loss&#x27;</span>: loss, <span class="string">&#x27;hiddens&#x27;</span>: hiddens&#125;</span><br></pre></td></tr></table></figure></li><li><p><a href="https://pytorch-lightning.readthedocs.io/en/latest/common/optimizers.html#automatic-optimization"><code>configure_optimizers</code></a>: ä¼˜åŒ–å™¨å®šä¹‰ï¼Œè¿”å›ä¸€ä¸ªä¼˜åŒ–å™¨ï¼Œæˆ–æ•°ä¸ªä¼˜åŒ–å™¨ï¼Œæˆ–ä¸¤ä¸ªListï¼ˆä¼˜åŒ–å™¨ï¼ŒSchedulerï¼‰ã€‚å¦‚ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># most cases</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">configure_optimizers</span>(<span class="params">self</span>):</span></span><br><span class="line">    opt = Adam(self.parameters(), lr=<span class="number">1e-3</span>)</span><br><span class="line">    <span class="keyword">return</span> opt</span><br><span class="line"></span><br><span class="line"><span class="comment"># multiple optimizer case (e.g.: GAN)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">configure_optimizers</span>(<span class="params">self</span>):</span></span><br><span class="line">    generator_opt = Adam(self.model_gen.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line">    disriminator_opt = Adam(self.model_disc.parameters(), lr=<span class="number">0.02</span>)</span><br><span class="line">    <span class="keyword">return</span> generator_opt, disriminator_opt</span><br><span class="line"></span><br><span class="line"><span class="comment"># example with learning rate schedulers</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">configure_optimizers</span>(<span class="params">self</span>):</span></span><br><span class="line">    generator_opt = Adam(self.model_gen.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line">    disriminator_opt = Adam(self.model_disc.parameters(), lr=<span class="number">0.02</span>)</span><br><span class="line">    discriminator_sched = CosineAnnealing(discriminator_opt, T_max=<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">return</span> [generator_opt, disriminator_opt], [discriminator_sched]</span><br><span class="line"></span><br><span class="line"><span class="comment"># example with step-based learning rate schedulers</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">configure_optimizers</span>(<span class="params">self</span>):</span></span><br><span class="line">    gen_opt = Adam(self.model_gen.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line">    dis_opt = Adam(self.model_disc.parameters(), lr=<span class="number">0.02</span>)</span><br><span class="line">    gen_sched = &#123;<span class="string">&#x27;scheduler&#x27;</span>: ExponentialLR(gen_opt, <span class="number">0.99</span>),</span><br><span class="line">                 <span class="string">&#x27;interval&#x27;</span>: <span class="string">&#x27;step&#x27;</span>&#125;  <span class="comment"># called after each training step</span></span><br><span class="line">    dis_sched = CosineAnnealing(discriminator_opt, T_max=<span class="number">10</span>) <span class="comment"># called every epoch</span></span><br><span class="line">    <span class="keyword">return</span> [gen_opt, dis_opt], [gen_sched, dis_sched]</span><br><span class="line"></span><br><span class="line"><span class="comment"># example with optimizer frequencies</span></span><br><span class="line"><span class="comment"># see training procedure in `Improved Training of Wasserstein GANs`, Algorithm 1</span></span><br><span class="line"><span class="comment"># https://arxiv.org/abs/1704.00028</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">configure_optimizers</span>(<span class="params">self</span>):</span></span><br><span class="line">    gen_opt = Adam(self.model_gen.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line">    dis_opt = Adam(self.model_disc.parameters(), lr=<span class="number">0.02</span>)</span><br><span class="line">    n_critic = <span class="number">5</span></span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">        &#123;<span class="string">&#x27;optimizer&#x27;</span>: dis_opt, <span class="string">&#x27;frequency&#x27;</span>: n_critic&#125;,</span><br><span class="line">        &#123;<span class="string">&#x27;optimizer&#x27;</span>: gen_opt, <span class="string">&#x27;frequency&#x27;</span>: <span class="number">1</span>&#125;</span><br><span class="line">    )</span><br></pre></td></tr></table></figure></li></ul></li><li><p>å¯ä»¥æŒ‡å®šçš„éƒ¨ä»¶æœ‰ï¼š</p><ul><li><code>forward</code>: å’Œæ­£å¸¸çš„<code>nn.Module</code>ä¸€æ ·ï¼Œç”¨äºinferenceã€‚å†…éƒ¨è°ƒç”¨æ—¶ï¼š<code>y=self(batch)</code></li><li><code>training_step_end</code>: åªåœ¨ä½¿ç”¨å¤šä¸ªnodeè¿›è¡Œè®­ç»ƒä¸”ç»“æœæ¶‰åŠå¦‚softmaxä¹‹ç±»éœ€è¦å…¨éƒ¨è¾“å‡ºè”åˆè¿ç®—çš„æ­¥éª¤æ—¶ä½¿ç”¨è¯¥å‡½æ•°ã€‚åŒç†ï¼Œ<code>validation_step_end</code>/<code>test_step_end</code>ã€‚</li><li><code>training_epoch_end</code>:<ul><li>åœ¨ä¸€ä¸ªè®­ç»ƒepochç»“å°¾å¤„è¢«è°ƒç”¨ã€‚</li><li>è¾“å…¥å‚æ•°ï¼šä¸€ä¸ªListï¼ŒListçš„å†…å®¹æ˜¯å‰é¢<code>training_step()</code>æ‰€è¿”å›çš„æ¯æ¬¡çš„å†…å®¹ã€‚</li><li>è¿”å›ï¼šNone</li></ul></li><li><code>validation_step(self, batch, batch_idx)</code>/<code>test_step(self, batch, batch_idx)</code>:<ul><li>æ²¡æœ‰è¿”å›å€¼é™åˆ¶ï¼Œä¸ä¸€å®šéè¦è¾“å‡ºä¸€ä¸ª<code>val_loss</code>ã€‚</li></ul></li><li><code>validation_epoch_end</code>/<code>test_epoch_end</code>:</li></ul></li><li><p>å·¥å…·å‡½æ•°æœ‰ï¼š</p><ul><li><p><code>freeze</code>ï¼šå†»ç»“æ‰€æœ‰æƒé‡ä»¥ä¾›é¢„æµ‹æ—¶å€™ä½¿ç”¨ã€‚ä»…å½“å·²ç»è®­ç»ƒå®Œæˆä¸”åé¢åªæµ‹è¯•æ—¶ä½¿ç”¨ã€‚</p></li><li><p><code>print</code>ï¼šå°½ç®¡è‡ªå¸¦çš„<code>print</code>å‡½æ•°ä¹Ÿå¯ä»¥ä½¿ç”¨ï¼Œä½†å¦‚æœç¨‹åºè¿è¡Œåœ¨åˆ†å¸ƒå¼ç³»ç»Ÿæ—¶ï¼Œä¼šæ‰“å°å¤šæ¬¡ã€‚è€Œä½¿ç”¨<code>self.print()</code>åˆ™åªä¼šæ‰“å°ä¸€æ¬¡ã€‚</p></li><li><p><code>log</code>ï¼šåƒæ˜¯TensorBoardç­‰logè®°å½•å™¨ï¼Œå¯¹äºæ¯ä¸ªlogçš„æ ‡é‡ï¼Œéƒ½ä¼šæœ‰ä¸€ä¸ªç›¸å¯¹åº”çš„æ¨ªåæ ‡ï¼Œå®ƒå¯èƒ½æ˜¯batch numberæˆ–epoch numberã€‚è€Œ<code>on_step</code>å°±è¡¨ç¤ºæŠŠè¿™ä¸ªlogå‡ºå»çš„é‡çš„æ¨ªåæ ‡è¡¨ç¤ºä¸ºå½“å‰batchï¼Œè€Œ<code>on_epoch</code>åˆ™è¡¨ç¤ºå°†logçš„é‡åœ¨æ•´ä¸ªepochä¸Šè¿›è¡Œç´¯ç§¯ålogï¼Œæ¨ªåæ ‡ä¸ºå½“å‰epochã€‚</p><table><thead><tr><th>LightningMoule Hook</th><th>on_step</th><th>on_epoch</th><th>prog_bar</th><th>logger</th></tr></thead><tbody><tr><td>training_step</td><td>T</td><td>F</td><td>F</td><td>T</td></tr><tr><td>training_step_end</td><td>T</td><td>F</td><td>F</td><td>T</td></tr><tr><td>training_epoch_end</td><td>F</td><td>T</td><td>F</td><td>T</td></tr><tr><td>validation_step*</td><td>F</td><td>T</td><td>F</td><td>T</td></tr><tr><td>validation_step_end*</td><td>F</td><td>T</td><td>F</td><td>T</td></tr><tr><td>validation_epoch_end*</td><td>F</td><td>T</td><td>F</td><td>T</td></tr></tbody></table><p><code>*</code> also applies to the test loop</p><blockquote><p>å‚æ•°</p><ul><li><strong>name</strong> (<a href="https://docs.python.org/3/library/stdtypes.html#str"><code>str</code></a>) â€“ key name</li><li><strong>value</strong> (<a href="https://docs.python.org/3/library/typing.html#typing.Any"><code>Any</code></a>) â€“ value name</li><li><strong>prog_bar</strong> (<a href="https://docs.python.org/3/library/functions.html#bool"><code>bool</code></a>) â€“ if True logs to the progress bar</li><li><strong>logger</strong> (<a href="https://docs.python.org/3/library/functions.html#bool"><code>bool</code></a>) â€“ if True logs to the logger</li><li><strong>on_step</strong> (<a href="https://docs.python.org/3/library/typing.html#typing.Optional"><code>Optional</code></a>[<a href="https://docs.python.org/3/library/functions.html#bool"><code>bool</code></a>]) â€“ if True logs at this step. None auto-logs at the training_step but not validation/test_step</li><li><strong>on_epoch</strong> (<a href="https://docs.python.org/3/library/typing.html#typing.Optional"><code>Optional</code></a>[<a href="https://docs.python.org/3/library/functions.html#bool"><code>bool</code></a>]) â€“ if True logs epoch accumulated metrics. None auto-logs at the val/test step but not training_step</li><li><strong>reduce_fx</strong> (<a href="https://docs.python.org/3/library/typing.html#typing.Callable"><code>Callable</code></a>) â€“ reduction function over step values for end of epoch. Torch.mean by default</li><li><strong>tbptt_reduce_fx</strong> (<a href="https://docs.python.org/3/library/typing.html#typing.Callable"><code>Callable</code></a>) â€“ function to reduce on truncated back prop</li><li><strong>tbptt_pad_token</strong> (<a href="https://docs.python.org/3/library/functions.html#int"><code>int</code></a>) â€“ token to use for padding</li><li><strong>enable_graph</strong> (<a href="https://docs.python.org/3/library/functions.html#bool"><code>bool</code></a>) â€“ if True, will not auto detach the graph</li><li><strong>sync_dist</strong> (<a href="https://docs.python.org/3/library/functions.html#bool"><code>bool</code></a>) â€“ if True, reduces the metric across GPUs/TPUs</li><li><strong>sync_dist_op</strong> (<a href="https://docs.python.org/3/library/typing.html#typing.Union"><code>Union</code></a>[<a href="https://docs.python.org/3/library/typing.html#typing.Any"><code>Any</code></a>, <a href="https://docs.python.org/3/library/stdtypes.html#str"><code>str</code></a>]) â€“ the op to sync across GPUs/TPUs</li><li><strong>sync_dist_group</strong> (<a href="https://docs.python.org/3/library/typing.html#typing.Optional"><code>Optional</code></a>[<a href="https://docs.python.org/3/library/typing.html#typing.Any"><code>Any</code></a>]) â€“ the ddp group</li></ul></blockquote></li><li><p><code>log_dict</code>ï¼šå’Œ<code>log</code>å‡½æ•°å”¯ä¸€çš„åŒºåˆ«å°±æ˜¯ï¼Œ<code>name</code>å’Œ<code>value</code>å˜é‡ç”±ä¸€ä¸ªå­—å…¸æ›¿æ¢ã€‚è¡¨ç¤ºåŒæ—¶logå¤šä¸ªå€¼ã€‚å¦‚ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">values = &#123;<span class="string">&#x27;loss&#x27;</span>: loss, <span class="string">&#x27;acc&#x27;</span>: acc, ..., <span class="string">&#x27;metric_n&#x27;</span>: metric_n&#125;</span><br><span class="line">self.log_dict(values)</span><br></pre></td></tr></table></figure></li><li><p><code>save_hyperparameters</code>ï¼šå‚¨å­˜<code>init</code>ä¸­è¾“å…¥çš„æ‰€æœ‰è¶…å‚ã€‚åç»­è®¿é—®å¯ä»¥ç”±<code>self.hparams.argX</code>æ–¹å¼è¿›è¡Œã€‚åŒæ—¶ï¼Œè¶…å‚è¡¨ä¹Ÿä¼šè¢«å­˜åˆ°æ–‡ä»¶ä¸­ã€‚</p></li></ul></li><li><p>å‡½æ•°å†…å»ºå˜é‡ï¼š</p><ul><li><code>device</code>ï¼šå¯ä»¥ä½¿ç”¨<code>self.device</code>æ¥æ„å»ºè®¾å¤‡æ— å…³å‹tensorã€‚å¦‚ï¼š<code>z = torch.rand(2, 3, device=self.device)</code>ã€‚</li><li><code>hparams</code>ï¼šå«æœ‰æ‰€æœ‰å‰é¢å­˜ä¸‹æ¥çš„è¾“å…¥è¶…å‚ã€‚</li><li><code>precision</code>ï¼šç²¾ç¡®åº¦ã€‚å¸¸è§32å’Œ16ã€‚</li></ul></li></ul><h3 id="è¦ç‚¹"><a class="markdownIt-Anchor" href="#è¦ç‚¹"></a> è¦ç‚¹</h3><ul><li>å¦‚æœå‡†å¤‡ä½¿ç”¨DataParallelï¼Œåœ¨å†™<code>training_step</code>çš„æ—¶å€™éœ€è¦è°ƒç”¨forwardå‡½æ•°ï¼Œ<code>z=self(x)</code></li></ul><h3 id="æ¨¡æ¿"><a class="markdownIt-Anchor" href="#æ¨¡æ¿"></a> æ¨¡æ¿</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LitModel</span>(<span class="params">pl.LightningModule</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">...</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">...</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">training_step</span>(<span class="params">...</span>)</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">    <span class="title">def</span> <span class="title">training_step_end</span>(<span class="params">...</span>)</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">    <span class="title">def</span> <span class="title">training_epoch_end</span>(<span class="params">...</span>)</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">    <span class="title">def</span> <span class="title">validation_step</span>(<span class="params">...</span>)</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">    <span class="title">def</span> <span class="title">validation_step_end</span>(<span class="params">...</span>)</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">    <span class="title">def</span> <span class="title">validation_epoch_end</span>(<span class="params">...</span>)</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">    <span class="title">def</span> <span class="title">test_step</span>(<span class="params">...</span>)</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">    <span class="title">def</span> <span class="title">test_step_end</span>(<span class="params">...</span>)</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">    <span class="title">def</span> <span class="title">test_epoch_end</span>(<span class="params">...</span>)</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">    <span class="title">def</span> <span class="title">configure_optimizers</span>(<span class="params">...</span>)</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">    <span class="title">def</span> <span class="title">any_extra_hook</span>(<span class="params">...</span>)</span></span><br></pre></td></tr></table></figure><h2 id="trainer"><a class="markdownIt-Anchor" href="#trainer"></a> Trainer</h2><h3 id="åŸºç¡€ä½¿ç”¨"><a class="markdownIt-Anchor" href="#åŸºç¡€ä½¿ç”¨"></a> åŸºç¡€ä½¿ç”¨</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model = MyLightningModule()</span><br><span class="line"></span><br><span class="line">trainer = Trainer()</span><br><span class="line">trainer.fit(model, train_dataloader, val_dataloader)</span><br></pre></td></tr></table></figure><p>å¦‚æœè¿<code>validation_step</code>éƒ½æ²¡æœ‰ï¼Œé‚£<code>val_dataloader</code>ä¹Ÿå°±ç®—äº†ã€‚</p><h3 id="ä¼ªä»£ç ä¸hooks"><a class="markdownIt-Anchor" href="#ä¼ªä»£ç ä¸hooks"></a> ä¼ªä»£ç ä¸hooks</h3><p><a href="https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html#hooks">Hooksé¡µé¢</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">...</span>):</span></span><br><span class="line">    on_fit_start()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> global_rank == <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># prepare data is called on GLOBAL_ZERO only</span></span><br><span class="line">        prepare_data()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> gpu/tpu <span class="keyword">in</span> gpu/tpus:</span><br><span class="line">        train_on_device(model.copy())</span><br><span class="line"></span><br><span class="line">    on_fit_end()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_on_device</span>(<span class="params">model</span>):</span></span><br><span class="line">    <span class="comment"># setup is called PER DEVICE</span></span><br><span class="line">    setup()</span><br><span class="line">    configure_optimizers()</span><br><span class="line">    on_pretrain_routine_start()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> epochs:</span><br><span class="line">        train_loop()</span><br><span class="line"></span><br><span class="line">    teardown()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_loop</span>():</span></span><br><span class="line">    on_train_epoch_start()</span><br><span class="line">    train_outs = []</span><br><span class="line">    <span class="keyword">for</span> train_batch <span class="keyword">in</span> train_dataloader():</span><br><span class="line">        on_train_batch_start()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ----- train_step methods -------</span></span><br><span class="line">        out = training_step(batch)</span><br><span class="line">        train_outs.append(out)</span><br><span class="line"></span><br><span class="line">        loss = out.loss</span><br><span class="line"></span><br><span class="line">        backward()</span><br><span class="line">        on_after_backward()</span><br><span class="line">        optimizer_step()</span><br><span class="line">        on_before_zero_grad()</span><br><span class="line">        optimizer_zero_grad()</span><br><span class="line"></span><br><span class="line">        on_train_batch_end(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> should_check_val:</span><br><span class="line">            val_loop()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># end training epoch</span></span><br><span class="line">    logs = training_epoch_end(outs)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">val_loop</span>():</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    torch.set_grad_enabled(<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    on_validation_epoch_start()</span><br><span class="line">    val_outs = []</span><br><span class="line">    <span class="keyword">for</span> val_batch <span class="keyword">in</span> val_dataloader():</span><br><span class="line">        on_validation_batch_start()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># -------- val step methods -------</span></span><br><span class="line">        out = validation_step(val_batch)</span><br><span class="line">        val_outs.append(out)</span><br><span class="line"></span><br><span class="line">        on_validation_batch_end(out)</span><br><span class="line"></span><br><span class="line">    validation_epoch_end(val_outs)</span><br><span class="line">    on_validation_epoch_end()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># set up for train</span></span><br><span class="line">    model.train()</span><br><span class="line">    torch.set_grad_enabled(<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h3 id="æ¨èå‚æ•°"><a class="markdownIt-Anchor" href="#æ¨èå‚æ•°"></a> æ¨èå‚æ•°</h3><p><a href="https://pytorch-lightning.readthedocs.io/en/latest/common/trainer.html#trainer-flags">å‚æ•°ä»‹ç»ï¼ˆé™„è§†é¢‘ï¼‰</a></p><p><a href="https://pytorch-lightning.readthedocs.io/en/latest/common/trainer.html#trainer-class-api">ç±»å®šä¹‰ä¸é»˜è®¤å‚æ•°</a></p><ul><li><p><code>default_root_dir</code>ï¼šé»˜è®¤å­˜å‚¨åœ°å€ã€‚æ‰€æœ‰çš„å®éªŒå˜é‡å’Œæƒé‡å…¨éƒ¨ä¼šè¢«å­˜åˆ°è¿™ä¸ªæ–‡ä»¶å¤¹é‡Œé¢ã€‚æ¨èæ˜¯ï¼Œæ¯ä¸ªæ¨¡å‹æœ‰ä¸€ä¸ªç‹¬ç«‹çš„æ–‡ä»¶å¤¹ã€‚æ¯æ¬¡é‡æ–°è®­ç»ƒä¼šäº§ç”Ÿä¸€ä¸ªæ–°çš„<code>version_x</code>å­æ–‡ä»¶å¤¹ã€‚</p></li><li><p><code>max_epochs</code>ï¼šæœ€å¤§è®­ç»ƒå‘¨æœŸæ•°ã€‚<code>trainer = Trainer(max_epochs=1000)</code></p></li><li><p><code>min_epochs</code>ï¼šè‡³å°‘è®­ç»ƒå‘¨æœŸæ•°ã€‚å½“æœ‰Early Stopæ—¶ä½¿ç”¨ã€‚</p></li><li><p><code>auto_scale_batch_size</code>ï¼šåœ¨è¿›è¡Œä»»ä½•è®­ç»ƒå‰è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„batch sizeã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># default used by the Trainer (no scaling of batch size)</span></span><br><span class="line">trainer = Trainer(auto_scale_batch_size=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># run batch size scaling, result overrides hparams.batch_size</span></span><br><span class="line">trainer = Trainer(auto_scale_batch_size=<span class="string">&#x27;binsearch&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># call tune to find the batch size</span></span><br><span class="line">trainer.tune(model)</span><br></pre></td></tr></table></figure></li><li><p><code>auto_select_gpus</code>ï¼šè‡ªåŠ¨é€‰æ‹©åˆé€‚çš„GPUã€‚å°¤å…¶æ˜¯åœ¨æœ‰GPUå¤„äºç‹¬å æ¨¡å¼æ—¶å€™ï¼Œéå¸¸æœ‰ç”¨ã€‚</p></li><li><p><code>auto_lr_find</code>ï¼šè‡ªåŠ¨æ‰¾åˆ°åˆé€‚çš„åˆå§‹å­¦ä¹ ç‡ã€‚ä½¿ç”¨äº†è¯¥<a href="https://arxiv.org/abs/1506.01186">è®ºæ–‡</a>çš„æŠ€æœ¯ã€‚å½“ä¸”ä»…å½“æ‰§è¡Œ<code>trainer.tune(model)</code>ä»£ç æ—¶å·¥ä½œã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># run learning rate finder, results override hparams.learning_rate</span></span><br><span class="line">trainer = Trainer(auto_lr_find=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># run learning rate finder, results override hparams.my_lr_arg</span></span><br><span class="line">trainer = Trainer(auto_lr_find=<span class="string">&#x27;my_lr_arg&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># call tune to find the lr</span></span><br><span class="line">trainer.tune(model)</span><br></pre></td></tr></table></figure></li><li><p><code>precision</code>ï¼šç²¾ç¡®åº¦ã€‚æ­£å¸¸æ˜¯32ï¼Œä½¿ç”¨16å¯ä»¥å‡å°å†…å­˜æ¶ˆè€—ï¼Œå¢å¤§batchã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># default used by the Trainer</span></span><br><span class="line">trainer = Trainer(precision=<span class="number">32</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 16-bit precision</span></span><br><span class="line">trainer = Trainer(precision=<span class="number">16</span>, gpus=<span class="number">1</span>)</span><br></pre></td></tr></table></figure></li><li><p><code>val_check_interval</code>ï¼šè¿›è¡ŒValidationæµ‹è¯•çš„å‘¨æœŸã€‚æ­£å¸¸ä¸º1ï¼Œè®­ç»ƒ1ä¸ªepochæµ‹è¯•4æ¬¡æ˜¯0.25ï¼Œæ¯1000 batchæµ‹è¯•ä¸€æ¬¡æ˜¯1000ã€‚</p><blockquote><ul><li>use (float) to check within a training epochï¼šæ­¤æ—¶è¿™ä¸ªå€¼ä¸ºä¸€ä¸ªepochçš„ç™¾åˆ†æ¯”ã€‚æ¯ç™¾åˆ†ä¹‹å¤šå°‘æµ‹è¯•ä¸€æ¬¡ã€‚</li><li>use (int) to check every n steps (batches)ï¼šæ¯å¤šå°‘ä¸ªbatchæµ‹è¯•ä¸€æ¬¡ã€‚</li></ul></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># default used by the Trainer</span></span><br><span class="line">trainer = Trainer(val_check_interval=<span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># check validation set 4 times during a training epoch</span></span><br><span class="line">trainer = Trainer(val_check_interval=<span class="number">0.25</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># check validation set every 1000 training batches</span></span><br><span class="line"><span class="comment"># use this when using iterableDataset and your dataset has no length</span></span><br><span class="line"><span class="comment"># (ie: production cases with streaming data)</span></span><br><span class="line">trainer = Trainer(val_check_interval=<span class="number">1000</span>)</span><br></pre></td></tr></table></figure></li><li><p><a href="https://pytorch-lightning.readthedocs.io/en/latest/common/trainer.html#gpus"><code>gpus</code></a>ï¼šæ§åˆ¶ä½¿ç”¨çš„GPUæ•°ã€‚å½“è®¾å®šä¸ºNoneæ—¶ï¼Œä½¿ç”¨cpuã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># default used by the Trainer (ie: train on CPU)</span></span><br><span class="line">trainer = Trainer(gpus=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># equivalent</span></span><br><span class="line">trainer = Trainer(gpus=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># int: train on 2 gpus</span></span><br><span class="line">trainer = Trainer(gpus=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># list: train on GPUs 1, 4 (by bus ordering)</span></span><br><span class="line">trainer = Trainer(gpus=[<span class="number">1</span>, <span class="number">4</span>])</span><br><span class="line">trainer = Trainer(gpus=<span class="string">&#x27;1, 4&#x27;</span>) <span class="comment"># equivalent</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># -1: train on all gpus</span></span><br><span class="line">trainer = Trainer(gpus=-<span class="number">1</span>)</span><br><span class="line">trainer = Trainer(gpus=<span class="string">&#x27;-1&#x27;</span>) <span class="comment"># equivalent</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># combine with num_nodes to train on multiple GPUs across nodes</span></span><br><span class="line"><span class="comment"># uses 8 gpus in total</span></span><br><span class="line">trainer = Trainer(gpus=<span class="number">2</span>, num_nodes=<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># train only on GPUs 1 and 4 across nodes</span></span><br><span class="line">trainer = Trainer(gpus=[<span class="number">1</span>, <span class="number">4</span>], num_nodes=<span class="number">4</span>)</span><br></pre></td></tr></table></figure></li><li><p><a href="https://pytorch-lightning.readthedocs.io/en/latest/common/trainer.html#limit-train-batches"><code>limit_train_batches</code></a>ï¼šä½¿ç”¨è®­ç»ƒæ•°æ®çš„ç™¾åˆ†æ¯”ã€‚å¦‚æœæ•°æ®è¿‡å¤šï¼Œæˆ–æ­£åœ¨è°ƒè¯•ï¼Œå¯ä»¥ä½¿ç”¨è¿™ä¸ªã€‚å€¼çš„èŒƒå›´ä¸º0~1ã€‚åŒæ ·ï¼Œæœ‰<code>limit_test_batches</code>ï¼Œ<code>limit_val_batches</code>ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># default used by the Trainer</span></span><br><span class="line">trainer = Trainer(limit_train_batches=<span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># run through only 25% of the training set each epoch</span></span><br><span class="line">trainer = Trainer(limit_train_batches=<span class="number">0.25</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># run through only 10 batches of the training set each epoch</span></span><br><span class="line">trainer = Trainer(limit_train_batches=<span class="number">10</span>)</span><br></pre></td></tr></table></figure></li><li><p><a href="https://pytorch-lightning.readthedocs.io/en/latest/common/trainer.html#fast-dev-run"><code>fast_dev_run</code></a>ï¼šboolé‡ã€‚å¦‚æœè®¾å®šä¸ºtrueï¼Œä¼šåªæ‰§è¡Œä¸€ä¸ªbatchçš„train, val å’Œ testï¼Œç„¶åç»“æŸã€‚ä»…ç”¨äºdebugã€‚</p><blockquote><p>Setting this argument will disable tuner, checkpoint callbacks, early stopping callbacks, loggers and logger callbacks like <code>LearningRateLogger</code> and runs for only 1 epoch</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># default used by the Trainer</span></span><br><span class="line">trainer = Trainer(fast_dev_run=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># runs 1 train, val, test batch and program ends</span></span><br><span class="line">trainer = Trainer(fast_dev_run=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># runs 7 train, val, test batches and program ends</span></span><br><span class="line">trainer = Trainer(fast_dev_run=<span class="number">7</span>)</span><br></pre></td></tr></table></figure></li></ul><h3 id="fitå‡½æ•°"><a class="markdownIt-Anchor" href="#fitå‡½æ•°"></a> .fit()å‡½æ•°</h3><p><code>Trainer.fit(model, train_dataloader=None, val_dataloaders=None, datamodule=None)</code>ï¼šè¾“å…¥ç¬¬ä¸€ä¸ªé‡ä¸€å®šæ˜¯modelï¼Œç„¶åå¯ä»¥è·Ÿä¸€ä¸ªLigntningDataModuleæˆ–ä¸€ä¸ªæ™®é€šçš„Train DataLoaderã€‚å¦‚æœå®šä¹‰äº†Val stepï¼Œä¹Ÿè¦æœ‰Val DataLoaderã€‚</p><blockquote><p>å‚æ•°</p><ul><li><strong>datamodule</strong> (<a href="https://docs.python.org/3/library/typing.html#typing.Optional"><code>Optional</code></a>[<a href="https://pytorch-lightning.readthedocs.io/en/latest/api/pytorch_lightning.core.datamodule.html#pytorch_lightning.core.datamodule.LightningDataModule"><code>LightningDataModule</code></a>]) â€“ A instance of <code>LightningDataModule</code>.</li><li><strong>model</strong> (<a href="https://pytorch-lightning.readthedocs.io/en/latest/api/pytorch_lightning.core.lightning.html#pytorch_lightning.core.lightning.LightningModule"><code>LightningModule</code></a>) â€“ Model to fit.</li><li><strong>train_dataloader</strong> (<a href="https://docs.python.org/3/library/typing.html#typing.Optional"><code>Optional</code></a>[<a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader"><code>DataLoader</code></a>]) â€“ A Pytorch DataLoader with training samples. If the model has a predefined train_dataloader method this will be skipped.</li><li><strong>val_dataloaders</strong> (<a href="https://docs.python.org/3/library/typing.html#typing.Union"><code>Union</code></a>[<a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader"><code>DataLoader</code></a>, <a href="https://docs.python.org/3/library/typing.html#typing.List"><code>List</code></a>[<a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader"><code>DataLoader</code></a>], <a href="https://docs.python.org/3/library/constants.html#None"><code>None</code></a>]) â€“ Either a single Pytorch Dataloader or a list of them, specifying validation samples. If the model has a predefined val_dataloaders method this will be skipped</li></ul></blockquote><h3 id="å…¶ä»–è¦ç‚¹"><a class="markdownIt-Anchor" href="#å…¶ä»–è¦ç‚¹"></a> å…¶ä»–è¦ç‚¹</h3><ul><li><code>.test()</code>è‹¥éç›´æ¥è°ƒç”¨ï¼Œä¸ä¼šè¿è¡Œã€‚<code>trainer.test()</code></li><li><code>.test()</code>ä¼šè‡ªåŠ¨loadæœ€ä¼˜æ¨¡å‹ã€‚</li><li><code>model.eval()</code> and <code>torch.no_grad()</code> åœ¨è¿›è¡Œæµ‹è¯•æ—¶ä¼šè¢«è‡ªåŠ¨è°ƒç”¨ã€‚</li><li>é»˜è®¤æƒ…å†µä¸‹ï¼Œ<code>Trainer()</code>è¿è¡ŒäºCPUä¸Šã€‚</li></ul><h3 id="ä½¿ç”¨æ ·ä¾‹"><a class="markdownIt-Anchor" href="#ä½¿ç”¨æ ·ä¾‹"></a> ä½¿ç”¨æ ·ä¾‹</h3><ol><li>æ‰‹åŠ¨æ·»åŠ å‘½ä»¤è¡Œå‚æ•°ï¼š</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> argparse <span class="keyword">import</span> ArgumentParser</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>(<span class="params">hparams</span>):</span></span><br><span class="line">    model = LightningModule()</span><br><span class="line">    trainer = Trainer(gpus=hparams.gpus)</span><br><span class="line">    trainer.fit(model)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    parser = ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--gpus&#x27;</span>, default=<span class="literal">None</span>)</span><br><span class="line">    args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    main(args)</span><br></pre></td></tr></table></figure><ol start="2"><li>è‡ªåŠ¨æ·»åŠ æ‰€æœ‰<code>Trainer</code>ä¼šç”¨åˆ°çš„å‘½ä»¤è¡Œå‚æ•°ï¼š</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> argparse <span class="keyword">import</span> ArgumentParser</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>(<span class="params">args</span>):</span></span><br><span class="line">    model = LightningModule()</span><br><span class="line">    trainer = Trainer.from_argparse_args(args)</span><br><span class="line">    trainer.fit(model)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    parser = ArgumentParser()</span><br><span class="line">    parser = Trainer.add_argparse_args(</span><br><span class="line">        <span class="comment"># group the Trainer arguments together</span></span><br><span class="line">        parser.add_argument_group(title=<span class="string">&quot;pl.Trainer args&quot;</span>)</span><br><span class="line">    )</span><br><span class="line">    args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    main(args)</span><br></pre></td></tr></table></figure><ol start="3"><li>æ··åˆå¼ï¼Œæ—¢ä½¿ç”¨<code>Trainer</code>ç›¸å…³å‚æ•°ï¼Œåˆä½¿ç”¨ä¸€äº›è‡ªå®šä¹‰å‚æ•°ï¼Œå¦‚å„ç§æ¨¡å‹è¶…å‚ï¼š</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> argparse <span class="keyword">import</span> ArgumentParser</span><br><span class="line"><span class="keyword">import</span> pytorch_lightning <span class="keyword">as</span> pl</span><br><span class="line"><span class="keyword">from</span> pytorch_lightning <span class="keyword">import</span> LightningModule, Trainer</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>(<span class="params">args</span>):</span></span><br><span class="line">    model = LightningModule()</span><br><span class="line">    trainer = Trainer.from_argparse_args(args)</span><br><span class="line">    trainer.fit(model)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    parser = ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--batch_size&#x27;</span>, default=<span class="number">32</span>, <span class="built_in">type</span>=<span class="built_in">int</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--hidden_dim&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">128</span>)</span><br><span class="line">    parser = Trainer.add_argparse_args(</span><br><span class="line">        <span class="comment"># group the Trainer arguments together</span></span><br><span class="line">        parser.add_argument_group(title=<span class="string">&quot;pl.Trainer args&quot;</span>)</span><br><span class="line">    )</span><br><span class="line">    args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    main(args)</span><br></pre></td></tr></table></figure><h3 id="æ‰€æœ‰å‚æ•°"><a class="markdownIt-Anchor" href="#æ‰€æœ‰å‚æ•°"></a> æ‰€æœ‰å‚æ•°</h3><blockquote><p><code>Trainer.``__init__</code>(<em>logger=True</em>, <em>checkpoint_callback=True</em>, <em>callbacks=None</em>, <em>default_root_dir=None</em>, <em>gradient_clip_val=0</em>, <em>process_position=0</em>, <em>num_nodes=1</em>, <em>num_processes=1</em>, <em>gpus=None</em>, <em>auto_select_gpus=False</em>, <em>tpu_cores=None</em>, <em>log_gpu_memory=None</em>, <em>progress_bar_refresh_rate=None</em>, <em>overfit_batches=0.0</em>, <em>track_grad_norm=- 1</em>, <em>check_val_every_n_epoch=1</em>, <em>fast_dev_run=False</em>, <em>accumulate_grad_batches=1</em>, <em>max_epochs=None</em>, <em>min_epochs=None</em>, <em>max_steps=None</em>, <em>min_steps=None</em>, <em>limit_train_batches=1.0</em>, <em>limit_val_batches=1.0</em>, <em>limit_test_batches=1.0</em>, <em>limit_predict_batches=1.0</em>, <em>val_check_interval=1.0</em>, <em>flush_logs_every_n_steps=100</em>, <em>log_every_n_steps=50</em>, <em>accelerator=None</em>, <em>sync_batchnorm=False</em>, <em>precision=32</em>, <em>weights_summary=â€˜topâ€™</em>, <em>weights_save_path=None</em>, <em>num_sanity_val_steps=2</em>, <em>truncated_bptt_steps=None</em>, <em>resume_from_checkpoint=None</em>, <em>profiler=None</em>, <em>benchmark=False</em>, <em>deterministic=False</em>, <em>reload_dataloaders_every_epoch=False</em>, <em>auto_lr_find=False</em>, <em>replace_sampler_ddp=True</em>, <em>terminate_on_nan=False</em>, <em>auto_scale_batch_size=False</em>, <em>prepare_data_per_node=True</em>, <em>plugins=None</em>, <em>amp_backend=â€˜nativeâ€™</em>, <em>amp_level=â€˜O2â€™</em>, <em>distributed_backend=None</em>, <em>move_metrics_to_cpu=False</em>, <em>multiple_trainloader_mode=â€˜max_size_cycleâ€™</em>, <em>stochastic_weight_avg=False</em>)</p></blockquote><h3 id="logå’Œreturn-lossåˆ°åº•åœ¨åšä»€ä¹ˆ"><a class="markdownIt-Anchor" href="#logå’Œreturn-lossåˆ°åº•åœ¨åšä»€ä¹ˆ"></a> Logå’Œreturn lossåˆ°åº•åœ¨åšä»€ä¹ˆ</h3><p>To add a training loop use the training_step method</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LitClassifier</span>(<span class="params">pl.LightningModule</span>):</span></span><br><span class="line"></span><br><span class="line">     <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, model</span>):</span></span><br><span class="line">         <span class="built_in">super</span>().__init__()</span><br><span class="line">         self.model = model</span><br><span class="line"></span><br><span class="line">     <span class="function"><span class="keyword">def</span> <span class="title">training_step</span>(<span class="params">self, batch, batch_idx</span>):</span></span><br><span class="line">         x, y = batch</span><br><span class="line">         y_hat = self.model(x)</span><br><span class="line">         loss = F.cross_entropy(y_hat, y)</span><br><span class="line">         <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure><ul><li>æ— è®ºæ˜¯<code>training_step</code>ï¼Œè¿˜æ˜¯<code>validation_step</code>ï¼Œ<code>test_step</code>è¿”å›å€¼éƒ½æ˜¯<code>loss</code>ã€‚è¿”å›çš„lossä¼šè¢«ç”¨ä¸€ä¸ªlistæ”¶é›†èµ·æ¥ã€‚</li></ul><p>Under the hood, Lightning does the following (pseudocode):</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># put model in train mode</span></span><br><span class="line">model.train()</span><br><span class="line">torch.set_grad_enabled(<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">losses = []</span><br><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> train_dataloader:</span><br><span class="line">    <span class="comment"># forward</span></span><br><span class="line">    loss = training_step(batch)</span><br><span class="line">    losses.append(loss.detach())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># backward</span></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># apply and clear grads</span></span><br><span class="line">    optimizer.step()</span><br><span class="line">    optimizer.zero_grad()</span><br></pre></td></tr></table></figure><h4 id="training-epoch-level-metrics"><a class="markdownIt-Anchor" href="#training-epoch-level-metrics"></a> Training epoch-level metrics</h4><p>If you want to calculate epoch-level metrics and log them, use the <code>.log</code> method</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">training_step</span>(<span class="params">self, batch, batch_idx</span>):</span></span><br><span class="line">    x, y = batch</span><br><span class="line">    y_hat = self.model(x)</span><br><span class="line">    loss = F.cross_entropy(y_hat, y)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># logs metrics for each training_step,</span></span><br><span class="line">    <span class="comment"># and the average across the epoch, to the progress bar and logger</span></span><br><span class="line">    self.log(<span class="string">&#x27;train_loss&#x27;</span>, loss, on_step=<span class="literal">True</span>, on_epoch=<span class="literal">True</span>, prog_bar=<span class="literal">True</span>, logger=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure><ul><li>å¦‚æœåœ¨<code>x_step</code>å‡½æ•°ä¸­ä½¿ç”¨äº†<code>.log()</code>å‡½æ•°ï¼Œé‚£ä¹ˆè¿™ä¸ªé‡å°†ä¼šè¢«é€æ­¥è®°å½•ä¸‹æ¥ã€‚æ¯ä¸€ä¸ª<code>log</code>å‡ºå»çš„å˜é‡éƒ½ä¼šè¢«è®°å½•ä¸‹æ¥ï¼Œæ¯ä¸€ä¸ª<code>step</code>ä¼šé›†ä¸­ç”Ÿæˆä¸€ä¸ªå­—å…¸dictï¼Œè€Œæ¯ä¸ªepochéƒ½ä¼šæŠŠè¿™äº›å­—å…¸æ”¶é›†èµ·æ¥ï¼Œå½¢æˆä¸€ä¸ªå­—å…¸çš„listã€‚</li></ul><p>The .log object automatically reduces the requested metrics across the full epoch. Hereâ€™s the pseudocode of what it does under the hood:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">outs = []</span><br><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> train_dataloader:</span><br><span class="line">    <span class="comment"># forward</span></span><br><span class="line">    out = training_step(val_batch)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># backward</span></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># apply and clear grads</span></span><br><span class="line">    optimizer.step()</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">epoch_metric = torch.mean(torch.stack([x[<span class="string">&#x27;train_loss&#x27;</span>] <span class="keyword">for</span> x <span class="keyword">in</span> outs]))</span><br></pre></td></tr></table></figure><h4 id="train-epoch-level-operations"><a class="markdownIt-Anchor" href="#train-epoch-level-operations"></a> Train epoch-level operations</h4><p>If you need to do something with all the outputs of each training_step, override training_epoch_end yourself.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">training_step</span>(<span class="params">self, batch, batch_idx</span>):</span></span><br><span class="line">    x, y = batch</span><br><span class="line">    y_hat = self.model(x)</span><br><span class="line">    loss = F.cross_entropy(y_hat, y)</span><br><span class="line">    preds = ...</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&#x27;loss&#x27;</span>: loss, <span class="string">&#x27;other_stuff&#x27;</span>: preds&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">training_epoch_end</span>(<span class="params">self, training_step_outputs</span>):</span></span><br><span class="line">   <span class="keyword">for</span> pred <span class="keyword">in</span> training_step_outputs:</span><br><span class="line">       <span class="comment"># do something</span></span><br></pre></td></tr></table></figure><p>The matching pseudocode is:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">outs = []</span><br><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> train_dataloader:</span><br><span class="line">    <span class="comment"># forward</span></span><br><span class="line">    out = training_step(val_batch)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># backward</span></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># apply and clear grads</span></span><br><span class="line">    optimizer.step()</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">training_epoch_end(outs)</span><br></pre></td></tr></table></figure><h2 id="datamodule"><a class="markdownIt-Anchor" href="#datamodule"></a> DataModule</h2><p><a href="https://pytorch-lightning.readthedocs.io/en/latest/extensions/datamodules.html">ä¸»é¡µé¢</a></p><h3 id="ä»‹ç»"><a class="markdownIt-Anchor" href="#ä»‹ç»"></a> ä»‹ç»</h3><ul><li><p>é¦–å…ˆï¼Œè¿™ä¸ª<code>DataModule</code>å’Œä¹‹å‰å†™çš„Datasetå®Œå…¨ä¸å†²çªã€‚å‰è€…æ˜¯åè€…çš„ä¸€ä¸ªåŒ…è£…ï¼Œå¹¶ä¸”è¿™ä¸ªåŒ…è£…å¯ä»¥è¢«ç”¨äºå¤šä¸ªtorch Dataset ä¸­ã€‚åœ¨æˆ‘çœ‹æ¥ï¼Œå…¶æœ€å¤§çš„ä½œç”¨å°±æ˜¯æŠŠå„ç§train/val/teståˆ’åˆ†ã€DataLoaderåˆå§‹åŒ–ä¹‹ç±»çš„é‡å¤ä»£ç é€šè¿‡åŒ…è£…ç±»çš„æ–¹å¼å¾—ä»¥è¢«ç®€å•çš„å¤ç”¨ã€‚</p></li><li><p>å…·ä½“ä½œç”¨é¡¹ç›®ï¼š</p><ul><li>Download instructionsï¼šä¸‹è½½</li><li>Processing instructionsï¼šå¤„ç†</li><li>Split instructionsï¼šåˆ†å‰²</li><li>Train dataloaderï¼šè®­ç»ƒé›†Dataloader</li><li>Val dataloader(s)ï¼šéªŒè¯é›†Dataloader</li><li>Test dataloader(s)ï¼šæµ‹è¯•é›†Dataloader</li></ul></li><li><p>å…¶æ¬¡ï¼Œ<code>pl.LightningDataModule</code>ç›¸å½“äºä¸€ä¸ªåŠŸèƒ½åŠ å¼ºç‰ˆçš„torch Datasetï¼ŒåŠ å¼ºçš„åŠŸèƒ½åŒ…æ‹¬ï¼š</p><ul><li><code>prepare_data(self)</code>ï¼š<ul><li>æœ€æœ€å¼€å§‹çš„æ—¶å€™ï¼Œè¿›è¡Œä¸€äº›æ— è®ºGPUæœ‰å¤šå°‘åªè¦æ‰§è¡Œä¸€æ¬¡çš„æ“ä½œï¼Œå¦‚å†™å…¥ç£ç›˜çš„ä¸‹è½½æ“ä½œã€åˆ†è¯æ“ä½œ(tokenize)ç­‰ã€‚</li><li>è¿™é‡Œæ˜¯ä¸€åŠ³æ°¸é€¸å¼å‡†å¤‡æ•°æ®çš„å‡½æ•°ã€‚</li><li>ç”±äºåªåœ¨å•çº¿ç¨‹ä¸­è°ƒç”¨ï¼Œä¸è¦åœ¨è¿™ä¸ªå‡½æ•°ä¸­è¿›è¡Œ<code>self.x=y</code>ä¼¼çš„èµ‹å€¼æ“ä½œã€‚</li><li>ä½†å¦‚æœæ˜¯è‡ªå·±ç”¨è€Œä¸æ˜¯ç»™å¤§ä¼—åˆ†å‘çš„è¯ï¼Œè¿™ä¸ªå‡½æ•°å¯èƒ½å¹¶ä¸éœ€è¦è°ƒç”¨ï¼Œå› ä¸ºæ•°æ®æå‰å¤„ç†å¥½å°±å¥½äº†ã€‚</li></ul></li><li><code>setup(self, stage=None)</code>ï¼š<ul><li>å®ä¾‹åŒ–æ•°æ®é›†ï¼ˆDatasetï¼‰ï¼Œå¹¶è¿›è¡Œç›¸å…³æ“ä½œï¼Œå¦‚ï¼šæ¸…ç‚¹ç±»æ•°ï¼Œåˆ’åˆ†train/val/testé›†åˆç­‰ã€‚</li><li>å‚æ•°<code>stage</code>ç”¨äºæŒ‡ç¤ºæ˜¯å¤„äºè®­ç»ƒå‘¨æœŸ(<code>fit</code>)è¿˜æ˜¯æµ‹è¯•å‘¨æœŸ(<code>test</code>)ï¼Œå…¶ä¸­ï¼Œ<code>fit</code>å‘¨æœŸéœ€è¦æ„å»ºtrainå’Œvalä¸¤è€…çš„æ•°æ®é›†ã€‚</li><li>setupå‡½æ•°ä¸éœ€è¦è¿”å›å€¼ã€‚åˆå§‹åŒ–å¥½çš„train/val/test setç›´æ¥èµ‹å€¼ç»™selfå³å¯ã€‚</li></ul></li><li><code>train_dataloader/val_dataloader/test_dataloader</code>ï¼š<ul><li>åˆå§‹åŒ–<code>DataLoader</code>ã€‚</li><li>è¿”å›ä¸€ä¸ªDataLoaderé‡ã€‚</li></ul></li></ul></li></ul><h3 id="ç¤ºä¾‹"><a class="markdownIt-Anchor" href="#ç¤ºä¾‹"></a> ç¤ºä¾‹</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MNISTDataModule</span>(<span class="params">pl.LightningDataModule</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, data_dir: <span class="built_in">str</span> = <span class="string">&#x27;./&#x27;</span>, batch_size: <span class="built_in">int</span> = <span class="number">64</span>, num_workers: <span class="built_in">int</span> = <span class="number">8</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.data_dir = data_dir</span><br><span class="line">        self.batch_size = batch_size</span><br><span class="line">        self.num_workers = num_workers</span><br><span class="line"></span><br><span class="line">        self.transform = transforms.Compose([</span><br><span class="line">            transforms.ToTensor(),</span><br><span class="line">            transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))</span><br><span class="line">        ])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># self.dims is returned when you call dm.size()</span></span><br><span class="line">        <span class="comment"># Setting default dims here because we know them.</span></span><br><span class="line">        <span class="comment"># Could optionally be assigned dynamically in dm.setup()</span></span><br><span class="line">        self.dims = (<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">        self.num_classes = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">prepare_data</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># download</span></span><br><span class="line">        MNIST(self.data_dir, train=<span class="literal">True</span>, download=<span class="literal">True</span>)</span><br><span class="line">        MNIST(self.data_dir, train=<span class="literal">False</span>, download=<span class="literal">True</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setup</span>(<span class="params">self, stage=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="comment"># Assign train/val datasets for use in dataloaders</span></span><br><span class="line">        <span class="keyword">if</span> stage == <span class="string">&#x27;fit&#x27;</span> <span class="keyword">or</span> stage <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            mnist_full = MNIST(self.data_dir, train=<span class="literal">True</span>, transform=self.transform)</span><br><span class="line">            self.mnist_train, self.mnist_val = random_split(mnist_full, [<span class="number">55000</span>, <span class="number">5000</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Assign test dataset for use in dataloader(s)</span></span><br><span class="line">        <span class="keyword">if</span> stage == <span class="string">&#x27;test&#x27;</span> <span class="keyword">or</span> stage <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            self.mnist_test = MNIST(self.data_dir, train=<span class="literal">False</span>, transform=self.transform)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train_dataloader</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> DataLoader(self.mnist_train, batch_size=self.batch_size, num_workers=self.num_workers)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">val_dataloader</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> DataLoader(self.mnist_val, batch_size=self.batch_size, num_workers=self.num_workers)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_dataloader</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> DataLoader(self.mnist_test, batch_size=self.batch_size, num_workers=self.num_workers)</span><br></pre></td></tr></table></figure><h3 id="è¦ç‚¹-2"><a class="markdownIt-Anchor" href="#è¦ç‚¹-2"></a> è¦ç‚¹</h3><ul><li>è‹¥åœ¨DataModuleä¸­å®šä¹‰äº†ä¸€ä¸ª<code>self.dims</code> å˜é‡ï¼Œåé¢å¯ä»¥è°ƒç”¨<code>dm.size()</code>è·å–è¯¥å˜é‡ã€‚</li></ul><h2 id="saving-and-loading"><a class="markdownIt-Anchor" href="#saving-and-loading"></a> Saving and Loading</h2><p><a href="https://pytorch-lightning.readthedocs.io/en/latest/common/weights_loading.html">ä¸»é¡µé¢</a></p><h3 id="saving"><a class="markdownIt-Anchor" href="#saving"></a> Saving</h3><ul><li><p><a href="https://pytorch-lightning.readthedocs.io/en/latest/extensions/generated/pytorch_lightning.callbacks.ModelCheckpoint.html#pytorch_lightning.callbacks.ModelCheckpoint">ModelCheckpoint</a>: è‡ªåŠ¨å‚¨å­˜çš„callback moduleã€‚é»˜è®¤æƒ…å†µä¸‹trainingè¿‡ç¨‹ä¸­åªä¼šè‡ªåŠ¨å‚¨å­˜æœ€æ–°çš„æ¨¡å‹ä¸ç›¸å…³å‚æ•°ï¼Œè€Œç”¨æˆ·å¯ä»¥é€šè¿‡è¿™ä¸ªmoduleè‡ªå®šä¹‰ã€‚å¦‚è§‚æµ‹ä¸€ä¸ª<code>val_loss</code>çš„é‡ï¼Œå¹¶å‚¨å­˜top 3å¥½çš„æ¨¡å‹ï¼Œä¸”åŒæ—¶å‚¨å­˜æœ€åä¸€ä¸ªepochçš„æ¨¡å‹ï¼Œç­‰ç­‰ã€‚ä¾‹ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pytorch_lightning.callbacks <span class="keyword">import</span> ModelCheckpoint</span><br><span class="line"></span><br><span class="line"><span class="comment"># saves a file like: my/path/sample-mnist-epoch=02-val_loss=0.32.ckpt</span></span><br><span class="line">checkpoint_callback = ModelCheckpoint(</span><br><span class="line">    monitor=<span class="string">&#x27;val_loss&#x27;</span>,</span><br><span class="line">    filename=<span class="string">&#x27;sample-mnist-&#123;epoch:02d&#125;-&#123;val_loss:.2f&#125;&#x27;</span>,</span><br><span class="line">    save_top_k=<span class="number">3</span>,</span><br><span class="line">    mode=<span class="string">&#x27;min&#x27;</span>,</span><br><span class="line">    save_last=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">trainer = pl.Trainer(gpus=<span class="number">1</span>, max_epochs=<span class="number">3</span>, progress_bar_refresh_rate=<span class="number">20</span>, callbacks=[checkpoint_callback])</span><br></pre></td></tr></table></figure></li><li><p>å¦å¤–ï¼Œä¹Ÿå¯ä»¥æ‰‹åŠ¨å­˜å‚¨checkpoint: <code>trainer.save_checkpoint(&quot;example.ckpt&quot;)</code></p></li><li><p><code>ModelCheckpoint</code> Callbackä¸­ï¼Œå¦‚æœ<code>save_weights_only =True</code>ï¼Œé‚£ä¹ˆå°†ä¼šåªå‚¨å­˜æ¨¡å‹çš„æƒé‡ï¼ˆç›¸å½“äº<code>model.save_weights(filepath)</code>ï¼‰ï¼Œåä¹‹ä¼šå‚¨å­˜æ•´ä¸ªæ¨¡å‹ï¼ˆç›¸å½“äº<code>model.save(filepath)</code>ï¼‰ã€‚</p></li></ul><h3 id="loading"><a class="markdownIt-Anchor" href="#loading"></a> Loading</h3><ul><li><p>loadä¸€ä¸ªæ¨¡å‹ï¼ŒåŒ…æ‹¬å®ƒçš„weightsã€biaseså’Œè¶…å‚æ•°ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">model = MyLightingModule.load_from_checkpoint(PATH)</span><br><span class="line"></span><br><span class="line">print(model.learning_rate)</span><br><span class="line"><span class="comment"># prints the learning_rate you used in this checkpoint</span></span><br><span class="line"></span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line">y_hat = model(x)</span><br></pre></td></tr></table></figure></li><li><p>loadæ¨¡å‹æ—¶æ›¿æ¢ä¸€äº›è¶…å‚æ•°ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LitModel</span>(<span class="params">LightningModule</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_dim, out_dim</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.save_hyperparameters()</span><br><span class="line">        self.l1 = nn.Linear(self.hparams.in_dim, self.hparams.out_dim)</span><br><span class="line">        </span><br><span class="line"><span class="comment"># if you train and save the model like this it will use these values when loading</span></span><br><span class="line"><span class="comment"># the weights. But you can overwrite this</span></span><br><span class="line">LitModel(in_dim=<span class="number">32</span>, out_dim=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># uses in_dim=32, out_dim=10</span></span><br><span class="line">model = LitModel.load_from_checkpoint(PATH)</span><br><span class="line"></span><br><span class="line"><span class="comment"># uses in_dim=128, out_dim=10</span></span><br><span class="line">model = LitModel.load_from_checkpoint(PATH, in_dim=<span class="number">128</span>, out_dim=<span class="number">10</span>)</span><br></pre></td></tr></table></figure></li><li><p>å®Œå…¨loadè®­ç»ƒçŠ¶æ€ï¼šloadåŒ…æ‹¬æ¨¡å‹çš„ä¸€åˆ‡ï¼Œä»¥åŠå’Œè®­ç»ƒç›¸å…³çš„ä¸€åˆ‡å‚æ•°ï¼Œå¦‚<code>model, epoch, step, LR schedulers, apex</code>ç­‰</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model = LitModel()</span><br><span class="line">trainer = Trainer(resume_from_checkpoint=<span class="string">&#x27;some/path/to/my_checkpoint.ckpt&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># automatically restores model, epoch, step, LR schedulers, apex, etc...</span></span><br><span class="line">trainer.fit(model)</span><br></pre></td></tr></table></figure></li></ul><h2 id="callbacks"><a class="markdownIt-Anchor" href="#callbacks"></a> Callbacks</h2><ul><li>Callback æ˜¯ä¸€ä¸ªè‡ªåŒ…å«çš„ç¨‹åºï¼Œå¯ä»¥ä¸è®­ç»ƒæµç¨‹äº¤ç»‡åœ¨ä¸€èµ·ï¼Œè€Œä¸ä¼šæ±¡æŸ“ä¸»è¦çš„ç ”ç©¶é€»è¾‘ã€‚</li><li>Callback å¹¶éåªä¼šåœ¨epochç»“å°¾è°ƒç”¨ã€‚pytorch-lightning æä¾›äº†æ•°åä¸ªhookï¼ˆæ¥å£ï¼Œè°ƒç”¨ä½ç½®ï¼‰å¯ä¾›é€‰æ‹©ï¼Œä¹Ÿå¯ä»¥è‡ªå®šä¹‰callbackï¼Œå®ç°ä»»ä½•æƒ³å®ç°çš„æ¨¡å—ã€‚</li><li>æ¨èä½¿ç”¨æ–¹å¼æ˜¯ï¼Œéšé—®é¢˜å’Œé¡¹ç›®å˜åŒ–çš„æ“ä½œï¼Œè¿™äº›å‡½æ•°å†™åˆ°lightning moduleé‡Œé¢ï¼Œè€Œç›¸å¯¹ç‹¬ç«‹ï¼Œç›¸å¯¹è¾…åŠ©æ€§çš„ï¼Œéœ€è¦å¤ç”¨çš„å†…å®¹åˆ™å¯ä»¥å®šä¹‰å•ç‹¬çš„æ¨¡å—ï¼Œä¾›åç»­æ–¹ä¾¿åœ°æ’æ‹”ä½¿ç”¨ã€‚</li></ul><h3 id="callbacksæ¨è"><a class="markdownIt-Anchor" href="#callbacksæ¨è"></a> Callbacksæ¨è</h3><p><a href="https://pytorch-lightning.readthedocs.io/en/latest/extensions/callbacks.html#built-in-callbacks">å†…å»ºCallbacks</a></p><ul><li><p><code>EarlyStopping(monitor='early_stop_on', min_delta=0.0, patience=3, verbose=False, mode='min', strict=True)</code>ï¼šæ ¹æ®æŸä¸ªå€¼ï¼Œåœ¨æ•°ä¸ªepochæ²¡æœ‰æå‡çš„æƒ…å†µä¸‹æå‰åœæ­¢è®­ç»ƒã€‚</p><blockquote><p>å‚æ•°ï¼š</p><ul><li><strong>monitor</strong> (<a href="https://docs.python.org/3/library/stdtypes.html#str"><code>str</code></a>) â€“ quantity to be monitored. Default: <code>'early_stop_on'</code>.</li><li><strong>min_delta</strong> (<a href="https://docs.python.org/3/library/functions.html#float"><code>float</code></a>) â€“ minimum change in the monitored quantity to qualify as an improvement, i.e. an absolute change of less than min_delta, will count as no improvement. Default: <code>0.0</code>.</li><li><strong>patience</strong> (<a href="https://docs.python.org/3/library/functions.html#int"><code>int</code></a>) â€“ number of validation epochs with no improvement after which training will be stopped. Default: <code>3</code>.</li><li><strong>verbose</strong> (<a href="https://docs.python.org/3/library/functions.html#bool"><code>bool</code></a>) â€“ verbosity mode. Default: <code>False</code>.</li><li><strong>mode</strong> (<a href="https://docs.python.org/3/library/stdtypes.html#str"><code>str</code></a>) â€“ one of <code>'min'</code>, <code>'max'</code>. In <code>'min'</code> mode, training will stop when the quantity monitored has stopped decreasing and in <code>'max'</code> mode it will stop when the quantity monitored has stopped increasing.</li><li><strong>strict</strong> (<a href="https://docs.python.org/3/library/functions.html#bool"><code>bool</code></a>) â€“ whether to crash the training if monitor is not found in the validation metrics. Default: <code>True</code>.</li></ul></blockquote><p>ç¤ºä¾‹ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pytorch_lightning <span class="keyword">import</span> Trainer</span><br><span class="line"><span class="keyword">from</span> pytorch_lightning.callbacks <span class="keyword">import</span> EarlyStopping</span><br><span class="line"></span><br><span class="line">early_stopping = EarlyStopping(<span class="string">&#x27;val_loss&#x27;</span>)</span><br><span class="line">trainer = Trainer(callbacks=[early_stopping])</span><br></pre></td></tr></table></figure></li><li><p><code>ModelCheckpoint</code>ï¼šè§ä¸Šæ–‡<strong>Saving and Loading</strong>.</p></li><li><p><code>PrintTableMetricsCallback</code>ï¼šåœ¨æ¯ä¸ªepochç»“æŸåæ‰“å°ä¸€ä»½ç»“æœæ•´ç†è¡¨æ ¼ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pl_bolts.callbacks <span class="keyword">import</span> PrintTableMetricsCallback</span><br><span class="line"></span><br><span class="line">callback = PrintTableMetricsCallback()</span><br><span class="line">trainer = pl.Trainer(callbacks=[callback])</span><br><span class="line">trainer.fit(...)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ------------------------------</span></span><br><span class="line"><span class="comment"># at the end of every epoch it will print</span></span><br><span class="line"><span class="comment"># ------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># lossâ”‚train_lossâ”‚val_lossâ”‚epoch</span></span><br><span class="line"><span class="comment"># â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€</span></span><br><span class="line"><span class="comment"># 2.2541470527648926â”‚2.2541470527648926â”‚2.2158432006835938â”‚0</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="logging"><a class="markdownIt-Anchor" href="#logging"></a> Logging</h2><ul><li><p><a href="https://pytorch-lightning.readthedocs.io/en/latest/extensions/logging.html">Logging</a>ï¼šLoggeré»˜è®¤æ˜¯TensorBoardï¼Œä½†å¯ä»¥æŒ‡å®šå„ç§ä¸»æµLogger<a href="https://pytorch-lightning.readthedocs.io/en/latest/extensions/logging.html#supported-loggers">æ¡†æ¶</a>ï¼Œ<a href="http://xn--Comet-gv5i.ml">å¦‚Comet.ml</a>ï¼ŒMLflowï¼ŒNetpuneï¼Œæˆ–ç›´æ¥CSVæ–‡ä»¶ã€‚å¯ä»¥åŒæ—¶ä½¿ç”¨å¤æ•°ä¸ªloggerã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pytorch_lightning <span class="keyword">import</span> loggers <span class="keyword">as</span> pl_loggers</span><br><span class="line"></span><br><span class="line"><span class="comment"># Default</span></span><br><span class="line">tb_logger = pl_loggers.TensorBoardLogger(</span><br><span class="line">    save_dir=os.getcwd(),</span><br><span class="line">    version=<span class="literal">None</span>,</span><br><span class="line">    name=<span class="string">&#x27;lightning_logs&#x27;</span></span><br><span class="line">)</span><br><span class="line">trainer = Trainer(logger=tb_logger)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Or use the same format as others</span></span><br><span class="line">tb_logger = pl_loggers.TensorBoardLogger(<span class="string">&#x27;logs/&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># One Logger</span></span><br><span class="line">comet_logger = pl_loggers.CometLogger(save_dir=<span class="string">&#x27;logs/&#x27;</span>)</span><br><span class="line">trainer = Trainer(logger=comet_logger)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Save code snapshot</span></span><br><span class="line">logger = pl_loggers.TestTubeLogger(<span class="string">&#x27;logs/&#x27;</span>, create_git_tag=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Multiple Logger</span></span><br><span class="line">tb_logger = pl_loggers.TensorBoardLogger(<span class="string">&#x27;logs/&#x27;</span>)</span><br><span class="line">comet_logger = pl_loggers.CometLogger(save_dir=<span class="string">&#x27;logs/&#x27;</span>)</span><br><span class="line">trainer = Trainer(logger=[tb_logger, comet_logger])</span><br></pre></td></tr></table></figure><p>é»˜è®¤æƒ…å†µä¸‹ï¼Œæ¯50ä¸ªbatch logä¸€æ¬¡ï¼Œå¯ä»¥é€šè¿‡è°ƒæ•´å‚æ•°</p></li><li><p>å¦‚æœæƒ³è¦logè¾“å‡ºéscalarï¼ˆæ ‡é‡ï¼‰çš„å†…å®¹ï¼Œå¦‚å›¾ç‰‡ï¼Œæ–‡æœ¬ï¼Œç›´æ–¹å›¾ç­‰ç­‰ï¼Œå¯ä»¥ç›´æ¥è°ƒç”¨<code>self.logger.experiment.add_xxx()</code>æ¥å®ç°æ‰€éœ€æ“ä½œã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">training_step</span>(<span class="params">...</span>):</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="comment"># the logger you used (in this case tensorboard)</span></span><br><span class="line">    tensorboard = self.logger.experiment</span><br><span class="line">    tensorboard.add_image()</span><br><span class="line">    tensorboard.add_histogram(...)</span><br><span class="line">    tensorboard.add_figure(...)</span><br></pre></td></tr></table></figure></li><li><p>ä½¿ç”¨logï¼šå¦‚æœæ˜¯TensorBoardï¼Œé‚£ä¹ˆï¼š<code>tensorboard --logdir ./lightning_logs</code>ã€‚åœ¨Jupyter Notebookä¸­ï¼Œå¯ä»¥ä½¿ç”¨ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Start tensorboard.</span></span><br><span class="line">%load_ext tensorboard</span><br><span class="line">%tensorboard --logdir lightning_logs/</span><br></pre></td></tr></table></figure><p>åœ¨è¡Œå†…æ‰“å¼€TensorBoardã€‚</p></li><li><p>å°æŠ€å·§ï¼šå¦‚æœåœ¨å±€åŸŸç½‘å†…å¼€å¯äº†TensorBoardï¼ŒåŠ ä¸Šflag <code>--bind_all</code>å³å¯ä½¿ç”¨ä¸»æœºåè®¿é—®ï¼š</p><p><code>tensorboard --logdir lightning_logs --bind_all</code> -&gt; <code>http://SERVER-NAME:6006/</code></p></li></ul><h3 id="åŒæ—¶ä½¿ç”¨tensorboardå’Œcsv-logger"><a class="markdownIt-Anchor" href="#åŒæ—¶ä½¿ç”¨tensorboardå’Œcsv-logger"></a> åŒæ—¶ä½¿ç”¨TensorBoardå’ŒCSV Logger</h3><p>å¦‚æœåŒæ—¶ä½¿ç”¨ä¸¤ä¸ªLoggerï¼ŒPLä¼šæœ‰ç¿æ™ºæ“ä½œï¼šå¦‚æœä¿å­˜æ ¹ç›®å½•ç›¸åŒï¼Œä»–ä»¬ä¼šä¾æ¬¡å»ºç«‹ä¸¤ä¸ªversionæ–‡ä»¶å¤¹ï¼Œä»¤äººçª’æ¯ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pytorch_lightning.loggers <span class="keyword">import</span> TensorBoardLogger, CSVLogger</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_loggers</span>():</span></span><br><span class="line">    loggers = []</span><br><span class="line">    loggers.append(TensorBoardLogger(</span><br><span class="line">        save_dir=<span class="string">&#x27;lightning_logs&#x27;</span>, name=<span class="string">&#x27;tb&#x27;</span></span><br><span class="line">    ))</span><br><span class="line"></span><br><span class="line">    loggers.append(CSVLogger(</span><br><span class="line">        save_dir=<span class="string">&#x27;lightning_logs&#x27;</span>, name=<span class="string">&#x27;csv&#x27;</span></span><br><span class="line">    ))</span><br><span class="line"></span><br><span class="line">    loggers.append(CometLogger(</span><br><span class="line">        save_dir=<span class="string">&#x27;lightning_logs&#x27;</span>, name=<span class="string">&#x27;tt&#x27;</span></span><br><span class="line">    ))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loggers</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_callbacks</span>(<span class="params">logger</span>):</span></span><br><span class="line">    callbacks = []</span><br><span class="line">    dirpath = <span class="string">f&#x27;lightning_logs/<span class="subst">&#123;logger.name&#125;</span>/version_<span class="subst">&#123;logger.version&#125;</span>/checkpoints&#x27;</span></span><br><span class="line">    callbacks.append(ModelCheckpoint(</span><br><span class="line">        dirpath=dirpath,</span><br><span class="line">        monitor=<span class="string">&#x27;loss_epoch&#x27;</span>,</span><br><span class="line">        filename=<span class="string">&#x27;&#123;epoch:02d&#125;-&#123;val_loss:.2f&#125;&#x27;</span>,</span><br><span class="line">        save_top_k=<span class="number">3</span>,</span><br><span class="line">        mode=<span class="string">&#x27;max&#x27;</span>,</span><br><span class="line">        save_last=<span class="literal">True</span></span><br><span class="line">    ))</span><br><span class="line">    <span class="keyword">return</span> callbacks</span><br><span class="line"></span><br><span class="line">loggers = load_loggers()</span><br><span class="line">callbacks = load_callbacks(loggers[<span class="number">0</span>])</span><br><span class="line">trainer = pl.Trainer(logger=loggers, callbacks=callbacks)</span><br></pre></td></tr></table></figure><h2 id="transfer-learning"><a class="markdownIt-Anchor" href="#transfer-learning"></a> Transfer Learning</h2><p><a href="https://pytorch-lightning.readthedocs.io/en/latest/starter/introduction_guide.html#transfer-learning">ä¸»é¡µé¢</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ImagenetTransferLearning</span>(<span class="params">LightningModule</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># init a pretrained resnet</span></span><br><span class="line">        backbone = models.resnet50(pretrained=<span class="literal">True</span>)</span><br><span class="line">        num_filters = backbone.fc.in_features</span><br><span class="line">        layers = <span class="built_in">list</span>(backbone.children())[:-<span class="number">1</span>]</span><br><span class="line">        self.feature_extractor = nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># use the pretrained model to classify cifar-10 (10 image classes)</span></span><br><span class="line">        num_target_classes = <span class="number">10</span></span><br><span class="line">        self.classifier = nn.Linear(num_filters, num_target_classes)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        self.feature_extractor.<span class="built_in">eval</span>()</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            representations = self.feature_extractor(x).flatten(<span class="number">1</span>)</span><br><span class="line">        x = self.classifier(representations)</span><br><span class="line">        ...</span><br></pre></td></tr></table></figure><h2 id="å…³äºdeviceæ“ä½œ"><a class="markdownIt-Anchor" href="#å…³äºdeviceæ“ä½œ"></a> å…³äºdeviceæ“ä½œ</h2><p>LightningModules know what device they are on! Construct tensors on the device directly to avoid CPU-&gt;Device transfer.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># bad</span></span><br><span class="line">t = torch.rand(<span class="number">2</span>, <span class="number">2</span>).cuda()</span><br><span class="line"></span><br><span class="line"><span class="comment"># good (self is LightningModule)</span></span><br><span class="line">t = torch.rand(<span class="number">2</span>, <span class="number">2</span>, device=self.device)</span><br></pre></td></tr></table></figure><p>For tensors that need to be model attributes, it is best practice to register them as buffers in the modulesâ€™s <code>__init__</code> method:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># bad</span></span><br><span class="line">self.t = torch.rand(<span class="number">2</span>, <span class="number">2</span>, device=self.device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># good</span></span><br><span class="line">self.register_buffer(<span class="string">&quot;t&quot;</span>, torch.rand(<span class="number">2</span>, <span class="number">2</span>))</span><br></pre></td></tr></table></figure><p>å‰é¢ä¸¤æ®µæ˜¯æ•™ç¨‹ä¸­çš„æ–‡æœ¬ã€‚ç„¶è€Œå®é™…ä¸Šæœ‰ä¸€ä¸ªæš—å‘ï¼š</p><p>å¦‚æœä½ ä½¿ç”¨äº†ä¸€ä¸ªä¸­ç»§çš„<code>pl.LightningModule</code>ï¼Œè€Œè¿™ä¸ªmoduleé‡Œé¢å®ä¾‹åŒ–äº†æŸä¸ªæ™®é€šçš„<code>nn.Module</code>ï¼Œè€Œè¿™ä¸ªæ¨¡å‹ä¸­åˆéœ€è¦å†…éƒ¨ç”Ÿæˆä¸€äº›tensorï¼Œæ¯”å¦‚å›¾ç‰‡æ¯ä¸ªé€šé“çš„meanï¼Œstdä¹‹ç±»ï¼Œé‚£ä¹ˆå¦‚æœä½ ä»<code>pl.LightningModule</code>ä¸­passä¸€ä¸ª<code>self.device</code>ï¼Œå®é™…ä¸Šåœ¨ä¸€å¼€å§‹è¿™ä¸ª<code>self.device</code>æ°¸è¿œæ˜¯<code>cpu</code>ã€‚æ‰€ä»¥å¦‚æœä½ åœ¨è°ƒç”¨çš„<code>nn.Module</code>çš„<code>__init__()</code>ä¸­åˆå§‹åŒ–ï¼Œä½¿ç”¨<code>to(device)</code>æˆ–å¹²è„†ä»€ä¹ˆéƒ½ä¸ç”¨ï¼Œç»“æœå°±æ˜¯å®ƒæ°¸è¿œéƒ½åœ¨<code>cpu</code>ä¸Šã€‚</p><p>ä½†æ˜¯ï¼Œç»è¿‡å®éªŒï¼Œè™½ç„¶<code>pl.LightningModule</code>åœ¨<code>__init__()</code>é˜¶æ®µ<code>self.device</code>è¿˜æ˜¯<code>cpu</code>ï¼Œå½“è¿›å…¥äº†<code>training_step()</code>ä¹‹åï¼Œå°±è¿…é€Ÿå˜ä¸ºäº†<code>cuda</code>ã€‚æ‰€ä»¥ï¼Œå¯¹äºå­æ¨¡å—ï¼Œæœ€ä½³æ–¹æ¡ˆæ˜¯ï¼Œä½¿ç”¨ä¸€ä¸ª<code>forward</code>ä¸­ä¼ å…¥çš„é‡ï¼Œå¦‚<code>x</code>ï¼Œä½œä¸ºä¸€ä¸ªreferenceå˜é‡ï¼Œç”¨<code>type_as</code>å‡½æ•°å°†åœ¨æ¨¡å‹ä¸­ç”Ÿæˆçš„tensoréƒ½æ”¾åˆ°å’Œè¿™ä¸ªå‚è€ƒå˜é‡ç›¸åŒçš„deviceä¸Šå³å¯ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RDNFuse</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">init_norm_func</span>(<span class="params">self, ref</span>):</span></span><br><span class="line">        self.mean = torch.tensor(np.array(self.mean_sen), dtype=torch.float32).type_as(ref)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">hasattr</span>(self, <span class="string">&#x27;mean&#x27;</span>):</span><br><span class="line">            self.init_norm_func(x)</span><br></pre></td></tr></table></figure><h2 id="å…³äºlimit_train_batchesé€‰é¡¹"><a class="markdownIt-Anchor" href="#å…³äºlimit_train_batchesé€‰é¡¹"></a> å…³äº<code>limit_train_batches</code>é€‰é¡¹</h2><p>è¿™é‡Œæ¶‰åŠåˆ°ä¸€ä¸ªé—®é¢˜ï¼Œå°±æ˜¯æ¯ä¸ªepochä½¿ç”¨éƒ¨åˆ†æ•°æ®è€Œéå…¨éƒ¨æ—¶ï¼Œç¨‹åºå°†ä¼šæ€ä¹ˆå·¥ä½œã€‚</p><blockquote><p>The shuffling happens when the iterator is created. In the case of the for loop, that happens just before the for loop starts. You can create the iterator manually with:</p></blockquote><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Iterator gets created, the data has been shuffled at this point.</span></span><br><span class="line">data_iterator = <span class="built_in">iter</span>(namesTrainLoader)</span><br></pre></td></tr></table></figure><blockquote><p>By default the data loader uses <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.RandomSampler"><code>torch.utils.data.RandomSampler</code></a> if you set <code>shuffle=True</code> (without providing your own sampler). Its implementation is very straight forward and you can see where the data is shuffled when the iterator is created by looking at the <a href="https://github.com/pytorch/pytorch/blob/f3e620ee83f080283445aa1a7242d40e30eb6a7f/torch/utils/data/sampler.py#L103-L107"><code>RandomSampler.__iter__</code></a> method:</p></blockquote><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__iter__</span>(<span class="params">self</span>):</span></span><br><span class="line">    n = <span class="built_in">len</span>(self.data_source)</span><br><span class="line">    <span class="keyword">if</span> self.replacement:</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">iter</span>(torch.randint(high=n, size=(self.num_samples,), dtype=torch.int64).tolist())</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">iter</span>(torch.randperm(n).tolist())</span><br></pre></td></tr></table></figure><blockquote><p>The return statement is the important part, where the shuffling takes place. It simply creates a random permutation of the indices.</p><p>That means you will see your entire dataset every time you fully consume the iterator, just in a different order every time. Therefore there is no data lost (not including cases with <code>drop_last=True</code>) and your model will see all data at every epoch.</p></blockquote><p>æ€»ç»“ä¸‹æ¥ï¼Œå¦‚æœä½¿ç”¨äº†<code>shuffle=True</code>é€‰é¡¹ï¼Œé‚£ä¹ˆå³ä½¿æ¯æ¬¡éƒ½ä¸è·‘å®Œæ•´ä¸ªepochï¼Œä½ è¿˜æ˜¯æœ‰æœºä¼šè§åˆ°æ‰€æœ‰çš„æ•°æ®çš„ã€‚æ•°æ®é›†çš„shuffleå‘ç”Ÿåœ¨<code>iter</code>è¢«åˆ›å»ºçš„æ—¶å€™ï¼Œåœ¨æˆ‘ä»¬ä¸€èˆ¬çš„ä»£ç ä¸­ï¼Œä¹Ÿå°±æ˜¯å†…å±‚forå¾ªç¯å¼€å§‹æ—¶ã€‚ä½†å¦‚æœä½ æ²¡æœ‰é€‰æ‹©<code>shuffle=True</code>ï¼Œé‚£ä½ å°†æ°¸è¿œåªèƒ½çœ‹åˆ°ä½ è®¾å®šçš„å‰é¢Nä¸ªæ•°æ®ã€‚</p><h2 id="points"><a class="markdownIt-Anchor" href="#points"></a> Points</h2><ul><li><p><code>pl.seed_everything(1234)</code>ï¼šå¯¹æ‰€æœ‰ç›¸å…³çš„éšæœºé‡å›ºå®šç§å­ã€‚</p></li><li><p>ä½¿ç”¨LR Scheduleræ—¶å€™ï¼Œä¸ç”¨è‡ªå·±<code>.step()</code>ã€‚å®ƒä¹Ÿè¢«Trainerè‡ªåŠ¨å¤„ç†äº†ã€‚<a href="https://pytorch-lightning.readthedocs.io/en/latest/common/optimizers.html?highlight=scheduler#">Optimization ä¸»é¡µé¢</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Single optimizer</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> epochs:</span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> data:</span><br><span class="line">        loss = model.training_step(batch, batch_idx, ...)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> scheduler <span class="keyword">in</span> schedulers:</span><br><span class="line">        scheduler.step()</span><br><span class="line">        </span><br><span class="line"><span class="comment"># Multiple optimizers</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> epochs:</span><br><span class="line">  <span class="keyword">for</span> batch <span class="keyword">in</span> data:</span><br><span class="line">     <span class="keyword">for</span> opt <span class="keyword">in</span> optimizers:</span><br><span class="line">        disable_grads_for_other_optimizers()</span><br><span class="line">        train_step(opt)</span><br><span class="line">        opt.step()</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> scheduler <span class="keyword">in</span> schedulers:</span><br><span class="line">     scheduler.step()</span><br></pre></td></tr></table></figure></li><li><p>å…³äºåˆ’åˆ†trainå’Œvalé›†åˆçš„æ–¹æ³•ã€‚ä¸PLæ— å…³ï¼Œä½†å¾ˆå¸¸ç”¨ï¼Œä¸¤ä¸ªä¾‹å­ï¼š</p><ol><li><code>random_split(range(10), [3, 7], generator=torch.Generator().manual_seed(42))</code></li><li>å¦‚ä¸‹ï¼š</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader, random_split</span><br><span class="line"><span class="keyword">from</span> torchvision.datasets <span class="keyword">import</span> MNIST</span><br><span class="line"></span><br><span class="line">mnist_full = MNIST(self.data_dir, train=<span class="literal">True</span>, transform=self.transform)</span><br><span class="line">self.mnist_train, self.mnist_val = random_split(mnist_full, [<span class="number">55000</span>, <span class="number">5000</span>])</span><br></pre></td></tr></table></figure><p>Parametersï¼š</p><ul><li><strong>dataset</strong> (<a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset"><em>Dataset</em></a>) â€“ Dataset to be split</li><li><strong>lengths</strong> (<em>sequence</em>) â€“ lengths of splits to be produced</li><li><strong>generator</strong> (<a href="https://pytorch.org/docs/stable/generated/torch.Generator.html#torch.Generator"><em>Generator</em></a>) â€“ Generator used for the random permutation.</li></ul></li><li><p>å¦‚æœä½¿ç”¨äº†<code>PrintTableMetricsCallback</code>ï¼Œé‚£ä¹ˆ<code>validation_step</code>ä¸è¦returnå†…å®¹ï¼Œå¦åˆ™ä¼šç‚¸ã€‚</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;pytorch-lighting&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#pytorch-lighting&quot;&gt;&lt;/a&gt; Pytorch-Lighting&lt;/h1&gt;
&lt;h2 id=&quot;å†™åœ¨å‰é¢&quot;&gt;&lt;a class=&quot;markdownI</summary>
      
    
    
    
    
    <category term="deep-learning" scheme="https://www.miracleyoo.com/tags/deep-learning/"/>
    
    <category term="pytorch" scheme="https://www.miracleyoo.com/tags/pytorch/"/>
    
    <category term="pytorch-lightning" scheme="https://www.miracleyoo.com/tags/pytorch-lightning/"/>
    
  </entry>
  
  <entry>
    <title>Macã€Windowsã€iPadä¸‰ç«¯å®Œç¾è®ºæ–‡ç®¡ç†ã€é˜…è¯»ä¸ç¼–è¾‘ç³»ç»Ÿé…ç½®</title>
    <link href="https://www.miracleyoo.com/2020/04/26/paper-zotero-dropbox/"/>
    <id>https://www.miracleyoo.com/2020/04/26/paper-zotero-dropbox/</id>
    <published>2020-04-26T22:09:00.000Z</published>
    <updated>2020-04-26T22:09:00.050Z</updated>
    
    <content type="html"><![CDATA[<p>ç®¡ç†å¥½è‡ªå·±æ‰‹ä¸­çš„è®ºæ–‡ï¼Œä¸è®©ä»–ä»¬è¢«åå™¬ä¸â€œDownloadâ€æ–‡ä»¶å¤¹çš„èŒ«èŒ«æ–‡ä»¶æµ·æ´‹ä¸­å·²éæ˜“äº‹ï¼Œè€Œèƒ½åœ¨éœ€è¦æ—¶è¿…é€Ÿå®šä½ï¼Œèƒ½åœ¨Windowsçš„Desktopä¸ä¾¿æºçš„MacBookä¸Šæ— ç¼å¯¹æ¥è®ºæ–‡åº“åˆ™éœ€è¦ç›¸å¯¹ç²¾ç»†åŒ–çš„ç®¡ç†ã€‚ç„¶è€Œï¼Œå¾ˆå¤šæ—¶å€™å¹¶ä¸é€‚åˆå±•å¼€è‡ªå·±çš„ç¬”è®°æœ¬ç”µè„‘æ¥â€œéƒ‘é‡â€åœ°é˜…è¯»ä¸€ç¯‡è®ºæ–‡ï¼Œåœ¨ä¸€äº›ç›¸å¯¹é›¶ç¢çš„æ—¶é—´é‡Œéšæ‰‹æŠ½å‡ºåŒ…ä¸­çš„iPadï¼Œè¯»è¯»å‰é¢é¡ºæ‰‹å­˜ä¸‹çš„è®ºæ–‡ï¼Œåˆ™å¯å¤§å¤§å¢åŠ è‡ªå·±çš„å­¦æœ¯å¹¸ç¦æ„Ÿã€‚</p><h2 id="éœ€æ±‚åˆ†æ"><a class="markdownIt-Anchor" href="#éœ€æ±‚åˆ†æ"></a> éœ€æ±‚åˆ†æ</h2><p>ä¸Šé¢è¿™å‡ ç‚¹ä¹Ÿæ­£æ˜¯æˆ‘å¯¹è®ºæ–‡ç®¡ç†ç³»ç»Ÿçš„è¦æ±‚ã€‚æ³¨æ„è¿™é‡Œæåˆ°çš„æ˜¯â€œç³»ç»Ÿâ€ï¼Œè€Œå¹¶æ˜¯ä¸€ä¸ªå•ä¸€çš„è½¯ä»¶ã€‚è¿™é‡Œæç‚¼ä¸€ä¸‹æ—¥å¸¸å¯¹è®ºæ–‡ç®¡ç†åŠé˜…è¯»çš„éœ€æ±‚ï¼Œæ‚¨å¯ä»¥çœ‹çœ‹å’Œè‡ªå·±çš„éœ€æ±‚æ˜¯å¦å»åˆï¼š</p><ol><li>ä»¥åˆ†å±‚ç›®å½•çš„å½¢å¼å°†è®ºæ–‡è¿›è¡Œå½’æ¡£ï¼Œå¹¶ä¸”æœ‰æ—¶éœ€è¦è®©åŒä¸€ç¯‡è®ºæ–‡åŒæ—¶å­˜æ”¾äºå¤šä¸ªç›®å½•ä¸­ã€‚</li><li>æ”¯æŒå¤šåŠç›®å½•ï¼ˆå¤š&gt;2ï¼‰ã€‚</li><li>æ”¯æŒä»ç½‘é¡µä¸Šä¾¿æ·åœ°å‚¨å­˜è®ºæ–‡ä»¥åŠæ–‡æ¡£ã€‚</li><li>æ”¯æŒæ‹–å…¥PDFè‡ªåŠ¨å¯»æ‰¾è®ºæ–‡ä¿¡æ¯ã€‚</li><li>éœ€è¦å¯¹è®ºæ–‡çš„PDFåŸä»¶è¿›è¡Œå­˜å‚¨ï¼Œæœ€å¥½èƒ½å¤Ÿè‡ªåŠ¨ä¸‹è½½ç¼ºå¤±çš„PDFã€‚</li><li>éœ€è¦åœ¨Macå’ŒWindowsç«¯éƒ½èƒ½è®¿é—®è®ºæ–‡ç›®å½•ï¼Œä¸”å¯¹PDFæ–‡ä»¶çš„ä¿®æ”¹èƒ½å¤ŸåŒæ­¥ã€‚</li><li>PDFçš„å­˜å‚¨æœ€å¥½å’Œæ•°æ®åº“ç³»ç»Ÿåˆ†ç¦»ï¼Œä»¥ä¾¿æœç´¢ã€å•ç‹¬æ›´æ”¹æˆ–è®¿é—®ã€‚</li><li>éœ€è¦å¯¹è®ºæ–‡è¿›è¡Œå¯è‡ªå®šä¹‰æ ¼å¼çš„è‡ªåŠ¨é‡å‘½åã€‚</li><li>ç•Œé¢ä¸èƒ½å¤ªä¸‘ã€‚</li><li>æ”¯æŒé«˜åº¦è‡ªå®šä¹‰æˆ–æœ‰å……è¶³çš„åŠŸèƒ½ï¼Œæœ€å¥½å¯ä»¥ä½¿ç”¨ç¬¬ä¸‰æ–¹æ’ä»¶ã€‚</li><li>æ”¯æŒå„ç§å¼•æ–‡æ ¼å¼ã€‚</li><li>æ”¯æŒLatexå’ŒWordçš„ä¾¿æ·å¼•ç”¨ï¼ŒWordæœ€å¥½æœ‰æ’ä»¶ã€‚</li><li>æ‹¥æœ‰è¾ƒå¤§çš„äº‘å­˜å‚¨ç©ºé—´ï¼Œè‡³å°‘è¶³ä»¥å­˜å‚¨æ‰€æœ‰çš„PDFæ–‡æ¡£ã€‚</li><li>å¯ä»¥ä»iPadä¸Šè®¿é—®å¹¶ä¸”å¯ä»¥åŒæ­¥ã€ä¸Šä¼ å¯¹è®ºæ–‡çš„æ›´æ”¹ã€‚</li><li>ä¸‰ä¸ªå¹³å°PDFé˜…è¯»å™¨é…ç½®æœ€å¥½ç»Ÿä¸€ï¼Œä»¥å…é«˜äº®ã€æ’å…¥æ–‡æœ¬ç­‰æ ¼å¼ä¸ä¸€ã€‚</li></ol><p>å½’çº³å‡ºçš„è¿™å‡ ç‚¹ä¾¿æ˜¯æˆ‘å¯¹è®ºæ–‡ç®¡ç†ç³»ç»Ÿçš„æ‰€æœ‰éœ€æ±‚äº†ã€‚ä¹‹åä¾¿æ˜¯å¯¹å„ç§è®ºæ–‡ç®¡ç†è½¯ä»¶çš„è¯•ç”¨å’Œç»„åˆã€‚è¿™é‡Œç›´å¥”ä¸»é¢˜ï¼Œç»™å‡ºæˆ‘ç°åœ¨çš„å…¨å¥—ç³»ç»Ÿé…ç½®åŠé€‰æ‹©çš„åŸå› ã€‚</p><h2 id="ç³»ç»Ÿé…ç½®"><a class="markdownIt-Anchor" href="#ç³»ç»Ÿé…ç½®"></a> ç³»ç»Ÿé…ç½®</h2><ul><li>Macä¸Windowsç«¯ä¸»è®ºæ–‡ç®¡ç†è½¯ä»¶ï¼š<a href="https://www.zotero.org/">Zotero</a></li><li>ä¸»è¦æ’ä»¶ï¼š<a href="http://zotfile.com/">zotfile</a>ï¼Œ<a href="https://github.com/retorquere/zotero-better-bibtex">zotero-better-bibtex</a></li><li>Macã€Windowsä¸iPadç»Ÿä¸€PDFåŒæ­¥è½¯ä»¶ï¼šDropbox</li><li>Macã€Windowsä¸iPadç»Ÿä¸€PDFé˜…è¯»å™¨ï¼šAdobe Acrobat</li></ul><h2 id="é€‰ç”¨åŸå› "><a class="markdownIt-Anchor" href="#é€‰ç”¨åŸå› "></a> é€‰ç”¨åŸå› </h2><h3 id="zotero"><a class="markdownIt-Anchor" href="#zotero"></a> Zotero</h3><p>å„å¤§å¹³å°ä¸Šä»¥åŠZoteroå®˜ç½‘å¯¹å…¶è®²è§£éƒ½å¾ˆå¤šä¹Ÿå¾ˆå……åˆ†äº†ï¼Œå¦‚æœä½ èƒ½å¤Ÿå¹¶ä¸”æ„¿æ„èŠ±ä¸Šä¸€äº›æ—¶é—´æ¥è¿›è¡Œè‡ªå®šä¹‰é…ç½®ï¼Œå®ƒå°†æ˜¯ä¸€ä¸ªå¯ä»¥æ»¡è¶³å‡ ä¹æ‰€æœ‰å¯¹è®ºæ–‡ç®¡ç†éœ€æ±‚çš„ç»ˆæè½¯ä»¶ã€‚æˆ‘è¿™é‡ŒåªæŒ‡å‡ºä¸€äº›æˆ‘è®¤ä¸ºéå¸¸ä¸é”™çš„ç‰¹æ€§ã€‚</p><ol><li>è·¨å¹³å°ã€‚Macï¼ŒWindowså’ŒLinuxéƒ½æœ‰æ”¯æŒã€‚</li><li>æµè§ˆå™¨è®ºæ–‡æŠ“å–æ’ä»¶å¾ˆå¥½ç”¨ã€‚æ—¢å¯ç›´æ¥æŠ“å–PDFæ–‡ç« ä¹‹åè§£æå‡ºè®ºæ–‡ï¼Œä¹Ÿå¯åœ¨å¦‚Google Scholarç­‰é¡µé¢ç›´æ¥æ‰¹é‡æŠ“å–æ·»åŠ è®ºæ–‡ç´¢å¼•ï¼Œå¹¶å†è‡ªåŠ¨ä¸‹è½½ç›¸åº”çš„PDFã€‚ç”šè‡³åœ¨ä¸€äº›ä½œä¸šæ€§è´¨çš„å°è®ºæ–‡ä¸­æœ‰æ—¶éœ€è¦ç›´æ¥å¼•ç”¨æŸä¸ªç½‘é¡µæˆ–æŸä¸ªæ–‡æ¡£ï¼Œå®ƒä¹Ÿå¯ä»¥ç›´æ¥ç”Ÿæˆæ¡ç›®ã€‚</li><li>æ”¯æŒå¤šçº§ç›®å½•ã€‚è¿™ä¸ªå¤šç†è®ºä¸Šä¼¼ä¹å¯ä»¥æ— é™å¤šä¸‹å»ï¼Œéå¸¸è‡ªç”±ã€‚</li><li>æœ‰å¾ˆå¥½ç”¨çš„Wordæ’ä»¶ï¼Œä½¿ç”¨ä½“éªŒä¸æ»‘æµç•…ã€‚</li><li>æ‹¥æœ‰åœ¨çº¿çš„åºå¤§å¼•ç”¨æ ¼å¼åº“ï¼ŒåŸºæœ¬å¯ä»¥æ‰¾åˆ°æ‰€æœ‰éœ€è¦çš„å¼•æ–‡æ ¼å¼ã€‚</li><li>å¯ä»¥åŠ è½½å¾ˆå¤šç¬¬ä¸‰æ–¹æ’ä»¶ï¼Œå¦‚æ”¯æŒè‡ªå®šä¹‰æ ¼å¼é‡å‘½åçš„zotfileï¼Œé’ˆå¯¹è¾“å‡ºå¼•ç”¨è¿›è¡Œä¼˜åŒ–çš„better-bibtexç­‰ã€‚</li><li>å¯ä»¥å°†æ¡ç›®çš„PDFæ–‡ä»¶å‚¨å­˜ç›®å½•å•åˆ—å‡ºæ¥ï¼Œå­˜åˆ°ä¸€ä¸ªè‡ªå®šä¹‰çš„åœ°æ–¹ï¼Œæ¯”å¦‚Dropboxæ–‡ä»¶å¤¹å†…éƒ¨ã€‚</li></ol><h3 id="dropbox"><a class="markdownIt-Anchor" href="#dropbox"></a> Dropbox</h3><ol><li>å› ä¸ºç°åœ¨åœ¨ç¾å›½è¯»ä¹¦ï¼ŒDropboxçš„æœåŠ¡ç›¸å¯¹æ¥è¯´æ˜¯å¿«é€Ÿä¸”ç¨³å®šçš„ã€‚</li><li>Dropboxçš„åŒæ­¥åŠŸèƒ½åšçš„éå¸¸å¥½ï¼Œè¿™ä¹Ÿæ˜¯å…¶åœ¨æ­¤é¢†åŸŸæ·±è€•å¤šå¹´çš„ç»“æœã€‚</li><li>æœ€é‡è¦ä¸€ç‚¹ï¼ŒDropboxåœ¨iPadä¸Šå’ŒAdobe Acrobatæœ‰ç€åŸç”Ÿçš„é›†æˆã€‚åœ¨Dropboxä¸­ä½¿ç”¨Acrobatæ‰“å¼€å¹¶ç¼–è¾‘æ–‡ä»¶ï¼Œå…¶ä¿®æ”¹æ˜¯å¯ä»¥ç›´æ¥åŒæ­¥åˆ°Dropboxäº‘ç«¯çš„ã€‚è¿™ä¸€ç‚¹å¯¹äºç§»åŠ¨ç«¯æµè§ˆå’Œç¼–è¾‘è®ºæ–‡èµ·åˆ°äº†è‡³å…³é‡è¦çš„ä½œç”¨ã€‚</li><li>å…è´¹ç‰ˆè™½ç„¶åªæœ‰2Gåˆå§‹ç©ºé—´ï¼Œä½†æ˜¯å¯ä»¥é€šè¿‡é‚€è¯·å¥½å‹æ³¨å†Œè¾¾åˆ°æœ€å¤§çš„18Gã€‚è™½ç„¶ä¸æ˜¯ç‰¹åˆ«å¤§ï¼Œä½†æ˜¯å¯¹äºå­˜å‚¨è®ºæ–‡å·²ç»ç»°ç»°æœ‰ä½™äº†ã€‚ï¼ˆå¦è¿™ä¸ªé‚€è¯·æ³¨å†Œé€ç©ºé—´å¯ä»¥ç›´æ¥å»æ·˜å®æœç´¢ï¼Œå¯ä»¥ç”»å¾ˆå°‘çš„é’±å¾—åˆ°å¾ˆå¤šæ³¨å†ŒæœåŠ¡ï¼Œç›´è¾¾18Gã€‚ï¼‰</li></ol><h3 id="adobe-acrobat"><a class="markdownIt-Anchor" href="#adobe-acrobat"></a> Adobe Acrobat</h3><ol><li>å¤šå¹³å°æ”¯æŒã€‚Macï¼ŒWindowsï¼ŒLinuxï¼ŒiOSï¼ŒAndroidéƒ½æœ‰ç€å¾ˆå¥½çš„æ”¯æŒã€‚</li><li>ä¸“ä¸šï¼Œæ”¯æŒå„ç§ç¼–è¾‘æ–¹å¼ã€‚å¸¸è§çš„é«˜äº®ã€ä¸‹åˆ’çº¿ã€æ·»åŠ æ–‡æœ¬ã€ç”»æ–¹æ¡†ã€åšæ‰¹æ³¨ç­‰è‡ªç„¶éƒ½æ˜¯æ”¯æŒçš„ã€‚</li><li>å¾ˆå¤šé«˜æ ¡éƒ½å’ŒAdobeå…¬å¸æœ‰ç€åè®®ï¼Œä½¿ç”¨å­¦ç”Ÿé‚®ç®±å¯ä»¥ç›´æ¥å…è´¹ä½¿ç”¨å…¨å¥—åŠŸèƒ½ã€‚</li><li>åŒå‰é¢æ‰€è¿°ï¼Œå…¶å’ŒDropboxçš„å…³è”æ€§æ”¯æŒæ˜¯æ•´å¥—ç³»ç»ŸæˆåŠŸçš„å…³é”®ã€‚</li></ol><h3 id="å¯¹æ¯”åŸå› "><a class="markdownIt-Anchor" href="#å¯¹æ¯”åŸå› "></a> å¯¹æ¯”åŸå› </h3><ol><li>ä¹‹å‰æœ‰åœ¨ç”¨Mendeleyï¼Œä½†æ˜¯å¯¹æ¯”Zoteroï¼Œå°¤å…¶æ˜¯å¯¹æ¯”Zoteroå’Œå…¶ç¬¬ä¸‰æ–¹æ’ä»¶çš„ä¸°å¯ŒåŠŸèƒ½åï¼Œå‰è€…æ˜æ˜¾åŠ›ä¸ä»å¿ƒã€‚å¦å¤–Windowsç‰ˆæœ¬å…¶ç•Œé¢æ²¡æœ‰é’ˆå¯¹é«˜åˆ†è¾¨ç‡è¿›è¡Œé€‚é…ï¼Œå¹¶ä¸”ä½¿ç”¨äº†é»˜è®¤çš„å®‹ä½“ï¼Œæ˜¾ç¤ºè‹±æ–‡ä¸‘é™‹ä¸å ªï¼Œä¸”æ— æ³•æ›´æ”¹ã€‚åœ¨è®ºå›ä¸Šçœ‹åˆ°æœ‰è®¸å¤šå›å‹å‡ å¹´å‰å°±æå‡ºäº†è¿™äº›é—®é¢˜ï¼Œç„¶è€Œæ˜¾ç„¶å¼€å‘è€…å¹¶æ²¡æœ‰åšå‡ºç›¸åº”ã€‚å¯¹æ¯”Zoteroï¼Œå…¶è®ºå›ç¯å¢ƒã€æ´»è·ƒç¨‹åº¦ä»¥åŠé—®é¢˜è§£å†³é€Ÿåº¦éƒ½ä¼šæ›´å¥½ã€‚</li><li>Endnoteæ˜¯æ”¶è´¹è½¯ä»¶ï¼Œæˆ‘å¹¶æ²¡æœ‰æ·±å…¥ä½¿ç”¨ï¼Œè¿™é‡Œä¸å¤šç½®è¯„ï¼Œä½†å„ä½å¯ä»¥å®¹æ˜“æŸ¥åˆ°Endnoteå’ŒZoteroçš„åŒºåˆ«ã€‚</li><li>iPadä¸Šä¹Ÿè€ƒè™‘è¿‡ä½¿ç”¨PDF Reader â€“ Document Expertä½œä¸ºæµè§ˆå’Œç¼–è¾‘è½¯ä»¶ï¼Œä½†æ˜¯ä»Dropboxæ‰“å¼€çš„æ–‡ä»¶ç¼–è¾‘åæ˜¯ä»¥å‰¯æœ¬çš„å½¢å¼å­˜åœ¨äº†æœ¬åœ°ï¼Œå¹¶æ²¡æœ‰è¢«åŒæ­¥ï¼Œè¿™æ˜¯æ— æ³•æ¥å—çš„ã€‚</li></ol><h2 id="é…ç½®ç»†èŠ‚"><a class="markdownIt-Anchor" href="#é…ç½®ç»†èŠ‚"></a> é…ç½®ç»†èŠ‚</h2><h3 id="zoteroè®¾ç½®éƒ¨åˆ†"><a class="markdownIt-Anchor" href="#zoteroè®¾ç½®éƒ¨åˆ†"></a> Zoteroè®¾ç½®éƒ¨åˆ†</h3><ol><li>åœ¨æ‰€æœ‰éœ€è¦åŒæ­¥çš„ç”µè„‘ä¸Šç™»å½•Zoteroçš„è´¦å·ï¼Œå¦‚æ²¡æœ‰ï¼Œè¯·æ³¨å†Œã€‚</li><li>æ‰“å¼€è®¾ç½®ï¼Œæ›´æ”¹<code>Files and Folders</code> ä¸­çš„<code>Base Directory</code>é€‰é¡¹ä¸ºä½ çš„åŒæ­¥ç›˜åœ°å€ï¼Œå¦‚Dropboxï¼ŒOneDriveï¼Œåšæœäº‘ç­‰ã€‚è¯·ä¸è¦åŠ¨ä¸‹é¢çš„<code>Data Directory Location</code>ï¼Œè¿™ä¸ªæ˜¯Zoteroçš„æ€»ä½“æ•°æ®åº“çš„åœ°å€ï¼Œä¸å»ºè®®æ”¾åˆ°äº‘æ–‡ä»¶å¤¹ä¸‹ï¼Œå› ä¸ºåªè¦æœ‰ä¸¤ä¸ªç«¯åŒæ—¶ä½¿ç”¨Zoteroè¿™ä¸ªåŒæ­¥å°±å´©æ‰äº†ã€‚</li></ol><p><img src="/2020/04/26/paper-zotero-dropbox/image-20191110225913571.png" alt="image-20191110225913571"></p><ol start="3"><li>å®‰è£…<a href="http://zotfile.com/">zotfile</a>ã€‚æ›´æ”¹æœ‰å…³æ–‡ä»¶çš„è®¾ç½®ã€‚</li></ol><p>ä»Toolsæ è¿›å…¥ZotFile Preference</p><p><img src="/2020/04/26/paper-zotero-dropbox/image-20191110230601630.png" alt="image-20191110230601630"></p><p>æ›´æ”¹PDFæ–‡ä»¶å­˜å‚¨ä½ç½®ã€‚è¿™é‡Œæ˜¯æŠŠæ–‡ä»¶å‚¨å­˜åˆ°äº‘ç›˜çš„å…³é”®æ­¥éª¤ã€‚ä¸Šé¢é‚£ä¸ªæ›´æ”¹æ–‡ä»¶å­˜å‚¨åœ°å€çš„ä½œç”¨æ˜¯æŒ‡å®šæœªæ¥åŠ å…¥çš„PDFæ–‡ä»¶çš„å­˜å‚¨åœ°å€ï¼Œè€Œè¿™é‡Œæ˜¯æŠŠå·²ç»åœ¨åº“çš„æ–‡ä»¶ç§»åŠ¨åˆ°è¿™ä¸ªåœ°å€ã€‚ä¸¤ä¸ªåœ°å€ç›¸åŒã€‚</p><p><img src="/2020/04/26/paper-zotero-dropbox/image-20191110230944192.png" alt="image-20191110230944192"></p><p>æ›´æ”¹é‡å‘½åç›¸å…³çš„è®¾ç½®ã€‚è¿™é‡Œçš„%yå°±æ˜¯è®ºæ–‡å‘è¡¨å¹´ä»½ï¼Œ%jæ˜¯æœŸåˆŠåï¼Œ%tæ˜¯è®ºæ–‡æ ‡é¢˜ã€‚è€Œä¸­é—´çš„ä¸‹åˆ’çº¿åˆ™åªæ˜¯å•çº¯çš„ä¼šåœ¨é‡å‘½ååçš„æ–‡ä»¶åä¸­çš„ä¸¤ä¸ªå…ƒç´ ä¹‹é—´åŠ ä¸€ä¸ªä¸‹æ»‘çº¿ç½¢äº†ï¼Œè¿™é‡Œå¯ä»¥æ›¿æ¢åšä»»æ„ã€‚</p><p><img src="/2020/04/26/paper-zotero-dropbox/image-20191110230654373.png" alt="image-20191110230654373"></p><p>åœ¨ä½ çš„æ‰€æœ‰éœ€è¦åŒæ­¥çš„ç”µè„‘ä¸Šåšå®Œä¸Šè¿°æ­¥éª¤åï¼Œå¦‚æœä½ ä¹‹å‰æ²¡æœ‰Zoteroæˆ–å®ƒæ˜¯å…¨æ–°çš„æ²¡æœ‰æ¡ç›®ï¼Œé‚£ä½ çš„è®¾å®šå·²ç»ç»“æŸã€‚å¦‚æœåº“ä¸­å·²æœ‰å¾ˆå¤šè®ºæ–‡ï¼Œæƒ³è¦ç›´æ¥ç§»åŠ¨åˆ°Dropboxç›¸åº”ç›®å½•ä¸‹ï¼Œé‚£ä¹ˆè¯·æ‰§è¡Œä¸‹ä¸€æ­¥ï¼š</p><ol start="4"><li>ç§»åŠ¨ä¸é‡å‘½åå·²æœ‰æ–‡ä»¶</li></ol><p><img src="/2020/04/26/paper-zotero-dropbox/image-20191110231928468.png" alt="image-20191110231928468"></p><p>ç‚¹å‡» My Libraryï¼Œå…¨é€‰æ‰€æœ‰æ¡ç›®ï¼Œå³é”®é€‰æ‹©<code>Manage Attachments</code>-&gt;<code>Rename Attachments</code>å¼€å§‹ç§»åŠ¨å’Œé‡å‘½åã€‚</p><p><img src="/2020/04/26/paper-zotero-dropbox/image-20191110232045736.png" alt="image-20191110232045736"></p><p><img src="/2020/04/26/paper-zotero-dropbox/image-20191110232150562.png" alt="image-20191110232150562"></p><h3 id="ipadè®¾ç½®éƒ¨åˆ†"><a class="markdownIt-Anchor" href="#ipadè®¾ç½®éƒ¨åˆ†"></a> iPadè®¾ç½®éƒ¨åˆ†</h3><ol><li>ä¸‹è½½Dropboxå’ŒAcrobatã€‚</li><li>æ‰“å¼€Dropboxï¼Œè¿›å…¥ä½ çš„è®ºæ–‡åŒæ­¥æ–‡ä»¶å¤¹ï¼Œä»»é€‰ä¸€ç¯‡ç‚¹å‡»æ‰“å¼€</li><li>å³ä¸‹è§’æ‰¾åˆ°ä¸€ä¸ªå…‰æ ‡é”®ï¼Œç‚¹å‡»ï¼Œä¼šæç¤ºç”¨Adobe Acrobat Readeræ‰“å¼€ã€‚</li><li>All set.</li></ol><p><img src="/2020/04/26/paper-zotero-dropbox/IMG_2601.jpg" alt="IMG_2601"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;ç®¡ç†å¥½è‡ªå·±æ‰‹ä¸­çš„è®ºæ–‡ï¼Œä¸è®©ä»–ä»¬è¢«åå™¬ä¸â€œDownloadâ€æ–‡ä»¶å¤¹çš„èŒ«èŒ«æ–‡ä»¶æµ·æ´‹ä¸­å·²éæ˜“äº‹ï¼Œè€Œèƒ½åœ¨éœ€è¦æ—¶è¿…é€Ÿå®šä½ï¼Œèƒ½åœ¨Windowsçš„Desktopä¸ä¾¿æºçš„MacBookä¸Šæ— ç¼å¯¹æ¥è®ºæ–‡åº“åˆ™éœ€è¦ç›¸å¯¹ç²¾ç»†åŒ–çš„ç®¡ç†ã€‚ç„¶è€Œï¼Œå¾ˆå¤šæ—¶å€™å¹¶ä¸é€‚åˆå±•å¼€è‡ªå·±çš„ç¬”è®°æœ¬ç”µè„‘æ¥â€œéƒ‘é‡â€åœ°é˜…è¯»ä¸€ç¯‡è®ºæ–‡</summary>
      
    
    
    
    
    <category term="tool" scheme="https://www.miracleyoo.com/tags/tool/"/>
    
    <category term="paper" scheme="https://www.miracleyoo.com/tags/paper/"/>
    
  </entry>
  
  <entry>
    <title>é¿å…è„æ´»ï¼Œå®Œç¾ä½¿ç”¨Markdownåœ¨çŸ¥ä¹ç¼–è¾‘å†…å®¹</title>
    <link href="https://www.miracleyoo.com/2020/04/26/markdown-4-zhihu/"/>
    <id>https://www.miracleyoo.com/2020/04/26/markdown-4-zhihu/</id>
    <published>2020-04-26T22:01:57.000Z</published>
    <updated>2020-04-26T22:04:53.940Z</updated>
    
    <content type="html"><![CDATA[<p>çŸ¥ä¹ä¸Šçš„æœ¬æ–‡é“¾æ¥ï¼š<a href="https://zhuanlan.zhihu.com/p/97455277">Link</a></p><p>é¦–å…ˆåæ§½ä¸€ä¸‹çŸ¥ä¹çš„ç¼–è¾‘å™¨ã€‚è™½ç„¶ä¸ªäººåšå®¢ä¸Šçš„ä¸å°‘å†…å®¹éƒ½æ›¾æœ‰æƒ³è¿‡æ¬åˆ°çŸ¥ä¹ä¸€ä»½ï¼Œä½†æ˜¯çŸ¥ä¹çš„ç¼–è¾‘å™¨çœŸçš„æ˜¯ä»¤äººç»æœ›å¼çš„éš¾ç”¨ã€‚å°½ç®¡ç°åœ¨å¯ä»¥ä½¿ç”¨æ–‡ä»¶å¯¼å…¥åŠŸèƒ½å¯¼å…¥mdæ–‡ä»¶å’ŒWordæ–‡æ¡£ï¼Œä¸”èƒ½æ”¯æŒä¸€äº›ç®€å•çš„Markdownè¯­æ³•ï¼Œä½†æ¯ç§é€”å¾„éƒ½æœ‰ç€æ— æ³•é¿å…çš„ç¼ºç‚¹ï¼Œä»ç»“æœä¸Šæ¥è¯´åˆ™æ˜¯åªèƒ½è¢«è¿«æ¥å—æˆ–æ˜¯ä¸å®Œç¾çš„æ ¼å¼äº¦æˆ–æ˜¯å¤§é‡æ‰‹åŠ¨ä¸”é‡å¤çš„å›¾ç‰‡ä¸Šä¼ ã€‚</p><p>å£è¯´æ— å‡­ï¼Œè¿™é‡Œæ”¾ä¸€ä¸‹å‡ ç§æ–¹æ³•çš„å¯¹æ¯”å›¾æ¥è¯¦è¿°ä¸€ä¸‹é—®é¢˜æ‰€åœ¨ï¼š</p><h3 id="typoraä¸­åŸæ–‡ä»¶"><a class="markdownIt-Anchor" href="#typoraä¸­åŸæ–‡ä»¶"></a> Typoraä¸­åŸæ–‡ä»¶</h3><img src="/2020/04/26/markdown-4-zhihu/image-20191214174243537.png" alt="image-20191214174243537" style="zoom:50%;"><p>è¿™ä»½æµ‹è¯•æ–‡ä»¶è™½ç„¶çŸ­ï¼Œä½†æ˜¯åŸºæœ¬åŒ…å«äº†å¸¸è§å‡ ç§è¦ç´ ï¼šæ ‡é¢˜ã€æ­£æ–‡ã€å›¾ç‰‡ã€è¡¨æ ¼ã€ä»£ç ã€å…¬å¼ã€‚ä¸‹é¢è®©æˆ‘ä»¬çœ‹çœ‹çŸ¥ä¹æ”¯æŒçš„å‡ ç§ä¸Šä¼ æ–¹å¼çš„æ•ˆæœï¼š</p><h3 id="1-ç›´æ¥å¤åˆ¶typoraä¸­çš„å†…å®¹åˆ°çŸ¥ä¹ç¼–è¾‘å™¨"><a class="markdownIt-Anchor" href="#1-ç›´æ¥å¤åˆ¶typoraä¸­çš„å†…å®¹åˆ°çŸ¥ä¹ç¼–è¾‘å™¨"></a> 1. ç›´æ¥å¤åˆ¶Typoraä¸­çš„å†…å®¹åˆ°çŸ¥ä¹ç¼–è¾‘å™¨</h3><img src="/2020/04/26/markdown-4-zhihu/image-20191214174118623.png" alt="image-20191214174118623" style="zoom:50%;"><p>å¯ä»¥çœ‹åˆ°ï¼Œæ ‡é¢˜å’Œæ­£æ–‡åŒºåˆ†å¼€äº†ï¼Œä¸è¿‡æ‰€æœ‰çš„æ ‡é¢˜éƒ½å˜æˆäº†ä¸€çº§æ ‡é¢˜ã€‚å¦å¤–æœ¬åœ°çš„å›¾ç‰‡æ— æ³•å¯¼å…¥ï¼Œåªå‰©ä¸‹ä¸€ä¸ªå±•å ä½ç¬¦ã€‚è¡¨æ ¼å…¨ä¹±ï¼Œå…¬å¼ç›´æ¥æ¶ˆå¤±äº†ã€‚ä½†ä»£ç çš„é«˜äº®ä»æ˜¯C++ï¼Œæ­£ç¡®ã€‚</p><h3 id="2-ç›´æ¥å¯¼å…¥markdownæ–‡ä»¶"><a class="markdownIt-Anchor" href="#2-ç›´æ¥å¯¼å…¥markdownæ–‡ä»¶"></a> 2. ç›´æ¥å¯¼å…¥Markdownæ–‡ä»¶</h3><p>ä½ å¯ä»¥åœ¨ç¼–è¾‘å™¨çš„è¿™ä¸ªä½ç½®å¯¼å…¥æ–‡ä»¶ï¼š</p><img src="/2020/04/26/markdown-4-zhihu/image-20191214174529632.png" alt="image-20191214174529632" style="zoom:33%;"><img src="/2020/04/26/markdown-4-zhihu/image-20191214174506716.png" alt="image-20191214174506716" style="zoom:33%;"><p>å¯¼å…¥åˆšæ‰æˆ‘ä»¬çœ‹åˆ°çš„æµ‹è¯•æ–‡ä»¶åŸæ¡£çš„æ•ˆæœæ˜¯è¿™æ ·çš„ï¼š</p><img src="/2020/04/26/markdown-4-zhihu/image-20191214174704023.png" alt="image-20191214174704023" style="zoom:50%;"><p>åŒå‰ï¼Œæ ‡é¢˜å’Œæ­£æ–‡åŒºåˆ†å¼€äº†ï¼Œä¸è¿‡æ‰€æœ‰çš„æ ‡é¢˜éƒ½å˜æˆäº†ä¸€çº§æ ‡é¢˜ã€‚å¦å¤–æœ¬åœ°çš„å›¾ç‰‡æ— æ³•å¯¼å…¥ï¼Œåªå‰©ä¸‹ä¸€ä¸ªå ä½ç¬¦ã€‚è¡¨æ ¼å…¨ä¹±ï¼Œå…¬å¼æ²¡æœ‰æ¶ˆå¤±ï¼Œä½†ä¹Ÿå¹¶æ²¡æœ‰è¢«æ¸²æŸ“ã€‚ä»£ç çš„é«˜äº®ä»æ˜¯C++ï¼Œæ­£ç¡®ã€‚</p><h3 id="3-å…ˆä½¿ç”¨typoraå¯¼å‡ºä¸ºwordå†ç”¨çŸ¥ä¹ç¼–è¾‘å™¨å¯¼å…¥word"><a class="markdownIt-Anchor" href="#3-å…ˆä½¿ç”¨typoraå¯¼å‡ºä¸ºwordå†ç”¨çŸ¥ä¹ç¼–è¾‘å™¨å¯¼å…¥word"></a> 3. å…ˆä½¿ç”¨Typoraå¯¼å‡ºä¸ºWordï¼Œå†ç”¨çŸ¥ä¹ç¼–è¾‘å™¨å¯¼å…¥Word</h3><p>ä¸Šé¢çš„ä¸¤ç§æœ€ç›´è§‚çš„æ–¹æ³•çš„ä¸€å¤§é—®é¢˜å°±æ˜¯å›¾ç‰‡å¯¼å…¥ä¸è¿›å»ã€‚è€Œå¯¹äºä¸€äº›é•¿ç¯‡çš„ç§‘æŠ€æ–‡ç« ï¼Œå›¾ç‰‡æ—¢å¤šåˆé‡è¦ï¼Œæ‰‹åŠ¨ä¸€ä¸ªä¸ªæ·»åŠ å®¹æ˜“é”™è€Œä¸”æµªè´¹ç§‘ç ”äººå‘˜çš„æ—¶é—´å’Œçƒ­æƒ…ã€‚å½“ç„¶æˆ‘çŸ¥é“å¯¼å…¥Markdownæ—¶å¹¶æ²¡æœ‰é¡ºå¸¦æŠŠå›¾ç‰‡æœ¬èº«å¯¼å…¥è¿›å»ï¼Œä½†æˆ‘ä»è§‰å¾—è¿™æ˜¯çŸ¥ä¹å›¢é˜Ÿåº”è¯¥åšçš„å·¥ä½œï¼Œè€Œä¸”æ˜¯ç›¸å½“åŸºæœ¬çš„å·¥ä½œã€‚å¥½å§ï¼Œæ—¢ç„¶ç°åœ¨ä¸å¯è¡Œï¼Œé‚£ä¹ˆå¯¼å‡ºæˆWordå†å¯¼å…¥è¯¥ä¸ä¼šæœ‰è¿™ä¸ªé—®é¢˜äº†å§ï¼Œæˆ‘ä»¬æ¥çœ‹çœ‹ï¼š</p><img src="/2020/04/26/markdown-4-zhihu/image-20191214175626414.png" alt="image-20191214175626414" style="zoom:50%;"><p>å¥½å®¶ä¼™ï¼Œå›¾ç‰‡å¯¼å…¥è¿›å»äº†ï¼Œè¡¨æ ¼ç›´æ¥ç‚¸é£å¤©äº†ï¼Œè€Œä¸”æ›´å¯æ°”çš„æ˜¯ä»£ç çš„é«˜äº®æ²¡äº†ï¼Œæ ¼å¼ä¹Ÿå‡ºç°äº†é—®é¢˜ã€‚å…¶ä»–çš„å˜›ï¼Œä¸çœ‹ä¸å¾—äº†ï¼Œä¸€çœ‹å‘ç°å…¬å¼ä¼¼ä¹ç›´æ¥æ²¡äº†ï¼Œä¸­é—´è¿˜è«åå…¶å¦™å¤šäº†ä¸€å †ç©ºè¡Œã€‚å½“ç„¶ï¼Œæ ‡é¢˜ç­‰çº§çš„é—®é¢˜è¿˜æ˜¯æ²¡è§£å†³ã€‚</p><p>é‚£æ˜¯Typoraå¯¼å‡ºWordå¯¼å‡ºçš„ä¸å¥½å—ï¼Ÿæˆ‘æ‰“å¼€äº†å¯¼å‡ºçš„Wordæ–‡ä»¶ï¼š</p><img src="/2020/04/26/markdown-4-zhihu/image-20191214180048117.png" alt="image-20191214180048117" style="zoom:50%;"><p>å…¬å¼å­˜åœ¨ï¼Œé«˜äº®æ­£ç¡®ï¼Œæ ‡é¢˜ç­‰çº§æ­£ç¡®ï¼Œè¡¨æ ¼æ­£ç¡®ï¼Œæ²¡æœ‰å¥‡æ€ªçš„ç©ºè¡Œã€‚è™½ç„¶å’ŒMarkdownæ¸²æŸ“çš„ç»“æœç›¸æ¯”ä¹Ÿå¹¶ä¸å¥½çœ‹è¯´å®è¯ï¼Œä½†è‡³å°‘å®ƒæ˜¯å¯¹çš„ï¼Œè€ŒçŸ¥ä¹ç¼–è¾‘å™¨é”™çš„äº”èŠ±å…«é—¨ã€‚</p><h2 id="é‚£ä¹ˆå¦‚ä½•æ‹¯æ•‘è‡ªå·±çš„åŒæ‰‹å’Œçµé­‚å‘¢"><a class="markdownIt-Anchor" href="#é‚£ä¹ˆå¦‚ä½•æ‹¯æ•‘è‡ªå·±çš„åŒæ‰‹å’Œçµé­‚å‘¢"></a> é‚£ä¹ˆï¼Œå¦‚ä½•æ‹¯æ•‘è‡ªå·±çš„åŒæ‰‹å’Œçµé­‚å‘¢ï¼Ÿ</h2><h3 id="é¦–å…ˆè°ƒæ•´å¥½ä½ çš„markdownç¼–è¾‘å™¨"><a class="markdownIt-Anchor" href="#é¦–å…ˆè°ƒæ•´å¥½ä½ çš„markdownç¼–è¾‘å™¨"></a> é¦–å…ˆè°ƒæ•´å¥½ä½ çš„Markdownç¼–è¾‘å™¨</h3><p>ä¸ºä»€ä¹ˆè¦é¦–å…ˆè°ƒæ•´å¥½ç¼–è¾‘å™¨å‘¢ï¼Ÿè¿™é‡Œæˆ‘è¯´çš„è°ƒæ•´ä¸»è¦æŒ‡çš„æ˜¯å¯¹å›¾ç‰‡ç®¡ç†æ–¹å¼çš„è°ƒæ•´ã€‚å¦‚æœæ‚¨ä½¿ç”¨Typoraï¼Œå»ºè®®åœ¨åå¥½è®¾ç½®é¡µé¢å°†ç›¸å…³å‚æ•°è°ƒæ•´è‡³å’Œä¸‹å›¾å®Œå…¨ä¸€è‡´ï¼Œä»¥é˜²åé¢å‡ºç°é—®é¢˜ã€‚</p><p>è¿™é‡Œåšçš„å·¥ä½œä¸»è¦æ˜¯å°†æ‰€æœ‰æ¥æºçš„å›¾ç‰‡éƒ½è‡ªåŠ¨ä¿å­˜è‡³åŒåæ–‡ä»¶å¤¹ä¸‹ï¼Œä»¥ç›¸å¯¹è·¯å¾„å‚¨å­˜ã€‚ä½¿ç”¨å…¶ä»–Markdownç¼–è¾‘å™¨çš„å°ä¼™ä¼´ä¹Ÿå¯ä»¥å¯¹ç…§è°ƒæ•´ã€‚è¿™ä¹ˆåšçš„ç›®çš„ä¸»è¦æ˜¯ä¸ºäº†æ–¹ä¾¿åé¢å¯¹å›¾ç‰‡çš„æ‰¹é‡ä¸Šä¼ ä¸è½¬æ¢ã€‚</p><img src="/2020/04/26/markdown-4-zhihu/image-20191214221536561.png" alt="image-20191214221536561" style="zoom:50%;"><p>ç›¸ä¿¡å¾ˆå¤šåŒå­¦çœ‹åˆ°è¿™é‡Œå°±ä¼šå‘å‡ºç–‘é—®ï¼Œä¸ºä»€ä¹ˆä¸é€‚ç”¨iPicä¹‹ç±»çš„å›¾åºŠè½¯ä»¶ç›´æ¥ä¸Šä¼ è‡³å›¾åºŠå‘¢ï¼Ÿæ—¢æ–¹ä¾¿åˆèˆ’é€‚ã€‚æˆ‘çš„ç­”æ¡ˆæ˜¯ï¼Œå› ä¸ºæˆ‘åƒè¿‡äºã€‚æˆ‘çš„å†…å®¹ä¹‹å‰ä¸€ç›´ç‹¬å‘äºæˆ‘çš„ä¸ªäººåšå®¢ï¼Œç„¶è€Œä»Šå¹´ä¸­æ—¬ï¼Œçªç„¶ä¹‹é—´æ•´ä¸ªç½‘ç«™æ‰€æœ‰çš„å›¾ç‰‡éƒ½æŒ‚æ‰äº†ï¼Œåªæ˜¾ç¤ºä¸€ä¸ªå ä½ç¬¦å’Œæ— æ³•è®¿é—®çš„æç¤ºï¼Œä¹‹åæˆ‘å‘ç°ä¹‹å‰ä½¿ç”¨çš„æ–°æµªå›¾åºŠåŠ å…¥äº†é˜²ç›—é“¾ï¼Œæ‰€ä»¥å°±GGäº†ã€‚å½“ç„¶åé¢æˆ‘ä¹Ÿç”¨Pythonå†ä¸€æ¬¡è§£å†³äº†è¿™ä¸ªé—®é¢˜ï¼Œå¯¹è§£å†³æ–¹æ³•æ„Ÿå…´è¶£çš„å›¾å½¢å¯ä»¥ç§»æ­¥è¿™é‡Œï¼Œç„¶è€Œè¿™ä¸€æ¬¡çš„æ•™è®­è®©æˆ‘ç†è§£äº†è¿™äº›å›¾åºŠ<strong>å¹¶ä¸å¯æ§</strong>ã€‚å®ƒä»¬éšæ—¶å¯ä»¥å‰¥å¤ºæ‰ä½ åšå®¢ä¸­çš„å…¨éƒ¨å›¾ç‰‡ï¼Œè€Œä½ æ˜¯æ— åŠ›è‡³æçš„ã€‚</p><p>åœ¨é‚£ä¹‹åï¼Œæˆ‘å°±é€‰æ‹©äº†æœ¬åœ°å‚¨å­˜+Githubå¤‡ä»½çš„æ¨¡å¼ï¼Œè¿™æ ·æ—¢å¯ä»¥æ°¸ä¹…æœ‰å®‰å¿ƒçš„æœ¬åœ°æ¡£ï¼Œä¹Ÿæœ‰æ–¹ä¾¿ä½¿ç”¨çš„Githubé“¾æ¥ï¼Œå¯ä»¥è¯´æ˜¯æ—¢æ–¹ä¾¿åˆå®‰å…¨ã€‚</p><h3 id="ä¹‹åè§£å†³å›¾ç‰‡ä¸Šä¼ é—®é¢˜"><a class="markdownIt-Anchor" href="#ä¹‹åè§£å†³å›¾ç‰‡ä¸Šä¼ é—®é¢˜"></a> ä¹‹åè§£å†³å›¾ç‰‡ä¸Šä¼ é—®é¢˜</h3><p>æœ€æ–¹ä¾¿çš„è§£å†³åŠæ³•å³ä¸ºåˆ©ç”¨å¥½GitHubçš„èµ„æºäº†ã€‚å»ºç«‹ä¸€ä¸ªPublicçš„GitHubä»“åº“ï¼Œè¿™é‡Œæˆ‘å‘½åä½œ**<a href="https://github.com/miracleyoo/Markdown4Zhihu">Markdown4Zhihu</a>**ï¼Œæ³¨æ„ä¸€å®šè¦ä¸ºPublicï¼Œå¦åˆ™çŸ¥ä¹æ— æ³•è®¿é—®è¿™äº›å›¾ç‰‡ã€‚</p><img src="/2020/04/26/markdown-4-zhihu/image-20191214221339326.png" alt="image-20191214221339326" style="zoom:50%;"><p>å½“ç„¶ï¼Œå¦‚æœä½ è§‰å¾—éº»çƒ¦ï¼Œä¹Ÿå¯ä»¥ç›´æ¥folkæˆ‘å»ºå¥½çš„ä»“åº“ï¼Œä¸€ä¼šå„¿æˆ‘ä»¬è¦æåˆ°çš„â€œä¸€é”®MarkdownçŸ¥ä¹é€‚é…è„šæœ¬â€ä¹Ÿä¼šåœ¨è¿™ä¸ªä»“åº“é‡Œã€‚ä½ åªéœ€è¦å°†ä½ çš„æ–‡ä»¶å’Œç›¸åº”çš„å›¾ç‰‡æ–‡ä»¶å¤¹æ”¾åˆ°è¿™ä¸ª<code>Data</code>å­ç›®å½•ä¸‹ï¼Œå³å¯è°ƒç”¨è„šæœ¬ä¸€é”®è½¬æ¢ï¼Œå¹¶å°†æ¶‰åŠåˆ°çš„å›¾ç‰‡è‡ªåŠ¨æ¨åˆ°ä½ ç›¸åº”çš„GitHubä»“åº“ä¸­ã€‚</p><img src="/2020/04/26/markdown-4-zhihu/image-20191214213407292.png" alt="image-20191214213407292" style="zoom:50%;"><p>è¿™æ˜¯æˆ‘ä»¬ä½¿ç”¨è„šæœ¬ä¸€é”®è½¬æ¢åçš„ç»“æœã€‚å®ƒå¾ˆå¥½çš„è§£å†³çš„å›¾ç‰‡ä¸Šä¼ çš„é—®é¢˜ï¼ŒåŒæ—¶ä¹Ÿä¿è¯äº†ä»£ç æ®µçš„é«˜äº®ï¼ŒåŒæ—¶ï¼Œæ‰€æœ‰çš„è¡Œå†…å…¬å¼å’Œå¤šè¡Œå…¬å¼éƒ½å¾—åˆ°äº†è½¬æ¢ã€‚è½¬æ¢åçš„å…¬å¼åœ¨çŸ¥ä¹ä¸Šä¼ æ–‡ä»¶ä¹‹åï¼Œæ˜¯å¯äº¤äº’çš„ï¼Œå³ä½ å¯ä»¥åœ¨ä¸Šä¼ ä¹‹ååœ¨çŸ¥ä¹ç¼–è¾‘å™¨ä¸­ä¿®æ”¹ä½ çš„å…¬å¼ï¼Œè€Œä¸å¿…é‡æ–°å†æ¥ä¸€éã€‚</p><p>è‡³äºè¡¨æ ¼ï¼Œè¿™ä¸ªçœŸæœ¨å¾—åŠæ³•ï¼Œå› ä¸ºçŸ¥ä¹å‹æ ¹ä¸æ”¯æŒè¡¨æ ¼ä½ è¯´è¿™å’‹æ•´å˜›ã€‚ä½†æ˜¯ä¹Ÿä¸æ˜¯æ²¡æœ‰å¯æ›¿ä»£æ–¹æ¡ˆã€‚å¦‚æœè¡¨æ ¼ä¸æ˜¯å¾ˆå¤šï¼Œä½ å¯ä»¥ç›´æ¥å¯¹å…¶è¿›è¡Œæˆªå›¾ï¼Œåˆ å»åŸä»£ç åç²˜è´´æˆªå›¾ã€‚ä¹‹åå®ƒå°±ä¼šæŒ‰ç…§å›¾ç‰‡æ¨¡å¼è¢«å…¼å®¹ä¸Šå»ã€‚å¦‚æœä½ ä¸æƒ³æˆªå›¾ä¹Ÿå¯ï¼Œåšäº†ç›¸åº”æ“ä½œåä¼šå¾—åˆ°ä¸Šå›¾çš„ç»“æœï¼Œå¯¹äºå°‘é‡è¡¨æ ¼æ¥çœ‹ä¹Ÿæ˜¯OKçš„ã€‚ä½ å¯ä»¥åœ¨<a href="https://zhuanlan.zhihu.com/p/97432671">è¿™é‡Œ</a>çœ‹åˆ°ä¸Šä¼ åˆ°çŸ¥ä¹åçš„æ•ˆæœã€‚</p><h3 id="æœ€åæ˜¯å…·ä½“ä½¿ç”¨æµç¨‹"><a class="markdownIt-Anchor" href="#æœ€åæ˜¯å…·ä½“ä½¿ç”¨æµç¨‹"></a> æœ€åæ˜¯å…·ä½“ä½¿ç”¨æµç¨‹</h3><p>è¿™é‡Œæˆ‘ä»¬å‡è®¾æ‚¨çš„æ–‡ä»¶åä¸º<code>ä¸€ä¸ªæµ‹è¯•æ–‡æ¡£.md</code>ï¼Œå¹¶å°†å…¶å’ŒåŒåå›¾ç‰‡æ–‡ä»¶å¤¹æ”¾åˆ°<code>Data</code>ç›®å½•ä¸‹ï¼ˆå¦‚æœæ–°å»ºæ–‡ä»¶æ—¶å°±ç›´æ¥åœ¨Dataé‡Œé¢å»ºä¼šæ›´åŠ æ–¹ä¾¿ï¼‰ï¼Œæ¥ç€æ‰“å¼€terminal(Linux/MacOS)æˆ–Git Bash(Windows)(æˆ–å…¶ä»–ä»»ä½•æ”¯æŒGitå‘½ä»¤çš„ç»ˆç«¯)ï¼Œ<code>cd</code>è¿›å…¥è¯¥é¡¹ç›®çš„æ ¹ç›®å½•ï¼Œå³<code>Markdown4Zhihu</code>ç›®å½•ï¼Œè¾“å…¥ä»¥ä¸‹å‘½ä»¤ï¼š</p><p><code>python zhihu-publisher.py --input=&quot;./Data/ä¸€ä¸ªæµ‹è¯•æ–‡æ¡£.md&quot;</code></p><p>OKï¼Œall set. åœ¨<code>Data</code>ç›®å½•ä¸‹ï¼Œä½ å¯ä»¥çœ‹åˆ°ä¸€ä¸ª<code>ä¸€ä¸ªæµ‹è¯•æ–‡æ¡£_for_zhihu.md</code>çš„æ–‡ä»¶ï¼Œå°†å®ƒä¸Šä¼ è‡³çŸ¥ä¹ç¼–è¾‘å™¨å³å¯ã€‚</p><p>PS: è„šæœ¬ä½¿ç”¨Python3ï¼ŒPython2å¯èƒ½ä¼šæœ‰æ½œåœ¨é—®é¢˜ã€‚</p><h2 id="æœ€åçš„è¯"><a class="markdownIt-Anchor" href="#æœ€åçš„è¯"></a> æœ€åçš„è¯</h2><p>çŸ¥ä¹çš„å¼€å‘è€…çš„é€»è¾‘å…¶å®æˆ‘çœŸçš„æ¯”è¾ƒè¿·ï¼Œæˆ‘ä»¬å¤§å­¦å­¦ç”Ÿå›¢é˜Ÿçš„è‡ªå»ºè®ºå›éƒ½å¯ä»¥åŸç”Ÿå®Œç¾æ”¯æŒMarkdownå’Œå…¬å¼ï¼Œç„¶è€ŒçŸ¥ä¹å´ä¸€ç›´è¯´è¿™ä¸ªåŠŸèƒ½å¿…è¦æ€§ä¸è¶³å¼ºè°ƒå¼€å‘éš¾åº¦ã€‚åŒæ ·ä»¤äººéš¾å—çš„æ˜¯çŸ¥ä¹çš„æœç´¢ï¼Œå¤šå°‘å¹´è¿‡å»äº†éçƒ­é—¨è¯é¢˜è¿˜æ˜¯ä¸€å¦‚æ—¢å¾€çš„éš¾ç”¨ï¼Œæœç´¢è¿˜æ˜¯å€ŸåŠ©Google çš„ â€œé—®é¢˜+çŸ¥ä¹â€ã€‚ä¸çŸ¥é“è¿™æ˜¯ä»€ä¹ˆåŸå› ï¼Œä¸è¿‡è¿˜æ˜¯å¸Œæœ›çŸ¥ä¹å›¢é˜Ÿå…ˆæŠŠè¿™äº›éå¸¸åŸºç¡€çš„ä¸œè¥¿åšå¥½å†å¤§è°ˆç”¨æˆ·ä½“éªŒã€‚</p><p>è¿™æ¬¡çš„è§£å†³æ–¹æ¡ˆéœ€è¦å¯¹GitHubå’Œå‘½ä»¤è¡Œæœ‰åŸºç¡€çš„äº†è§£ï¼Œä¸è¿‡è€ƒè™‘åˆ°ä¼šæ¥è¯»è¿™ç¯‡æ–‡ç« çš„äººåº”è¯¥ç¨‹åºå‘˜å±…å¤šï¼Œé—®é¢˜åº”è¯¥ä¸æ˜¯å¾ˆå¤§ã€‚è„šæœ¬è¿˜æ¯”è¾ƒæ–°ï¼Œå¦‚æœæœ‰bugæ¬¢è¿æå‡ºã€‚æœ€åå†æ”¾ä¸€ä¸‹GitHubé“¾æ¥ï¼Œå¦‚æœå®ƒæœ‰å¸®åˆ°ä½ ï¼Œå¸Œæœ›èƒ½éšæ‰‹ç•™ä¸‹ä¸€ä¸ªstarï¼Œè°¢è°¢ï¼<strong><a href="https://github.com/miracleyoo/Markdown4Zhihu">Markdown4Zhihu</a></strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;çŸ¥ä¹ä¸Šçš„æœ¬æ–‡é“¾æ¥ï¼š&lt;a href=&quot;https://zhuanlan.zhihu.com/p/97455277&quot;&gt;Link&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;é¦–å…ˆåæ§½ä¸€ä¸‹çŸ¥ä¹çš„ç¼–è¾‘å™¨ã€‚è™½ç„¶ä¸ªäººåšå®¢ä¸Šçš„ä¸å°‘å†…å®¹éƒ½æ›¾æœ‰æƒ³è¿‡æ¬åˆ°çŸ¥ä¹ä¸€ä»½ï¼Œä½†æ˜¯çŸ¥ä¹çš„ç¼–è¾‘å™¨çœŸçš„æ˜¯ä»¤äººç»æœ›å¼çš„éš¾ç”¨ã€‚å°½ç®¡ç°åœ¨å¯ä»¥ä½¿</summary>
      
    
    
    
    
    <category term="tool" scheme="https://www.miracleyoo.com/tags/tool/"/>
    
    <category term="markdown" scheme="https://www.miracleyoo.com/tags/markdown/"/>
    
    <category term="math" scheme="https://www.miracleyoo.com/tags/math/"/>
    
  </entry>
  
  <entry>
    <title>Dockerä¸Nivida-Dockerçš„ç”¨æ³•ä¸æ³¨æ„äº‹é¡¹</title>
    <link href="https://www.miracleyoo.com/2020/04/26/docker-et-nvidia/"/>
    <id>https://www.miracleyoo.com/2020/04/26/docker-et-nvidia/</id>
    <published>2020-04-26T21:56:52.000Z</published>
    <updated>2020-04-26T21:56:52.660Z</updated>
    
    <content type="html"><![CDATA[<h2 id="docker-images-and-containers"><a class="markdownIt-Anchor" href="#docker-images-and-containers"></a> Docker Images and Containers</h2><ul><li><p>æ¸…é™¤æ‰€æœ‰å·²ç»åœæ­¢çš„containerï¼š<code>docker container prune -f</code> ã€‚å…¶ä¸­ <code>-f</code> è¡¨ç¤ºä¸å¼¹å‡ºç¡®è®¤æç¤ºã€‚ä¹Ÿå¯ä½¿ç”¨<code>docker rm $(docker ps -a -q)</code>æ¥æ¸…ç†ã€‚å…¶ä¸­ï¼Œ<code>docker rm</code>ä»£è¡¨åˆ é™¤containerï¼Œè€Œ<code>docker rmi</code>åˆ™æ˜¯åˆ é™¤imageã€‚</p></li><li><p>å¦‚æœä½ éœ€è¦å®ä¾‹åŒ–ä¸€ä¸ªåªç”¨ä¸€æ¬¡çš„containerï¼Œé‚£ä¹ˆä½¿ç”¨<code>docker run --rm</code>å‚æ•°ï¼Œç»“æŸåä¼šè‡ªåŠ¨åˆ é™¤ã€‚</p></li><li><p><code>docker ps &lt;-a&gt;</code> å¯ä»¥åˆ—å‡ºæ­£åœ¨è¿è¡Œçš„/å…¨éƒ¨çš„containerã€‚å…¶æ•ˆæœå’Œ<code>docker container ls &lt;-a&gt;</code>ç›¸åŒã€‚è€Œè‹¥æƒ³åˆ—å‡ºå…¨éƒ¨imagesï¼Œåˆ™è¦ä½¿ç”¨<code>docker images</code>ã€‚</p></li><li><p>docker imagesä¸­çš„ç¯å¢ƒå˜é‡æœ‰å››ä¸ªæ¥æºï¼š</p><ol><li>Dockerfileä¸­é€šè¿‡<code>ENV</code>æŒ‡ä»¤æ·»åŠ çš„ç¯å¢ƒå˜é‡ï¼Œå¦‚<code>ENV PATH /opt/conda/bin:$PATH</code></li><li>Dockerfileä¸­é€šè¿‡ä¿®æ”¹<code>/root/.bashrc</code>æ–‡ä»¶ä½¿ç”¨<code>export</code>å‘½ä»¤æ·»åŠ åˆ°bashä¸­çš„ç¯å¢ƒå˜é‡ï¼Œå¦‚<code>export PATH=/OPT/conda/bin:$PATH</code>å‘½ä»¤ã€‚</li><li>åœ¨é€šè¿‡imageå®ä¾‹åŒ–containeræ—¶æ·»åŠ <code>-e</code>æˆ–<code>--env</code>å‚æ•°æ¥æ·»åŠ åˆ°ç¯å¢ƒä¸­çš„å˜é‡ã€‚è¿™ä¸ªæ–¹æ³•æœ‰å±€é™æ€§ï¼Œå®ƒä¸èƒ½å®Œæˆå¯¹å·²æœ‰å˜é‡çš„â€œæ·»åŠ â€æ“ä½œï¼Œåªèƒ½æ–°å»ºä¸€ä¸ªæ–°çš„ç¯å¢ƒå˜é‡ï¼Œå¦‚<code>--env NEW_VAR=/opt/conda/bin</code></li><li>åœ¨<code>docker run</code>æœ«ç«¯çš„containerå†…å‘½ä»¤çš„å‰é¢æ·»åŠ ä¸€å¥<code>export</code>å¼•å¯¼çš„å‘½ä»¤ï¼Œå¦‚ï¼š<code>docker run -it -v $(PWD):/app debian:jessie bash -c 'export PATH=$PATH:/opt/conda/bin; bash'</code>ã€‚å®ƒçš„ç¼ºç‚¹æ˜¯è¾ƒä¸ºå¤æ‚ã€‚</li></ol><p>å…¶ä¸­ï¼Œå¦‚æœèƒ½æ‰¾åˆ°æºDockerfileï¼Œæœ€å¥½çš„æ–¹æ³•æ˜¯é€šè¿‡ä¿®æ”¹Dockerfileç„¶åé‡æ–°buildå¾—åˆ°ä¸€ä¸ªè‡ªå·±çš„ç‰ˆæœ¬ã€‚å…¶æ¬¡æ˜¯æ–¹æ³•ä¸‰ï¼Œå®åœ¨ä¸è¡Œä½¿ç”¨æ–¹æ³•å››ã€‚å¦‚æœå…ˆè¿›å…¥bashå†è¿è¡Œå‘½ä»¤å¯ä»¥æ­£å¸¸è¿è¡Œï¼Œè€Œç›´æ¥ä½¿ç”¨<code>docker run</code>å‡ºç°äº†ç¯å¢ƒå˜é‡ç›¸å…³çš„å¤±è´¥æç¤ºï¼Œå¾ˆå¯èƒ½æ˜¯ç”±äºDockerfileå†™çš„æ—¶å€™ä½¿ç”¨çš„æ˜¯åœ¨<code>/root/.bashrc</code>ä¸­æ·»åŠ ç¯å¢ƒå˜é‡çš„æ–¹æ³•æ‰€è‡´ã€‚</p></li><li><p>å¦‚æœéœ€è¦ä¸€ä¸ªcontaineré•¿æœŸåœ¨åå°å¾…æœºå€™å‘½ï¼Œé‚£å¯ä»¥ä½¿ç”¨<code>-d</code>æˆ–<code>--detach</code>é€‰é¡¹å»ºç«‹ä¸€ä¸ªä¸€ç›´å¾…æœºçš„dockerè¿›ç¨‹ã€‚ä½¿ç”¨æ–¹æ³•ï¼š</p><ol><li><code>docker run -itd --name NAME xxx/xxx:xx /bin/bash</code></li><li><code>docker exec -it NAME your-command</code></li></ol></li><li><p>å¯åŠ¨æ—¶å¦‚æœéœ€è¦å¯¹æœ¬åœ°æ–‡ä»¶å¤¹å’ŒDockerå†…éƒ¨æ–‡ä»¶å¤¹åšæ˜ å°„ï¼Œåˆ™ä½¿ç”¨<code>docker run -v &lt;LOCAL_FOLDER&gt;:&lt;DOCKER_FOLDER&gt;</code> ã€‚ è¯¥å‚æ•°å¯ä»¥å¤æ•°æ¬¡å‡ºç°ï¼Œå¦‚ï¼š</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">docker run \</span><br><span class="line">    -v <span class="variable">$AUDIO_IN</span>:/input \</span><br><span class="line">    -v <span class="variable">$AUDIO_OUT</span>:/output \</span><br><span class="line">    -v <span class="variable">$MODEL_DIRECTORY</span>:/model \</span><br><span class="line">    -e MODEL_PATH=/model \</span><br><span class="line">    researchdeezer/spleeter \</span><br><span class="line">    separate -i /input/audio_1.mp3 /input/audio_2.mp3 -o /output</span><br></pre></td></tr></table></figure></li><li><p>docker runæ‰€æœ‰çš„å‚æ•°éƒ½åº”è¯¥å†™åœ¨é•œåƒåå­—<code>xxx/xxx:xx</code>å‰é¢ï¼Œå†™åœ¨å…¶åé¢çš„ç»Ÿç»Ÿä¼šè¢«è§†ä½œåœ¨docker containerä¸­è¿è¡Œçš„å‘½ä»¤æˆ–å‘½ä»¤å‚æ•°ã€‚</p></li><li><p>å¦‚æœä½ æœ‰äº†ä¸€ä¸ªåœ¨åå°æŒç»­è¿è¡Œçš„containerï¼Œä¸”ä½ æƒ³å¼„ä¸€ä¸ªäº¤äº’æ€§bashï¼Œæ­¤æ—¶ä½ ä»éœ€è¦åŠ ä¸Š<code>-it</code>å‚æ•°ï¼ŒåŒæ ·æ˜¯åœ¨<code>docker exec</code>åï¼Œcontaineråå­—å‰åŠ éœ€è¦çš„å‚æ•°ï¼Œrestartå’ŒstartåŒç†ã€‚</p></li><li><p>å¦‚æœä½ å¯¹ä½œè€…çš„Docker Imageä¸æ»¡æ„ï¼Œéœ€è¦ä¿®æ”¹ï¼Œæ­¤æ—¶æœ‰ä¸¤ç§æ–¹æ³•ï¼š</p><ol><li>æ‰¾åˆ°Dockerfileå¹¶ä¿®æ”¹ï¼Œ<code>docker build</code>ï¼Œ<code>docker push</code></li><li>ä½¿ç”¨bashè¿›å…¥ä¸€ä¸ªå®ä¾‹åŒ–çš„Imageï¼Œåœ¨é‡Œé¢åšä¸€é€šæ“ä½œï¼Œå‡ºæ¥åä½¿ç”¨<code>docker commit -m &lt;YOUR_MESSAGE&gt; -a &lt;AUTHOR_NAME&gt; &lt;CONTAINER_ID&gt; &lt;DOCKERHUB_USERNAME/NEW_IMAGE_NAME:TAG&gt;</code>æäº¤æ›´æ”¹ä½¿å…¶ä¿å­˜ä¸ºä¸€ä¸ªæ–°çš„é•œåƒï¼Œæœ€åä½¿ç”¨<code>docker push</code>æ¨é€æ–°çš„é•œåƒåˆ°docker hubã€‚å¦‚æœå‘½åæœ‰è¯¯æˆ–å¿˜è®°æ·»åŠ docker hub usernameä½œä¸ºå‰ç¼€ï¼Œé‚£ä¹ˆå¯ä»¥ä½¿ç”¨<code>docker tag &lt;existing-image&gt; &lt;hub-user&gt;/&lt;repo-name&gt;[:&lt;tag&gt;]</code>æ”¹åã€‚</li></ol><p>æ³¨æ„ï¼Œä½¿ç”¨<code>docker push</code>éœ€è¦æœ‰docker hubè´¦å·ï¼Œå¹¶åœ¨pushå‰ä½¿ç”¨<code>docker login</code>æ“ä½œç™»å½•ã€‚</p></li><li><p>ä¸€ä¸ªè¾¨æï¼š<code>docker commit</code>é’ˆå¯¹çš„æ˜¯ä¸€ä¸ªæ­£åœ¨è¿è¡Œçš„containerï¼Œä½¿å…¶å›ºåŒ–ä¸ºä¸€ä¸ªimageï¼›è€Œ<code>docker push</code>æ¨é€çš„åˆ™æ˜¯ä¸€ä¸ªimageåˆ°docker hubã€‚å‰è€…æ˜¯æœ¬åœ°æ“ä½œï¼Œåè€…æ˜¯ä¸Šä¼ æ“ä½œã€‚</p></li><li><p>ä¸€ä¸ªåŒºåˆ«ï¼š<code>docker start</code>æ˜¯å¯åŠ¨ä¸€ä¸ªå·²ç»åœæ­¢çš„containerï¼Œè€Œ<code>docker restart</code>åˆ™æ˜¯å…ˆstopä¸€ä¸ªcontainerå†startã€‚å¦‚æœä¸€ä¸ªcontainerå·²ç»åœæ­¢äº†ï¼Œé‚£ä¹ˆäºŒè€…ç­‰æ•ˆã€‚</p></li></ul><h2 id="dockerfile"><a class="markdownIt-Anchor" href="#dockerfile"></a> Dockerfile</h2><ul><li>Docker Hubä¸­å¹¶ä¸ç›´æ¥æä¾›Dockerfileï¼Œä½†å¯ä»¥é€šè¿‡æŸ¥çœ‹imageçš„â€œæ ‡ç­¾â€é¡µé¢çœ‹æ¯ä¸ªimageçš„dockerå»ºç«‹æ“ä½œã€‚ä½†ç”±äºDocker buildçš„æ—¶å€™ä½¿ç”¨gitä¼šå¾ˆæ–¹ä¾¿ï¼Œæ‰€ä»¥å¾ˆå¤šä½œè€…ä¼šåœ¨å…¶Githubä¸Šå‘å¸ƒè¿™äº›Dockerfileï¼Œå¾€å¾€å¯ä»¥æŸ¥çœ‹ä»‹ç»é¡µé¢æ‰¾åˆ°é“¾æ¥ã€‚</li><li>Dockerfileä¸­è®¾ç½®è¿›å…¥ç‚¹å‘½ä»¤ï¼š<code>ENTRYPOINT [&quot;spleeter&quot;]</code>ã€‚</li></ul><ol><li>è¿™é‡Œâ€spleeterâ€œæ˜¯ä¸€ä¸ªbinå¯æ‰§è¡Œæ–‡ä»¶ã€‚å®ƒçš„æ•ˆæœæ˜¯ï¼šæœ¬æ¥éœ€è¦ç”¨æˆ·åœ¨<code>docker run</code>æ—¶è¾“å…¥<code>docker run xxx/xxx:xx spleeter separate</code>ï¼Œ ç°åœ¨å°±åªç”¨è¾“å…¥<code>docker run xxx/xxx:xx separate</code>äº†ï¼Œå³runçš„æ—¶å€™å¸®ä½ å…ˆæ‰“äº†ä¸€ä¸ªå‘½ä»¤æ ‡è®°ä½†æ²¡ç»™ä½ æŒ‰å›è½¦ã€‚</li><li>å¦‚æœä½ å‘ç°è‡ªå·±åœ¨è¿è¡Œä¸€ä¸ªdocker imageæ—¶å€™æç¤ºäº†æŸä¸ªä½ æ²¡æœ‰è¾“å…¥çš„å‘½ä»¤çš„ç›¸å…³é—®é¢˜ï¼Œå¦‚<code>xxx don't have a parameter yyy, please input aaa, bbb, or ccc</code>ï¼Œå¾ˆæœ‰å¯èƒ½æ˜¯Dockerfileä¸­è®¾å®šäº†è¿›å…¥ç‚¹ã€‚</li><li>å¦‚æœä½œè€…åœ¨Dockerfileä¸­è®¾å®šäº†è¿›å…¥ç‚¹ï¼Œä½†ä½ éœ€è¦è¿›å…¥dockerè¿›è¡Œè°ƒè¯•æˆ–æ£€æŸ¥æ—¶ï¼Œå¯ä»¥ä½¿ç”¨<code>docker run -it --entrypoint bash</code>æ¥åˆ‡æ¢å…¥ç‚¹ï¼Œè¿›å…¥ä¸€ä¸ªbashå‘½ä»¤è¡Œä¸­è°ƒè¯•ã€‚</li></ol><ul><li><code>docker build</code>é’ˆå¯¹çš„æ˜¯ä¸€ä¸ªurlæˆ–æ˜¯ä¸€ä¸ªæœ¬åœ°çš„æ–‡ä»¶å¤¹ã€‚å¦‚æœæ˜¯æœ¬åœ°çš„æ–‡ä»¶å¤¹ï¼Œæ–‡ä»¶å¤¹å†…éœ€è¦å«æœ‰ä¸€ä¸ªä»¥<code>Dockerfile</code>ä¸ºåçš„æ–‡ä»¶ï¼Œå¦‚æœéœ€è¦å¯¼å…¥æŸäº›æ–‡ä»¶åˆ°Docker Imageä¸­ï¼Œåˆ™è¿™äº›æ–‡ä»¶éœ€è¦åœ¨æ­£ç¡®çš„ä½ç½®ã€‚<ol><li>å¦‚æœdockerfileçš„åå­—ä¸æ˜¯<code>Dockerfile</code>ï¼Œåˆ™ä½¿ç”¨<code>-f/--file &lt;DOCKERFILE_NAME&gt;</code>æ¥æŒ‡å®šåç§°ã€‚</li><li>å¦‚æœéœ€è¦æŒ‡å®šè¾“å‡ºimageçš„åå­—å’Œtagï¼Œåˆ™ä½¿ç”¨<code>-t/--tag</code>æ ‡ç­¾ï¼Œä»¥<code>name:tag</code>å‘½åã€‚</li><li>å¦‚æœbuildçš„æ—¶å€™å¿˜è®°äº†å‘½åimageï¼Œåˆ™è¾“å‡ºçš„imageæ²¡æœ‰åå­—å’Œtagï¼Œåªæœ‰ä¸€ä¸ªéšæœºåºå·ã€‚æ­¤æ—¶å¦‚æœè¦é‡å‘½åï¼Œå¯ä»¥ç”¨<code>docker tag &lt;SERIAL_NUMBER&gt; &lt;NAME:TAG&gt;</code> å‘½ä»¤ã€‚é»˜è®¤tagä¸ºlatestã€‚</li><li>Docker Buildç¤ºä¾‹ï¼š<ul><li>æœ¬åœ°æ–‡ä»¶å¤¹ï¼š<code>docker build -f &lt;NAME:TAG&gt; &lt;TARGET DICTIONARY&gt;</code></li><li>æœ¬åœ°æ–‡ä»¶ï¼š<code>docker build - &lt; &lt;Dockerfile_Path&gt;</code></li><li>URLï¼š<code>docker build https://github.com/&lt;USERNAME&gt;/&lt;REPONAME&gt;.git#&lt;BRUNCH&gt;:&lt;SUBFOLDERNAME&gt;</code></li></ul></li></ol></li></ul><h2 id="nivdia-docker"><a class="markdownIt-Anchor" href="#nivdia-docker"></a> Nivdia Docker</h2><ul><li><p>å…ˆæ”¾<a href="https://github.com/NVIDIA/nvidia-docker">é“¾æ¥</a>ã€‚è¿™é‡Œæ˜¯Nvidia Dockerçš„Githubä»“åº“ã€‚</p></li><li><p>å†è¯´ä½œç”¨ã€‚è‹¥æƒ³åœ¨Dockerä¸­è¿è¡ŒGPUç¨‹åºï¼Œåˆ™æ™®é€šçš„Dockeræ˜¯åšä¸åˆ°çš„ï¼Œç¨‹åºæ— æ³•é»˜è®¤åœ¨Dockerä¸­ä½¿ç”¨GPUè®¡ç®—èµ„æºï¼›å¦ä¸€æ–¹é¢ï¼Œå¦‚æœæœ¬åœ°å·²ç»å®‰è£…äº†æŸä¸ªç‰ˆæœ¬çš„CUDAï¼Œä½†ç›®æ ‡ç¨‹åºéœ€è¦ä¾èµ–å¦ä¸€ä¸ªç‰ˆæœ¬ï¼Œè¿™ä¹Ÿæ˜¯éå¸¸éº»çƒ¦çš„ã€‚è€ŒNvidia Dockerçš„å‡ºç°åˆ™å¾ˆå¥½è§£å†³äº†è¿™ä¸ªé—®é¢˜ã€‚å®ƒç›¸å½“äºåœ¨Dockerçš„ä¸‹é¢å¡è¿›äº†ä¸€å±‚CUDAå±‚ï¼Œä»‹äºContainerå’ŒOSä¹‹é—´ã€‚</p><p><img src="/2020/04/26/docker-et-nvidia/5b208976-b632-11e5-8406-38d379ec46aa.png" alt="Nvidia Docker åŸç†å›¾"></p></li><li><p>ç„¶åæ˜¯å®‰è£…ã€‚</p><ol><li><p>ä½œä¸ºå‰ç½®æ¡ä»¶ï¼Œéœ€è¦æœ¬æœºä¸Šå®‰è£…æœ‰Nvidia Driverï¼Œä¸å¼ºåˆ¶è¦æ±‚CUDAã€‚ï¼ˆä¸è¿‡æ—¢ç„¶éƒ½å®‰åˆ°Driveräº†ï¼Œä¸å¦‚æŠŠæœ¬æœºCUDAä¹Ÿè£…äº†ï¼‰å®˜æ–¹æ•™ç¨‹<a href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#ubuntu-installation">é“¾æ¥</a>ã€‚å½“ç„¶ï¼Œè¯·å®‰è£…Dockerã€‚</p></li><li><p>æ‰§è¡Œä»¥ä¸‹ä»£ç ï¼š</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Add the package repositories</span></span><br><span class="line">distribution=$(. /etc/os-release;<span class="built_in">echo</span> $ID<span class="variable">$VERSION_ID</span>)</span><br><span class="line">curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -</span><br><span class="line">curl -s -L https://nvidia.github.io/nvidia-docker/<span class="variable">$distribution</span>/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list</span><br><span class="line"></span><br><span class="line">sudo apt-get update &amp;&amp; sudo apt-get install -y nvidia-container-toolkit</span><br><span class="line">sudo systemctl restart docker</span><br></pre></td></tr></table></figure><p>ä»£ç å¯èƒ½ä¼šéšç€Nvidia Dockerçš„çš„å‡çº§è€Œå‘ç”Ÿå˜åŒ–ï¼Œæœ€å¥½å‚é˜…æœ¬ç« ç¬¬ä¸€æ¡çš„é“¾æ¥ã€‚</p></li></ol></li><li><p>è¯•è¿è¡Œï¼š</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#### Test nvidia-smi with the latest official CUDA image</span></span><br><span class="line">docker run --gpus all nvidia/cuda:10.0-base nvidia-smi</span><br><span class="line"></span><br><span class="line"><span class="comment"># Start a GPU enabled container on two GPUs</span></span><br><span class="line">docker run --gpus 2 nvidia/cuda:10.0-base nvidia-smi</span><br><span class="line"></span><br><span class="line"><span class="comment"># Starting a GPU enabled container on specific GPUs</span></span><br><span class="line">docker run --gpus <span class="string">&#x27;&quot;device=1,2&quot;&#x27;</span> nvidia/cuda:10.0-base nvidia-smi</span><br><span class="line">docker run --gpus <span class="string">&#x27;&quot;device=UUID-ABCDEF,1&quot;&#x27;</span> nvidia/cuda:10.0-base nvidia-smi</span><br><span class="line"></span><br><span class="line"><span class="comment"># Specifying a capability (graphics, compute, ...) for my container</span></span><br><span class="line"><span class="comment"># Note this is rarely if ever used this way</span></span><br><span class="line">docker run --gpus all,capabilities=utility nvidia/cuda:10.0-base nvidia-smi</span><br></pre></td></tr></table></figure><p>å…¶æ ‡å¿—æ€§ç‰¹ç‚¹å°±æ˜¯ä¸€ä¸ªå‚æ•°<code>--gpus &lt;PARAMETERS&gt;</code> ä¸€èˆ¬ä½¿ç”¨<code>--gpus all</code>å³å¯ï¼Œå…¶ä»–éƒ¨åˆ†å’Œæ™®é€šdockerä¸€æ¨¡ä¸€æ ·ã€‚</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;docker-images-and-containers&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#docker-images-and-containers&quot;&gt;&lt;/a&gt; Docker Images and Containers&lt;/h</summary>
      
    
    
    
    
    <category term="deep-learning" scheme="https://www.miracleyoo.com/tags/deep-learning/"/>
    
    <category term="docker" scheme="https://www.miracleyoo.com/tags/docker/"/>
    
    <category term="nvidia" scheme="https://www.miracleyoo.com/tags/nvidia/"/>
    
    <category term="gpu" scheme="https://www.miracleyoo.com/tags/gpu/"/>
    
  </entry>
  
  <entry>
    <title>Linux(Ubuntu)è£…æœºä¸é…ç½®ç¬”è®°</title>
    <link href="https://www.miracleyoo.com/2020/04/11/linux-setup/"/>
    <id>https://www.miracleyoo.com/2020/04/11/linux-setup/</id>
    <published>2020-04-11T22:11:47.000Z</published>
    <updated>2020-04-11T22:11:47.080Z</updated>
    
    <content type="html"><![CDATA[<h2 id="ç¡¬ç›˜ç›¸å…³"><a class="markdownIt-Anchor" href="#ç¡¬ç›˜ç›¸å…³"></a> ç¡¬ç›˜ç›¸å…³</h2><ol><li><p><strong>dfå‘½ä»¤</strong><br><code>df</code>ï¼šæ£€æŸ¥linuxæœåŠ¡å™¨çš„æ–‡ä»¶ç³»ç»Ÿçš„ç£ç›˜ç©ºé—´å ç”¨æƒ…å†µã€‚<strong>å®ƒåªä¼šæ˜¾ç¤ºå·²ç»æŒ‚è½½çš„ç£ç›˜ä¿¡æ¯ï¼</strong></p><p><code>df -h</code>, å³<code>--human-readble</code>ï¼šä»¥1024çš„å€æ•°çš„æ–¹å¼æ˜¾ç¤ºå¤§å°ã€‚(e.g., 1023M)</p><p><code>df -T</code>ï¼šæŸ¥çœ‹æ‰€æœ‰ç£ç›˜çš„æ–‡ä»¶ç³»ç»Ÿç±»å‹(type)</p></li><li><p><strong><code>fdisk</code>å‘½ä»¤</strong></p><p><code>fdisk</code>ï¼šå¼ºå¤§çš„ç£ç›˜ç›‘è§†å’Œæ“ä½œå·¥å…·ã€‚</p><p><code>fdisk -l</code>ä¼šæ˜¾ç¤º<strong>æ‰€æœ‰çš„</strong>ç£ç›˜å’Œåˆ†åŒºï¼ä¸è®ºæœ‰æ²¡æœ‰æŒ‚è½½ï¼Œéƒ½ä¼šè¢«åˆ—å‡ºæ¥ã€‚</p></li><li><p><strong>mountå‘½ä»¤</strong></p><p><code>mount</code>ï¼šæŒ‚è½½ä¸€ä¸ªæ–‡ä»¶ç³»ç»Ÿ</p><p><code>mount -t ntfs &lt;source&gt; &lt;target&gt;</code>ï¼šä»¥ntfsæ–‡ä»¶ç³»ç»Ÿçš„å½¢å¼ä»æºç›®å½•æŒ‚è½½åˆ°ç›®æ ‡ç›®å½•ã€‚tè¡¨ç¤ºtypesç±»å‹</p><p><code>mount -a</code>ï¼šæŒ‚è½½ fstab ä¸­çš„æ‰€æœ‰æ–‡ä»¶ç³»ç»Ÿã€‚aè¡¨ç¤ºall</p></li><li><p><strong>blkidå‘½ä»¤</strong></p><p><code>sudo blkid</code>ï¼šè·å–å„ä¸ªåˆ†åŒºçš„UUIDå’Œåˆ†åŒºç±»å‹TYPE</p></li><li><p>ç‰©ç†ç£ç›˜ä¸ç£ç›˜åˆ†åŒºï¼šä¸€ä¸ªç‰©ç†ç£ç›˜åœ¨<code>fdisk -l</code>ä¸­çš„æ˜¾ç¤ºå¾€å¾€ç±»ä¼¼äº<code>/dev/sda</code>ï¼Œ<code>/dev/sdb</code>ï¼Œ<code>/dev/nvme0n1</code>ã€‚ä¸€èˆ¬æƒ…å†µä¸‹æ˜¯ä¸å¸¦æ•°å­—çš„ï¼Œsda sdbæ˜¯æœ€å¸¸è§çš„å‘½åã€‚è€Œåˆ†åŒºå‘½ååˆ™æ˜¯å¦‚ï¼š<code>/dev/sda1</code>ï¼Œ<code>/dev/sdb2</code>ä¹‹ç±»åœ¨ç‰©ç†ç£ç›˜çš„åé¢å¸¦ä¸Šæ•°å­—è¡¨ç¤ºåˆ†åŒºç¼–å·ã€‚</p><p>ä½†æœ‰äº›å¦‚åŒç³»ç»Ÿä¸­ï¼Œå¯èƒ½ä¼šå‡ºç°æœ€åä¸€ä¸ªä¾‹å­ä¸­å±•ç¤ºçš„å‘½åï¼Œè¿™ç§ç£ç›˜çš„åˆ†åŒºåˆ™æ˜¯ä»¥<code>p[x]</code>ç»“å°¾ï¼Œå¦‚<code>/dev/nvme0n1p1</code>ï¼Œ<code>/dev/nvme0n1p9</code>ã€‚</p></li><li><p>Linuxå¼€æœºåä¸ä¼šè‡ªåŠ¨æŒ‚è½½Windowsæ–‡ä»¶æ ¼å¼NTFSçš„ç£ç›˜ã€‚</p></li><li><p><code>sudo chmod -R 777 &lt;Folder_Name&gt;</code> å¯ä»¥å–æ¶ˆä¸€ä¸ªæ–‡ä»¶å¤¹çš„å…¨éƒ¨è®¿é—®æƒé™ã€‚</p></li><li><p><code>chmod</code>å‘½ä»¤å¯¹ext3/4æ–‡ä»¶ç³»ç»Ÿï¼Œå³Linuxæ ¼å¼çš„æ–‡ä»¶ç³»ç»Ÿæ‰æœ‰æ•ˆï¼Œå¯¹å…¶ä»–æ–‡ä»¶ç³»ç»Ÿï¼Œå¦‚vfat(Fat32)ï¼ŒNTFSéƒ½æ˜¯æ— æ•ˆçš„ã€‚</p></li><li><p>/etc/fstab` æ–‡ä»¶æ˜¯æŒç®¡ç¡¬ç›˜è‡ªåŠ¨æŒ‚è½½é…ç½®çš„æ–‡ä»¶ï¼ŒåŒ…å«è‡ªåŠ¨æŒ‚è½½åˆ†åŒºè¿‡ç¨‹çš„å¿…è¦ä¿¡æ¯ã€‚æ¯ä¸€æ¡è®°å½•æ ¼å¼å¦‚ä¸‹ï¼š</p><p><code>[Device] [Mount Point] [File System Type] [Options] [Dump] [Pass]</code></p><p>å¦‚ï¼š</p><p><code>UUID=B45A01D55A019570 /data ntfs defaults 0 2</code></p><p>å…¶ä¸­ï¼š</p><p><code>[Options]</code> ï¼š<code>defaults</code>è¡¨ç¤ºç”¨é»˜è®¤çš„<code>rw, suid, dev, exec, auto, nouser, async</code>ç­‰é€‰é¡¹ï¼ˆä¸åŒå†…æ ¸å’Œæ–‡ä»¶ç³»ç»Ÿä¸åŒï¼‰è¿›è¡ŒæŒ‚è½½ï¼Œè¿™äº›é€‰é¡¹çš„å«ä¹‰ï¼š<code>rw</code> å¯è¯»å†™ï¼›<code>suid</code> æ‰§è¡Œç¨‹åºæ—¶éµå®ˆ<code>uuid</code>ï¼›<code>dev</code> è§£é‡Šå­—ç¬¦æˆ–ç¦æ­¢ç‰¹æ®Šè®¾å¤‡ï¼›<code>exec</code> å…è®¸æ‰§è¡ŒäºŒè¿›åˆ¶æ–‡ä»¶ï¼›<code>auto</code> å¯ä»¥<code>-a</code>æ–¹å¼åŠ è½½ï¼›<code>nouser</code> ç¦æ­¢æ™®é€šç”¨æˆ·æŒ‚è½½æ­¤æ–‡ä»¶ç³»ç»Ÿï¼›<code>async</code> æ‰€æœ‰I/Oå¼‚æ­¥å®Œæˆã€‚</p><p><code>[Dump]</code> ï¼šæ˜¯å¦å¼€å¯åˆ†åŒºå¤‡ä»½ï¼Œ0è¡¨ç¤ºå…³é—­</p><p><code>[Pass]</code>ï¼šç³»ç»Ÿå¯åŠ¨æ—¶æ£€æŸ¥åˆ†åŒºé”™è¯¯çš„é¡ºåºï¼Œrootä¸º1ï¼Œå…¶ä»–ä¸º2ï¼Œ0ä¸ºä¸æ£€æŸ¥ã€‚</p></li><li><p>åœ¨<code>fstab</code>æ–‡ä»¶ä¸­æ·»åŠ è®°å½•å‰ä¸€å®šè¦å…ˆå°è¯•ç”¨mountå‘½ä»¤æ‰‹åŠ¨æŒ‚è½½ã€‚</p></li></ol><h3 id="å‚è€ƒ"><a class="markdownIt-Anchor" href="#å‚è€ƒ"></a> å‚è€ƒ</h3><ol><li><a href="https://blog.csdn.net/qxqxqzzz/article/details/89790688">Ubuntu18.04 å¼€æœºè‡ªåŠ¨æŒ‚è½½å…¶ä»–ç¡¬ç›˜</a></li><li><a href="https://blog.csdn.net/ybdesire/article/details/79145180">LinuxæŸ¥çœ‹ä¸æŒ‚è½½æ–°ç£ç›˜</a></li></ol><h2 id="cudaçš„å®‰è£…"><a class="markdownIt-Anchor" href="#cudaçš„å®‰è£…"></a> CUDAçš„å®‰è£…</h2><ol><li><p>æ£€æŸ¥è‡ªå·±çš„GPUæ˜¯å¦æ˜¯CUDA-capableï¼Œåœ¨ç»ˆç«¯ä¸­è¾“å…¥<code>lspci | grep -I NVIDIA</code> ï¼Œä¼šæ˜¾ç¤ºè‡ªå·±çš„NVIDIA GPUç‰ˆæœ¬ä¿¡æ¯ï¼Œå»CUDAçš„å®˜ç½‘æŸ¥çœ‹è‡ªå·±çš„GPUç‰ˆæœ¬æ˜¯å¦åœ¨CUDAçš„æ”¯æŒåˆ—è¡¨ä¸­ã€‚</p></li><li><p>æ£€æŸ¥è‡ªå·±çš„Linuxç‰ˆæœ¬æ˜¯å¦æ”¯æŒ CUDAï¼ˆUbuntu ç¨³å®šæ”¯æŒç‰ˆæ²¡é—®é¢˜ï¼‰ã€‚</p></li><li><p>æ£€æŸ¥å…¶ä»–é—®é¢˜ã€‚è¿™é‡Œå°±ä¸è¯¦è¿°äº†ï¼Œæ­£å¸¸æƒ…å†µä¸‹ä¸€èˆ¬OKï¼Œè¿™é‡Œä¸»è¦è¦æ£€æŸ¥æ˜¯å¦å®‰è£…äº†<code>gcc</code>ï¼Œæ˜¯å¦å®‰è£…äº†<code>kernel header</code>å’Œ <code>package development</code>ã€‚å¦‚æœå®³æ€•å‡ºç°é—®é¢˜å¯ä»¥å‚è€ƒ<a href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#pre-installation-actions">å®˜ç½‘</a>æ‰§è¡Œè¿™å‡ æ­¥æ£€æµ‹ã€‚</p></li><li><p>äº<a href="https://developer.nvidia.com/cuda-downloads">CUDAå®˜ç½‘</a>ä¸‹è½½ä¸ç³»ç»Ÿå¯¹åº”çš„CUDAç‰ˆæœ¬ã€‚æœ€åä¸€ä¸ªé€‰é¡¹é€‰æ‹©<code>runfile</code>ï¼Œå› ä¸ºå…¶æ‰€éœ€æ­¥éª¤æœ€å°‘ï¼Œä¹Ÿå› æ­¤æœ€ä¸å®¹æ˜“å‡ºé—®é¢˜ã€‚æ‰€æœ‰é€‰é¡¹å®Œæˆåï¼Œä½ ä¼šçœ‹åˆ°å¦‚ä¸‹ä¸¤è¡Œå‘½ä»¤ï¼š</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget http://developer.download.nvidia.com/compute/cuda/10.2/Prod/local_installers/cuda_10.2.89_440.33.01_linux.run</span><br><span class="line">sudo sh cuda_10.2.89_440.33.01_linux.run</span><br></pre></td></tr></table></figure><p>å…ˆä¸è¦æ‰§è¡Œç¬¬äºŒæ¡<code>sudo</code>å¼€å¤´çš„æŒ‡ä»¤ï¼Œåªä½¿ç”¨<code>wget</code>ä¸‹è½½ã€‚</p></li><li><p>å¦‚æœä¹‹å‰æœ‰å®‰è£…è¿‡å…¶ä»–ç‰ˆæœ¬çš„CUDAå¹¶å¸Œæœ›å°†å…¶å¸è½½ï¼Œä½¿ç”¨<code>sudo nvidia-uninstall</code>å¸è½½ã€‚å¦‚æœè¯¥å‘½ä»¤ä¸åœ¨ç³»ç»Ÿè·¯å¾„ä¸­ï¼Œåˆ™ä½¿ç”¨<code>sudo /usr/bin/nvidia-uninstall</code>ï¼ˆä½ç½®å¯èƒ½å˜åŒ–ï¼‰å¸è½½ã€‚å¦‚æœè¿˜æ˜¯æ²¡æœ‰ï¼Œæˆ–æ˜¯ä¹‹å‰çš„é©±åŠ¨å·²ç»æŸåï¼Œåˆ™ï¼š</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get remove --purge nvidia*</span><br><span class="line">sudo chmod +x NVIDIA-Linux-x86_64-410.93.run</span><br><span class="line">sudo ./NVIDIA-Linux-x86_64-410.93.run --uninstall</span><br></pre></td></tr></table></figure></li><li><p>å±è”½<code>nouveau</code>é©±åŠ¨ã€‚</p></li></ol><h3 id="nouveauæ˜¯ä»€ä¹ˆ"><a class="markdownIt-Anchor" href="#nouveauæ˜¯ä»€ä¹ˆ"></a> Nouveauæ˜¯ä»€ä¹ˆ</h3><blockquote><h4 id="nouveau-accelerated-open-source-driver-for-nvidia-cards"><a class="markdownIt-Anchor" href="#nouveau-accelerated-open-source-driver-for-nvidia-cards"></a> Nouveau: Accelerated Open Source driver for nVidia cards</h4><p>The <strong>nouveau</strong> project aims to build high-quality, free/libre software drivers for <a href="https://nouveau.freedesktop.org/wiki/CodeNames/">nVidia cards</a>. â€œNouveauâ€ [<em>nuvo</em>] is the French word for â€œnewâ€. Nouveau is composed of a Linux kernel KMS driver (nouveau), Gallium3D drivers in Mesa, and the Xorg DDX (xf86-video-nouveau). The kernel components have also been ported to <a href="https://nouveau.freedesktop.org/wiki/NetBSD/">NetBSD</a>.</p></blockquote><p>ç®€å•è¯´ï¼Œnouveauæ˜¯Linuxç³»ç»Ÿé»˜è®¤çš„ç»™NVIDIAå¡é¢„è£…çš„ä¸€ä¸ªå›¾å½¢åŠ é€Ÿé©±åŠ¨ï¼Œè€Œè¿™ä¸ªé©±åŠ¨ä¼šä¸CUDAäº§ç”Ÿéƒ¨åˆ†å†²çªï¼Œæ‰€ä»¥åœ¨å®‰è£…CUDAä¹‹å‰éœ€è¦å°†å…¶ç¦ç”¨ï¼Œå¦åˆ™ä¼šå‡ºç°å¡åœ¨å¼€æœºç™»å½•ç•Œé¢æ— æ³•è¿›å…¥å›¾å½¢ç•Œé¢ï¼ˆä»ç„¶å¯ä»¥sshè®¿é—®ï¼‰ï¼Œé»‘å±ï¼Œé¼ æ ‡é”®ç›˜è¾“å…¥è¢«ç¦ç”¨ç­‰é—®é¢˜ä¸­çš„ä¸€ä¸ªæˆ–å¤šä¸ªï¼ˆäº²èº«ç»å†ï¼‰ã€‚</p><p>ç»§ç»­å®‰è£…æ•™ç¨‹ï¼š</p><ol start="6"><li><p>åˆšæ‰è¯´åˆ°è¦å±è”½<code>nouveau</code>ï¼Œé‚£ä¹ˆæ€ä¹ˆçŸ¥é“ä½ æœ‰æ²¡æœ‰è£…å®ƒå‘¢ï¼Ÿ<br>ä½¿ç”¨<code>lsmod | grep nouveau</code>å‘½ä»¤ï¼Œå¦‚æœæ²¡æœ‰è¾“å‡ºï¼Œå°±å¯ä»¥åˆ¤å®šä½ æ²¡æœ‰è¿è¡Œ<code>nouveau</code>ï¼Œå¯ä»¥ç›´æ¥è¿›å…¥ä¸‹ä¸€æ­¥ï¼Œå¦åˆ™ï¼š</p><ol><li><p>Create a file at <code>/etc/modprobe.d/blacklist-nouveau.conf</code> with the following contents:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">blacklist nouveau</span><br><span class="line">options nouveau modeset=0</span><br></pre></td></tr></table></figure></li><li><p>Regenerate the kernel initramfs:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo update-initramfs -u</span><br></pre></td></tr></table></figure></li><li><p>Restart.</p></li><li><p>Run <code>lsmod | grep nouveau</code> again. If there is no output, then you succeed.</p></li></ol></li><li><p>æ­¤åå»ºè®®è¿›å…¥ä¸€ä¸ªéå›¾å½¢ç•Œé¢å®‰è£…ï¼Œè¿™é‡Œå¯ä»¥åœ¨é‡å¯åä½¿ç”¨<code>ssh</code>æ¥å…¥ï¼Œä¹Ÿå¯ä»¥åœ¨é‡å¯åæŒ‰<code>alt+ctrl+f1</code>ï¼Œè¿›å…¥<strong>text mode</strong>ï¼Œç™»å½•è´¦æˆ·ã€‚</p></li><li><p>è¾“å…¥ <code>sudo service lightdm stop</code> å…³é—­å›¾å½¢åŒ–ç•Œé¢ã€‚</p></li><li><p>æ‰§è¡Œåˆšæ‰å®˜ç½‘ä¸­ç»™å‡ºçš„ç¬¬äºŒæ¡å‘½ä»¤ï¼š<code>sudo sh cuda_10.2.89_440.33.01_linux.run</code>ã€‚æ³¨æ„è¿™é‡Œçš„ç‰ˆæœ¬ä¼šä¸æ–­æœ‰å˜åŒ–ã€‚æ³¨æ„è¿™é‡Œæœ‰ä¸€ä¸ªç‚¹ï¼Œå³ä½ æ˜¯å¦è¦åŒæ—¶å®‰è£…OpenGLï¼Œå¦‚æœä½ æ˜¯åŒæ˜¾ï¼Œä¸”ä¸»æ˜¾æ˜¯éNVIDIAçš„GPUéœ€è¦é€‰æ‹©noï¼Œå¦åˆ™yesã€‚åŒç†ï¼Œå¦‚æœå‡†å¤‡é€‰noï¼Œä¹Ÿå¯ä»¥ä¸€å¼€å§‹å°±åŠ ä¸Šå‚æ•°<code>--no-opengl-files</code>ã€‚ å¦å¤–ï¼Œå¦‚æœä¸èƒ½ç›´æ¥æ‰§è¡Œï¼Œä½¿ç”¨<code>sudo chmod a+x cuda_xx.xx.xx_linux.run</code>ä¸ºå…¶èµ‹æƒã€‚</p></li><li><p>å®‰è£…æˆåŠŸåï¼Œä¼šæç¤ºä½ å°†cudaçš„å‡ ä¸ªè·¯å¾„æ·»åŠ åˆ°ç³»ç»Ÿè·¯å¾„ä¸­ï¼Œè¿™é‡Œé‡å¤ä¸€ä¸‹ï¼Œ</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> PATH=/usr/<span class="built_in">local</span>/cuda-10.2/bin:/usr/<span class="built_in">local</span>/cuda-10.2/NsightCompute-2019.1<span class="variable">$&#123;PATH:+:<span class="variable">$&#123;PATH&#125;</span>&#125;</span></span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=/usr/<span class="built_in">local</span>/cuda-10.2/lib64\</span><br><span class="line">                         <span class="variable">$&#123;LD_LIBRARY_PATH:+:<span class="variable">$&#123;LD_LIBRARY_PATH&#125;</span>&#125;</span></span><br></pre></td></tr></table></figure></li><li><p>ä½¿ç”¨<code>nvcc -V</code>æ£€æµ‹æ˜¯å¦å®‰è£…æˆåŠŸã€‚å½“ç„¶ä¹Ÿå¯ä»¥åŒæ—¶æµ‹è¯•<code>nvidia-smi</code>ã€‚è¿™é‡Œå¯èƒ½ä¼šæŠ¥é”™å¹¶æç¤ºéœ€è¦aptå®‰è£…ä¸€ä¸ªåŒ…ï¼ŒæŒ‰æç¤ºæ¥ã€‚</p></li><li><p>å®Œæˆã€‚</p></li></ol><h3 id="å‚è€ƒ-2"><a class="markdownIt-Anchor" href="#å‚è€ƒ-2"></a> å‚è€ƒ</h3><ol><li><a href="https://developer.nvidia.com/cuda-downloads">NVIDIA CUDAä¸‹è½½å®˜ç½‘</a></li><li><a href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html">NVIDIA å®˜æ–¹å®‰è£…æŒ‡å—ï¼ˆè‹±æ–‡ï¼‰</a></li><li><a href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#pre-installation-actions">NVIDIA å®˜æ–¹å®‰è£…æŒ‡å—ä¸­å‰ç½®æ£€æŸ¥éƒ¨åˆ†</a></li><li><a href="https://www.pugetsystems.com/labs/hpc/How-To-Install-CUDA-10-together-with-9-2-on-Ubuntu-18-04-with-support-for-NVIDIA-20XX-Turing-GPUs-1236/">How To Install CUDA 10 (together with 9.2) on Ubuntu 18.04 with support for NVIDIA 20XX Turing GPUs</a></li><li><a href="https://blog.csdn.net/lipi37/article/details/90407099">Ubuntu å®‰è£… cuda æ—¶å¡åœ¨ç™»å½•ç•Œé¢ï¼ˆlogin loop)çš„è§£å†³æ–¹æ¡ˆä¹‹ä¸€</a></li><li><a href="https://blog.csdn.net/wkk15903468980/article/details/56489704">ubuntuå®‰è£…cudaå¾ªç¯ç™»å½•</a></li><li><a href="https://blog.csdn.net/qq_33200967/article/details/80689543">Ubuntuå®‰è£…å’Œå¸è½½CUDAå’ŒCUDNN</a></li><li><a href="https://blog.csdn.net/wf19930209/article/details/81879514">Linuxå®‰è£…CUDAçš„æ­£ç¡®å§¿åŠ¿</a></li></ol><h2 id="cuda-ä¸-cudnn-çš„è”ç³»"><a class="markdownIt-Anchor" href="#cuda-ä¸-cudnn-çš„è”ç³»"></a> CUDA ä¸ CUDNN çš„è”ç³»</h2><ol><li>è¦å…ˆè£…CUDAå†è£…CUDNNã€‚</li><li>å‰è€…æ˜¯å¹³å°ï¼Œåè€…æ˜¯åŸºäºå¹³å°çš„æ·±åº¦å­¦ä¹ åŠ é€Ÿå™¨ã€‚åŠ é€Ÿå¯ä»¥åº”ç”¨äºå‡ ä¹å…¨éƒ¨æ·±åº¦å­¦ä¹ å¹³å°ã€‚è¿˜æ˜¯è¦å®‰çš„ã€‚</li><li>ä¸€èˆ¬æ·±åº¦å­¦ä¹ ä½¿ç”¨å®‰è£…runtimeç‰ˆæœ¬å³å¯ã€‚</li><li><a href="https://developer.nvidia.com/rdp/cudnn-download">CUDNNå®˜æ–¹ä¸‹è½½</a>ï¼Œ<a href="https://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html">CUDNNå®˜æ–¹å®‰è£…æ­¥éª¤</a></li></ol><h2 id="ä¿®å¤ubuntuä¸­æ£€æµ‹åˆ°ç³»ç»Ÿç¨‹åºé”™è¯¯çš„é—®é¢˜"><a class="markdownIt-Anchor" href="#ä¿®å¤ubuntuä¸­æ£€æµ‹åˆ°ç³»ç»Ÿç¨‹åºé”™è¯¯çš„é—®é¢˜"></a> ä¿®å¤Ubuntuä¸­â€œæ£€æµ‹åˆ°ç³»ç»Ÿç¨‹åºé”™è¯¯â€çš„é—®é¢˜</h2><h3 id="é—®é¢˜æè¿°"><a class="markdownIt-Anchor" href="#é—®é¢˜æè¿°"></a> é—®é¢˜æè¿°</h3><p>æ¯æ¬¡å¼€æœºæ—¶éƒ½ä¼šæœ‰â€œ<strong>Ubuntu xx.xx åœ¨å¯åŠ¨æ—¶æ£€æµ‹åˆ°ç³»ç»Ÿç¨‹åºé”™è¯¯</strong> â€å¼¹çª—å‡ºç°ã€‚å³ä½¿ç‚¹å‡»æŠ¥å‘Šä¸‹æ¬¡è¿˜ä¼šç»§ç»­å‡ºç°ã€‚</p><h3 id="é—®é¢˜æ¥æº"><a class="markdownIt-Anchor" href="#é—®é¢˜æ¥æº"></a> é—®é¢˜æ¥æº</h3><p>ä¹‹å‰çš„æŸä¸ªæ—¶åˆ»æŸä¸ªç¨‹åºå´©æºƒäº†ï¼Œè€ŒUbuntuæƒ³è®©ä½ å†³å®šè¦ä¸è¦æŠŠè¿™ä¸ªé—®é¢˜æŠ¥å‘Šç»™å¼€å‘è€…ï¼Œè¿™æ ·ä»–ä»¬å°±èƒ½å¤Ÿä¿®å¤è¿™ä¸ªé—®é¢˜ã€‚</p><h3 id="è§£å†³åŠæ³•"><a class="markdownIt-Anchor" href="#è§£å†³åŠæ³•"></a> è§£å†³åŠæ³•</h3><ol><li><code>sudo rm /var/crash/*</code> ï¼šåˆ é™¤è¿™äº›é”™è¯¯æŠ¥å‘Šã€‚ä½†æ˜¯å¦‚æœåˆæœ‰ä¸€ä¸ªç¨‹åºå´©æºƒäº†ï¼Œä½ å°±ä¼šå†æ¬¡çœ‹åˆ°â€œæ£€æµ‹åˆ°ç³»ç»Ÿç¨‹åºé”™è¯¯â€çš„é”™è¯¯ã€‚ä½ å¯ä»¥å†æ¬¡åˆ é™¤è¿™äº›æŠ¥å‘Šæ–‡ä»¶ï¼Œæˆ–è€…é€‰æ‹©ç¦ç”¨Apportæ¥å½»åº•åœ°æ‘†è„±è¿™ä¸ªé”™è¯¯å¼¹çª—ã€‚å¦‚æœä½ è¿™æ ·åšï¼Œç³»ç»Ÿä¸­ä»»ä½•ç¨‹åºå´©æºƒæ—¶ï¼Œç³»ç»Ÿéƒ½ä¸ä¼šå†é€šçŸ¥ä½ ã€‚ä½†è¿™æœªå¿…ä¸€ä»¶åäº‹ï¼Œé™¤éä½ æ„¿æ„å¡«å†™é”™è¯¯æŠ¥å‘Šã€‚å¦‚æœä½ ä¸æƒ³å¡«å†™é”™è¯¯æŠ¥å‘Šï¼Œé‚£ä¹ˆè¿™äº›é”™è¯¯é€šçŸ¥å­˜ä¸å­˜åœ¨éƒ½ä¸ä¼šæœ‰ä»€ä¹ˆåŒºåˆ«ã€‚</li><li><code>sudo vim /etc/default/apport</code> æ°¸ä¹…å±è”½è¿™äº›æŠ¥é”™ã€‚</li></ol><h3 id="å‚è€ƒ-3"><a class="markdownIt-Anchor" href="#å‚è€ƒ-3"></a> å‚è€ƒ</h3><ol><li><a href="https://blog.csdn.net/hywerr/article/details/72582082">å¦‚ä½•ä¿®å¤ubuntuä¸­æ£€æµ‹åˆ°ç³»ç»Ÿç¨‹åºé”™è¯¯çš„é—®é¢˜</a></li><li><a href="https://itsfoss.com/how-to-fix-system-program-problem-detected-ubuntu/">How To Fix System Program Problem Detected In Ubuntu</a></li></ol><h2 id="å®‰è£…python36ç‰ˆæœ¬çš„anaconda"><a class="markdownIt-Anchor" href="#å®‰è£…python36ç‰ˆæœ¬çš„anaconda"></a> å®‰è£…Python3.6ç‰ˆæœ¬çš„Anaconda</h2><p>ç”±äºä¹‹å‰ä½¿ç”¨çš„ä¸€äº›å¼€æºåº“å’Œè½¯ä»¶å¯¹3.7çš„æ”¯æŒæ€§å°šè¿˜æœ‰é—®é¢˜ï¼Œè€ŒAnacondaé»˜è®¤Pythonç‰ˆæœ¬ä¸º3.6ï¼Œ æ‰€ä»¥æœ‰å¿…è¦æŠŠAnacondaé™çº§ä¸º3.6ç‰ˆæœ¬ã€‚</p><p>å®‰è£…æ–¹æ³•ï¼š</p><ol><li><p>åˆ°Anacondaå®˜ç½‘ä¸‹è½½å¹¶å®‰è£…æœ€æ–°3.7ç‰ˆæœ¬ã€‚</p></li><li><p>ä¸–ç•Œçº¿å¼€å§‹åˆ†æ­§ï¼Œä½ å¯ä»¥é€‰æ‹©ä¿ç•™3.7ç‰ˆæœ¬çš„Anacondaï¼Œå¹¶åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿç¯å¢ƒï¼Œæˆ–æ˜¯ç›´æ¥æ›¿æ¢Pythonç‰ˆæœ¬ã€‚</p><ol><li><p>å¯¹å‰è€…ï¼Œ<br>è‹¥åªè¦ä¸€ä¸ªpythonç¯å¢ƒä¸è¦packagesï¼Œ</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda create --name ana36 python=3.6</span><br><span class="line"><span class="built_in">source</span> activate ana36</span><br></pre></td></tr></table></figure><p>åä¹‹ï¼Œå¦‚æœè¦å®‰è£…ä¸€ä¸ªæ–°çš„Anacondaï¼ŒåŒ…å«é»˜è®¤çš„æ‰€æœ‰packagesï¼Œ</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda create -n ana36 anaconda python=3.6</span><br><span class="line"><span class="built_in">source</span> activate ana36</span><br></pre></td></tr></table></figure></li><li><p>å¯¹åè€…ï¼Œ</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install python=3.6</span><br></pre></td></tr></table></figure></li></ol></li></ol><h2 id="æ·»åŠ vimæ‹·è´è‡³ç³»ç»Ÿå‰ªè´´æ¿å¿«æ·é”®æ”¯æŒ"><a class="markdownIt-Anchor" href="#æ·»åŠ vimæ‹·è´è‡³ç³»ç»Ÿå‰ªè´´æ¿å¿«æ·é”®æ”¯æŒ"></a> æ·»åŠ Vimæ‹·è´è‡³ç³»ç»Ÿå‰ªè´´æ¿å¿«æ·é”®æ”¯æŒ</h2><p>(from: <a href="http://vim.wikia.com/wiki/Mac_OS_X_clipboard_sharing">link</a>)</p><p>Having trouble copying selected text from Vim (not MacVim)? Since using <code>&quot;+y</code> or â€˜&quot;*yâ€™ in Vim on a Mac doesnâ€™t actually copy the selected text to the system clipboard, you might find it beneficial to do the following:</p><ol><li>Open your <code>~/.vimrc</code> file</li><li>add <code>vmap '' :w !pbcopy</code></li><li>Save it and <code>source</code> the file</li></ol><p>ç°åœ¨ï¼Œä½ å°±å¯ä»¥åœ¨ visual modeï¼Œ å³åœ¨Escå‘½ä»¤æ¨¡å¼åæŒ‰ä¸‹vé”®åçš„é€‰æ‹©æ¨¡å¼ä¸­ï¼Œé€‰å¥½éœ€è¦æ‹·è´åŒºåŸŸåï¼Œè¿å‡»ä¸¤æ¬¡<code>'</code> ï¼Œå³ä½¿ç”¨ <code>''</code>æ¥æ‹·è´æ‰€é€‰åŒºåŸŸã€‚</p><h2 id="åœ¨maclinuxä¸Šä½¿ç”¨sshæŒ‚è½½è¿œç¨‹ç½‘ç»œç¡¬ç›˜"><a class="markdownIt-Anchor" href="#åœ¨maclinuxä¸Šä½¿ç”¨sshæŒ‚è½½è¿œç¨‹ç½‘ç»œç¡¬ç›˜"></a> åœ¨Mac/Linuxä¸Šä½¿ç”¨sshæŒ‚è½½è¿œç¨‹ç½‘ç»œç¡¬ç›˜</h2><p>TL;DRï¼š</p><ol><li>å®‰è£…sshfs: <code>sudo apt-get install sshfs</code></li><li>ç›´æ¥åœ¨<code>~/.zshrc</code>ä¸­æ·»åŠ ä»¥ä¸‹è¡Œï¼šï¼ˆå½“ç„¶ï¼Œéœ€è¦æ›´æ”¹æ–‡ä»¶å¤¹åç§°ï¼Œä»¥åŠæŒ‚è½½åçš„å‘½åï¼‰</li></ol><h3 id="è¿æ¥æœ¬åœ°linux-server"><a class="markdownIt-Anchor" href="#è¿æ¥æœ¬åœ°linux-server"></a> è¿æ¥æœ¬åœ°Linux Server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">connect_misaka</span></span> () &#123;</span><br><span class="line">    <span class="keyword">if</span> [ ! -d <span class="string">&quot;/Volumes/misaka-home&quot;</span> ]</span><br><span class="line">    <span class="keyword">then</span></span><br><span class="line">        mkdir /Volumes/misaka-home</span><br><span class="line">        sshfs -o allow_other,default_permissions,IdentityFile=~/.ssh/id_rsa,reconnect,ServerAliveInterval=15,ServerAliveCountMax=3 misaka:/home/miracle /Volumes/misaka-home/ -ovolname=mk-home</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">if</span> [ ! -d <span class="string">&quot;/Volumes/misaka-storage&quot;</span> ]</span><br><span class="line">    <span class="keyword">then</span></span><br><span class="line">        mkdir /Volumes/misaka-storage</span><br><span class="line">        sshfs -o allow_other,default_permissions,IdentityFile=~/.ssh/id_rsa,reconnect,ServerAliveInterval=15,ServerAliveCountMax=3 misaka:/data /Volumes/misaka-storage/ -ovolname=mk-2T</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="è¿æ¥gypsum"><a class="markdownIt-Anchor" href="#è¿æ¥gypsum"></a> è¿æ¥Gypsum</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">connect_gypsum</span></span> () &#123;</span><br><span class="line">    <span class="keyword">if</span> [ ! -d <span class="string">&quot;/Volumes/gypsum/&quot;</span> ]</span><br><span class="line">    <span class="keyword">then</span></span><br><span class="line">        mkdir /Volumes/gypsum</span><br><span class="line">        sshfs -o allow_other,default_permissions,IdentityFile=~/.ssh/id_rsa,reconnect,ServerAliveInterval=15,ServerAliveCountMax=3 gypsum:/home/zhongyangzha /Volumes/gypsum/ -ovolname=gp-home</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">if</span> [ ! -d <span class="string">&quot;/Volumes/gypsum-scratch/&quot;</span> ]</span><br><span class="line">    <span class="keyword">then</span></span><br><span class="line">        mkdir /Volumes/gypsum-scratch/</span><br><span class="line">        sshfs -o allow_other,default_permissions,IdentityFile=~/.ssh/id_rsa,reconnect,ServerAliveInterval=15,ServerAliveCountMax=3 gypsum:/mnt/nfs/scratch1/zhongyangzha/ /Volumes/gypsum-scratch/ -ovolname=gp-scratch</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">if</span> [ ! -d <span class="string">&quot;/Volumes/gypsum-work/&quot;</span> ]</span><br><span class="line">    <span class="keyword">then</span></span><br><span class="line">        mkdir /Volumes/gypsum-work</span><br><span class="line">        sshfs -o allow_other,default_permissions,IdentityFile=~/.ssh/id_rsa,reconnect,ServerAliveInterval=15,ServerAliveCountMax=3 gypsum:/mnt/nfs/work1/trahman/zhongyangzha /Volumes/gypsum-work/ -ovolname=gp-work</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="å‚æ•°è§£é‡Š"><a class="markdownIt-Anchor" href="#å‚æ•°è§£é‡Š"></a> å‚æ•°è§£é‡Š</h3><ol><li><code>ovolname</code>ï¼šæŒ‚è½½ä¸Šç½‘ç»œç¡¬ç›˜ä¹‹åç¡¬ç›˜çš„å‘½å</li><li><code>IdentityFile</code>ï¼šå¦‚æœå·²ç»è®¾ç½®äº†å…å¯†ç™»å½•ï¼Œç”¨è¿™ä¸ªå‚æ•°æŒ‡æ˜sshç§é’¥ä½ç½®å³å¯ï¼Œä¸éœ€è¦è¾“å…¥å¯†ç ã€‚</li><li><code>&lt;source&gt; &lt;target&gt;</code>ï¼šç½‘ç»œç¡¬ç›˜æºä½ç½®&lt;username@ip.address:/the/source/path&gt; ä¸æœ¬æœºç›®æ ‡æŒ‚è½½ä½ç½®</li><li><code>reconnect,ServerAliveInterval=15,ServerAliveCountMax=3</code>ï¼šå¤šæ¬¡æ–­çº¿é‡è¿ï¼Œå¯ä»¥å†æ–­å¼€ç½‘ç»œè¿æ¥ã€æœåŠ¡å™¨é‡å¯ç­‰é—®é¢˜å‘ç”Ÿåå†æ¬¡è‡ªåŠ¨è¿æ¥ã€‚</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;ç¡¬ç›˜ç›¸å…³&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#ç¡¬ç›˜ç›¸å…³&quot;&gt;&lt;/a&gt; ç¡¬ç›˜ç›¸å…³&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;dfå‘½ä»¤&lt;/strong&gt;&lt;br&gt;
&lt;code&gt;df&lt;/code&gt;ï¼šæ£€æŸ¥linuxæœåŠ¡å™¨çš„æ–‡ä»¶ç³»</summary>
      
    
    
    
    
    <category term="python" scheme="https://www.miracleyoo.com/tags/python/"/>
    
    <category term="machine-learning" scheme="https://www.miracleyoo.com/tags/machine-learning/"/>
    
    <category term="deep-learning" scheme="https://www.miracleyoo.com/tags/deep-learning/"/>
    
    <category term="linux" scheme="https://www.miracleyoo.com/tags/linux/"/>
    
    <category term="ssh" scheme="https://www.miracleyoo.com/tags/ssh/"/>
    
    <category term="net-disk" scheme="https://www.miracleyoo.com/tags/net-disk/"/>
    
    <category term="cuda" scheme="https://www.miracleyoo.com/tags/cuda/"/>
    
  </entry>
  
  <entry>
    <title>Pandas Resample</title>
    <link href="https://www.miracleyoo.com/2020/03/24/pandas-resample/"/>
    <id>https://www.miracleyoo.com/2020/03/24/pandas-resample/</id>
    <published>2020-03-25T01:26:56.000Z</published>
    <updated>2020-04-26T22:27:22.090Z</updated>
    
    <content type="html"><![CDATA[<p>PandasåŸç”Ÿæ”¯æŒ<code>resample</code>åŠŸèƒ½ï¼Œå‰ææ˜¯ç›®æ ‡DataFrameéœ€è¦æœ‰ä¸€ä¸ªindexçš„columnã€‚å‡è®¾æˆ‘ä»¬ç°åœ¨åœ¨å¯¹ä¸€ä¸ªå–æ ·ç‡ä¸º30Hzçš„DataFrameåšæ“ä½œï¼Œå¹¶æƒ³å°†å®ƒå˜resampleä¸º16Hzã€‚</p><p>é¦–å…ˆæˆ‘ä»¬è¦å»ºç«‹ä¸€ä¸ª<code>timestamp</code>çš„åˆ—ï¼Œè¿™ä¸ªåå­—éšæ„ï¼Œç„¶åå®ƒæ˜¯ä»¥ç§’ä¸ºå•ä½çš„è¯¥å¸§çš„æ—¶é—´ï¼Œå¦‚3.25ï¼Œ14.33ã€‚ç„¶åæˆ‘ä»¬å°†å…¶è½¬æ¢ä¸ºdatatimeæ ¼å¼ï¼Œå•ä½ä¸ºsã€‚</p><p>ä¹‹åä¾¿æ˜¯ç›´æ¥resampleï¼Œresampleä¸­çš„<code>rule</code>ï¼Œå³ç¬¬ä¸€ä¸ªå‚æ•°ï¼ŒæŒ‡æ˜äº†resampleåä¸¤å¸§ä¹‹é—´çš„æ—¶é—´é—´éš”ï¼Œå³å‘¨æœŸã€‚å¦‚æœæˆ‘ä»¬æ˜¯16Hzï¼Œé‚£è¿™ä¸ªå‘¨æœŸä¸º62.5msã€‚</p><p><code>resample</code>æ–¹æ³•çš„æ ¼å¼æ˜¯ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DataFrame.resample(rule, how=<span class="literal">None</span>, axis=<span class="number">0</span>, fill_method=<span class="literal">None</span>, closed=<span class="literal">None</span>, label=<span class="literal">None</span>, convention=<span class="string">&#x27;start&#x27;</span>,kind=<span class="literal">None</span>, loffset=<span class="literal">None</span>, limit=<span class="literal">None</span>, base=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><h2 id="ç¤ºä¾‹ä»£ç "><a class="markdownIt-Anchor" href="#ç¤ºä¾‹ä»£ç "></a> ç¤ºä¾‹ä»£ç </h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df.index=pd.to_datetime(df[<span class="string">&#x27;timestamp&#x27;</span>],unit=<span class="string">&#x27;s&#x27;</span>)</span><br><span class="line">df=df.resample(<span class="string">&#x27;62.5L&#x27;</span>).mean()</span><br><span class="line">df=df.reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">del</span> df[<span class="string">&#x27;timestamp&#x27;</span>]</span><br></pre></td></tr></table></figure><h2 id="pandasæ—¶é—´ç¼©å†™"><a class="markdownIt-Anchor" href="#pandasæ—¶é—´ç¼©å†™"></a> Pandasæ—¶é—´ç¼©å†™</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">B         business day frequency</span><br><span class="line">C         custom business day frequency (experimental)</span><br><span class="line">D         calendar day frequency</span><br><span class="line">W         weekly frequency</span><br><span class="line">M         month end frequency</span><br><span class="line">SM        semi-month end frequency (15th and end of month)</span><br><span class="line">BM        business month end frequency</span><br><span class="line">CBM       custom business month end frequency</span><br><span class="line">MS        month start frequency</span><br><span class="line">SMS       semi-month start frequency (1st and 15th)</span><br><span class="line">BMS       business month start frequency</span><br><span class="line">CBMS      custom business month start frequency</span><br><span class="line">Q         quarter end frequency</span><br><span class="line">BQ        business quarter endfrequency</span><br><span class="line">QS        quarter start frequency</span><br><span class="line">BQS       business quarter start frequency</span><br><span class="line">A         year end frequency</span><br><span class="line">BA, BY    business year end frequency</span><br><span class="line">AS, YS    year start frequency</span><br><span class="line">BAS, BYS  business year start frequency</span><br><span class="line">BH        business hour frequency</span><br><span class="line">H         hourly frequency</span><br><span class="line">T, min    minutely frequency</span><br><span class="line">S         secondly frequency</span><br><span class="line">L, ms     milliseconds</span><br><span class="line">U, us     microseconds</span><br><span class="line">N         nanoseconds</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;PandasåŸç”Ÿæ”¯æŒ&lt;code&gt;resample&lt;/code&gt;åŠŸèƒ½ï¼Œå‰ææ˜¯ç›®æ ‡DataFrameéœ€è¦æœ‰ä¸€ä¸ªindexçš„columnã€‚å‡è®¾æˆ‘ä»¬ç°åœ¨åœ¨å¯¹ä¸€ä¸ªå–æ ·ç‡ä¸º30Hzçš„DataFrameåšæ“ä½œï¼Œå¹¶æƒ³å°†å®ƒå˜resampleä¸º16Hzã€‚&lt;/p&gt;
&lt;p&gt;é¦–å…ˆæˆ‘ä»¬è¦å»ºç«‹ä¸€ä¸ª&lt;co</summary>
      
    
    
    
    
    <category term="python" scheme="https://www.miracleyoo.com/tags/python/"/>
    
    <category term="machine-learning" scheme="https://www.miracleyoo.com/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>EMD, EEMDä¸CEEMD</title>
    <link href="https://www.miracleyoo.com/2020/03/12/eemd/"/>
    <id>https://www.miracleyoo.com/2020/03/12/eemd/</id>
    <published>2020-03-12T18:24:50.000Z</published>
    <updated>2020-04-26T22:25:10.220Z</updated>
    
    <content type="html"><![CDATA[<h2 id="emd"><a class="markdownIt-Anchor" href="#emd"></a> EMD</h2><p>EMD: Empirical Mode Decomposition</p><h3 id="ç‰¹å¾"><a class="markdownIt-Anchor" href="#ç‰¹å¾"></a> ç‰¹å¾</h3><ol><li>è‡ªé€‚åº”ã€‚ä¸å°æ³¢åˆ†æç›¸æ¯”ï¼Œå…‹æœäº†åŸºå‡½æ•°æ— è‡ªé€‚åº”æ€§çš„é—®é¢˜ï¼Œè§£å†³äº†å…¨å±€æœ€ä¼˜å°æ³¢åŸºåœ¨å±€éƒ¨å¹¶éæœ€ä¼˜çš„é—®é¢˜ï¼Œæœ‰åŸºå‡½æ•°è‡ªé€‚åº”ç‰¹æ€§ã€‚</li><li>å¯ä»¥ç›´æ¥è¿›è¡Œåˆ†è§£ï¼Œä¸éœ€è¦é¢„åˆ†æå’Œç ”ç©¶ã€‚</li></ol><h3 id="å†…æ¶µæ¨¡æ€åˆ†é‡"><a class="markdownIt-Anchor" href="#å†…æ¶µæ¨¡æ€åˆ†é‡"></a> å†…æ¶µæ¨¡æ€åˆ†é‡</h3><p>å†…æ¶µæ¨¡æ€åˆ†é‡ï¼ˆIntrinsic Mode Functions, IMFï¼‰å°±æ˜¯åŸå§‹ä¿¡å·è¢«EMDåˆ†è§£ä¹‹åå¾—åˆ°çš„å„å±‚ä¿¡å·åˆ†é‡ã€‚EMDçš„æå‡ºäººé»„é”·è®¤ä¸ºï¼Œä»»ä½•ä¿¡å·éƒ½å¯ä»¥æ‹†åˆ†æˆè‹¥å¹²ä¸ªå†…æ¶µæ¨¡æ€åˆ†é‡ä¹‹å’Œã€‚è€Œå†…æ¶µæ¨¡æ€åˆ†é‡æœ‰ä¸¤ä¸ªçº¦æŸæ¡ä»¶ï¼š</p><p>1ï¼‰åœ¨æ•´ä¸ªæ•°æ®æ®µå†…ï¼Œæå€¼ç‚¹çš„ä¸ªæ•°å’Œè¿‡é›¶ç‚¹çš„ä¸ªæ•°å¿…é¡»ç›¸ç­‰æˆ–ç›¸å·®æœ€å¤šä¸èƒ½è¶…è¿‡ä¸€ä¸ªã€‚</p><p>2ï¼‰åœ¨ä»»æ„æ—¶åˆ»ï¼Œç”±å±€éƒ¨æå¤§å€¼ç‚¹å½¢æˆçš„ä¸ŠåŒ…ç»œçº¿å’Œç”±å±€éƒ¨æå°å€¼ç‚¹å½¢æˆçš„ä¸‹åŒ…ç»œçº¿çš„å¹³å‡å€¼ä¸ºé›¶ï¼Œå³ä¸Šã€ä¸‹åŒ…ç»œçº¿ç›¸å¯¹äºæ—¶é—´è½´å±€éƒ¨å¯¹ç§°ã€‚</p><p>å•¥æ„æ€ï¼Ÿ</p><p>ç”¨ä¸ä¸¥è°¨çš„è¯­è¨€å’Œçµé­‚ç”»å¸ˆæ¥è§£é‡Šä¸€ä¸‹ï¼š</p><p>1ï¼‰å›¾çº¿è¦åå¤è·¨è¶Šxè½´ï¼Œåƒè¿™æ ·ï¼š</p><p><img src="/2020/03/12/eemd/v2-0e5b832aee81e8a9068c9665e6eb2a3a_1440w.jpg" alt="img"></p><p>åœ¨æ•´ä¸ªæ•°æ®æ®µå†…ï¼Œæå€¼ç‚¹çš„ä¸ªæ•°å’Œè¿‡é›¶ç‚¹çš„ä¸ªæ•°å¿…é¡»ç›¸ç­‰æˆ–ç›¸å·®æœ€å¤šä¸èƒ½è¶…è¿‡ä¸€ä¸ª</p><p>è€Œä¸èƒ½åƒè¿™æ ·æŸæ¬¡ç©¿è¿‡é›¶ç‚¹åå‡ºç°å¤šä¸ªæç‚¹ï¼š</p><p><img src="/2020/03/12/eemd/v2-921bc09334db7a4e443578091117788f_1440w.jpg" alt="æç‚¹æ•°ç›®åå¤š"></p><p>2ï¼‰åŒ…ç»œçº¿è¦å¯¹ç§°ï¼Œåƒè¿™æ ·ï¼š</p><p><img src="/2020/03/12/eemd/v2-8826ddaefd1cebee1841bf5ff083c494_1440w.jpg" alt="åŒ…ç»œçº¿å¯¹ç§°"></p><p>è€Œä¸èƒ½åƒè¿™æ ·ï¼š</p><p><img src="/2020/03/12/eemd/v2-deb9cd0d0dcb8a154f8621276cce9972_1440w.jpg" alt="åŒ…ç»œçº¿ä¸å¯¹ç§°"></p><p>æ´—æ´—çœ¼ç›ï¼Œçœ‹ä¸ªæ­£å¸¸ç‚¹çš„ä¾‹å­å§ï¼š</p><p><img src="/2020/03/12/eemd/v2-a609c2680a2f4c525648a414d9b0a358_1440w.jpg" alt="EMDåˆ†è§£"></p><p>ä¸Šå›¾ç”±7å¼ å›¾ç‰‡ç»„æˆï¼Œå…¶ä¸­ç¬¬1å¼ ä¸ºåŸå§‹ä¿¡å·ï¼Œåè¾¹ä¾æ¬¡ä¸ºEMDåˆ†è§£ä¹‹åå¾—åˆ°çš„6ä¸ªåˆ†é‡ï¼Œåˆ†åˆ«å«åšIMF1~IMF5ï¼Œæœ€åä¸€å¼ å›¾ä¸ºæ®‹å·®ï¼Œæ¯ä¸€ä¸ªIMFåˆ†é‡ä»£è¡¨äº†åŸå§‹ä¿¡å·ä¸­å­˜åœ¨çš„ä¸€ç§å†…æ¶µæ¨¡æ€åˆ†é‡ã€‚å¯ä»¥çœ‹å‡ºï¼Œæ¯ä¸ªIMFåˆ†é‡éƒ½æ˜¯æ»¡è¶³è¿™ä¸¤ä¸ªçº¦æŸæ¡ä»¶çš„ã€‚</p><h3 id="åˆ†è§£æ­¥éª¤"><a class="markdownIt-Anchor" href="#åˆ†è§£æ­¥éª¤"></a> åˆ†è§£æ­¥éª¤</h3><p>1ï¼‰æ ¹æ®åŸå§‹ä¿¡å·ä¸Šä¸‹æå€¼ç‚¹ï¼Œåˆ†åˆ«ç”»å‡ºä¸Šã€ä¸‹åŒ…ç»œçº¿ã€‚</p><p><img src="/2020/03/12/eemd/v2-c18c7b4e6d60711351a4d55cb8271320_1440w.jpg" alt="img">ä¸Šã€ä¸‹åŒ…ç»œçº¿</p><p>2ï¼‰æ±‚ä¸Šã€ä¸‹åŒ…ç»œçº¿çš„å‡å€¼ï¼Œç”»å‡ºå‡å€¼åŒ…ç»œçº¿ã€‚</p><p><img src="/2020/03/12/eemd/v2-d56c460e9dd9e245521140497afddb39_1440w.jpg" alt="img">å‡å€¼åŒ…ç»œçº¿</p><p>3ï¼‰åŸå§‹ä¿¡å·å‡å‡å€¼åŒ…ç»œçº¿ï¼Œå¾—åˆ°ä¸­é—´ä¿¡å·ã€‚</p><p><img src="/2020/03/12/eemd/v2-e74e49a23dda87df74a562809257ddda_1440w.jpg" alt="img">åŸå§‹ä¿¡å·å‡å‡å€¼åŒ…ç»œçº¿</p><p>4ï¼‰åˆ¤æ–­è¯¥ä¸­é—´ä¿¡å·æ˜¯å¦æ»¡è¶³IMFçš„ä¸¤ä¸ªæ¡ä»¶ï¼Œå¦‚æœæ»¡è¶³ï¼Œè¯¥ä¿¡å·å°±æ˜¯ä¸€ä¸ªIMFåˆ†é‡ï¼›å¦‚æœä¸æ˜¯ï¼Œä»¥è¯¥ä¿¡å·ä¸ºåŸºç¡€ï¼Œé‡æ–°åš1ï¼‰~4ï¼‰çš„åˆ†æã€‚IMFåˆ†é‡çš„è·å–é€šå¸¸éœ€è¦è‹¥å¹²æ¬¡çš„è¿­ä»£ã€‚</p><p><img src="/2020/03/12/eemd/v2-8b6643d803c3bdfb47639e65a75d4c8d_1440w.jpg" alt="img">ä¸æ»¡è¶³çº¦æŸ2ï¼Œéœ€è¦ç»§ç»­è¿­ä»£</p><p>ä½¿ç”¨ä¸Šè¿°æ–¹æ³•å¾—åˆ°ç¬¬ä¸€ä¸ªIMFåï¼Œç”¨åŸå§‹ä¿¡å·å‡IMF1ï¼Œä½œä¸ºæ–°çš„åŸå§‹ä¿¡å·ï¼Œå†é€šè¿‡1ï¼‰~4ï¼‰çš„åˆ†æï¼Œå¯ä»¥å¾—åˆ°IMF2ï¼Œä»¥æ­¤ç±»æ¨ï¼Œå®ŒæˆEMDåˆ†è§£ã€‚</p><p><img src="/2020/03/12/eemd/v2-f735266df804d187b1d173fe6f1bb168_1440w.jpg" alt="img">è¿­ä»£åˆ†è§£ç»“æœ</p><p>ä¸Šè¿°ä¾‹å­ä¸­çš„å›¾æ¥è‡ª<a href="http://perso.ens-lyon.fr/patrick.flandrin/emd.ppt">http://perso.ens-lyon.fr/patri</a></p><h2 id="eemd"><a class="markdownIt-Anchor" href="#eemd"></a> EEMD</h2><p>EEMD: Ensemble Empirical Mode Decomposition</p><p>ç®€å•çš„è¯´ï¼ŒEEMDæ˜¯åœ¨EMDçš„åŸºç¡€ä¸Šï¼Œå¯¹åŸå§‹ä¿¡å·è¿›è¡Œäº†Næ¬¡æ·»åŠ å„å¼‚ç­‰å¹…ç™½å™ªå£°å¹¶åˆ†åˆ«è¿›è¡ŒEMDåˆ†è§£åï¼Œå¯¹æ¯ä¸ªIMFä¸­é—´åˆ†é‡è¿›è¡Œå¹³å‡ã€‚</p><p>å…¶åŸç†æ˜¯é€šè¿‡åŠ å…¥ç™½å™ªå£°æ¥æ”¹å˜ä¿¡å·æå€¼ç‚¹çš„åˆ†å¸ƒï¼Œå¾—åˆ°ç¬¦åˆä¿¡å·ç‰¹å¾çš„ä¸Šä¸‹åŒ…ç»œçº¿ï¼Œæ¶ˆé™¤æ¨¡æ€æ··å æ•ˆåº”ã€‚åŠ å…¥çš„ç™½å™ªå£°é€šè¿‡å¤šæ¬¡å¹³å‡æ¶ˆé™¤ã€‚</p><h2 id="ceemd"><a class="markdownIt-Anchor" href="#ceemd"></a> CEEMD</h2><p>CEEMDæ˜¯åœ¨EEMDçš„åŸºç¡€ä¸Šï¼ŒæŠŠéšæœºæ·»åŠ çš„Nç»„ç™½å™ªå£°æ”¹ä¸ºäº†N/2ç»„æ­£å™ªå£°å’ŒN/2ç»„è´Ÿå™ªå£°ï¼Œä¾æ—§æ˜¯æœ€åè¿›è¡Œå¹³å‡ã€‚</p><p>æ ¹æ® Yeh ç­‰äººçš„ç ”ç©¶ï¼Œåœ¨åŠ å…¥ç›¸åŒæ•°é‡ä»¥åŠç›¸åŒå¹…å€¼çš„ç™½å™ªå£°æ—¶ï¼ŒEEMD å‰©ä½™å™ªå£°ä¼šéšç€é›†æˆå¹³å‡çš„æ¬¡æ•°è€Œé€æ¸å‡å°ã€‚CEEMD çš„å‰©ä½™å™ªå£°ä¸€ç›´ç»´æŒåœ¨ä¸€ä¸ªè¾ƒå°çš„ç¨‹åº¦ï¼Œä¸è®ºé›†æˆå¹³å‡æ¬¡æ•°å¤šå°‘ã€‚åœ¨ä¸€å®šç¨‹åº¦ä¸Šä½¿ç”¨ CEEMDæ–¹æ³•è¿›è¡Œä¿¡å·åˆ†è§£ï¼Œå¯ä»¥ä½¿ç”¨ç›¸å¯¹è¾ƒå°‘çš„é›†æˆå¹³å‡æ¬¡æ•°ï¼Œä»æŸç§æ„ä¹‰ä¸Šæ¥è¯´ï¼ŒCEEMDåœ¨ä¿è¯å°å‰©ä½™å™ªå£°å¹²æ‰°çš„æƒ…å†µä¸‹ï¼Œèƒ½å¤ŸèŠ‚çœè®¡ç®—æ—¶é—´ã€‚</p><p><img src="/2020/03/12/eemd/931855-20190117162939850-50932674.png" alt="img"><img src="/2020/03/12/eemd/931855-20190117163017276-1187230461.png" alt="img"></p><h2 id="pythonåº“"><a class="markdownIt-Anchor" href="#pythonåº“"></a> Pythonåº“</h2><p>EMD, EEMD, CEEMDAN and some visualization support are contained in this repository.</p><p>We can use <code>pip install EMD-signal</code> to install this library.</p><h2 id="å¼•ç”¨"><a class="markdownIt-Anchor" href="#å¼•ç”¨"></a> å¼•ç”¨</h2><ol><li><a href="https://www.cnblogs.com/Dinging006/p/10282993.html">EMDâ€”â€”EEMDâ€”â€”CEEMDè¯­éŸ³å¢å¼ºç®—æ³•åŸºç¡€</a></li><li><a href="https://zhuanlan.zhihu.com/p/40005057">è¿™ç¯‡æ–‡ç« èƒ½è®©ä½ æ˜ç™½ç»éªŒæ¨¡æ€åˆ†è§£ï¼ˆEMDï¼‰â€”â€”åŸºç¡€ç†è®ºç¯‡</a></li><li><a href="https://zhuanlan.zhihu.com/p/44833026">è¿™ç¯‡æ–‡ç« èƒ½è®©ä½ æ˜ç™½ç»éªŒæ¨¡æ€åˆ†è§£ï¼ˆEMDï¼‰â€”â€”IMFçš„ç‰©ç†å«ä¹‰</a></li><li><a href="https://www.researchgate.net/publication/220531146_Ensemble_Empirical_Mode_Decomposition_a_Noise-Assisted_Data_Analysis_Method">Ensemble Empirical Mode Decomposition: a Noise-Assisted Data Analysis Method</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;emd&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#emd&quot;&gt;&lt;/a&gt; EMD&lt;/h2&gt;
&lt;p&gt;EMD: Empirical Mode Decomposition&lt;/p&gt;
&lt;h3 id=&quot;ç‰¹å¾&quot;&gt;&lt;a class=&quot;markdownI</summary>
      
    
    
    
    
    <category term="signal-processing" scheme="https://www.miracleyoo.com/tags/signal-processing/"/>
    
    <category term="audio" scheme="https://www.miracleyoo.com/tags/audio/"/>
    
  </entry>
  
  <entry>
    <title>Face Recognition, Landmark and Relevant Other Feature Extraction</title>
    <link href="https://www.miracleyoo.com/2020/03/06/face-features/"/>
    <id>https://www.miracleyoo.com/2020/03/06/face-features/</id>
    <published>2020-03-07T01:42:43.000Z</published>
    <updated>2020-03-07T01:42:43.040Z</updated>
    
    <content type="html"><![CDATA[<h2 id="some-facts"><a class="markdownIt-Anchor" href="#some-facts"></a> Some Facts</h2><ol><li>The output of face detector is not always the same, it can be a square, a rectangle, or an oval bounding box.</li><li>Most of the landmark detectors need to take in an square bounding box for the detection.</li><li>Although the bounding box shape is different, they roughly have the same shape center. For the square and rectangle, they have the same bounding box center, and the edge length of the square box is roughly the same as the mean value of the two edge lengths of the rectangle. Here is a sample.</li></ol><p><img src="/2020/03/06/face-features/A48432AC-5A9B-48D6-A502-0777810A592A.png" alt="img"></p><blockquote><p>White: Dlib Result</p><p>Green: RetinaFace Result</p><p>Red: RetinaFace Transferred Result (Same center, length=(width+height)/2)</p></blockquote><ol start="4"><li>Many face detection and alignment models has an absolute detectable face size range in pixel. If the input image contains a face too big, some network cannot generate correct face bounding box or landmark, like RetinaFace, SFD, Hrnet. On the other hand, if the input image contains faces too small(also in absolute pixel), other network like MTCNN and other traditional method will fail.</li></ol><h2 id="libraries-and-papers"><a class="markdownIt-Anchor" href="#libraries-and-papers"></a> Libraries and Papers</h2><h3 id="face-detection"><a class="markdownIt-Anchor" href="#face-detection"></a> Face Detection</h3><h4 id="datasets"><a class="markdownIt-Anchor" href="#datasets"></a> Datasets</h4><table><thead><tr><th>Name</th><th>Site</th><th>Description</th></tr></thead><tbody><tr><td>Wider Face</td><td><a href="http://shuoyang1213.me/WIDERFACE/">Link</a></td><td><strong>32,203</strong> images, <strong>393,703</strong> faces labeled with a high degree of variability in scale, pose and occlusion</td></tr><tr><td>FFDB</td><td><a href="http://vis-www.cs.umass.edu/fddb/">Link</a></td><td><strong>5171</strong> faces, in which <strong>2845</strong> images from the <a href="http://tamaraberg.com/faceDataset/index.html">Faces in the Wild</a> data set</td></tr><tr><td>AFLW</td><td><a href="https://www.tugraz.at/institute/icg/research/team-bischof/lrs/downloads/aflw/">Link</a></td><td><strong>25k faces</strong> are annotated with up to <strong>21 landmarks</strong> per image</td></tr><tr><td></td><td></td><td></td></tr></tbody></table><h4 id="researches"><a class="markdownIt-Anchor" href="#researches"></a> Researches</h4><table><thead><tr><th>Name</th><th>Paper</th><th>Code</th><th>Year</th><th>Accuracy</th><th>Pre-trained Model</th></tr></thead><tbody><tr><td><a href="https://www.paperswithcode.com/paper/190500641">RetinaFace</a></td><td><a href="https://arxiv.org/pdf/1905.00641v2.pdf">Link</a></td><td><a href="https://github.com/deepinsight/insightface"> Original</a><br><a href="https://github.com/biubug6/Pytorch_Retinaface"> Pytorch</a></td><td>2019</td><td>Wider Face (Hard): 0.914</td><td>104M(Resnet)<br><a href="https://drive.google.com/drive/folders/1oZRSG0ZegbVkVwUd8wUIQx8W7yfZ_ki1">2M(MobileNet0.25)</a></td></tr><tr><td><a href="https://www.paperswithcode.com/paper/dsfd-dual-shot-face-detector">DFSD</a></td><td><a href="https://arxiv.org/pdf/1810.10220v3.pdf">Link</a></td><td><a href="https://github.com/TencentYoutuResearch/FaceDetection-DSFD">Link</a></td><td>2018</td><td>FDDB: 0.991<br>Wider Face: 0.960, 0.953, 0.900</td><td><a href="https://drive.google.com/file/d/1WeXlNYsM6dMP3xQQELI-4gxhwKUQxc3-/view">459MB</a></td></tr><tr><td><a href="SFD/S3FD">SFD/S3FD</a></td><td><a href="https://arxiv.org/pdf/1708.05237.pdf">Link</a></td><td><a href="https://github.com/sfzhang15/SFD">Original</a><br><a href="https://github.com/yxlijun/S3FD.pytorch">Pytorch</a></td><td>2017</td><td>FDDB: 0.983<br>Wider Face: 0.928, 0.913, 0.840</td><td><a href="https://pan.baidu.com/s/1epyTAUc6qSt3oZ7veK4oEw">85.7M</a></td></tr><tr><td><a href="https://www.paperswithcode.com/paper/joint-face-detection-and-alignment-using">MTCNN</a></td><td><a href="https://arxiv.org/abs/1604.02878">Link</a></td><td><a href="https://github.com/kuaikuaikim/DFace">Original</a><br><a href="https://github.com/ipazc/mtcnn">Pip Version</a></td><td>2016</td><td>Wider Face: 0.851,  0.820, 0.607</td><td><a href="https://github.com/ipazc/mtcnn/blob/master/mtcnn/data/mtcnn_weights.npy">2.85M</a></td></tr></tbody></table><h5 id="retinaface-pros-cons"><a class="markdownIt-Anchor" href="#retinaface-pros-cons"></a> RetinaFace Pros &amp; Cons:</h5><p>RetinaFace can generate an accurate rectangle face bounding box together with a 5-points facial landmark. It supports two backbone kernels: Resnet and MobileNet. The first one is more accurate but relatively slow, the MobileNet version is fast and really small.</p><p>RetinaFace focus more on the detection of the relatively small faces, and it can do a good(best) job on wider face dataset hard level. However, when the input is an image contain a really large face(About ${short_face_edge}&gt;700\space pixel $ ), RetinaFace tend to fail. Since there is also other people asking the same question on the issue of its GitHub page, I tend to think this is a design defects of RetinaFace.</p><p>Since the game streamersâ€™ face videos can be relatively large, I think this may become a fatal drawback. There are three possible solutions:</p><ol><li>Scale the input image to make sure the largest face short edge is smaller than 700, recommend around 500.</li><li>Wait for the author to change or change the pyramid weights parameters. This is delicate and success is not guaranteed.</li></ol><img src="/2020/03/06/face-features/image-20200306140736438.png" alt="image-20200306140736438" style="zoom:50%;"><h5 id="other-models"><a class="markdownIt-Anchor" href="#other-models"></a> Other Models</h5><p>DFSD can behave well on both easy, medium and hard level of Wider Face dataset. The only drawback is that it is much too large and slow. Not to mention real-time, it is even too heavy for GPU prediction when the input is a video and we also need to predict other features.</p><p>SFD has the similar problem as RetinaFace. It will also fail at big face cases.</p><p>MTCNN is just really small and easy to use. It is wrapped finely into a pip package and we can use one line to do face detection here. It behaves much worse in small faces, but better when the input face is big compared to other method. In fact, MTCNN might be a good choice for our project, since it is friendly to big face and fast enough.</p><h4 id="wrapped-libraries"><a class="markdownIt-Anchor" href="#wrapped-libraries"></a> Wrapped Libraries</h4><table><thead><tr><th>Name</th><th>Site</th><th>Year</th><th>Language</th><th>Pip (Name)</th></tr></thead><tbody><tr><td>Dlib</td><td><a href="http://dlib.net/">Link</a></td><td>2006-&gt;now</td><td>C++ &amp; Python</td><td>âˆš dlib</td></tr><tr><td>OpenFace V1</td><td><a href="http://cmusatyalab.github.io/openface/">Home Page</a><br><a href="https://github.com/cmusatyalab/openface">GitHub</a></td><td>2016</td><td>Python &amp; Lua</td><td>Ã— conda</td></tr><tr><td>OpenFace V2</td><td><a href="https://github.com/TadasBaltrusaitis/OpenFace">Link</a></td><td>2018</td><td>C++</td><td>Ã— compile locally</td></tr><tr><td>facenet-pytorch</td><td><a href="https://pypi.org/project/facenet-pytorch/">Link</a></td><td>2017</td><td>Python(PT)</td><td>âˆš facenet-pytorch</td></tr><tr><td>MTCNN</td><td><a href="https://pypi.org/project/mtcnn/">Link</a></td><td>2016</td><td>Python(TF)</td><td>âˆš mtcnn</td></tr></tbody></table><h5 id="comment"><a class="markdownIt-Anchor" href="#comment"></a> Comment</h5><ol><li>OpenFace V1 uses face detection model from dlib and OpenCV.</li><li>OpenFace V2 also used MTCNN as core face detector.</li></ol><h3 id="face-landmark"><a class="markdownIt-Anchor" href="#face-landmark"></a> Face Landmark</h3><h4 id="datasets-2"><a class="markdownIt-Anchor" href="#datasets-2"></a> Datasets</h4><table><thead><tr><th>Name</th><th>Site</th><th>Description</th></tr></thead><tbody><tr><td>300-W</td><td><a href="https://ibug.doc.ic.ac.uk/resources/300-W/">Link</a></td><td>68 points. Bounding boxes calculated by the boundary of all <strong>68</strong> points.</td></tr><tr><td>WFLW</td><td><a href="https://wywu.github.io/projects/LAB/WFLW.html">Link</a></td><td>Wider Facial Landmarks in-the-wild (WFLW) contains <strong>10000</strong> faces (7500 for training and 2500 for testing) with <strong>98</strong> fully manual annotated landmarks. Rich attribute annotations included, i.e., occlusion, pose, make-up, illumination, blur and expression.</td></tr><tr><td>COFW</td><td><a href="http://www.vision.caltech.edu/xpburgos/ICCV13/">Link</a></td><td>All images were hand annotated using the same <strong>29</strong> landmarks as in LFPW. Both the landmark positions and their occluded/unoccluded state are annotated. The faces are occluded to different degrees, with large variations in the type of occlusions encountered. COFW has an average occlusion of over <strong>23%</strong>.</td></tr></tbody></table><p>To increase the number of training images, and since<br>COFW has the exact same landmarks as LFPW, for training<br>we use the original non-augmented 845 LFPW faces + 500 COFW faces (<strong>1345</strong> total), and for testing the remaining <strong>507</strong> COFW faces. |<br>| AFLW  | <a href="https://www.tugraz.at/institute/icg/research/team-bischof/lrs/downloads/aflw/">Link</a> | Annotated Facial Landmarks in the Wild (AFLW) provides a large-scale collection of annotated face images gathered from the web, exhibiting a large variety in appearance (e.g., pose, expression, ethnicity, age, gender) as well as general imaging and environmental conditions. In total about <strong>25k faces</strong> are annotated with up to <strong>21 landmarks</strong> per image. |</p><h5 id="attention"><a class="markdownIt-Anchor" href="#attention"></a> Attention</h5><ol><li>The bounding box of 300-W dataset is not human labeled. It is the smallest rectangle which can accurately include every 68 points.</li></ol><img src="/2020/03/06/face-features/figure_4_n_2.png" alt="img" style="zoom:15%;"><h4 id="researches-2"><a class="markdownIt-Anchor" href="#researches-2"></a> Researches</h4><table><thead><tr><th>Name</th><th>Paper</th><th>Code</th><th>Year</th><th>Accuracy</th></tr></thead><tbody><tr><td><a href="https://www.paperswithcode.com/paper/adaptive-wing-loss-for-robust-face-alignment">AWing</a></td><td><a href="https://arxiv.org/pdf/1904.07399v2.pdf">Adaptive Wing Loss for Robust Face Alignment via Heatmap Regression</a></td><td><a href="https://github.com/protossw512/AdaptiveWingLoss">Link</a></td><td>2019</td><td>300-W: 3.07</td></tr><tr><td><a href="https://www.paperswithcode.com/paper/look-at-boundary-a-boundary-aware-face">LAB</a></td><td><a href="https://wywu.github.io/projects/LAB/LAB.html">Look at Boundary</a></td><td><a href="https://github.com/wywu/LAB">Link</a></td><td>2018</td><td>300-W: 3.49</td></tr><tr><td><a href="https://www.paperswithcode.com/paper/style-aggregated-network-for-facial-landmark">SAN</a></td><td><a href="https://arxiv.org/pdf/1803.04108v4.pdf">Style Aggregated Network</a></td><td><a href="https://github.com/D-X-Y/landmark-detection">Link</a></td><td>2018</td><td>300W NME: 3.98</td></tr><tr><td>HRNet</td><td><a href="https://arxiv.org/abs/1908.07919">Deep High-Resolution Representation Learning</a></td><td><a href="https://github.com/HRNet/HRNet-Facial-Landmark-Detection">Link</a></td><td>2019</td><td>300-W: 3.32</td></tr><tr><td>FAN</td><td><a href="https://arxiv.org/abs/1703.07332">Face Alignment Network</a></td><td><a href="https://github.com/1adrianb/face-alignment">Link</a></td><td>2017</td><td>300-W: Acc(7% threshold)66.9%</td></tr><tr><td><a href="https://www.paperswithcode.com/paper/deep-alignment-network-a-convolutional-neural">DAN-Menpo</a></td><td><a href="https://arxiv.org/pdf/1706.01789v2.pdf">Deep Alignment Network</a></td><td><a href="https://github.com/MarekKowalski/DeepAlignmentNetwork">Link</a></td><td>2017</td><td>300-W: 3.44</td></tr></tbody></table><p>The accuracy on 300-W is based on <strong>FULLSET (PUBLIC)</strong>.</p><h4 id="overview-on-researches"><a class="markdownIt-Anchor" href="#overview-on-researches"></a> Overview on researches</h4><ol><li>FAN is the final method I choose now. It cannot only generate 2D but also accurate 3D landmark, which is quite important for us considering the head pose and eye gaze can also be deduced from here.</li><li>Although HRNet seems to be good, it will crash completely when the input face is large(About <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mrow><mi>f</mi><mi>a</mi><mi>c</mi><mi>e</mi><mi mathvariant="normal">_</mi><mi>m</mi><mi>i</mi><mi>n</mi><mi mathvariant="normal">_</mi><mi>e</mi><mi>d</mi><mi>g</mi><mi>e</mi></mrow><mo>&gt;</mo><mn>250</mn></mrow><annotation encoding="application/x-tex">{face\_min\_edge} &gt; 250</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.00444em;vertical-align:-0.31em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mord mathdefault">a</span><span class="mord mathdefault">c</span><span class="mord mathdefault">e</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault">m</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault">e</span><span class="mord mathdefault">d</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault">e</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord">5</span><span class="mord">0</span></span></span></span>). Not really recommended if no extra operation added. But this can also be fixed by resize before sending to our pipeline, since our target is a single big-face player. When the input face size is limited, the result is quite decent.</li></ol><h4 id="wrapped-libraries-2"><a class="markdownIt-Anchor" href="#wrapped-libraries-2"></a> Wrapped Libraries</h4><table><thead><tr><th>Name</th><th>Site</th><th>Year</th><th>Language</th><th>Pip (Name)</th></tr></thead><tbody><tr><td>Dlib</td><td><a href="http://dlib.net/">Link</a></td><td>2006-&gt;now</td><td>C++ &amp; Python</td><td>âˆš dlib</td></tr><tr><td>OpenFace V1</td><td><a href="http://cmusatyalab.github.io/openface/">Home Page</a><br><a href="https://github.com/cmusatyalab/openface">GitHub</a></td><td>2016</td><td>Python &amp; Lua</td><td>Ã— conda</td></tr><tr><td>OpenFace V2</td><td><a href="https://github.com/TadasBaltrusaitis/OpenFace">Link</a></td><td>2018</td><td>C++</td><td>Ã— compile locally</td></tr><tr><td>face-alignment</td><td><a href="https://github.com/1adrianb/face-alignment">Link</a></td><td>2017</td><td>Python &amp; Lua</td><td>âˆš face-alignment</td></tr></tbody></table><h3 id="eye-blinking"><a class="markdownIt-Anchor" href="#eye-blinking"></a> Eye Blinking</h3><h4 id="datasets-3"><a class="markdownIt-Anchor" href="#datasets-3"></a> Datasets</h4><table><thead><tr><th>Name</th><th>Site</th><th>Description</th></tr></thead><tbody><tr><td>Closed Eyes In The Wild (CEW)</td><td><a href="http://parnec.nuaa.edu.cn/xtan/data/ClosedEyeDatabases.html">Link</a></td><td>2423 subjects, among which 1192 subjects with both eyes closed are collected directly from Internet, and 1231 subjects with eyes open are selected from the Labeled Face in the Wild (LFW [2]) database. Cropped coarse faces resized to the 100Ã—100 and extract eye patches of 24Ã—24 centered at the localized eye position.</td></tr><tr><td>EBV</td><td><a href="https://drive.google.com/file/d/1jJTImI-QkmGYFS-0UmE1qvqbwoYOCPnR/view?usp=sharing">Link</a></td><td>It contains <strong>11376</strong> video clips, each clip has around <strong>15</strong> image series, whether contains a blink or not. The video fps they use is <strong>30</strong>.</td></tr><tr><td>Eyeblink8</td><td><a href="https://www.blinkingmatters.com/research">Link</a></td><td>8 videos with 4 individuals (1 wearing glasses). Videos are recorded in a home environment. 408 eye blinks on 70 992 annotated frames with resolution 640x480.</td></tr><tr><td>MRL</td><td><a href="http://mrl.cs.vsb.cz/eyedataset">Link</a></td><td>Infrared images in low and high resolution, all captured in various lightning conditions and by different devices. Approximately 15 000 annotation for pupil points (images).</td></tr><tr><td>RT-BENE</td><td><a href="https://zenodo.org/record/3685316#.XmL4pJP0lQI">Link</a></td><td>Annotations of the eye-openness of more than 200,000 eye images, including more than 10,000 images where the eyes are closed.</td></tr></tbody></table><h4 id="researches-3"><a class="markdownIt-Anchor" href="#researches-3"></a> Researches</h4><table><thead><tr><th>Name</th><th>Paper</th><th>Code</th><th>Description</th><th>Pre-trained Model</th></tr></thead><tbody><tr><td>In Ictu Oculi</td><td><a href="https://arxiv.org/abs/1806.02877">Link</a></td><td><a href="https://github.com/danmohaha/WIFS2018_In_Ictu_Oculi">Link</a></td><td>Using Blink to detect Fake Video.</td><td><a href="https://drive.google.com/file/d/1OJZ4mvZefwMJ7Knpsf_RFhCsA4xbAOMc/view">429M</a></td></tr><tr><td>RT-GENE &amp; RT-BENE</td><td><a href="http://openaccess.thecvf.com/content_ECCV_2018/html/Tobias_Fischer_RT-GENE_Real-Time_Eye_ECCV_2018_paper.html">Link</a></td><td><a href="https://github.com/Tobias-Fischer/rt_gene">Link</a></td><td>Robust gaze estimation in natural environments.</td><td></td></tr></tbody></table><h4 id="my-update"><a class="markdownIt-Anchor" href="#my-update"></a> My Update</h4><ol><li>Build a new Resnet18-LSTM based eye blink detection network, which reaches 99.8% accuracy on both training and testing set the same as â€œIn Ictu Oculiâ€ paper proposed.</li><li>Build a new mixed dataset which has three classes: open, closed, and not-eye. Not-eye class includes hand, cup, microphone, hat, fast food, and bedroom background. They are frequently appearing objects in the gamerâ€™s streaming video. In many cases, part of the face are covered by this kind of things, but the face landmark detector can still give a predicted landmark. For example, oneâ€™s left eye may be shield by a microphone constantly due to the camera angle, but we can still get the useful information from his right eye. So in these cases, the new dataset will be more representative.</li><li>All of these new 6-classes images are collected from google image. Total number is <strong>2738</strong>, image number of each class is roughly balanced. I did a manual selecting to make sure the image is usable and representative of that classes. Every collected image will be resized to <strong>48, 64, and 128</strong>(the short edge), and then randomly crop three <strong>(32,32)</strong> images from each resized image. At last, <strong>32855</strong> images are collected.</li><li>EBV dataset from the author â€œIn Ictu Oculiâ€ is used as base dataset. It contains <strong>11376</strong> video clips, each clip has around <strong>15</strong> image series, whether contains a blink or not. The video fps they use is <strong>30</strong>. I build the new dataset by inserting 1, 2, or 3 continuous background images into the video clip image folder. The insert position is random, and the proportion of inserting 0,1,2,3 background images is: 40%, 10%, 30%, 20%. The inserted images is also randomly selected continuous images from all generated <strong>32855</strong> images. Training and validation set separation is the same as original dataset.</li><li>A new â€œRobust-Eye-Blinkâ€ network is trained based on this new dataset, and after sufficient training, it can reach 99.7% at both train and test dataset.</li></ol><h3 id="head-pose"><a class="markdownIt-Anchor" href="#head-pose"></a> Head Pose</h3><h4 id="calculation"><a class="markdownIt-Anchor" href="#calculation"></a> Calculation</h4><p>3D Facial Landmark -&gt; <a href="https://en.wikipedia.org/wiki/Rotation_matrix">Rotation matrix</a> -&gt; <a href="https://en.wikipedia.org/wiki/Euler_angles">Euler angles</a> -&gt; <a href="https://carsexplained.wordpress.com/2017/02/21/fundamentals-of-car-science-pitch-and-roll/">(yaw, pitch, roll)</a></p><img src="/2020/03/06/face-features/1*U4ZQ8UjzouVMRo2Fgsz7UA.png" alt="yaw pitch roll of head" style="zoom:50%;"><p>Visualization of yaw, pitch and roll: <a href="http://www.ctralie.com/Teaching/COMPSCI290/Materials/EulerAnglesViz/">Link</a></p><p><strong>Euler angles:</strong></p><p><img src="/2020/03/06/face-features/300px-Eulerangles.svg.png" alt="img"></p><h5 id="implementation"><a class="markdownIt-Anchor" href="#implementation"></a> Implementation</h5><img src="/2020/03/06/face-features/image-20200306134751864.png" alt="image-20200306134751864" style="zoom:40%;"><p>Use the 3D landmark computed, and set the vector from 1 to 17 as the x axis, and 9 to 28 as the y axis, then the z axis is computed by set it perpendicular to both x and y, pointing out of front face.</p><p>Now, the head pose detection part has been wrapped into a module, we can get the pose within one line.</p><h4 id="code-reference"><a class="markdownIt-Anchor" href="#code-reference"></a> Code Reference</h4><ol><li><a href="https://github.com/jerryhouuu/Face-Yaw-Roll-Pitch-from-Pose-Estimation-using-OpenCV">Face-Yaw-Roll-Pitch-from-Pose-Estimation-using-OpenCV</a></li><li><a href="https://gist.github.com/crmccreary/1593090">euler_angles_from_rotation_matrix</a></li></ol><h3 id="emotion"><a class="markdownIt-Anchor" href="#emotion"></a> Emotion</h3><h4 id="can-facial-expression-really-tell-emotion"><a class="markdownIt-Anchor" href="#can-facial-expression-really-tell-emotion"></a> Can facial expression really tell emotion</h4><h5 id="cons"><a class="markdownIt-Anchor" href="#cons"></a> Cons</h5><ol><li>Facial expression is not universal, it also depend on culture and education. Like in Asia, people tend to convey more emotion in their eyes, but in western culture, people use their mouth to deliver more information.</li><li>Human can easily trick the face expression to emotion system, since what they show is not necessarily what they feel.</li><li>One certain facial expression can have multiple possible meanings, and this tend to depend on things near the face, namely the context. Like a soccer player win the game and shouting, without the context, you will judge him as angry or so.</li><li>The current facial expression classification method usually classify all of the emotion into several classes, like 6 or 7. But the fact is that each big emotion contain multiple sub-emotions which is more delicate. They can overlap or differ.</li><li>After reading 1000 papers, they find there was little to no evidence that people can reliably infer someone elseâ€™s emotional state from a set of facial movements.</li></ol><h5 id="pros"><a class="markdownIt-Anchor" href="#pros"></a> Pros</h5><ol><li>It is actually accurate. Affectiva has reached an accuracy of more than 90%.</li><li>Most of the culture share the similar facial expression.</li></ol><h4 id="datasets-4"><a class="markdownIt-Anchor" href="#datasets-4"></a> Datasets</h4><table><thead><tr><th>Name</th><th>Site</th><th>Description</th></tr></thead><tbody><tr><td>FER2013</td><td><a href="https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data">Kaggle Link</a></td><td>48x48 pixel grayscale images of faces. (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral). The training set consists of 28,709 examples. The public test set consists of 3,589 examples. The final test set consists of another 3,589 examples.</td></tr><tr><td><a href="https://ieeexplore.ieee.org/document/5543262">CK+</a></td><td><a href="http://www.consortium.ri.cmu.edu/ckagree/">Link</a></td><td>Posed Facial Expressions: 593 sequences from 123 subjects.</td></tr></tbody></table><h4 id="wrapped-libraries-3"><a class="markdownIt-Anchor" href="#wrapped-libraries-3"></a> Wrapped Libraries</h4><table><thead><tr><th>Name</th><th>Site</th><th>Year</th><th>Language</th><th>Pip/Pt model</th></tr></thead><tbody><tr><td>Facial-Expression-Recognition</td><td><a href="https://github.com/WuJie1010/Facial-Expression-Recognition.Pytorch">Link</a></td><td>2018</td><td>Python(PT)</td><td><a href="https://drive.google.com/file/d/1Oy_9YmpkSKX1Q8jkOhJbz3Mc7qjyISzU/view">76M</a></td></tr></tbody></table><h4 id="reference"><a class="markdownIt-Anchor" href="#reference"></a> Reference</h4><ol><li><a href="https://www.nature.com/articles/d41586-020-00507-5">Why faces donâ€™t always tell the truth about feelings</a></li></ol><p>By Zhongyang Zhang</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;some-facts&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#some-facts&quot;&gt;&lt;/a&gt; Some Facts&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;The output of face detector is not always </summary>
      
    
    
    
    
    <category term="python" scheme="https://www.miracleyoo.com/tags/python/"/>
    
    <category term="deep-learning" scheme="https://www.miracleyoo.com/tags/deep-learning/"/>
    
    <category term="machine-earning" scheme="https://www.miracleyoo.com/tags/machine-earning/"/>
    
    <category term="face-detection" scheme="https://www.miracleyoo.com/tags/face-detection/"/>
    
    <category term="face-alignment" scheme="https://www.miracleyoo.com/tags/face-alignment/"/>
    
    <category term="face-features" scheme="https://www.miracleyoo.com/tags/face-features/"/>
    
    <category term="face-expression" scheme="https://www.miracleyoo.com/tags/face-expression/"/>
    
    <category term="eye-blink" scheme="https://www.miracleyoo.com/tags/eye-blink/"/>
    
    <category term="head-pose" scheme="https://www.miracleyoo.com/tags/head-pose/"/>
    
  </entry>
  
  <entry>
    <title>Python åœ¨ç±»çš„é™æ€å‡½æ•°ä¸­è°ƒç”¨å¦ä¸€ä¸ªé™æ€å‡½æ•°</title>
    <link href="https://www.miracleyoo.com/2020/03/04/python-call-static-in-static/"/>
    <id>https://www.miracleyoo.com/2020/03/04/python-call-static-in-static/</id>
    <published>2020-03-04T23:28:42.000Z</published>
    <updated>2020-04-26T22:28:54.930Z</updated>
    
    <content type="html"><![CDATA[<p>æœ‰ä¸¤ç§å¸¸è§è§£å†³åŠæ³•ï¼š</p><ol><li>è°ƒç”¨ç›®æ ‡å‡½æ•°çš„<code>__func__()</code>æ–¹æ³•ã€‚</li><li>ä½¿ç”¨<code>CLASS_NAME.target_func()</code>æ–¹æ³•ã€‚è¿™ç§æ–¹æ³•æ›´åŠ å¹²å‡€ã€Pythonicã€‚</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Klass</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod  </span><span class="comment"># use as decorator</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">stat_func</span>():</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">42</span></span><br><span class="line"></span><br><span class="line">    _ANS = stat_func.__func__()  <span class="comment"># call the staticmethod</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">method</span>(<span class="params">self</span>):</span></span><br><span class="line">        ret = Klass.stat_func()</span><br><span class="line">        <span class="keyword">return</span> ret</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;æœ‰ä¸¤ç§å¸¸è§è§£å†³åŠæ³•ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;è°ƒç”¨ç›®æ ‡å‡½æ•°çš„&lt;code&gt;__func__()&lt;/code&gt;æ–¹æ³•ã€‚&lt;/li&gt;
&lt;li&gt;ä½¿ç”¨&lt;code&gt;CLASS_NAME.target_func()&lt;/code&gt;æ–¹æ³•ã€‚è¿™ç§æ–¹æ³•æ›´åŠ å¹²å‡€ã€Pythonicã€‚&lt;/li&gt;
&lt;/ol</summary>
      
    
    
    
    
    <category term="python" scheme="https://www.miracleyoo.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>Pythonçš„èµ‹å€¼ä¸æ·±æµ…æ‹·è´å®ä¾‹è§£æ</title>
    <link href="https://www.miracleyoo.com/2020/02/11/python-copy/"/>
    <id>https://www.miracleyoo.com/2020/02/11/python-copy/</id>
    <published>2020-02-11T23:54:55.000Z</published>
    <updated>2020-04-26T22:55:09.170Z</updated>
    
    <content type="html"><![CDATA[<h2 id="å¯¹è±¡æ˜¯ä¸€ä¸ªå®šå€¼"><a class="markdownIt-Anchor" href="#å¯¹è±¡æ˜¯ä¸€ä¸ªå®šå€¼"></a> å¯¹è±¡æ˜¯ä¸€ä¸ªå®šå€¼</h2><p>æ­¤æ—¶ä¸‰ç§æ–¹æ³•çš„ä½œç”¨å®é™…ä¸Šæ˜¯ç›¸åŒçš„ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"></span><br><span class="line">a = <span class="string">&quot;äºšä¸å¨œ&quot;</span></span><br><span class="line">b = a</span><br><span class="line">c = copy.copy(a)</span><br><span class="line">d = copy.deepcopy(a)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;æºï¼šid(a)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(a))</span><br><span class="line">print(<span class="string">&quot;èµ‹å€¼ï¼šid(b)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(b))</span><br><span class="line">print(<span class="string">&quot;æµ…æ‹·è´ï¼šid(c)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(c))</span><br><span class="line">print(<span class="string">&quot;æ·±æ‹·è´ï¼šid(d)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(d))</span><br></pre></td></tr></table></figure><p>è¾“å‡ºå¦‚ä¸‹:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">æºï¼šid(a)-&gt;&gt;&gt; 4394180400</span><br><span class="line">èµ‹å€¼ï¼šid(b)-&gt;&gt;&gt; 4394180400</span><br><span class="line">æµ…æ‹·è´ï¼šid(c)-&gt;&gt;&gt; 4394180400</span><br><span class="line">æ·±æ‹·è´ï¼šid(d)-&gt;&gt;&gt; 4394180400</span><br></pre></td></tr></table></figure><p>å¦‚æœaçš„å€¼è¢«æ›´æ”¹ï¼Œåªæœ‰aæœ¬èº«çš„idä¼šæ”¹å˜ï¼Œbcdéƒ½ä¸å˜ã€‚</p><h2 id="å¯¹è±¡æ˜¯ä¸€ä¸ªå¼•ç”¨"><a class="markdownIt-Anchor" href="#å¯¹è±¡æ˜¯ä¸€ä¸ªå¼•ç”¨"></a> å¯¹è±¡æ˜¯ä¸€ä¸ªå¼•ç”¨</h2><ul><li>é¦–å…ˆï¼Œå…ƒç»„ï¼Œæ•°ç»„ï¼Œå­—å…¸ï¼Œç±»ç­‰çš„æœ¬è´¨éƒ½æ˜¯å¼•ç”¨ï¼Œæˆ–ç§°ä¹‹ä¸ºâ€œæŒ‡é’ˆâ€ï¼Œæ¯ä¸ªå¼•ç”¨æŒ‡å‘çš„å®ä½“éƒ½æ˜¯æœ‰å…¶ç›¸åº”åœ°å€çš„ï¼Œæ¯”å¦‚è¿™é‡Œçš„<code>â€œäºšä¸å¨œâ€</code>åœ¨å†…å­˜ä¸­æœ‰ä¸€ä¸ªå…·ä½“çš„åœ°å€ï¼Œè€Œ<code>[â€œäºšä¸å¨œâ€]</code>åˆ™æ˜¯ä¸€ä¸ªå¯¹äºå†…å­˜ä¸­â€œäºšä¸å¨œâ€å®ä½“çš„ä¸€ä¸ªå¼•ç”¨é›†ï¼Œè¿™ä¸ªå¼•ç”¨é›†æœ¬èº«ä¹Ÿæœ‰ä¸€ä¸ªç‹¬ç‰¹çš„åœ°å€ã€‚</li><li>å¯¹äºä¸å¯å˜å¯¹è±¡ï¼ŒPython ç”¨å¼•ç”¨è®¡æ•°çš„æ–¹å¼ç®¡ç†å®ƒä»¬ï¼Œæ‰€ä»¥ Python ä¸ä¼šå¯¹å€¼ç›¸åŒçš„ä¸å¯å˜å¯¹è±¡ï¼Œç”³è¯·å•ç‹¬çš„å†…å­˜ç©ºé—´ã€‚åªä¼šè®°å½•å®ƒçš„å¼•ç”¨æ¬¡æ•°ã€‚</li><li>ä½¿ç”¨â€œå¼•ç”¨é›†â€èµ‹å€¼æ˜¯æŠŠå¼•ç”¨é›†æœ¬èº«çš„åœ°å€èµ‹ç»™äº†å·¦è¾¹çš„å˜é‡ï¼Œå³ä¸€ä¸ªå¼•ç”¨çš„å¼•ç”¨ã€‚</li><li>ä½¿ç”¨èµ‹å€¼çš„æ–¹æ³•å¾—åˆ°çš„å¯¹è±¡ï¼Œå½“åŸâ€œå¼•ç”¨é›†â€ä¸­çš„ä»»ä½•å¼•ç”¨å‘ç”Ÿä»»ä½•æ”¹å˜æ—¶ï¼Œå…¶éƒ½ä¼šéšç€æ”¹å˜ï¼Œå°±åƒä¸€ä¸ªå¿«æ·æ–¹å¼ã€‚ä½†å¦‚æœåŸâ€œå¼•ç”¨é›†â€ç›´æ¥è¢«è¦†ç›–äº†ï¼Œåˆ™ä¸ä¼šéšä¹‹æ”¹å˜ã€‚</li></ul><h3 id="ä¾‹"><a class="markdownIt-Anchor" href="#ä¾‹"></a> ä¾‹ï¼š</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ä¸€ä½æ•°ç»„æ›´æ”¹å†…å±‚å…ƒç´ </span></span><br><span class="line">a=[<span class="string">&quot;äºšä¸å¨œ&quot;</span>]</span><br><span class="line">b=a</span><br><span class="line">b = a</span><br><span class="line">c = copy.copy(a)</span><br><span class="line">d = copy.deepcopy(a)</span><br><span class="line"></span><br><span class="line">a[<span class="number">0</span>] = <span class="string">&quot;æ¡äºº&quot;</span></span><br><span class="line">print(<span class="string">&quot;æºï¼šid(a)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(a))</span><br><span class="line">print(<span class="string">&quot;èµ‹å€¼ï¼šid(b)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(b))</span><br><span class="line">print(<span class="string">&quot;æµ…æ‹·è´ï¼šid(c)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(c))</span><br><span class="line">print(<span class="string">&quot;æ·±æ‹·è´ï¼šid(d)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(d))</span><br><span class="line">print(a,b,c,d)</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">æºï¼šid(a)-&gt;&gt;&gt; 4585988416</span></span><br><span class="line"><span class="string">èµ‹å€¼ï¼šid(b)-&gt;&gt;&gt; 4585988416</span></span><br><span class="line"><span class="string">æµ…æ‹·è´ï¼šid(c)-&gt;&gt;&gt; 4585374256</span></span><br><span class="line"><span class="string">æ·±æ‹·è´ï¼šid(d)-&gt;&gt;&gt; 4585117648</span></span><br><span class="line"><span class="string">[&#x27;æ¡äºº&#x27;] [&#x27;æ¡äºº&#x27;] [&#x27;äºšä¸å¨œ&#x27;] [&#x27;äºšä¸å¨œ&#x27;]</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ä¸€ä½æ•°ç»„å®Œå…¨å˜æ›´</span></span><br><span class="line">a=[<span class="string">&quot;äºšä¸å¨œ&quot;</span>]</span><br><span class="line">b=a</span><br><span class="line">b = a</span><br><span class="line">c = copy.copy(a)</span><br><span class="line">d = copy.deepcopy(a)</span><br><span class="line"></span><br><span class="line">a=[<span class="string">&quot;åˆ©å…¹&quot;</span>]</span><br><span class="line">print(<span class="string">&quot;æºï¼šid(a)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(a))</span><br><span class="line">print(<span class="string">&quot;èµ‹å€¼ï¼šid(b)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(b))</span><br><span class="line">print(<span class="string">&quot;æµ…æ‹·è´ï¼šid(c)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(c))</span><br><span class="line">print(<span class="string">&quot;æ·±æ‹·è´ï¼šid(d)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(d))</span><br><span class="line">print(a,b,c,d)</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">æºï¼šid(a)-&gt;&gt;&gt; 4586047600</span></span><br><span class="line"><span class="string">èµ‹å€¼ï¼šid(b)-&gt;&gt;&gt; 4583430096</span></span><br><span class="line"><span class="string">æµ…æ‹·è´ï¼šid(c)-&gt;&gt;&gt; 4585223344</span></span><br><span class="line"><span class="string">æ·±æ‹·è´ï¼šid(d)-&gt;&gt;&gt; 4585988416</span></span><br><span class="line"><span class="string">[&#x27;åˆ©å…¹&#x27;] [&#x27;äºšä¸å¨œ&#x27;] [&#x27;äºšä¸å¨œ&#x27;] [&#x27;äºšä¸å¨œ&#x27;]</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># äºŒç»´æ•°ç»„æ›´æ”¹æœ€å†…å±‚å…ƒç´ </span></span><br><span class="line">a=[[<span class="string">&quot;äºšä¸å¨œ&quot;</span>]]</span><br><span class="line">b=a</span><br><span class="line">b = a</span><br><span class="line">c = copy.copy(a)</span><br><span class="line">print(<span class="string">&quot;æºï¼ˆé‡èµ‹å€¼å‰ï¼‰ï¼šid(a)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(a))</span><br><span class="line">d = copy.deepcopy(a)</span><br><span class="line"></span><br><span class="line">a[<span class="number">0</span>][<span class="number">0</span>]=<span class="string">&quot;åˆ©å…¹&quot;</span></span><br><span class="line">print(<span class="string">&quot;æºï¼šid(a)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(a))</span><br><span class="line">print(<span class="string">&quot;èµ‹å€¼ï¼šid(b)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(b))</span><br><span class="line">print(<span class="string">&quot;æµ…æ‹·è´ï¼šid(c)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(c))</span><br><span class="line">print(<span class="string">&quot;æ·±æ‹·è´ï¼šid(d)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(d))</span><br><span class="line">print(a,b,c,d)</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">æºï¼ˆé‡èµ‹å€¼å‰ï¼‰ï¼šid(a)-&gt;&gt;&gt; 4586327008</span></span><br><span class="line"><span class="string">æºï¼šid(a)-&gt;&gt;&gt; 4586327008</span></span><br><span class="line"><span class="string">èµ‹å€¼ï¼šid(b)-&gt;&gt;&gt; 4586327008</span></span><br><span class="line"><span class="string">æµ…æ‹·è´ï¼šid(c)-&gt;&gt;&gt; 4586041088</span></span><br><span class="line"><span class="string">æ·±æ‹·è´ï¼šid(d)-&gt;&gt;&gt; 4585375216</span></span><br><span class="line"><span class="string">[[&#x27;åˆ©å…¹&#x27;]] [[&#x27;åˆ©å…¹&#x27;]] [[&#x27;åˆ©å…¹&#x27;]] [[&#x27;äºšä¸å¨œ&#x27;]]</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># äºŒç»´æ•°ç»„æ›´æ”¹ç¬¬ä¸€ç»´</span></span><br><span class="line">a=[[<span class="string">&quot;äºšä¸å¨œ&quot;</span>]]</span><br><span class="line">b=a</span><br><span class="line">b = a</span><br><span class="line">c = copy.copy(a)</span><br><span class="line">print(<span class="string">&quot;æºï¼ˆé‡èµ‹å€¼å‰ï¼‰ï¼šid(a)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(a))</span><br><span class="line">d = copy.deepcopy(a)</span><br><span class="line"></span><br><span class="line">a[<span class="number">0</span>]=[<span class="string">&quot;åˆ©å…¹&quot;</span>]</span><br><span class="line">print(<span class="string">&quot;æºï¼šid(a)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(a))</span><br><span class="line">print(<span class="string">&quot;èµ‹å€¼ï¼šid(b)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(b))</span><br><span class="line">print(<span class="string">&quot;æµ…æ‹·è´ï¼šid(c)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(c))</span><br><span class="line">print(<span class="string">&quot;æ·±æ‹·è´ï¼šid(d)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(d))</span><br><span class="line">print(a,b,c,d)</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">æºï¼ˆé‡èµ‹å€¼å‰ï¼‰ï¼šid(a)-&gt;&gt;&gt; 4585239328</span></span><br><span class="line"><span class="string">æºï¼šid(a)-&gt;&gt;&gt; 4585239328</span></span><br><span class="line"><span class="string">èµ‹å€¼ï¼šid(b)-&gt;&gt;&gt; 4585239328</span></span><br><span class="line"><span class="string">æµ…æ‹·è´ï¼šid(c)-&gt;&gt;&gt; 4586082944</span></span><br><span class="line"><span class="string">æ·±æ‹·è´ï¼šid(d)-&gt;&gt;&gt; 4586327008</span></span><br><span class="line"><span class="string">[[&#x27;åˆ©å…¹&#x27;]] [[&#x27;åˆ©å…¹&#x27;]] [[&#x27;äºšä¸å¨œ&#x27;]] [[&#x27;äºšä¸å¨œ&#x27;]]</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># äºŒç»´æ•°ç»„å®Œå…¨å˜æ›´</span></span><br><span class="line">a=[[<span class="string">&quot;äºšä¸å¨œ&quot;</span>]]</span><br><span class="line">b=a</span><br><span class="line">b = a</span><br><span class="line">c = copy.copy(a)</span><br><span class="line">print(<span class="string">&quot;æºï¼ˆé‡èµ‹å€¼å‰ï¼‰ï¼šid(a)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(a))</span><br><span class="line">d = copy.deepcopy(a)</span><br><span class="line"></span><br><span class="line">a=[[<span class="string">&quot;åˆ©å…¹&quot;</span>]]</span><br><span class="line">print(<span class="string">&quot;æºï¼šid(a)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(a))</span><br><span class="line">print(<span class="string">&quot;èµ‹å€¼ï¼šid(b)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(b))</span><br><span class="line">print(<span class="string">&quot;æµ…æ‹·è´ï¼šid(c)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(c))</span><br><span class="line">print(<span class="string">&quot;æ·±æ‹·è´ï¼šid(d)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(d))</span><br><span class="line">print(a,b,c,d)</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">æºï¼ˆé‡èµ‹å€¼å‰ï¼‰ï¼šid(a)-&gt;&gt;&gt; 4586082944</span></span><br><span class="line"><span class="string">æºï¼šid(a)-&gt;&gt;&gt; 4585468704</span></span><br><span class="line"><span class="string">èµ‹å€¼ï¼šid(b)-&gt;&gt;&gt; 4586082944</span></span><br><span class="line"><span class="string">æµ…æ‹·è´ï¼šid(c)-&gt;&gt;&gt; 4586327008</span></span><br><span class="line"><span class="string">æ·±æ‹·è´ï¼šid(d)-&gt;&gt;&gt; 4586041088</span></span><br><span class="line"><span class="string">[[&#x27;åˆ©å…¹&#x27;]] [[&#x27;äºšä¸å¨œ&#x27;]] [[&#x27;äºšä¸å¨œ&#x27;]] [[&#x27;äºšä¸å¨œ&#x27;]]</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><ul><li>èµ‹å€¼æ˜¯å®Œå…¨çš„å¿«æ·æ–¹å¼ã€‚</li><li>æµ…æ‹·è´çš„å®è´¨æ˜¯å¯¹ä¸€ä¸ªâ€œå¼•ç”¨é›†â€çš„æ‰€æœ‰å¼•ç”¨çš„æ‹·è´ï¼Œå³æ‹·è´äº†ä¸€ä»½â€œå¼•ç”¨é›†â€ä¸­è®°å½•çš„æ‰€æœ‰çš„è¿™äº›çš„ä¸å¯å˜å¯¹è±¡çš„åœ°å€ï¼Œä½†åªæ‹·è´äº†ä¸€å±‚ï¼Œæˆ–ç§°å¹¶æ²¡æœ‰æŠŠè¿™äº›å¯¹è±¡æœ¬èº«æ‹·è´ä¸€éã€‚</li><li>å¦‚æœå¼•ç”¨é›†é‡Œè¿˜æœ‰å¼•ç”¨é›†xï¼Œé‚£ä¹ˆæµ…æ‹·è´å¯¹xçš„ä½œç”¨å’Œèµ‹å€¼ç›¸åŒï¼Œå³å¦‚æœxé‡Œçš„å…ƒç´ å˜äº†ï¼Œæµ…æ‹·è´çš„ç»“æœè¿˜æ˜¯ä¼šè·Ÿç€å˜ã€‚</li><li>æ·±æ‹·è´æŠŠæ‹·è´å¯¹è±¡é‡Œé¢çš„æ‰€æœ‰å±‚çš„å¼•ç”¨é›†å…¨éƒ¨åšäº†æ‹·è´åŠ¨ä½œï¼Œç›´åˆ°å¼•ç”¨åˆ°ä¸å¯å˜å˜é‡ï¼Œæ‰€ä»¥å¯ä»¥è¯´æ·±æ‹·è´å‡ºæ¥çš„ç»“æœå’Œå…¶æ‹·è´å¯¹è±¡æ²¡æœ‰ä»»ä½•è€¦åˆå…³ç³»äº†ã€‚</li></ul><h2 id="ç®€è¦ç‰ˆæœ¬"><a class="markdownIt-Anchor" href="#ç®€è¦ç‰ˆæœ¬"></a> ç®€è¦ç‰ˆæœ¬</h2><ul><li>ç”±äº Python å†…éƒ¨å¼•ç”¨è®¡æ•°çš„ç‰¹æ€§ï¼Œå¯¹äºä¸å¯å˜å¯¹è±¡ï¼Œæµ…æ‹·è´å’Œæ·±æ‹·è´çš„ä½œç”¨æ˜¯ä¸€è‡´çš„ï¼Œå°±ç›¸å½“äºå¤åˆ¶äº†ä¸€ä»½å‰¯æœ¬ï¼ŒåŸå¯¹è±¡å†…éƒ¨çš„ä¸å¯å˜å¯¹è±¡çš„æ”¹å˜ï¼Œä¸ä¼šå½±å“åˆ°å¤åˆ¶å¯¹è±¡ã€‚</li><li>æµ…æ‹·è´çš„æ‹·è´ã€‚å…¶å®æ˜¯æ‹·è´äº†åŸå§‹å…ƒç´ çš„å¼•ç”¨ï¼ˆå†…å­˜åœ°å€ï¼‰ï¼Œæ‰€ä»¥å½“æ‹·è´å¯å˜å¯¹è±¡æ—¶ï¼ŒåŸå¯¹è±¡å†…å¯å˜å¯¹è±¡çš„å¯¹åº”å…ƒç´ çš„æ”¹å˜ï¼Œä¼šåœ¨å¤åˆ¶å¯¹è±¡çš„å¯¹åº”å…ƒç´ ä¸Šï¼Œæœ‰æ‰€ä½“ç°ã€‚</li><li>æ·±æ‹·è´åœ¨é‡åˆ°å¯å˜å¯¹è±¡æ—¶ï¼Œåˆåœ¨å†…éƒ¨åšäº†æ–°å»ºäº†ä¸€ä¸ªå‰¯æœ¬ã€‚æ‰€ä»¥ï¼Œä¸ç®¡å®ƒå†…éƒ¨çš„å…ƒç´ å¦‚ä½•å˜åŒ–ï¼Œéƒ½ä¸ä¼šå½±å“åˆ°åŸæ¥å‰¯æœ¬çš„å¯å˜å¯¹è±¡ã€‚</li></ul><h2 id="å‚è€ƒ"><a class="markdownIt-Anchor" href="#å‚è€ƒ"></a> å‚è€ƒ</h2><p><a href="https://juejin.im/post/5c6943266fb9a049ed316931">5å¼ å›¾å½»åº•ç†è§£Pythonä¸­çš„æµ…æ‹·è´ä¸æ·±æ‹·è´</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;å¯¹è±¡æ˜¯ä¸€ä¸ªå®šå€¼&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#å¯¹è±¡æ˜¯ä¸€ä¸ªå®šå€¼&quot;&gt;&lt;/a&gt; å¯¹è±¡æ˜¯ä¸€ä¸ªå®šå€¼&lt;/h2&gt;
&lt;p&gt;æ­¤æ—¶ä¸‰ç§æ–¹æ³•çš„ä½œç”¨å®é™…ä¸Šæ˜¯ç›¸åŒçš„ã€‚&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;t</summary>
      
    
    
    
    
    <category term="python" scheme="https://www.miracleyoo.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>MATLAB ä¸­ä¸å‡½æ•°ã€æ–¹ç¨‹ç›¸å…³å†…å®¹</title>
    <link href="https://www.miracleyoo.com/2020/01/10/matlab-func/"/>
    <id>https://www.miracleyoo.com/2020/01/10/matlab-func/</id>
    <published>2020-01-11T00:01:11.000Z</published>
    <updated>2020-04-26T23:03:26.220Z</updated>
    
    <content type="html"><![CDATA[<h2 id="ç¬¦å·å˜é‡-syms"><a class="markdownIt-Anchor" href="#ç¬¦å·å˜é‡-syms"></a> ç¬¦å·å˜é‡ syms</h2><p>åœ¨MATLABä¸­åˆ›å»ºæˆ–å®šä¹‰ä¸€ä¸ªå‡½æ•°éœ€è¦ç”¨åˆ°ç¬¦å·å˜é‡ã€‚ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œæƒ³è¦ç»˜åˆ¶å‡½æ•°å›¾åƒæ—¶ï¼Œå¾€å¾€ä½¿ç”¨<code>x=[a:0.01:b]</code>çš„æ–¹å¼å…ˆåˆ›å»ºä¸€ä¸ªxçš„ç¦»æ•£å®šä¹‰åŸŸï¼Œç„¶åå†ç”¨<code>y=func(x)</code>çš„æ–¹å¼å®šä¹‰å‡½æ•°æœ¬èº«ï¼Œæœ€åä½¿ç”¨plot(x,y)çš„æ–¹å¼ç»˜åˆ¶å›¾åƒã€‚</p><p>ç„¶è€Œï¼Œå½“æ¶‰åŠåˆ°å‡½æ•°æå€¼ã€æ±‚å¯¼ã€æ–¹ç¨‹æ±‚è§£ã€è¿ç»­å›¾åƒç»˜åˆ¶ç­‰é—®é¢˜æ—¶ï¼Œè¿™ç§æ–¹æ³•å°±ä¸å¤Ÿç”¨äº†ã€‚</p><p>æƒ³è¦åˆ›å»ºä¸€ä¸ª<strong>ç¬¦å·å‡½æ•°</strong>ï¼Œæˆ‘ä»¬é¦–å…ˆè¦åˆ›å»ºä¸€ä¸ªæˆ–å¤šä¸ª<strong>ç¬¦å·å˜é‡</strong>ï¼Œç”¨ä»¥è¡¨ç¤ºç¬¦å·å‡½æ•°æœ¬èº«ã€‚å…¶å®šä¹‰æ–¹å¼å³ä¸º<code>syms x x1 x2</code>ã€‚å…¶ä¸­<code>x,x1,x2</code> éƒ½æ˜¯ç¬¦å·å˜é‡ï¼Œä¸€ä¸ªç¬¦å·å‡½æ•°å¯ä»¥ç”±å¤šä¸ªç¬¦å·å˜é‡ç»„æˆã€‚</p><p>ç¬¦å·å˜é‡å¯ä»¥æœ‰å®šä¹‰åŸŸï¼Œè¿™é‡Œæˆ–ç§°<strong>é™åˆ¶æ¡ä»¶</strong>ã€‚</p><p>é™åˆ¶æ¡ä»¶å¯ä»¥åœ¨å®šä¹‰æ—¶å°±åŠ ä¸Šï¼Œä½†å¾€å¾€æ˜¯è¾ƒä¸ºç®€å•çš„æ¡ä»¶ï¼Œå¦‚<em>positive</em>, <em>real</em>, <em>integer</em> ç­‰ã€‚</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% Create symbolic variables x and y, and assume that they are integers.</span></span><br><span class="line">syms x y integer</span><br><span class="line"></span><br><span class="line"><span class="comment">% Create another variable z, and assume that it has a positive rational value.</span></span><br><span class="line">syms z positive rational</span><br><span class="line"></span><br><span class="line"><span class="comment">% Check assumptions on each variable. For example, check assumptions set on the variable x.</span></span><br><span class="line">assumptions(x)</span><br><span class="line"></span><br><span class="line"><span class="comment">% Clear assumptions on x, y, and z.</span></span><br><span class="line">assume([x y z],<span class="string">&#x27;clear&#x27;</span>)</span><br><span class="line">assumptions</span><br><span class="line"></span><br><span class="line"><span class="comment">% Create a 1-by-3 symbolic array a and assume that the array elements have real values.</span></span><br><span class="line">syms a [<span class="number">1</span> <span class="number">3</span>] <span class="built_in">real</span></span><br><span class="line">assumptions</span><br></pre></td></tr></table></figure><p>å…¶æ¬¡ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ä½¿ç”¨æ›´åŠ ç²¾ç¡®çš„æ–¹æ³•è¿›è¡Œé™å®šï¼Œå³ä½¿ç”¨<code>assume</code>å‘½ä»¤ã€‚</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">syms x</span><br><span class="line">assume(<span class="number">0</span>&lt;x&lt;<span class="number">4</span>)</span><br></pre></td></tr></table></figure><h2 id="å®šä¹‰å‡½æ•°"><a class="markdownIt-Anchor" href="#å®šä¹‰å‡½æ•°"></a> å®šä¹‰å‡½æ•°</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% æ–¹æ³•1 ä½¿ç”¨è¿™ç§æ–¹æ³•ä¸ç”¨ç‰¹æ„å®šä¹‰è‡ªå˜é‡</span></span><br><span class="line">y = @(t) <span class="built_in">cos</span>(<span class="number">3</span>*t);</span><br><span class="line"></span><br><span class="line"><span class="comment">% æ–¹æ³•2 å…ˆå®šä¹‰è‡ªå˜é‡ä¸ºç¬¦å·å˜é‡å†å®šä¹‰å‡½æ•°æœ¬èº«</span></span><br><span class="line">syms x</span><br><span class="line">fun = <span class="number">0.5</span>*x*(<span class="built_in">exp</span>(<span class="number">-2</span>*x)+<span class="built_in">exp</span>(<span class="number">-1.5</span>*x)+<span class="built_in">exp</span>(-x))</span><br></pre></td></tr></table></figure><h2 id="å¿«é€Ÿç»˜åˆ¶å‡½æ•°å›¾åƒ"><a class="markdownIt-Anchor" href="#å¿«é€Ÿç»˜åˆ¶å‡½æ•°å›¾åƒ"></a> å¿«é€Ÿç»˜åˆ¶å‡½æ•°å›¾åƒ</h2><p>MATLABä¸­çš„å‡½æ•°<code>fplot</code>å¯ä»¥è¿…é€Ÿç»˜åˆ¶ä¸€ä¸ªç¬¦å·å‡½æ•°çš„å‡½æ•°å›¾åƒï¼Œå¹¶å¯ä»¥å¯¹å…¶æ˜¾ç¤ºçš„xèŒƒå›´è¿›è¡Œè®¾å®šã€‚</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fplot(fun)</span><br><span class="line">fplot(fun,x,[<span class="number">1</span>,<span class="number">2</span>])</span><br></pre></td></tr></table></figure><p>é»˜è®¤æƒ…å†µä¸‹ï¼Œå…¶ç»˜åˆ¶åŒºé—´ä¸º<code>[-5, 5]</code>ï¼Œä½†å¦‚æœç¬¦å·å˜é‡æœ¬èº«æœ‰å®šä¹‰åŸŸé™åˆ¶ï¼Œåˆ™ä¼šä¼˜å…ˆå…¶å®šä¹‰åŸŸï¼Œä¼˜å…ˆçº§æœ€é«˜çš„æ˜¯åœ¨ç»˜åˆ¶å‡½æ•°ä¸­æŒ‡å®šçš„ç»˜åˆ¶åŒºé—´ã€‚</p><p>å½“ç„¶ï¼Œ<code>fplot</code>å‡½æ•°è¿˜å¯ä»¥ç»˜åˆ¶å¤šæ¡æ›²çº¿ã€åˆ†æ®µå‡½æ•°ä»¥åŠå‚æ•°å‡½æ•°ç­‰ï¼Œè¯¦è§<a href="https://ww2.mathworks.cn/help/matlab/ref/fplot.html">å¸®åŠ©æ–‡æ¡£</a>ï¼Œè¿™é‡Œç»™å‡ºå‡ ä¸ªç®€å•å¸¸ç”¨ä¾‹å­ã€‚</p><p>æŒ‡å®šç»˜å›¾åŒºé—´å¹¶ç»˜åˆ¶åˆ†æ®µå‡½æ•°<br><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>e</mi><mi>x</mi></msup><mtext>Â </mtext><mi mathvariant="normal">âˆ’</mi><mn>3</mn><mo>&lt;</mo><mi>x</mi><mo>&lt;</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">e^x\space âˆ’3&lt;x&lt;0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.747722em;vertical-align:-0.08333em;"></span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">x</span></span></span></span></span></span></span></span><span class="mspace">Â </span><span class="mord">âˆ’</span><span class="mord">3</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span></p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>c</mi><mi>o</mi><mi>s</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mtext>Â </mtext><mn>0</mn><mo>&lt;</mo><mi>x</mi><mo>&lt;</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">cos(x)\space 0&lt;x&lt;3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">c</span><span class="mord mathdefault">o</span><span class="mord mathdefault">s</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace">Â </span><span class="mord">0</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span></span></span></span></p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ä½¿ç”¨ <span class="built_in">hold</span> on ç»˜åˆ¶å¤šä¸ªçº¿æ¡ã€‚ä½¿ç”¨ fplot çš„ç¬¬äºŒä¸ªè¾“å…¥å‚æ•°æŒ‡å®šç»˜å›¾åŒºé—´ã€‚ä½¿ç”¨ <span class="string">&#x27;b&#x27;</span> å°†ç»˜åˆ¶çš„çº¿æ¡é¢œè‰²æŒ‡å®šä¸ºè“è‰²ã€‚åœ¨ç›¸åŒåæ ‡åŒºä¸­ç»˜åˆ¶å¤šä¸ªçº¿æ¡æ—¶ï¼Œåæ ‡è½´èŒƒå›´ä¼šè°ƒæ•´ä»¥å®¹çº³æ‰€æœ‰æ•°æ®ã€‚</span><br><span class="line">fplot(@(x) <span class="built_in">exp</span>(x),[<span class="number">-3</span> <span class="number">0</span>],<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line"><span class="built_in">hold</span> on</span><br><span class="line">fplot(@(x) <span class="built_in">cos</span>(x),[<span class="number">0</span> <span class="number">3</span>],<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line"><span class="built_in">hold</span> off</span><br><span class="line">grid on</span><br></pre></td></tr></table></figure><img src="/2020/01/10/matlab-func/specifyplottingintervalandplotpiecewisefunctionsexample_01_zh_CN.png" alt="img" style="zoom:50%;"><p>å½“ç„¶ï¼Œä½¿ç”¨<code>fplot</code>æ–¹æ³•ç»˜åˆ¶çš„å›¾åƒä¹Ÿæ˜¯å¯ä»¥è¿›è¡Œæ ·å¼è‡ªå®šä¹‰çš„ï¼š</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fplot(@(x) <span class="built_in">sin</span>(x+<span class="built_in">pi</span>/<span class="number">5</span>),<span class="string">&#x27;Linewidth&#x27;</span>,<span class="number">2</span>);</span><br><span class="line"><span class="built_in">hold</span> on</span><br><span class="line">fplot(@(x) <span class="built_in">sin</span>(x-<span class="built_in">pi</span>/<span class="number">5</span>),<span class="string">&#x27;--or&#x27;</span>);</span><br><span class="line">fplot(@(x) <span class="built_in">sin</span>(x),<span class="string">&#x27;-.*c&#x27;</span>)</span><br><span class="line"><span class="built_in">hold</span> off</span><br></pre></td></tr></table></figure><img src="/2020/01/10/matlab-func/specifylinepropertiesanddisplaymarkersexample_01_zh_CN.png" alt="img" style="zoom:50%;"><h2 id="è§£æ–¹ç¨‹"><a class="markdownIt-Anchor" href="#è§£æ–¹ç¨‹"></a> è§£æ–¹ç¨‹</h2><p>MATLABä¸­æœ‰ä¸¤ç§å¸¸ç”¨è§£æ–¹ç¨‹çš„å‡½æ•°ï¼š<code>solve</code>å’Œ<code>vpasolve</code>ã€‚å‰è€…ä¼šè¿”å›ä¸€ä¸ªç¬¦å·è§£ï¼Œå®ƒçš„åšæ³•å°±åƒäººç±»æ‰‹å·¥æ¨ç†ä¸€æ ·ï¼Œè®¡ç®—å‡ºæ‰€æœ‰çš„ç¬¦å·è§£ã€‚è€Œåè€…åˆ™ä¼šè®¡ç®—æ–¹ç¨‹çš„æ•°å€¼è§£ï¼Œä¸”åªä¼šè¿”å›å…¶æ‰¾åˆ°çš„ç¬¬ä¸€ä¸ªæ•°å€¼è§£ã€‚</p><p>å½“æˆ‘ä»¬æƒ³è¦ä½¿ç”¨<code>vpasolve</code>ç®—å‡ºæŸä¸ªxèŒƒå›´ä¸­çš„æ‰€æœ‰è§£æ—¶å€™ï¼Œæˆ‘ä»¬æœ‰ä¸¤ç§æ–¹æ³•ï¼š</p><h3 id="1-ç”»å‡ºæ–¹ç¨‹å¯¹åº”çš„å‡½æ•°å›¾åƒå¹¶ä¼ ç»™vpasolveä¸€ä¸ªçŒœæµ‹èµ·ç‚¹"><a class="markdownIt-Anchor" href="#1-ç”»å‡ºæ–¹ç¨‹å¯¹åº”çš„å‡½æ•°å›¾åƒå¹¶ä¼ ç»™vpasolveä¸€ä¸ªçŒœæµ‹èµ·ç‚¹"></a> 1. ç”»å‡ºæ–¹ç¨‹å¯¹åº”çš„å‡½æ•°å›¾åƒï¼Œå¹¶ä¼ ç»™<code>vpasolve</code>ä¸€ä¸ªçŒœæµ‹èµ·ç‚¹</h3><p>å¦‚ç»™å®šæ–¹ç¨‹<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>200</mn><mo>âˆ—</mo><mi>s</mi><mi>i</mi><mi>n</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><msup><mi>x</mi><mn>3</mn></msup><mo>âˆ’</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">200*sin(x) = x^3 - 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord">0</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">âˆ—</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">s</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.897438em;vertical-align:-0.08333em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">âˆ’</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>, æˆ‘ä»¬å…ˆç”»å‡ºå®ƒçš„å›¾åƒè¿›è¡Œè§‚å¯Ÿï¼š</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">syms x</span><br><span class="line">eqnLeft = <span class="number">200</span>*<span class="built_in">sin</span>(x);</span><br><span class="line">eqnRight = x^<span class="number">3</span> - <span class="number">1</span>;</span><br><span class="line">fplot([eqnLeft eqnRight])</span><br><span class="line">title([texlabel(eqnLeft) <span class="string">&#x27; = &#x27;</span> texlabel(eqnRight)])</span><br></pre></td></tr></table></figure><img src="/2020/01/10/matlab-func/FindMultipleSolutionsBySpecifyingInitialGuessesExample_01.png" alt="img" style="zoom:50%;"><p>è§‚å¯Ÿåå‘ç°ï¼Œè¿™ä¸ªæ–¹ç¨‹æœ‰ä¸‰ä¸ªè§£ï¼Œåˆ†åˆ«åœ¨-3, 0, 4çš„é™„è¿‘ï¼Œäºæ˜¯æˆ‘ä»¬å¯ä»¥ç”¨ä»¥ä¸‹è¯­å¥æ‰¾åˆ°å…¶æ‰€æœ‰çš„ä¸‰ä¸ªè§£</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">S1 = vpasolve(eqnLeft == eqnRight, x);</span><br><span class="line">S2 = vpasolve(eqnLeft == eqnRight, x, <span class="number">-3</span>);</span><br><span class="line">S3 = vpasolve(eqnLeft == eqnRight, x, <span class="number">4</span>);</span><br></pre></td></tr></table></figure><h3 id="2-ä½¿vpasolveæ‹¥æœ‰ä¸€ä¸ªéšæœºèµ·ç‚¹å¹¶è¿›è¡Œå¾ªç¯"><a class="markdownIt-Anchor" href="#2-ä½¿vpasolveæ‹¥æœ‰ä¸€ä¸ªéšæœºèµ·ç‚¹å¹¶è¿›è¡Œå¾ªç¯"></a> 2. ä½¿<code>vpasolve</code>æ‹¥æœ‰ä¸€ä¸ªéšæœºèµ·ç‚¹ï¼Œå¹¶è¿›è¡Œå¾ªç¯</h3><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> n = <span class="number">1</span>:<span class="number">3</span></span><br><span class="line">    S = vpasolve(f,x,[<span class="number">0</span>,<span class="number">2</span>],<span class="string">&#x27;Random&#x27;</span>,<span class="built_in">true</span>)</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="3-ä»…é’ˆå¯¹å¤šé¡¹å¼å‡½æ•°"><a class="markdownIt-Anchor" href="#3-ä»…é’ˆå¯¹å¤šé¡¹å¼å‡½æ•°"></a> 3. ä»…é’ˆå¯¹å¤šé¡¹å¼å‡½æ•°</h3><p>å¦‚æœä½ çš„å‡½æ•°æ˜¯ä¸€ä¸ªæ ‡å‡†çš„å¤šç›¸ä¼¼å‡½æ•°ï¼Œé‚£ä¹ˆä½ å¯ä»¥ä½¿ç”¨<code>roots</code>å‡½æ•°ä¸€æ¬¡æ€§å¾—åˆ°æ‰€æœ‰çš„è§£ã€‚è¯¦æƒ…è¯·å‚é˜…<a href="https://www.mathworks.com/help/matlab/ref/roots.html">å¸®åŠ©æ–‡æ¡£</a>ã€‚</p><h2 id="å¯»æ‰¾å‡½æ•°æå¤§æå°å€¼"><a class="markdownIt-Anchor" href="#å¯»æ‰¾å‡½æ•°æå¤§æå°å€¼"></a> å¯»æ‰¾å‡½æ•°æå¤§æå°å€¼</h2><p>åœ¨MATLABä¸­ä¼¼ä¹æ²¡æœ‰ç›´æ¥ä¸€é”®æ±‚å‡ºå‡½æ•°çš„æœ€å€¼çš„åŠæ³•ï¼Œä½†æˆ‘ä»¬å´å¯ä»¥ç”¨<code>fminsearch</code>æ±‚å‡ºæŸä¸ªç‚¹é™„è¿‘çš„æå€¼ã€‚</p><p>ä¸å‰é¢æåˆ°çš„è§£æ–¹ç¨‹ç±»ä¼¼ï¼Œç”±äºè¯¥å‡½æ•°å¹¶ä¸ä¼šç›´æ¥çš„æŠŠå…¨å±€æœ€å€¼ç»™ä½ ï¼Œæ‰€ä»¥æœ€å¥½å…ˆæŠŠå‡½æ•°å›¾åƒç”»å‡ºæ¥ï¼Œç„¶åè§‚å¯Ÿéœ€è¦æ±‚çš„æå€¼åœ¨é‚£ä¸ªç‚¹é™„è¿‘ï¼Œç„¶åä½¿ç”¨<code>fminsearch</code>å‡½æ•°æŠŠç›¸å…³ç‚¹çš„æ¨ªåæ ‡è§£å‡ºï¼Œå¦‚æœéœ€è¦æœ€å€¼çš„å€¼ï¼Œå†æŠŠè¿™ä¸ªæ¨ªåæ ‡å¸¦å›å»æ±‚å€¼ã€‚</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">syms x</span><br><span class="line">y=<span class="built_in">real</span>((<span class="number">1</span>-<span class="built_in">exp</span>(<span class="number">8</span>*<span class="built_in">i</span>*<span class="built_in">pi</span>*<span class="built_in">cos</span>(x)))/(<span class="number">1</span>-<span class="built_in">exp</span>(<span class="built_in">i</span>*<span class="built_in">pi</span>*<span class="built_in">cos</span>(x))));</span><br><span class="line">fplot(y,[<span class="number">0</span>,<span class="number">3</span>]);</span><br><span class="line">fminsearch(matlabFunction(-y),<span class="number">1.5</span>);</span><br><span class="line"><span class="comment">% ans = 1.5708</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><img src="/2020/01/10/matlab-func/image-20200216152601687.png" alt="image-20200216152601687" style="zoom:35%;"><p>è¯·æ³¨æ„ï¼Œè¿™é‡Œåœ¨searchçš„æ—¶å€™æˆ‘å°†yæ”¹ä¸ºäº†-yï¼Œå› ä¸ºæˆ‘è¦æ‰¾çš„æ˜¯æå¤§å€¼è€Œéæå°å€¼ã€‚</p><p>æ¥ç€ï¼Œæˆ‘ä»¬å°†å‡½æ•°yå˜ä¸º<code>matlabFunction</code>å‹å˜é‡ï¼Œåœ¨æ ¹æ®åˆšæ‰è¾“å‡ºçš„å€¼æ±‚å‡ºæå€¼å¤§å°ï¼š</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">q=matlabFunction(y)</span><br><span class="line">q(<span class="number">1.5708</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>äºæ˜¯ï¼Œæˆ‘ä»¬å°±æ‰¾åˆ°äº†å‡½æ•°åœ¨è¯¥ç‚¹é™„è¿‘çš„æå€¼ã€‚</p><p>ä½ ç”šè‡³å¯ä»¥çœ‹åˆ°MATLABçš„ä¼˜åŒ–è·¯å¾„ï¼š</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">options = optimset(<span class="string">&#x27;PlotFcns&#x27;</span>,@optimplotfval);</span><br><span class="line">fun = @(x)<span class="number">100</span>*(x(<span class="number">2</span>) - x(<span class="number">1</span>)^<span class="number">2</span>)^<span class="number">2</span> + (<span class="number">1</span> - x(<span class="number">1</span>))^<span class="number">2</span>;</span><br><span class="line">x0 = [<span class="number">-1.2</span>,<span class="number">1</span>];</span><br><span class="line">x = fminsearch(fun,x0,options)</span><br></pre></td></tr></table></figure><img src="/2020/01/10/matlab-func/image-20200216153158018.png" alt="image-20200216153158018" style="zoom:33%;"><h2 id="å¯¹å‡½æ•°æ±‚å¯¼"><a class="markdownIt-Anchor" href="#å¯¹å‡½æ•°æ±‚å¯¼"></a> å¯¹å‡½æ•°æ±‚å¯¼</h2><p>å®šä¹‰å¥½ä¸€ä¸ªç¬¦å·å‡½æ•°åï¼Œç›´æ¥ä½¿ç”¨<code>diff</code>å‘½ä»¤å³å¯å¯¹å‡½æ•°è¿›è¡Œç¬¦å·æ±‚å¯¼ã€‚</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">syms x</span><br><span class="line">fun=<span class="number">0.5</span>*x*(<span class="built_in">exp</span>(<span class="number">-2</span>*x)+<span class="built_in">exp</span>(<span class="number">-1.5</span>*x)+<span class="built_in">exp</span>(-x))</span><br><span class="line">diff(fun) <span class="comment">% or diff(fun, x)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>éœ€è¦æ³¨æ„çš„ä¸€ç‚¹æ˜¯ï¼Œ<code>diff</code>å‡½æ•°ä¸ä½†å¯¹ç¬¦å·å‡½æ•°æœ‰æ•ˆï¼Œå…¶å¯¹æ•°åˆ—ä¹Ÿæ˜¯æœ‰æ•ˆçš„ï¼š</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X = [<span class="number">1</span> <span class="number">1</span> <span class="number">2</span> <span class="number">3</span> <span class="number">5</span> <span class="number">8</span> <span class="number">13</span> <span class="number">21</span>];</span><br><span class="line">Y = diff(X)</span><br><span class="line"><span class="comment">% Y = 1Ã—7</span></span><br><span class="line"><span class="comment">%     0     1     1     2     3     5     8</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;ç¬¦å·å˜é‡-syms&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#ç¬¦å·å˜é‡-syms&quot;&gt;&lt;/a&gt; ç¬¦å·å˜é‡ syms&lt;/h2&gt;
&lt;p&gt;åœ¨MATLABä¸­åˆ›å»ºæˆ–å®šä¹‰ä¸€ä¸ªå‡½æ•°éœ€è¦ç”¨åˆ°ç¬¦å·å˜é‡ã€‚ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œæƒ³è¦ç»˜åˆ¶å‡½æ•°å›¾åƒæ—¶ï¼Œå¾€å¾€ä½¿ç”¨&lt;code</summary>
      
    
    
    
    
    <category term="matlab" scheme="https://www.miracleyoo.com/tags/matlab/"/>
    
  </entry>
  
  <entry>
    <title>Pytorch Core Code Research</title>
    <link href="https://www.miracleyoo.com/2019/12/11/Pytorch-Core-Code-Research/"/>
    <id>https://www.miracleyoo.com/2019/12/11/Pytorch-Core-Code-Research/</id>
    <published>2019-12-11T21:35:01.000Z</published>
    <updated>2019-12-12T01:08:49.630Z</updated>
    
    <content type="html"><![CDATA[<h2 id="pytorch-release-version-composition"><a class="markdownIt-Anchor" href="#pytorch-release-version-composition"></a> Pytorch Release Version Composition</h2><p>The repository cloned from GitHub <a href="https://github.com/pytorch/pytorch">pytorch/pytorch</a> is different from the package we download using <code>pip install</code> or <code>conda install</code>. In fact, the former contains many C/C++ based files, which consist of the basic of Pytorch, while the latter is more concise and contains compiled libraries and dll files instead.</p><p>Here, letâ€™s discuss the release version, or the installed package at first. The package has a lot of components, Here I only pick out some most important parts to do explanation.</p><p><img src="/2019/12/11/Pytorch-Core-Code-Research/image-20191128191350467.png" alt="image-20191128191350467"></p><h4 id="nn"><a class="markdownIt-Anchor" href="#nn"></a> nn</h4><p>All deep learning layersâ€™ python entrance are located here. They mainly collect parameters from init input and do some modification to the input data. After that it will send core computation operation together with parameters into <code>torch._C</code> based functions.</p><h4 id="autograd"><a class="markdownIt-Anchor" href="#autograd"></a> autograd</h4><p>Contains a series of base functions which serves for back propagation. Also, if you dig in, the core implementation is still from C libraries. Variable wrap is also put here, but now it is just omitted because of the merge of tensor and Variable.</p><h4 id="cuda"><a class="markdownIt-Anchor" href="#cuda"></a> CUDA</h4><p>Mainly these parts are contained in <code>cuda</code> folder: Stream, Event, Broadcast and Random.</p><ul><li>A CUDA stream is a linear sequence of execution that belongs to a specific device, independent from other streams.</li><li>CUDA events are synchronization markers that can be used to monitor the deviceâ€™s progress, to accurately measure timing, and to synchronize CUDA streams.</li><li>Broadcast related functions mainly do the jobs to make sure operations run on different GPUs and gather correctly.</li></ul><h4 id="optim"><a class="markdownIt-Anchor" href="#optim"></a> optim</h4><p><code>torch.optim</code> is a package implementing various optimization algorithms. Most commonly used methods are already supported, like <code>adam</code>, <code>sgd</code> and <code>adagrad</code>.</p><h4 id="distributed"><a class="markdownIt-Anchor" href="#distributed"></a> distributed</h4><p>The <code>distributions</code> package contains parameterizable probability distributions and sampling functions. This allows the construction of stochastic computation graphs and stochastic gradient estimators for optimization.</p><h4 id="onnx"><a class="markdownIt-Anchor" href="#onnx"></a> onnx</h4><p>The <code>torch.onnx</code> module contains functions to export models into the ONNX IR format. These models can be loaded with the ONNX library and then converted to models which run on other deep learning frameworks.</p><h4 id="tensor"><a class="markdownIt-Anchor" href="#tensor"></a> tensor</h4><p>Most basic tensor class defined here. It inherit a super class from C lib, called <code>torch._C._TensorBase</code> . And it attaches a lot of method like <code>register_hook</code>,<code>resize</code>, <code>norm</code> to tensor class. All these method eventually call C based libraries.</p><h4 id="lib"><a class="markdownIt-Anchor" href="#lib"></a> lib</h4><p>The library where compiled C/C++ files located. There are <code>.dll</code> files as well as <code>.lib</code> files. According to the bug reports on google, I believe <code>.dll</code> files are specially compiled for the compatibility of windows and <code>.lib</code> can be used in linux and some of them are also usable in Windows.(If you find a more accurate explanation, please tell me:) These files included: <code>_C.lib</code>, <code>c10.lib</code>, <code>torch.lib</code>, <code>c10_cuda.lib</code>.</p><h4 id="functional"><a class="markdownIt-Anchor" href="#functional"></a> functional</h4><p>Functions related to tensor operation are all located here. In fact, again, they are wrappers of functions from C libraries. You can find functions like <code>tensordot</code>, <code>unique</code>, <code>split</code> in this file.</p><h4 id="utils"><a class="markdownIt-Anchor" href="#utils"></a> utils</h4><p>All kinds of utilities codes are located here. This include dataset related code <code>dataloader.py</code>, <code>dataset.py</code>, <code>sampler.py</code>, also include save and output related <code>checkpoint.py</code>. Some TensorBoard support can also be found here.</p><h2 id="how-pytorch-manage-its-inner-resource"><a class="markdownIt-Anchor" href="#how-pytorch-manage-its-inner-resource"></a> How Pytorch manage its inner resource</h2><h3 id="what-is-tensor"><a class="markdownIt-Anchor" href="#what-is-tensor"></a> What is Tensor</h3><p>In <a href="https://en.wikipedia.org/wiki/Mathematics">mathematics</a>, a <strong>tensor</strong> is an algebraic object that describes a <a href="https://en.wikipedia.org/wiki/Linear_mapping">linear mapping</a> from one set of algebraic objects to another. Objects that tensors may map between include, but are not limited to, <a href="https://en.wikipedia.org/wiki/Vector_(mathematics_and_physics)">vectors</a> and <a href="https://en.wikipedia.org/wiki/Scalar_(mathematics)">scalars</a>, and, recursively, even other tensors. The tensor is the central data structure in PyTorch.  Itâ€™s an n-dimensional data structure containing some sort of scalar type, e.g., floats, ints, et cetera. We can think of a tensor as consisting of some data, and then some metadata describing the size of the tensor, the type of the elements in contains (dtype), what device the tensor lives on (CPU memory,  CUDA memory)</p><p>![what is tensor](Simple Tutorials on Tensors.jpg)</p><h3 id="how-tensor-organizes"><a class="markdownIt-Anchor" href="#how-tensor-organizes"></a> How Tensor organizes</h3><p>TH library is responsible for the computation,storage and memory management of Tensor. It divide the â€œTensorâ€ into two separate parts: Storage and Access/View.</p><p>Storage: <strong>THStorage</strong>. It manage the way of storing the Tensor.</p><p>Access: <strong>THTensor</strong>. It provide a access to user.</p><p><img src="/2019/12/11/Pytorch-Core-Code-Research/image-20191203093005864.png" alt="image-20191203093005864"></p><h4 id="data-storage"><a class="markdownIt-Anchor" href="#data-storage"></a> Data Storage</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">THStorage</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"> real *data;</span><br><span class="line"> <span class="keyword">ptrdiff_t</span> size;</span><br><span class="line"> <span class="keyword">int</span> refcount;</span><br><span class="line"> <span class="keyword">char</span> flag;</span><br><span class="line"> THAllocator *allocator;</span><br><span class="line"> <span class="keyword">void</span> *allocatorContext;</span><br><span class="line"> <span class="class"><span class="keyword">struct</span> <span class="title">THStorage</span> *<span class="title">view</span>;</span></span><br><span class="line">&#125; THStorage;</span><br></pre></td></tr></table></figure><ul><li>All of the â€œTensorâ€ in CPU is in fact a C pointer pointing to a data structure in memory like this. And it use reference count to do memory management.</li><li><strong>refcount</strong>: Here we apply reference count method to do automatic garbage collection. When the reference number becomes 0, this struct will be freed automatically.</li></ul><h4 id="data-access"><a class="markdownIt-Anchor" href="#data-access"></a> Data Access</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">THTensor</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"> <span class="keyword">long</span> *size;</span><br><span class="line"> <span class="keyword">long</span> *stride;</span><br><span class="line"> <span class="keyword">int</span> nDimension;</span><br><span class="line"></span><br><span class="line"> <span class="comment">// Attention: storage-&gt;size might be bigger than the size of tensor.</span></span><br><span class="line"> THStorage *storage;</span><br><span class="line"> <span class="keyword">ptrdiff_t</span> storageOffset;</span><br><span class="line"> <span class="keyword">int</span> refcount;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">char</span> flag;</span><br><span class="line"></span><br><span class="line">&#125; THTensor;</span><br></pre></td></tr></table></figure><ul><li><strong>nDimension</strong>: The number of dimensions</li><li><strong>size</strong>: It contains the length information of all dimensions.</li><li><strong>refcount</strong>: Reference count</li><li><strong>storage</strong>: Pointer of this data structure</li><li><strong>stride</strong>: The size of each dimension.</li></ul><h4 id="memory-allocator"><a class="markdownIt-Anchor" href="#memory-allocator"></a> Memory Allocator</h4><h5 id="c10coreallocatorh"><a class="markdownIt-Anchor" href="#c10coreallocatorh"></a> <code>/c10/core/Allocator.h</code></h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;memory&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">C10_API</span> <span class="title">Allocator</span> &#123;</span></span><br><span class="line">  <span class="keyword">virtual</span> ~Allocator() = <span class="keyword">default</span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> DataPtr <span class="title">allocate</span><span class="params">(<span class="keyword">size_t</span> n)</span> <span class="keyword">const</span> </span>= <span class="number">0</span>;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> DeleterFnPtr <span class="title">raw_deleter</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nullptr</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">void</span>* <span class="title">raw_allocate</span><span class="params">(<span class="keyword">size_t</span> n)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">auto</span> dptr = allocate(n);</span><br><span class="line">    AT_ASSERT(dptr.get() == dptr.get_context());</span><br><span class="line">    <span class="keyword">return</span> dptr.release_context();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">raw_deallocate</span><span class="params">(<span class="keyword">void</span>* ptr)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">auto</span> d = raw_deleter();</span><br><span class="line">    AT_ASSERT(d);</span><br><span class="line">    d(ptr);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>The <code>allocate</code> function is directly included from head file <code>memory</code>.</p><h5 id="atensrcththallocatorcpp"><a class="markdownIt-Anchor" href="#atensrcththallocatorcpp"></a> <code>/aten/src/TH/THAllocator.cpp</code></h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">at::DataPtr <span class="title">THMapAllocator::makeDataPtr</span><span class="params">(<span class="keyword">const</span> <span class="keyword">char</span> *filename, <span class="keyword">int</span> flags, <span class="keyword">size_t</span> size, <span class="keyword">size_t</span>* actual_size_out)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">auto</span>* context = <span class="keyword">new</span> THMapAllocator(filename, flags, size);</span><br><span class="line">  <span class="keyword">if</span> (actual_size_out) *actual_size_out = context-&gt;size();</span><br><span class="line">  <span class="keyword">return</span> &#123;context-&gt;data(), context, &amp;deleteTHMapAllocator, at::DeviceType::CPU&#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>Default allocator is malloc/free allocator. malloc and realloc raise an error (using THError) on allocation failure.</p></blockquote><h3 id="understand-parameters"><a class="markdownIt-Anchor" href="#understand-parameters"></a> Understand Parameters</h3><p>It is hard and not straightforward enough to understand stride and storage offset, so letâ€™s borrow some images from <a href="http://blog.ezyang.com/2019/05/pytorch-internals/">ezyang</a>, who is supposed to be an inner developer of Pytorch, to elaborate this problem.</p><p>A tensor is a mathematical concept. But to represent it on our computers, we have to define some sort of physical representation for them. The most common representation is to lay out each element of the tensor contiguously in memory (thatâ€™s where the term contiguous comes from), writing out each row to memory.</p><p><img src="/2019/12/11/Pytorch-Core-Code-Research/image-20191128191750794.png" alt="image-20191128191750794"></p><p>Please notice the relationship of sizes and strides. If we get a tensor with a size of (D,H,W) and this tensor is directly defined by user rather than a slice or result of some operation, the stride of it will be (H*W, W, 1). You can compare and draw a conclusion yourself. Each stride element in a certain dimension will be the product of all the following dimensions, and the stride of the last dimension will be 1.</p><p>Physically, stride means how many blocks of memory computer need to skip to get to the starting position of the next corresponding dimension. And if we use a formula to compute the memory position of a <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>T</mi><mi>e</mi><mi>n</mi><mi>s</mi><mi>o</mi><mi>r</mi><mo stretchy="false">[</mo><mi>i</mi><mo separator="true">,</mo><mi>j</mi><mo separator="true">,</mo><mi>k</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">Tensor[i,j,k]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault">e</span><span class="mord mathdefault">n</span><span class="mord mathdefault">s</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mopen">[</span><span class="mord mathdefault">i</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.05724em;">j</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mclose">]</span></span></span></span>, it will be <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>s</mi><mi>t</mi><mi>o</mi><mi>r</mi><mi>a</mi><mi>g</mi><mi>e</mi><mi>O</mi><mi>f</mi><mi>f</mi><mi>s</mi><mi>e</mi><mi>t</mi><mo>+</mo><mi>i</mi><mo>âˆ—</mo><mi>s</mi><mi>t</mi><mi>r</mi><mi>i</mi><mi>d</mi><mi>e</mi><mo stretchy="false">[</mo><mn>0</mn><mo stretchy="false">]</mo><mo>+</mo><mi>j</mi><mo>âˆ—</mo><mi>s</mi><mi>t</mi><mi>r</mi><mi>i</mi><mi>d</mi><mi>e</mi><mo stretchy="false">[</mo><mn>1</mn><mo stretchy="false">]</mo><mo>+</mo><mi>k</mi><mo>âˆ—</mo><mi>s</mi><mi>t</mi><mi>r</mi><mi>i</mi><mi>d</mi><mi>e</mi><mo stretchy="false">[</mo><mn>2</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">storageOffset + i * stride[0] + j * stride[1] + k * stride[2]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">s</span><span class="mord mathdefault">t</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mord mathdefault">s</span><span class="mord mathdefault">e</span><span class="mord mathdefault">t</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">i</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">âˆ—</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">s</span><span class="mord mathdefault">t</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">i</span><span class="mord mathdefault">d</span><span class="mord mathdefault">e</span><span class="mopen">[</span><span class="mord">0</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.85396em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05724em;">j</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">âˆ—</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">s</span><span class="mord mathdefault">t</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">i</span><span class="mord mathdefault">d</span><span class="mord mathdefault">e</span><span class="mopen">[</span><span class="mord">1</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">âˆ—</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">s</span><span class="mord mathdefault">t</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">i</span><span class="mord mathdefault">d</span><span class="mord mathdefault">e</span><span class="mopen">[</span><span class="mord">2</span><span class="mclose">]</span></span></span></span>.</p><p>In the example image above, Iâ€™ve specified that the tensor contains 32-bit integers, so you can see that each integer lies in a physical address, each offset four bytes from each other. To remember what the actual dimensions of the tensor are, we have to also record what the sizes are as extra metadata.</p><p><img src="/2019/12/11/Pytorch-Core-Code-Research/image-20191128192741907.png" alt="image-20191128192741907"></p><p>Then comes to the memory offset. What does this mean? As we has mentioned before, a tensor storage may support multiple tensor view, and if we sliced the first N elements, then we will start from N+1 memory position. The following examples will give a further explanation.</p><p><img src="/2019/12/11/Pytorch-Core-Code-Research/image-20191128193018098.png" alt="image-20191128193018098"></p><p>You can see in the left example, we start at the third element block, so that means we skip two block, and here the offset is 2. Because of the slice, the two dimensional tensor becomes one dimensional tensor, and conjoint elements are continuous in physical storage, this means the strides is [1]. Size is the number of elements in this case and it is 2.</p><p>In the right example, conjoint elements are not continuous, but it do start from the beginning, so the strides is [2] and offset is 0. There are still two elements in total so the sizes donâ€™t change.</p><p>Whatâ€™s more, if you still find it somehow difficult to understand, you may try <a href="https://ezyang.github.io/stride-visualizer/index.html">this website</a> to playing with these parameters and see the dynamic process.</p><h3 id="tensor-implementation-dispatch"><a class="markdownIt-Anchor" href="#tensor-implementation-dispatch"></a> Tensor implementation dispatch</h3><p>As we know, although in Python, you can use any type of data as you wish, as the interpreter will take care of the rest of the things. However, since the basic kernels are written in C/C++, functions from Python need to be dispatched into same functions with different input and device type. To a C/C++ functions, a certain function cannot take in <code>int</code> and <code>float</code> Tensor as a same <code>X</code> at the same time, they need separate implementation.</p><p><img src="/2019/12/11/Pytorch-Core-Code-Research/image-20191128221930437.png" alt="image-20191128221930437"></p><h3 id="how-to-dispatch"><a class="markdownIt-Anchor" href="#how-to-dispatch"></a> How to dispatch</h3><p>As we discussed above, the basic C/C++ implementation need to dispatch according to data and device type. But in code, how to actually do this work?</p><p><img src="/2019/12/11/Pytorch-Core-Code-Research/image-20191128222130891.png" alt="image-20191128222130891"></p><p>There are basically three methods.</p><ol><li>Write these functions with different data and device type separately, and manually.</li><li>Using template function to build those dispatched function in the compiling time. But this only works in C++, while many code in Pytorch is still written in C.</li><li>Apply the magic item â€“ Macro. By defining the function name as a Macro which takes in one or some parameters, like the data type name, we can compile this function in different types by <code>#define</code> and <code>#undef</code> multiple times, setting the variables in function name macro into various type name to compile the function into many copies which support different types.</li></ol><p>Hereâ€™s a simplified example:</p><h4 id="file-structure"><a class="markdownIt-Anchor" href="#file-structure"></a> File structure:</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">â”œâ”€â”€ add.c <span class="comment"># Used to extend generic/add.c</span></span><br><span class="line">â”œâ”€â”€ add.h <span class="comment"># Used to extend generic/add.h</span></span><br><span class="line">â”œâ”€â”€ general.h <span class="comment"># Including other header files</span></span><br><span class="line">â””â”€â”€ generic</span><br><span class="line"> â”œâ”€â”€ add.c <span class="comment"># Definition of generic function add</span></span><br><span class="line"> â””â”€â”€ add.h <span class="comment"># Definition of generic type Vector</span></span><br></pre></td></tr></table></figure><h4 id="addh"><a class="markdownIt-Anchor" href="#addh"></a> add.h</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// add.h</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;general.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> CONCAT_2_EXPAND(A, B) A ## B</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> CONCAT_2(A, B) CONCAT_2_EXPAND(A, B)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> CONCAT_3_EXPAND(A, B, C) A ## B ## C</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> CONCAT_3(A, B, C) CONCAT_3_EXPAND(A, B, C)</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> Vector_(NAME) CONCAT_3(Num, Vector_, NAME)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> Vector CONCAT_2(Num, Vector)</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> num float</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> Num Float</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;generic/add.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">undef</span> num</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">undef</span> Num</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> num double</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> Num Double</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;generic/add.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">undef</span> num</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">undef</span> Num</span></span><br></pre></td></tr></table></figure><h4 id="addc"><a class="markdownIt-Anchor" href="#addc"></a> add.c</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// add.c</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;add.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> num float</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> Num Float</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;generic/add.c&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">undef</span> num</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">undef</span> Num</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> num double</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> Num Double</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;generic/add.c&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">undef</span> num</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">undef</span> Num</span></span><br></pre></td></tr></table></figure><h4 id="genericaddh"><a class="markdownIt-Anchor" href="#genericaddh"></a> generic/add.h</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// generic/add.h</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">Vector</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">num *data;</span><br><span class="line"><span class="keyword">int</span> n;</span><br><span class="line">&#125; Vector;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">extern</span> <span class="keyword">void</span> <span class="title">Vector_</span><span class="params">(add)</span><span class="params">(Vector *C, Vector *A, Vector *B)</span></span>;</span><br></pre></td></tr></table></figure><h4 id="genericaddc"><a class="markdownIt-Anchor" href="#genericaddc"></a> generic/add.c</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// generic/add.c</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Vector_</span><span class="params">(add)</span><span class="params">(Vector *C, Vector *A, Vector *B)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">int</span> i, n;</span><br><span class="line">n = C-&gt;n;</span><br><span class="line"><span class="keyword">for</span>(i=<span class="number">0</span>;i&lt;n;i++)</span><br><span class="line">&#123;</span><br><span class="line">C-&gt;data[i] = A-&gt;data[i] + B-&gt;data[i];</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="an-example-finding-thstorage"><a class="markdownIt-Anchor" href="#an-example-finding-thstorage"></a> An Example finding THStorage</h2><p>I try to find the definition of THStorage, since it will give us a brief understand of the file management structure of pytorch, and we can also grab a basic idea of how those macros and includes are forming this huge project. We start from <code>torch/csrc/Storage.cpp</code>, and check step by step to the file included.</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Storage.cpp                 -&gt;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;TH/TH.h&gt;          -&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;TH/THStorageFunction.h&gt;   -&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;TH/generic/THStorage.h&gt;   -&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;c10/core/StorageImpl.h&gt;</span></span></span><br></pre></td></tr></table></figure><p>Find the macro definition in <code>TH/generic/THStorage.h</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> THStorage at::StorageImpl</span></span><br></pre></td></tr></table></figure><p>Find the structure definition in <code>c10/core/StorageImpl.h</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">namespace</span> c10 &#123;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">C10_API</span> <span class="title">StorageImpl</span> <span class="keyword">final</span> :</span> <span class="keyword">public</span> c10::intrusive_ptr_target &#123;</span><br><span class="line">...</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">  caffe2::TypeMeta  data_type_;  <span class="comment">// Data type</span></span><br><span class="line">  DataPtr data_ptr_;             <span class="comment">// Data pointer</span></span><br><span class="line">  <span class="keyword">int64_t</span> numel_;                <span class="comment">// Data number</span></span><br><span class="line">  <span class="keyword">bool</span> resizable_;</span><br><span class="line">  <span class="keyword">bool</span> received_cuda_;</span><br><span class="line">  Allocator* allocator_;         <span class="comment">// Data&#x27;s allocator</span></span><br><span class="line">&#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Therefore, the hidding real tpye of <code>THWStorage</code> is <code>at::StorageImpl</code>, and it is the implementation of data storage. Letâ€™s look into the definition of <code>THPStorage_(pynew)</code> at first, when the value of  <code>cdata</code> is not provided, it need to create an implementation of class <code>THWStorage</code> using function <code>THWStorage_(NAME)</code>,  and the value of NAME can possibly be:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">new</span>                <span class="comment">// New a THStorage, if size not specified, size=0, that means using default Allocator</span></span><br><span class="line"><span class="built_in">free</span></span><br><span class="line">size</span><br><span class="line">get</span><br><span class="line"><span class="built_in">set</span></span><br><span class="line">data</span><br><span class="line">newWithSize        <span class="comment">// New THStorageï¼Œspecify size but use default Allocator</span></span><br><span class="line">newWithAllocator   <span class="comment">// New THStorageï¼Œspecify size and Allocator</span></span><br><span class="line">copy_functions</span><br><span class="line">copyByte</span><br><span class="line">...</span><br><span class="line">copyCudaByte</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>And also some macro definitions:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> THWStorage_(NAME) THStorage_(NAME)     <span class="comment">// torch/csrc/THP.h</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> THStorage_(NAME) TH_CONCAT_4(TH,Real,Storage_,NAME)   <span class="comment">// TH/THStorageFunctions.h</span></span></span><br></pre></td></tr></table></figure><p>The declaration of function <code>THStorage_(NAME)</code> lives in <code>TH/generic/THStorage.h</code>, <code>TH/generic/THStorageCopy.h</code> and the implementation part lies in corresponding cpp files.</p><p>(BTW, if using cuda, the declaration of  <code>#define THWStorage_(NAME) THCStorage_(NAME)</code>lie in <code>THC/generic/THCStorage.h</code> and <code>THC/generic/THCStorageCopy.h</code>)</p><p>Take THStorage_(newWithSize) function as an example, look into <code>TH/generic/THStorage.cpp</code> and we can find the definition:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">THStorage* <span class="title">THStorage_</span><span class="params">(newWithSize)</span><span class="params">(<span class="keyword">ptrdiff_t</span> size)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  THStorage* storage = c10::make_instrusive&lt;at::StorageImpl&gt;(</span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> THQUANTIZED</span></span><br><span class="line">    caffe2::TypeMeta::Make&lt;<span class="keyword">quantized_t</span>&gt;(),</span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">    caffe2::TypeMeta::Make&lt;<span class="keyword">scalar_t</span>&gt;(),        <span class="comment">// New a scalar_t type</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">    size,</span><br><span class="line">    getTHDefaultAllocator(),</span><br><span class="line">    <span class="literal">true</span>).release();</span><br><span class="line">  <span class="keyword">return</span> storage;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Itâ€™s not hard to infer from this code block that it new an <code>StorageImpl</code>, and add an intrusive pointer pointing to one of them, at last return a pointer pointing to <code>StorageImpl</code> and destroy the intrusive pointer. Macro THStorage is <code>at::StorageImpl</code>, so this method simply new a <code>StorageImpl and return a pointer pointing to it. According to the definition of</code>c10::make_instrusive`, this work will actually be done by the constructor of StorageImplâ€™ and it is:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">StorageImpl(</span><br><span class="line">    caffe2::TypeMeta data_type,</span><br><span class="line">    int64_4 numel,</span><br><span class="line">    at::Allocator* allocator,</span><br><span class="line">    <span class="keyword">bool</span> resizable)</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>We will only traced here and this show a representative example of how pytorch inner code call and implement those method.</p><h2 id="autograd-2"><a class="markdownIt-Anchor" href="#autograd-2"></a> Autograd</h2><p>Autograd is a method which support automatic computation of gradient which will be used in the back propagation. Autograd depend directly on the computational graph. Computational graph is used for defining the pipeline of a model. It combines functions with variables and shows how they connect to each other.</p><p><img src="/2019/12/11/Pytorch-Core-Code-Research/image-20191128215249350.png" alt="image-20191128215249350"></p><p>A directed graph with the following property:</p><ol><li>Edge: a function, or a functionâ€™s dependency</li><li>Points with input edges: a function (or operator)</li><li>Points with output edges: a variable</li></ol><p>Computational graph has two major types, they are dynamic and static computational graphs. TensorFlow applies static graph, it has the following characteristics:</p><ul><li>First define the structure of the graph, and then assign values to the leaf nodes (this is the origin of placeholder)</li><li>Then forward according to the assignment of leaf nodes</li></ul><p>Pytorch, on the other hand, utilize dynamic graph. The structure of the graph is established at the same time as the forward, so there is no need to use placeholder.</p><p>Here is an example inner code of autograd.</p><p><img src="/2019/12/11/Pytorch-Core-Code-Research/image-20191128215538638.png" alt="image-20191128215538638"></p><p>Here we will elaborate these parameters which get involved in this process.</p><ul><li><p><strong>Data</strong>: Itâ€™s the data a variable is holding.</p></li><li><p><strong>requires_grad</strong>: This member, if true starts tracking all the operation history and forms a backward graph for gradient calculation.</p></li><li><p><strong>grad:</strong> grad holds the value of gradient. If requires_grad is False it will hold a None value. Even if requires_grad is True, it will hold a None value unless .backward() function is called from some other node.</p></li><li><p><strong>grad_fn:</strong> This is the backward function used to calculate the gradient.</p></li><li><p><strong>is_leaf</strong>: A node is leaf if :</p><ol><li><p>It was initialized explicitly by some function like x = torch.tensor(1.0) or x = torch.randn(1, 1) (basically all the tensor initializing methods discussed at the beginning of this post).</p></li><li><p>It is created after operations on tensors which all have requires_grad = False.</p></li><li><p>It is created by calling .detach() method on some tensor.</p></li></ol></li></ul><p><img src="/2019/12/11/Pytorch-Core-Code-Research/image-20191128215740348.png" alt="image-20191128215740348"></p><h2 id="pytorch-source-code-composition"><a class="markdownIt-Anchor" href="#pytorch-source-code-composition"></a> Pytorch Source Code Composition</h2><p>Since different data type, different devices are supported, and python code call C/C++ based code, the source code structure is not easy to understand. Here is the most important parts in the root directory.</p><p><img src="/2019/12/11/Pytorch-Core-Code-Research/image-20191128193909092.png" alt="image-20191128193909092"></p><p>And provide a more detailed directory comment as well as explanation below.</p><p><img src="/2019/12/11/Pytorch-Core-Code-Research/image-20191128194349295.png" alt="image-20191128194349295"></p><h3 id="explanation-of-crucial-folders"><a class="markdownIt-Anchor" href="#explanation-of-crucial-folders"></a> Explanation of crucial folders</h3><h4 id="c10"><a class="markdownIt-Anchor" href="#c10"></a> C10</h4><p><strong>C</strong>affe <strong>Ten</strong>sor Library: Most basic tensor library. Codes here can be deployed to mobile devices as well as servers. It contains the core abstractions of PyTorch, including the actual implementations of the Tensor and Storage data structures.</p><h4 id="aten"><a class="markdownIt-Anchor" href="#aten"></a> ATen</h4><p><strong>A</strong> <strong>TEN</strong>sor library for C<ins>11, the C</ins> tensor library for Pytorch. It is a C++ library that implements the <strong>operations</strong> of Tensors. If youâ€™re looking for where some kernel code lives, chances are itâ€™s in ATen. ATen itself bifurcates into two neighborhoods of operators: the â€œnativeâ€ operators, which are modern, C++ implementations of operators, and the â€œlegacyâ€ operators (TH, THC, THNN, THCUNN), which are legacy, C implementations. The legacy operators are the bad part of town; try not to spend too much time there if you can.</p><h4 id="caffe2"><a class="markdownIt-Anchor" href="#caffe2"></a> Caffe2</h4><p>This part is from the original Caffe2. After the merge of Pytorch and Caffe2, Caffe2 become a kind of backend in Pytorch.</p><h4 id="torch"><a class="markdownIt-Anchor" href="#torch"></a> Torch</h4><p>This is the part normally called by user when then use Pytorch to train or test their models. It contains what you are most familiar with: the actual Python modules that you import and use.</p><h4 id="torchcsrc"><a class="markdownIt-Anchor" href="#torchcsrc"></a> Torch/csrc</h4><p>The C++ code that implements what you might call the frontend of PyTorch. In more descriptive terms, it implements the binding code that translates between the Python and C++ universe, and also some pretty important pieces of PyTorch, like the autograd engine and the JIT compiler. It also contains the C++ frontend code.</p><h3 id="mechanism-inside-a-simple-call"><a class="markdownIt-Anchor" href="#mechanism-inside-a-simple-call"></a> Mechanism inside a simple call</h3><p><img src="/2019/12/11/Pytorch-Core-Code-Research/image-20191128223910466.png" alt="image-20191128223910466"></p><h2 id="basic-condition-of-memory-management-in-pytorch"><a class="markdownIt-Anchor" href="#basic-condition-of-memory-management-in-pytorch"></a> Basic Condition of Memory Management in Pytorch</h2><ol><li>Every tensor will be assigned with a allocator when it is initialized.</li><li><code>c10/core/Allocator.h</code>: Pytorch default allocator class defined here.</li></ol><p>Some Policy in <code>c10/core/Allocator.h</code>:</p><ul><li><p>A DataPtr is a unique pointer (with an attached deleter and some context for the deleter) to some memory, which also records what device is for its data. nullptr DataPtrs can still have a nontrivial device; this allows us to treat zero-size allocations uniformly with non-zero allocations.</p></li><li><p>Choice of CPU here is arbitrary; if thereâ€™s an â€œundefinedâ€ device, we could use that too.</p></li><li><p>The deleter can be changed while running using function <code>compare_exchange_deleter</code>.</p></li><li><p>This context is used to generate DataPtr which have arbitrary <code>std::function</code> deleters associated with them.  In some user facing functions, we give a (user-friendly) interface for constructing tensors from external data which take an arbitrary <code>std::function</code> deleter.  Grep for InefficientStdFunctionContext to find these occurrences.</p><p>This context is inefficient because we have to do a dynamic allocation <code>InefficientStdFunctionContext</code>, on top of the dynamic allocation which is implied by <code>std::function</code> itself.</p></li></ul><ol start="3"><li>There is a fake allocator in Aten(<code>aten/src/ATen/CPUFixedAllocator.h</code>), which just throws exceptions if some cpu fixed operation is actually used, like <code>cpu_fixed_malloc</code>, <code>cpu_fixed_realloc</code>, <code>cpu_fixed_free</code>.</li><li><code>c10/core/CPUAllocator.cpp</code> contains functions: <code>alloc_cpu</code>, <code>free_cpu</code>, <code>memset_junk</code>,  <code>alloc_cpu</code> even has the code dealing with NUMA machine. And there is a class <code>MemoryAllocationReporter</code> which is used to report C10â€™s memory allocation and deallocation status.</li><li><code>c10/core/Allocator.cpp</code>: Set and get allocator for different device type.</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">DeviceType::CPU</span><br><span class="line">DeviceType::CUDA</span><br><span class="line">DeviceType::OPENGL</span><br><span class="line">DeviceType::OPENCL</span><br><span class="line">DeviceType::MKLDNN</span><br><span class="line">DeviceType::IDEEP</span><br><span class="line">DeviceType::HIP</span><br><span class="line">DeviceType::FPGA</span><br><span class="line">DeviceType::MSNPU</span><br><span class="line">DeviceType::XLA</span><br></pre></td></tr></table></figure><ol start="6"><li><p><code>c10/core/StorageImpl.h</code> &amp; <code>c10/core/Storage.h</code>: Mainly allocates memory buffer using given allocator and creates a storage with it. Mark.</p></li><li><p><code>c10/cuda/CUDACachingAllocator.cpp</code> is a caching allocator for CUDA. It has the following description:</p></li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">Yet another caching allocator for CUDA device allocations.</span><br><span class="line"></span><br><span class="line">- Allocations are associated with a stream. Once freed, blocks can be</span><br><span class="line">  re-allocated on the same stream, but not on any other stream.</span><br><span class="line">- The allocator attempts to find the smallest cached block that will fit the</span><br><span class="line">  requested size. If the block is larger than the requested size, it may be</span><br><span class="line">  split. If no block is found, the allocator will delegate to cudaMalloc.</span><br><span class="line">- If the cudaMalloc fails, the allocator will free all cached blocks that</span><br><span class="line">  are not split and retry the allocation.</span><br><span class="line">- Large (&gt;1MB) and small allocations are stored in separate pools.</span><br><span class="line">  Small requests are packed into 2MB buffers. Large requests will use the</span><br><span class="line">  smallest available free block or allocate a new block using cudaMalloc.</span><br><span class="line">  To reduce fragmentation, requests between 1MB and 10MB will allocate and</span><br><span class="line">  split a 20MB block, if no free block of sufficient size is available.</span><br><span class="line"></span><br><span class="line">With this allocator, allocations and frees should logically be considered</span><br><span class="line">&quot;usages&quot; of the memory segment associated with streams, just like kernel</span><br><span class="line">launches. The programmer must insert the proper synchronization if memory</span><br><span class="line">segments are used from multiple streams.</span><br><span class="line"></span><br><span class="line">The library provides a recordStream() function to help insert the correct</span><br><span class="line">synchronization when allocations are used on multiple streams. This will</span><br><span class="line">ensure that the block is not reused before each recorded stream completes</span><br><span class="line">work.</span><br></pre></td></tr></table></figure><h2 id="how-python-interact-with-cc"><a class="markdownIt-Anchor" href="#how-python-interact-with-cc"></a> How Python interact with C/C++</h2><h3 id="compile-c-program-to-so-library-and-call-it-in-python"><a class="markdownIt-Anchor" href="#compile-c-program-to-so-library-and-call-it-in-python"></a> Compile C program to .so library and call it in python</h3><h4 id="compile-as-shared-library"><a class="markdownIt-Anchor" href="#compile-as-shared-library"></a> Compile as shared library</h4><ol><li>Finish writing your C code.</li><li>Compile it into a <code>*.so</code> file.</li><li>Import <code>ctypes</code> in python file.</li><li>Load <code>*.so</code> file inside a python file.</li><li>*Define the input type of a C function.</li><li>Call function inside the <code>*.so</code> file.</li></ol><p><strong>function.c</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">myFunction</span><span class="params">(<span class="keyword">int</span> num)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (num == <span class="number">0</span>)&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span>&#123;</span><br><span class="line">      <span class="keyword">if</span> ((num &amp; (num - <span class="number">1</span>)) == <span class="number">0</span>)</span><br><span class="line">          <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">      <span class="keyword">else</span></span><br><span class="line">          <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>Compile</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc -fPIC -shared -o libfun.so function.c</span><br></pre></td></tr></table></figure><p><strong><a href="http://function.py">function.py</a></strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> ctypes </span><br><span class="line">NUM = <span class="number">16</span>      </span><br><span class="line">fun = ctypes.CDLL(libfun.so)   </span><br><span class="line">fun.myFunction.argtypes=[ctypes.c_int] </span><br><span class="line">returnVale = fun.myFunction(NUM)     </span><br></pre></td></tr></table></figure><h4 id="add-wrapper-in-c-file"><a class="markdownIt-Anchor" href="#add-wrapper-in-c-file"></a> Add wrapper in C++ file</h4><p>If this is a C++ file, you need to expose the function you want to use in a <code>extern &quot;C&quot;</code> wrapper.</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Foo</span>&#123;</span></span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">()</span></span>&#123;</span><br><span class="line">            <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;Hello&quot;</span> &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">// Since ctypes can only talk to C functions, you need </span></span><br><span class="line"><span class="comment">// to provide those declaring them as extern &quot;C&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> &#123;</span><br><span class="line">    <span class="function">Foo* <span class="title">Foo_new</span><span class="params">()</span></span>&#123; <span class="keyword">return</span> <span class="keyword">new</span> Foo(); &#125;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">Foo_bar</span><span class="params">(Foo* foo)</span></span>&#123; foo-&gt;bar(); &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>And then compile:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">g++ -c -fPIC foo.cpp -o foo.o</span><br><span class="line">g++ -shared -Wl,-install_name,libfoo.so -o libfoo.so  foo.o</span><br></pre></td></tr></table></figure><p>Afterwards, thing in Python code are similar as those in C.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> ctypes <span class="keyword">import</span> cdll</span><br><span class="line">lib = cdll.LoadLibrary(<span class="string">&#x27;./libfoo.so&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Foo</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.obj = lib.Foo_new()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">bar</span>(<span class="params">self</span>):</span></span><br><span class="line">        lib.Foo_bar(self.obj)</span><br><span class="line"><span class="comment"># Once you have that you can call it like</span></span><br><span class="line"></span><br><span class="line">f = Foo()</span><br><span class="line">f.bar() <span class="comment">#and you will see &quot;Hello&quot; on the screen</span></span><br></pre></td></tr></table></figure><h3 id="c-file-include-module-and-expose"><a class="markdownIt-Anchor" href="#c-file-include-module-and-expose"></a> C++ file include module and Expose</h3><p>Include &lt;boost/python.hpp&gt; the function in BOOST_PYTHON_MODULE</p><p>A C++ Function can be exposed to Python by writing a Boost.Python wrapper:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;boost/python.hpp&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">char</span> <span class="keyword">const</span>* <span class="title">greet</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">   <span class="keyword">return</span> <span class="string">&quot;hello, world&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">BOOST_PYTHON_MODULE(hello_ext)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">using</span> <span class="keyword">namespace</span> boost::python;</span><br><span class="line">    def(<span class="string">&quot;greet&quot;</span>, greet);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Thatâ€™s it. Weâ€™re done. We can now build this as a shared library. The resulting DLL is now visible to Python. Hereâ€™s a sample Python session:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> hello_ext</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span> hello_ext.greet()</span><br><span class="line">hello, world</span><br></pre></td></tr></table></figure><h2 id="integrating-a-ccuda-operation-with-pytorch"><a class="markdownIt-Anchor" href="#integrating-a-ccuda-operation-with-pytorch"></a> Integrating a C++/CUDA Operation with PyTorch</h2><p>When we want to build a customized method or module, we can choose whether to build it in python or C++. The former is easier but the C++ version is faster and more efficient, especially when we want to build a frequently used or time consuming module. Here comes the explanation.</p><h4 id="cpu-integration"><a class="markdownIt-Anchor" href="#cpu-integration"></a> CPU Integration</h4><p>Besides integrate C++ file in python and use it in Pytorch, Pytorch itself provides us with two quite straightforward way to finish this job. They are Building with <code>setuptools</code> and JIT Compiling Extensions.</p><p>For the â€œahead of timeâ€ flavor, we build our C++ extension by writing a <code>setup.py</code> script that uses setuptools to compile our C++ code. For the LLTM, it looks as simple as this:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> setuptools <span class="keyword">import</span> setup, Extension</span><br><span class="line"><span class="keyword">from</span> torch.utils <span class="keyword">import</span> cpp_extension</span><br><span class="line"></span><br><span class="line">setup(name=<span class="string">&#x27;lltm_cpp&#x27;</span>,</span><br><span class="line">      ext_modules=[cpp_extension.CppExtension(<span class="string">&#x27;lltm_cpp&#x27;</span>, [<span class="string">&#x27;lltm.cpp&#x27;</span>])],</span><br><span class="line">      cmdclass=&#123;<span class="string">&#x27;build_ext&#x27;</span>: cpp_extension.BuildExtension&#125;)</span><br></pre></td></tr></table></figure><p>The JIT compilation mechanism provides you with a way of compiling and loading your extensions on the fly by calling a simple function in PyTorchâ€™s API called <code>torch.utils.cpp_extension.load()</code>. For the LLTM, this would look as simple as this:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.cpp_extension <span class="keyword">import</span> load</span><br><span class="line"></span><br><span class="line">lltm_cpp = load(name=<span class="string">&quot;lltm_cpp&quot;</span>, sources=[<span class="string">&quot;lltm.cpp&quot;</span>])</span><br></pre></td></tr></table></figure><h4 id="cuda-integration"><a class="markdownIt-Anchor" href="#cuda-integration"></a> CUDA Integration</h4><p>Integration of our CUDA-enabled op with PyTorch is again very straightforward. If you want to write a <code>setup.py</code> script, it could look like this:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> setuptools <span class="keyword">import</span> setup</span><br><span class="line"><span class="keyword">from</span> torch.utils.cpp_extension <span class="keyword">import</span> BuildExtension, CUDAExtension</span><br><span class="line"></span><br><span class="line">setup(</span><br><span class="line">    name=<span class="string">&#x27;lltm&#x27;</span>,</span><br><span class="line">    ext_modules=[</span><br><span class="line">        CUDAExtension(<span class="string">&#x27;lltm_cuda&#x27;</span>, [</span><br><span class="line">            <span class="string">&#x27;lltm_cuda.cpp&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;lltm_cuda_kernel.cu&#x27;</span>,</span><br><span class="line">        ])</span><br><span class="line">    ],</span><br><span class="line">    cmdclass=&#123;</span><br><span class="line">        <span class="string">&#x27;build_ext&#x27;</span>: BuildExtension</span><br><span class="line">    &#125;)</span><br></pre></td></tr></table></figure><p>Instead of <code>CppExtension()</code>, we now use <code>CUDAExtension()</code>. We can just specify the <code>.cu</code> file along with the <code>.cpp</code> files â€“ the library takes care of all the hassle this entails for you. The JIT mechanism is even simpler:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.cpp_extension <span class="keyword">import</span> load</span><br><span class="line"></span><br><span class="line">lltm = load(name=<span class="string">&#x27;lltm&#x27;</span>, sources=[<span class="string">&#x27;lltm_cuda.cpp&#x27;</span>, <span class="string">&#x27;lltm_cuda_kernel.cu&#x27;</span>])</span><br></pre></td></tr></table></figure><h2 id="conclusion"><a class="markdownIt-Anchor" href="#conclusion"></a> Conclusion</h2><ul><li>Pytorchâ€™s python part doesnâ€™t have special care on memory management, means it just works in the way standard python programs work.</li><li>Current Pytorch source codes contains codes from multiple source, some of them are pure legacy, some come from caffe2, some serves as basic code, some are packed into dlls to serve python. Also, codes are different for those in CPU and CUDA, we need to focus on the right part if any optimization want to be made.</li><li>Almost all Pytorch core modules and functions are implemented in C++ based code and that will be much more efficient.</li><li>Every tensor is attached with a memory allocator, which can not only do the work of allocate and free, but also record the device on which it is located. Different kinds of allocator for different data type can be delivered as input parameter, this makes the code more compatible.</li><li>Pytorch combines multiple code dispatch method and they work well for C and C++ code.</li><li>Python can call compiled C file using ctypes, but Pytorch provides a toolset which makes it even easier.</li></ul><h2 id="reference"><a class="markdownIt-Anchor" href="#reference"></a> Reference</h2><ul><li><a href="http://blog.ezyang.com/2019/05/pytorch-internals/">PyTorch internals</a></li><li><a href="https://towardsdatascience.com/pytorch-autograd-understanding-the-heart-of-pytorchs-magic-2686cd94ec95">PyTorch Autograd</a></li><li><a href="https://pytorch.org/docs/stable/index.html">PYTORCH DOCUMENTATION</a></li><li><a href="https://zhuanlan.zhihu.com/p/34629243">PyTorchæºç æµ…æ</a></li><li><a href="https://github.com/pytorch/pytorch">Pytorch GitHub Repo</a></li></ul><h2 id="slides"><a class="markdownIt-Anchor" href="#slides"></a> Slides</h2><p>![Final Report_1.jpg](Final Report_1.jpg)</p><p>![Final Report_1.jpg](Final Report_2.jpg)</p><p>![Final Report_1.jpg](Final Report_3.jpg)</p><p>![Final Report_1.jpg](Final Report_4.jpg)</p><p>![Final Report_1.jpg](Final Report_5.jpg)</p><p>![Final Report_1.jpg](Final Report_6.jpg)</p><p>![Final Report_1.jpg](Final Report_7.jpg)</p><p>![Final Report_1.jpg](Final Report_8.jpg)</p><p>![Final Report_1.jpg](Final Report_9.jpg)</p><p>![Final Report_1.jpg](Final Report_10.jpg)</p><p>![Final Report_1.jpg](Final Report_11.jpg)</p><p>![Final Report_1.jpg](Final Report_12.jpg)</p><p>![Final Report_1.jpg](Final Report_13.jpg)</p><p>![Final Report_1.jpg](Final Report_14.jpg)</p><p>![Final Report_1.jpg](Final Report_15.jpg)</p><p>![Final Report_1.jpg](Final Report_16.jpg)</p><p>![Final Report_1.jpg](Final Report_17.jpg)</p><p>![Final Report_1.jpg](Final Report_18.jpg)</p><p>![Final Report_1.jpg](Final Report_19.jpg)</p><p>![Final Report_1.jpg](Final Report_20.jpg)</p><p>![Final Report_1.jpg](Final Report_21.jpg)</p><p>![Final Report_1.jpg](Final Report_22.jpg)</p><p>![Final Report_1.jpg](Final Report_23.jpg)</p><p><strong>Zhongyang Zhang</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;pytorch-release-version-composition&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#pytorch-release-version-composition&quot;&gt;&lt;/a&gt; Pytorch Release V</summary>
      
    
    
    
    
    <category term="machine learning" scheme="https://www.miracleyoo.com/tags/machine-learning/"/>
    
    <category term="deep learning" scheme="https://www.miracleyoo.com/tags/deep-learning/"/>
    
    <category term="Pytorch" scheme="https://www.miracleyoo.com/tags/Pytorch/"/>
    
    <category term="C++" scheme="https://www.miracleyoo.com/tags/C/"/>
    
    <category term="C" scheme="https://www.miracleyoo.com/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>Video Classification Investigation Report</title>
    <link href="https://www.miracleyoo.com/2019/11/07/video-classification/"/>
    <id>https://www.miracleyoo.com/2019/11/07/video-classification/</id>
    <published>2019-11-07T18:00:06.000Z</published>
    <updated>2019-11-07T18:00:06.350Z</updated>
    
    <content type="html"><![CDATA[<h1 id="overview"><a class="markdownIt-Anchor" href="#overview"></a> Overview</h1><p>Video classification, or in our case, more specifically, action recognition, are studied for a long time. There are many traditional as well as deep learning based method developed to address this problem, and the latest action recognition result trained on a large dataset Kinetics can even reach 98% accuracy. Considering the fact that the action we need to classify is not too much, giving enough data and using the pre-trained model on Kinetics, the result can be quite promising.</p><h1 id="tough-points-in-video-classification"><a class="markdownIt-Anchor" href="#tough-points-in-video-classification"></a> Tough Points in Video Classification</h1><ol><li>The huge computational cost</li><li>How to capture long context and make decision comprehensively</li><li>How to design the classification structure which contain spatiotemporal information</li><li>How to deal with a smaller dataset</li></ol><h1 id="approaches-overview"><a class="markdownIt-Anchor" href="#approaches-overview"></a> Approaches overview</h1><h2 id="the-core-idea"><a class="markdownIt-Anchor" href="#the-core-idea"></a> The core idea</h2><ol><li>Try to build a workflow which can combine both spatial information and temporal information.</li><li>Try to focus on both frame itself and the motion near each frame.</li><li>Try to make decision based on the whole video rather than only parts of it.</li><li>Try to decrease the computational cost and remove the long pre-process.</li></ol><h2 id="two-basic-methods"><a class="markdownIt-Anchor" href="#two-basic-methods"></a> Two basic methods</h2><h3 id="single-stream-network"><a class="markdownIt-Anchor" href="#single-stream-network"></a> <a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42455.pdf">Single Stream Network</a></h3><p><img src="/2019/11/07/video-classification/image-20191028125241454.png" alt="image-20191028125241454"></p><p>There are four ways of fusion, which means combine the information from each frame together to derive the final answer. They are:</p><ol><li>Single frame uses single architecture that fuses information from all frames at the last stage.</li><li>Late fusion uses two nets with shared parameters, spaced 15 frames apart, and also combines predictions at the end.</li><li>Early fusion combines in the first layer by convolving over 10 frames.</li><li>Slow fusion involves fusing at multiple stages, a balance between early and late fusion.</li></ol><h3 id="two-stream-networks"><a class="markdownIt-Anchor" href="#two-stream-networks"></a> <a href="https://arxiv.org/pdf/1406.2199.pdf">Two Stream Networks</a></h3><p><img src="/2019/11/07/video-classification/image-20191028125608889.png" alt="image-20191028125608889"></p><p>Video can naturally be decomposed into spatial and temporal components.</p><ol><li>The spatial part, in the form of individual frame appearance, carries information about scenes and objects depicted in the video.</li><li>The temporal part, in the form of motion across the frames, conveys the movement of the observer (the camera) and the objects. In fact, the essence of â€œmotionâ€ is <a href="https://en.wikipedia.org/wiki/Optical_flow">optical flow</a>.</li></ol><h1 id="improvement-of-methods"><a class="markdownIt-Anchor" href="#improvement-of-methods"></a> Improvement of methods</h1><p>Firstly Iâ€™d like to show a graph which shows an overview of all previous action classification architectures drawn in the paper <a href="https://arxiv.org/abs/1705.07750">Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset</a>.</p><p><img src="/2019/11/07/video-classification/image-20191028130233266.png" alt="image-20191028130233266"></p><p>To summarize, there are these kinds of improved methods:</p><ol><li><p><a href="https://arxiv.org/abs/1411.4389">LRCN</a>: Long-term Recurrent Convolutional Networks for Visual Recognition and Description</p><p><img src="/2019/11/07/video-classification/GenericLRCN_high.png" alt="2 stream architecture"></p><p>Send each frame to a CNN at first and then uses the features extracted as the input of LSTM.</p></li><li><p><a href="https://arxiv.org/pdf/1412.0767">C3D</a>: Learning Spatiotemporal Features with 3D Convolutional Networks</p><p><img src="/2019/11/07/video-classification/c3d_high-1572285955778.png" alt="SegNet Architecture"></p><p>The first time using 3D Conv to process frames.</p></li><li><p><a href="https://arxiv.org/abs/1502.08029">Conv3D &amp; Attention</a>: Describing Videos by Exploiting Temporal Structure</p><p><img src="/2019/11/07/video-classification/Larochelle_paper_high.png" alt="Attention Mechanism"></p><p>Add a attention mask before send the CNN-extracted feature into LSTM.</p></li><li><p><a href="https://arxiv.org/abs/1604.06573">TwoStreamFusion</a>: Convolutional Two-Stream Network Fusion for Video Action Recognition</p><p><img src="/2019/11/07/video-classification/fusion_strategies_high.png" alt="SegNet Architecture"></p><p>Fuse two stream in a smarter way and get a better result.</p></li><li><p><a href="https://arxiv.org/abs/1608.00859">TSN</a> :Temporal Segment Networks: Towards Good Practices for Deep Action Recognition</p><p><img src="/2019/11/07/video-classification/tsn_high.png" alt="SegNet Architecture"></p><p>Select video snippets not completely randomly, but divide the video into k equal-length parts and choose a snippets randomly from each division.</p></li><li><p><a href="https://arxiv.org/pdf/1704.02895.pdf">ActionVlad</a>:ActionVLAD: Learning spatio-temporal aggregation for action classification</p><p><img src="/2019/11/07/video-classification/actionvlad-1572285243641.png" alt="SegNet Architecture"></p><p>In this work, the most notable contribution by the authors is the usage of learnable feature aggregation (VLAD) as compared to normal aggregation using maxpool or avgpool.</p></li><li><p><a href="https://arxiv.org/abs/1704.00389">HiddenTwoStream</a>:Hidden Two-Stream Convolutional Networks for Action Recognition</p><p><img src="/2019/11/07/video-classification/image-20191028134438690.png" alt="image-20191028134438690"></p><p>It uses a â€œMotionNetâ€ to take the place of optical flow.</p></li><li><p><a href="https://arxiv.org/abs/1705.07750">I3D</a>: Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset</p><p>Mainly used pretrained network by ImageNet and Kinetics dataset. Also, it use different 3D network for images and optical flows.</p></li><li><p><a href="https://arxiv.org/abs/1711.08200">T3D</a>: Temporal 3D ConvNets: New Architecture and Transfer Learning for Video Classification</p><p><img src="/2019/11/07/video-classification/ttl_layer_high.png" alt="SegNet Architecture"></p><p>Transfer a 2-D DenseNet to a 3D one.</p></li></ol><h1 id="result-comparation"><a class="markdownIt-Anchor" href="#result-comparation"></a> Result comparation</h1><p><img src="/2019/11/07/video-classification/image-20191028133828231.png" alt="image-20191028133828231"></p><p><img src="/2019/11/07/video-classification/image-20191028133226300.png" alt="image-20191028133226300"></p><h1 id="current-thought"><a class="markdownIt-Anchor" href="#current-thought"></a> Current Thought</h1><p>As we can see from the analysis above, the I3D is the most computational efficient and accurate method. Also, the pre-trained model of I3D is provided by the author, so we can also take advantage of it. Now I think we should collect enough data of the corresponding action. Moreover, I noticed that there are many new method on Temporal Action Proposals, Temporal Action Localization and Dense-Captioning Events in Videos appearing this year in the competition ActivityNet, I may research into it to get better result later.</p><h1 id="datasets"><a class="markdownIt-Anchor" href="#datasets"></a> Datasets</h1><ul><li><a href="https://www.crcv.ucf.edu/data/UCF101.php">UCF101</a></li><li><a href="https://cs.stanford.edu/people/karpathy/deepvideo/">Sports-1M</a></li><li><a href="https://deepmind.com/research/open-source/kinetics">Kinetics</a></li><li><a href="http://activity-net.org/download.html">ActivityNet Version 1.3 dataset</a></li></ul><h1 id="codes"><a class="markdownIt-Anchor" href="#codes"></a> Codes</h1><ul><li><a href="https://github.com/hassony2/kinetics_i3d_pytorch">I3D models transfered from Tensorflow to PyTorch</a></li><li><a href="https://github.com/deepmind/kinetics-i3d">I3D models trained on Kinetics</a></li><li><a href="https://github.com/kenshohara/video-classification-3d-cnn-pytorch">Video Classification Using 3D ResNet</a></li></ul><h1 id="reference"><a class="markdownIt-Anchor" href="#reference"></a> Reference</h1><ul><li><a href="http://blog.qure.ai/notes/deep-learning-for-videos-action-recognition-review">Deep Learning for Videos: A 2018 Guide to Action Recognition</a></li><li><a href="https://arxiv.org/abs/1705.07750">Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset</a></li><li><a href="https://github.com/jinwchoi/awesome-action-recognition">Awesome Action Recognition</a></li><li><a href="http://activity-net.org/index.html">ActivityNet</a></li><li><a href="https://www.sciencedirect.com/science/article/abs/pii/0004370281900242">Determining optical flow</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;overview&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#overview&quot;&gt;&lt;/a&gt; Overview&lt;/h1&gt;
&lt;p&gt;Video classification, or in our case, more specificall</summary>
      
    
    
    
    
    <category term="machine-learning" scheme="https://www.miracleyoo.com/tags/machine-learning/"/>
    
    <category term="deep-learning" scheme="https://www.miracleyoo.com/tags/deep-learning/"/>
    
    <category term="cv" scheme="https://www.miracleyoo.com/tags/cv/"/>
    
    <category term="video-classification" scheme="https://www.miracleyoo.com/tags/video-classification/"/>
    
  </entry>
  
  <entry>
    <title>Paper Reading ï¼š &quot;NOSEï¼š A Novel Odor Sensing Engine for Ambient Monitoring of the Frying Cooking Method in Kitchen Environments&quot;</title>
    <link href="https://www.miracleyoo.com/2019/10/24/paper-rev-nose/"/>
    <id>https://www.miracleyoo.com/2019/10/24/paper-rev-nose/</id>
    <published>2019-10-24T23:40:02.000Z</published>
    <updated>2019-10-25T15:10:18.900Z</updated>
    
    <content type="html"><![CDATA[<h1 id="one-line-summary"><a class="markdownIt-Anchor" href="#one-line-summary"></a> One Line Summary</h1><p>NOSE: A device which utilize order sensing component and machine learning to detect which kind of cooking method and which kind of foods, oils are used when you are cooking. It can be used to periodically reports to users about their cooking habits.</p><h1 id="terms"><a class="markdownIt-Anchor" href="#terms"></a> Terms</h1><ol><li>MOS Gas Sensor: A sensor which is sensitive to specific target analytes and attempts to replicate the human olfactory system by detecting various types of odors.</li></ol><h1 id="points"><a class="markdownIt-Anchor" href="#points"></a> Points</h1><ol><li>In the real-world environment, we cannot get the data with a start and end well defined. Here the author exploited a two-level classification approach.</li></ol><p><img src="/2019/10/24/paper-rev-nose/image-20191024193802569.png" alt="image-20191024193802569"></p><h1 id="images"><a class="markdownIt-Anchor" href="#images"></a> Images</h1><p><img src="/2019/10/24/paper-rev-nose/image-20191021152129125.png" alt="image-20191021152129125"></p><p><img src="/2019/10/24/paper-rev-nose/image-20191021154348447.png" alt="image-20191021154348447"></p><h1 id="questions"><a class="markdownIt-Anchor" href="#questions"></a> Questions</h1><ol><li>We can use multiple dimensional information to detect what is going on. For example, if we add sound detect devices or infrared sensor and use their signals to do analysis at the same time, the accuracy may get dramatically improved. If camera can also be applied, even more detailed information can be obtained.</li><li>Regarding the privacy issue, perhaps we can consider using a embedded auto-clip algorithm which make it possible to only output a limited region which only contains the main region of the Target-of-Interest.</li></ol><p><img src="/2019/10/24/paper-rev-nose/image-20191024193841882.png" alt="image-20191024193841882"></p><ol start="3"><li>We can even combine different sensor and use one as the trigger of another. For example, camera will only work when the odor sensor feels that there is someone cooking or when infrared sensor feels that someone is approaching or the microphone hears the noise of cooking.</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;one-line-summary&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#one-line-summary&quot;&gt;&lt;/a&gt; One Line Summary&lt;/h1&gt;
&lt;p&gt;NOSE: A device which utilize o</summary>
      
    
    
    
    
    <category term="machine-learning" scheme="https://www.miracleyoo.com/tags/machine-learning/"/>
    
    <category term="paper" scheme="https://www.miracleyoo.com/tags/paper/"/>
    
    <category term="HCI" scheme="https://www.miracleyoo.com/tags/HCI/"/>
    
    <category term="mobile-health" scheme="https://www.miracleyoo.com/tags/mobile-health/"/>
    
  </entry>
  
  <entry>
    <title>Plan of Project Tomasulo Visual</title>
    <link href="https://www.miracleyoo.com/2019/10/22/tomasulo/"/>
    <id>https://www.miracleyoo.com/2019/10/22/tomasulo/</id>
    <published>2019-10-22T22:36:58.000Z</published>
    <updated>2019-10-22T22:40:12.460Z</updated>
    
    <content type="html"><![CDATA[<h1 id="aims"><a class="markdownIt-Anchor" href="#aims"></a> Aims</h1><ol><li>Build a project to visualize the workflow of Tomasuloâ€™s algorithm.</li><li>The project should contain at least these parts: Cycle graph, Register info, Pipeline, Data info, Code info and statistics.</li><li>We can add some additional components.</li></ol><h1 id="points"><a class="markdownIt-Anchor" href="#points"></a> Points</h1><ol><li>Language: Java</li><li>GUI Support: Swing</li><li>Collaboration Platform: <a href="https://github.com/miracleyoo/Tomasulo-Visual">GitHub</a></li><li>Divide pattern: By components. Each one 2 components.</li><li>DDL: Next week(Oct 29)</li><li>Algorithm Reference: <a href="https://youtu.be/jyjE6NHtkiA">Youtube</a></li></ol><h1 id="reference-images"><a class="markdownIt-Anchor" href="#reference-images"></a> Reference Images</h1><p>![WinMips64](Plan de Project Tomasulo Visual/image-20191022180533866.png)</p><p>![Slides](Plan de Project Tomasulo Visual/image-20191022180615852.png)</p><p>![Youtube Course](Plan de Project Tomasulo Visual/image-20191022180646659.png)</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;aims&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#aims&quot;&gt;&lt;/a&gt; Aims&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;Build a project to visualize the workflow of Tomasuloâ€™s algo</summary>
      
    
    
    
    
    <category term="computer-architecture" scheme="https://www.miracleyoo.com/tags/computer-architecture/"/>
    
  </entry>
  
  <entry>
    <title>Paper Readingï¼š &quot;W!NCEï¼š Unobtrusive Sensing of Upper Facial Action Units with EOG-based Eyewear&quot;</title>
    <link href="https://www.miracleyoo.com/2019/10/20/paper-rev-wnce/"/>
    <id>https://www.miracleyoo.com/2019/10/20/paper-rev-wnce/</id>
    <published>2019-10-20T23:07:48.000Z</published>
    <updated>2019-10-20T23:17:04.490Z</updated>
    
    <content type="html"><![CDATA[<h2 id="one-line-summary"><a class="markdownIt-Anchor" href="#one-line-summary"></a> One Line Summary</h2><p>W!NCW developes a two-stage processing pipeline which can do continuously and unobtrusively sensing of upper facial action units with high fidelity. Because it doesnâ€™t use camera so it also eliminate the privacy concerns.</p><h2 id="terms"><a class="markdownIt-Anchor" href="#terms"></a> Terms</h2><ol><li>Electrooculography(EOG, çœ¼çƒç”µå›¾æ£€æŸ¥): A technique for measuring the corneo-retinal standing potential that exists between the front and the back of the human eye. The resulting signal is called the electrooculogram. Primary applications are in ophthalmological diagnosis and in recording eye movements.</li><li>Motion artifacts removal pipeline: Mainly used to remove noise across multiple EOF channels and many different head movement patterns. It is based on neural network.</li><li></li></ol><h2 id="points"><a class="markdownIt-Anchor" href="#points"></a> Points</h2><ol><li>There are already standard Facial Action Coding System(FACS) along with camera based methods which can be applied to check facial expressions, but their positioning is awkward and they may bring in privacy problems.</li><li>The hardware is not a lab-product, rather, it is based on commercially available comfortable daily eyeware device J!NS MEME.</li><li>EOG metrics is useful for recognizing different types of activities such as reading and writing. since each activity has its own unique eye movement pattern.</li><li>The EOG sensors are placed on the nose and the IMU sensor is embedded in the temples of the eyeglass.</li><li>W!NCE takes the body motion into consideration, while existing work work in motion artifact removal from physiological signals couldnâ€™t do so.</li><li>The lower face action is harder to be detected because the signal are generated  in distant muscles, so it will be damped when reaches the sensor.</li><li>J!NS MEME employs stainless steel eletrodes which belong to the stiff material dry eletrodes. It has a lower price and a good electrical performance and lower possiblility of skin irritation compared to gel-based ones.</li><li>Some actions of heads will cast a similar influence on EOG sensors(like nod and lower eyebrows), while the IMU signals will be quite different, which can help confirm the real action.</li><li>We have to consider the signal variation across individuals, since the face shape, the shape of nose-bridge, the fit of the glasses behind the ear, the variation in the way individuals use upper facial muscles influence the signals captured greatly.</li><li>Personalizing with transfer learning is utilized to address the problem above. The device will take some labled data from user when they use it for the first time, and only re-train the last layer(full-connection layer).</li><li>The CNN model will not always be in the working state. In fact, the model process will only be triggered when substantial EOG activities are detected after the motion artifact removal stage. Also, the motion artifact removal model will only run when significant variation is observed in the raw EOG signal.</li></ol><h2 id="question"><a class="markdownIt-Anchor" href="#question"></a> Question</h2><ol><li>What if user sweet on there nose? Will it affect the accuracy of EOG sensor?</li><li>This eye-glass based design will be easy to accommodate for those who always wearing a glass, but to the others who donâ€™t have the habit, it might be difficult.</li><li>For the CNN and motion artifact removal trigger, for the emotions or movement which only generate minor signal, like the lower face action, will it be detected?</li><li>How to know whether the prediction is right or not? User may express multiple emotion and movement at the same time. Same question when dataset is collected.</li><li>Why people will need, or need to buy this product? Will a normal person have the requisition to know their facial action and emotion all day? If so, what can the data collected derive?</li></ol><h2 id="images"><a class="markdownIt-Anchor" href="#images"></a> Images</h2><p><img src="/2019/10/20/paper-rev-wnce/image-20191020171322278.png" alt="image-20191020171322278"></p><p><img src="/2019/10/20/paper-rev-wnce/image-20191020172902493.png" alt="image-20191020172902493"></p><p><img src="/2019/10/20/paper-rev-wnce/image-20191020190355816.png" alt="image-20191020190355816"></p><p><img src="/2019/10/20/paper-rev-wnce/image-20191020173940080.png" alt="image-20191020173940080"></p><p><img src="/2019/10/20/paper-rev-wnce/image-20191020183735447.png" alt="image-20191020183735447"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;one-line-summary&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#one-line-summary&quot;&gt;&lt;/a&gt; One Line Summary&lt;/h2&gt;
&lt;p&gt;W!NCW developes a two-stage pr</summary>
      
    
    
    
    
    <category term="machine-learning" scheme="https://www.miracleyoo.com/tags/machine-learning/"/>
    
    <category term="deep-learning" scheme="https://www.miracleyoo.com/tags/deep-learning/"/>
    
    <category term="paper" scheme="https://www.miracleyoo.com/tags/paper/"/>
    
    <category term="HCI" scheme="https://www.miracleyoo.com/tags/HCI/"/>
    
    <category term="mobile-health" scheme="https://www.miracleyoo.com/tags/mobile-health/"/>
    
  </entry>
  
  <entry>
    <title>Paper Readingï¼š &quot;wPerfï¼š Generic Off-CPU Analysis to Identify Bottleneck Waiting Events&quot;</title>
    <link href="https://www.miracleyoo.com/2019/10/19/paper-rev-wperf/"/>
    <id>https://www.miracleyoo.com/2019/10/19/paper-rev-wperf/</id>
    <published>2019-10-20T01:40:57.000Z</published>
    <updated>2019-10-20T23:15:20.160Z</updated>
    
    <content type="html"><![CDATA[<h2 id="one-line-summary"><a class="markdownIt-Anchor" href="#one-line-summary"></a> One Line Summary</h2><p>Some waiting events can cast impact to multiple threads. A method which can computes not only the local impact of a waiting event, but also whether such impact can indirectly reach other threads is developed.</p><h2 id="important-terms"><a class="markdownIt-Anchor" href="#important-terms"></a> Important terms</h2><ol><li>On-CPU analysis: Used to identify bottlenecks created by execution.</li><li>Off-CPU analysis: Used to identify bottlenecks created by waiting.</li><li>False wakeup: A phenomenon that a thread is woken up but finds its condi- tion to continue is not satisfied, so it has to sleep again.</li><li>Knot(in the wait-for graph): A section which never wait for the outside threads. Because optimizing outside events will not influence the status inside(and will not improve overall thoughput), so each knot must contain a bottlenect. In a graph, a knot is a nonempty set K of vertices such that the reachable set of each vertex in K is exactly set K; a sink is a vertex with no edges directed from it.</li><li>Cascaded redistribution: If thread A waits for thread B from t1 to t2, wPerf checks what B is doing during t1 to t2 and if B is waiting for an- other thread, wPerf will re-distribute the corresponding weight and perform the check recursively.</li></ol><h2 id="points"><a class="markdownIt-Anchor" href="#points"></a> Points</h2><ol><li>wPerf act on events(Get the impact of events on all threads).</li><li>On-CPU analysis already has some tools good enough, while Off-CPU analysis is still inaccurate.</li><li>Wait-for graph: Each thread is a vertex and a directed edge from A to B means the time thread A waits for B.</li><li>Events with a small local impact usually have a small global im- pact, but events with a large local impact may not have a large global impact.</li><li>Things to be recorded: scheduling events, IRQ(interrupt request) events, information for I/O devices, information for busy waiting, call stacks.</li><li>wPerf can start and stop recording at any time.</li><li>wPerf treat I/O device as a pseudo I/O thread.</li><li>In order to minimize the overhead, recorder buffers events and flushs the buffers to trace file in the background. Also, the recorder creates a buffer and a trace file for each core to avoid contention.</li></ol><p><img src="/2019/10/19/paper-rev-wperf/image-20191019213731331.png" alt="image-20191019213731331"></p><h2 id="graphs"><a class="markdownIt-Anchor" href="#graphs"></a> Graphs</h2><p><img src="/2019/10/19/paper-rev-wperf/image-20191019184627121.png" alt="image-20191019184627121"></p><p><img src="/2019/10/19/paper-rev-wperf/image-20191019193352798.png" alt="image-20191019193352798"></p><h2 id="pros"><a class="markdownIt-Anchor" href="#pros"></a> Pros</h2><ol><li>It innovatively utilizes the â€œwait-forâ€ graph method to investigate the wating relationship between threads, which make it easy to locate the bottleneck.</li><li>wPerf takes all these I/O operation, busy waiting, false wakeup into consideration, which make it more accuarte and competible to various cases.</li><li>Introduced â€œcascaded redistributionâ€ which can help us find the origin bottleneck rather than simply take the waiting thread as the reason of latency.</li></ol><h2 id="cons"><a class="markdownIt-Anchor" href="#cons"></a> Cons</h2><ol><li>It can not be applied to distributed system currently.</li><li>It mainly foucuses on Off-CPU analysis, it may consider the combination of both On-CPU and Off-CPU analysis.</li><li>It brings in overheads in its recording process, especially when there are many waiting events.</li></ol><p><strong>Zhongyang Zhang</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;one-line-summary&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#one-line-summary&quot;&gt;&lt;/a&gt; One Line Summary&lt;/h2&gt;
&lt;p&gt;Some waiting events can cast i</summary>
      
    
    
    
    
    <category term="paper" scheme="https://www.miracleyoo.com/tags/paper/"/>
    
    <category term="system" scheme="https://www.miracleyoo.com/tags/system/"/>
    
    <category term="computer-architecture" scheme="https://www.miracleyoo.com/tags/computer-architecture/"/>
    
  </entry>
  
  <entry>
    <title>ç”¨PythonæŠ¢æ•‘ä½ çš„Hexoåšå®¢å›¾åºŠé“¾æ¥åˆ°æœ¬åœ°</title>
    <link href="https://www.miracleyoo.com/2019/10/02/hexo-image-migrator/"/>
    <id>https://www.miracleyoo.com/2019/10/02/hexo-image-migrator/</id>
    <published>2019-10-03T03:47:49.000Z</published>
    <updated>2019-10-04T02:04:49.240Z</updated>
    
    <content type="html"><![CDATA[<h2 id="é—®é¢˜èƒŒæ™¯"><a class="markdownIt-Anchor" href="#é—®é¢˜èƒŒæ™¯"></a> é—®é¢˜èƒŒæ™¯</h2><p>ç”±äºè¿‘æœŸå„å¤§å…è´¹å›¾åºŠçº·çº·åŠ å…¥äº†é˜²ç›—é“¾æœºåˆ¶ï¼ˆå¦‚æ–°æµªï¼‰å¹¶åœæ­¢å¯¹ä¸ªäººåšå®¢ç”¨çš„å›¾åºŠé“¾æ¥è¿›è¡Œè®¿é—®æˆæƒï¼Œåšå®¢ä¸Šçš„å›¾ç‰‡å‡ºç°äº†å¤§é¢ç§¯çš„æ— æ³•æ˜¾ç¤ºï¼ˆå¦‚æœ¬åšå®¢ï¼‰ï¼Œä¸¥é‡å½±å“äº†åšå®¢çš„æµè§ˆä½“éªŒã€‚ç„¶è€Œç°åœ¨ç›´æ¥ä½¿ç”¨æ–‡ä¸­é“¾æ¥å°šè¿˜å¯ä»¥å°†å›¾ç‰‡ä¸‹è½½åˆ°æœ¬åœ°ï¼Œä½†è¿™ä¹Ÿå¹¶æ— æ³•å¾—åˆ°ä»»ä½•å®˜æ–¹ä¿éšœï¼Œæ‰€ä»¥å½“åŠ¡ä¹‹æ€¥æ˜¯æŠŠæ‰€æœ‰å›¾åºŠç…§ç‰‡ä¸‹è½½åˆ°æœ¬åœ°ï¼Œç”¨hexoåŸç”Ÿçš„å›¾ç‰‡æ’å…¥æ ¼å¼è¿›è¡Œæ’å…¥ã€‚</p><p>è€Œåœ¨å…è´¹å›¾åºŠæ¸æ¸ä¸å†å¯ç”¨çš„ç°åœ¨ï¼Œå½“åŠ¡ä¹‹æ€¥å…¶å®å·²ç»ä¸æ˜¯å†æ¬¡æ›´æ¢å›¾åºŠï¼Œè€Œæ˜¯æŠŠè¿™äº›å›¾ç‰‡æŠ¢æ•‘åˆ°æœ¬åœ°ï¼Œå¹¶ç›´æ¥å°†åŸå›¾éƒ¨ç½²åˆ°æœåŠ¡å™¨ä¸Šï¼›æˆ–æ˜¯è‡ªå·±æ­å»ºå›¾åºŠã€‚ä¸ºäº†èŠ‚çœæ—¶é—´å’Œæˆæœ¬ï¼Œæˆ‘è¿™é‡Œé‡‡ç”¨äº†ç›´æ¥å°†åŸå›¾éƒ¨ç½²åˆ°æœåŠ¡å™¨ä¸Šçš„æ“ä½œã€‚</p><h2 id="è¿™ä¸ªé—®é¢˜å¯ä»¥æ‹†è§£ä¸ºä»¥ä¸‹å‡ ç‚¹"><a class="markdownIt-Anchor" href="#è¿™ä¸ªé—®é¢˜å¯ä»¥æ‹†è§£ä¸ºä»¥ä¸‹å‡ ç‚¹"></a> è¿™ä¸ªé—®é¢˜å¯ä»¥æ‹†è§£ä¸ºä»¥ä¸‹å‡ ç‚¹ï¼š</h2><ol><li>åœ¨_postæ–‡ä»¶å¤¹ä¸­å»ºç«‹ä¸markdownæ–‡ä»¶åŒåæ–‡ä»¶å¤¹ç”¨äºå­˜æ”¾å›¾ç‰‡ã€‚</li><li>éå†æ–‡ä»¶å¤¹ä¸­æ–‡ä»¶å¹¶ç”¨æ­£åˆ™åŒ¹é…çš„æ–¹å¼åŒ¹é…å¾—åˆ°å¾…æ›¿æ¢çš„é“¾æ¥ã€‚</li><li>ä¸‹è½½æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶å¹¶å­˜å‚¨åˆ°ç›¸åº”ä½ç½®ã€‚</li><li>å°†åŸæ–‡ä»¶ä¸­çš„<code>![name](link)</code>æ›¿æ¢ä¸ºå¯åœ¨ç½‘é¡µä¸Šæ˜¾ç¤ºçš„è¯­å¥ã€‚</li></ol><p>äºæ˜¯æˆ‘ä¸ºäº†æ–¹ä¾¿ä½¿ç”¨pythonå†™äº†ä¸€ä¸ªè„šæœ¬ï¼Œä½¿å¾—ä¸Šé¢è¿™å‡ æ­¥å¯ä»¥è‡ªåŠ¨å®Œæˆã€‚ä¸‹é¢è´´ä¸Šä¸»è¦ä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    names=os.listdir(root)</span><br><span class="line">    files=[i <span class="keyword">for</span> i <span class="keyword">in</span> names <span class="keyword">if</span> i.endswith(<span class="string">&#x27;.md&#x27;</span>) <span class="keyword">and</span> <span class="keyword">not</span> os.path.isdir(os.path.join(root, i)) <span class="keyword">and</span> <span class="keyword">not</span> i.startswith(<span class="string">&#x27;.&#x27;</span>)]</span><br><span class="line">    file_paths = [os.path.join(root, i) <span class="keyword">for</span> i <span class="keyword">in</span> files]</span><br><span class="line">    dirs=[i <span class="keyword">for</span> i <span class="keyword">in</span> names <span class="keyword">if</span> os.path.isdir(os.path.join(root, i)) <span class="keyword">and</span> <span class="keyword">not</span> i.startswith(<span class="string">&#x27;.&#x27;</span>)]</span><br><span class="line">    dir_paths = [os.path.join(root, i) <span class="keyword">for</span> i <span class="keyword">in</span> dirs]</span><br><span class="line">    print(files)</span><br><span class="line">    <span class="keyword">for</span> file_iter <span class="keyword">in</span> files:</span><br><span class="line">        name_temp = os.path.splitext(os.path.split(file_iter)[-<span class="number">1</span>])[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> name_temp <span class="keyword">not</span> <span class="keyword">in</span> dirs:</span><br><span class="line">            dir_temp = os.path.join(root, name_temp)</span><br><span class="line">            os.mkdir(dir_temp)</span><br><span class="line">        download(os.path.join(root,file_iter))</span><br><span class="line"></span><br><span class="line"><span class="comment"># å¯¹æ¯ä¸ªæ–‡ä»¶ä¸­çš„é“¾æ¥åˆ†åˆ«è¿›è¡Œä¸‹è½½å’Œæ›¿æ¢é“¾æ¥å¤„ç†</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download</span>(<span class="params">file_path</span>):</span></span><br><span class="line">    print(<span class="string">&quot;==&gt; Now dealing with file:&quot;</span>, file_path)</span><br><span class="line">    dir_name = os.path.splitext(os.path.split(file_path)[-<span class="number">1</span>])[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># filename = &quot;test&quot;</span></span><br><span class="line">    name = file_path.split(<span class="string">u&quot;/&quot;</span>)</span><br><span class="line">    filename = name[-<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">with</span> codecs.<span class="built_in">open</span>(file_path, encoding=<span class="string">&quot;UTF-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        text = f.read()</span><br><span class="line">    <span class="comment"># regex</span></span><br><span class="line">    result = re.findall(<span class="string">&#x27;!\[(.*)\]\((.*)\)&#x27;</span>, text)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, content <span class="keyword">in</span> <span class="built_in">enumerate</span>(result):</span><br><span class="line">        image_quote = content[<span class="number">0</span>]</span><br><span class="line">        image_url = content[<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="comment"># download img</span></span><br><span class="line">            img_data = requests.get(image_url).content</span><br><span class="line">            <span class="comment"># img name spell</span></span><br><span class="line">            image_name = image_url.strip(<span class="string">&quot;/&quot;</span>).split(<span class="string">&quot;/&quot;</span>)[-<span class="number">1</span>]</span><br><span class="line">            image_path = os.path.join(root, dir_name, image_name)</span><br><span class="line">            print(<span class="string">&quot;==&gt;&quot;</span>, image_path, <span class="string">&#x27;~~~&#x27;</span>, image_url)</span><br><span class="line">            <span class="comment"># write to file</span></span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(image_path, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> handler:</span><br><span class="line">                handler.write(img_data)</span><br><span class="line"></span><br><span class="line">            text=text.replace(<span class="string">&quot;![&quot;</span>+image_quote+<span class="string">&quot;](&quot;</span>+image_url+<span class="string">&quot;)&quot;</span>, <span class="string">&quot;![&quot;</span>+image_quote+<span class="string">&quot;](&quot;</span>+image_name+<span class="string">&#x27;)&#x27;</span>)</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">    <span class="keyword">with</span> codecs.<span class="built_in">open</span>(file_path, mode=<span class="string">&quot;w+&quot;</span>, encoding=<span class="string">&quot;UTF-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(text)</span><br></pre></td></tr></table></figure><p>å¦‚æœ‰éœ€æ±‚ï¼Œæ¨èæŸ¥çœ‹æ›´åŠ è¯¦ç»†çš„ä½¿ç”¨è¯´æ˜å’Œæ³¨æ„äº‹é¡¹ã€‚é¡¹ç›®åœ¨<a href="https://link.zhihu.com/?target=https%3A//github.com/miracleyoo/hexo-migrator">Github</a>ä¸Šï¼Œå¹¶é™„æœ‰step-by-stepçš„è¯´æ˜ï¼Œå³ä½¿æ²¡æœ‰ç¼–ç¨‹åŸºç¡€ä¹Ÿå¯ä»¥è½»æ˜“ä¸Šæ‰‹ã€‚</p><p>å¦‚æœæœ‰å¸®åŠ©åˆ°ä½ ï¼Œæ¬¢è¿Staræ”¯æŒä¸€ä¸‹hhh~ ğŸ˜ƒ</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;é—®é¢˜èƒŒæ™¯&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#é—®é¢˜èƒŒæ™¯&quot;&gt;&lt;/a&gt; é—®é¢˜èƒŒæ™¯&lt;/h2&gt;
&lt;p&gt;ç”±äºè¿‘æœŸå„å¤§å…è´¹å›¾åºŠçº·çº·åŠ å…¥äº†é˜²ç›—é“¾æœºåˆ¶ï¼ˆå¦‚æ–°æµªï¼‰å¹¶åœæ­¢å¯¹ä¸ªäººåšå®¢ç”¨çš„å›¾åºŠé“¾æ¥è¿›è¡Œè®¿é—®æˆæƒï¼Œåšå®¢ä¸Šçš„å›¾ç‰‡å‡ºç°äº†å¤§é¢ç§¯çš„æ— æ³•æ˜¾ç¤ºï¼ˆå¦‚æœ¬</summary>
      
    
    
    
    
    <category term="python" scheme="https://www.miracleyoo.com/tags/python/"/>
    
    <category term="tool" scheme="https://www.miracleyoo.com/tags/tool/"/>
    
    <category term="blog" scheme="https://www.miracleyoo.com/tags/blog/"/>
    
  </entry>
  
</feed>
