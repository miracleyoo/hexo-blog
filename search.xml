<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>2018.3.18 刚哥指导</title>
    <url>/2018/03/19/2018318-gangge/</url>
    <content><![CDATA[<h1 id="2018318-刚哥指导"><a class="markdownIt-Anchor" href="#2018318-刚哥指导"></a> 2018.3.18 刚哥指导</h1>
<ul>
<li>
<p>后续的清洗数据工作：</p>
<ol>
<li>先用正则匹配将唯一能匹配到knowledge中的某个pattern的问题自动打上标签</li>
<li>然后判断是否属于某些较大且正确率较高的主问题，如果结果正确，直接打上标签</li>
<li>把余下的归属于某些小问题的log分配给人工打</li>
</ol>
<span id="more"></span>
</li>
<li>
<p>用最短的时间完成DSSM的模型搭建工作，并给出测试结果</p>
</li>
<li>
<p>要尽快给出一个可信的1w条左右的测试集，要求分布均衡，每一类都要4个问题左右，并且由人工挑选保证无误</p>
</li>
<li>
<p>（Triplet Loss）可以考虑使用MQ1Q2这样的一个主问题两个log这样的方式，当Q1属于某个主问题而Q2不属于时，满足下式：||f(M1)-f(Q1)||&lt;||f(M1)-f(Q2)||，用这样的方法来3个3个的训练</p>
</li>
<li>
<p>用正则匹配法会丢失不少词语和语义信息，而深度学习可以弥补这一点</p>
</li>
<li>
<p>分类的方法可以继续推进，但是现在主要着眼于使用搜索+匹配的方式</p>
</li>
<li>
<p>最后可以尝试建立R2X这样的从正则表达式利用GAN的方法自动生成有价值的，像是正常log的问题</p>
</li>
</ul>
]]></content>
      <tags>
        <tag>machine-learning</tag>
        <tag>deep-learning</tag>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>全连接层与1x1卷积的关系</title>
    <url>/2019/02/12/1x1conv/</url>
    <content><![CDATA[<h2 id="理解全连接层"><a class="markdownIt-Anchor" href="#理解全连接层"></a> 理解全连接层：</h2>
<p><strong>全连接层可以由卷积核深度为上层特征图深度的卷积运算代替，卷积后channel上每个1x1卷积核都会作为一个输出，可看作全连接层的一个点。</strong></p>
<p>假设最后一个卷积层的输出为7×7×512，连接此卷积层的全连接层为1×1×4096。</p>
<p>如果将这个全连接层转化为卷积层：</p>
<span id="more"></span>
<ol>
<li>共有4096组滤波器（<strong>通道数4096</strong>）</li>
<li>每个卷积核的大小为<strong>512x7×7</strong></li>
<li>则输出为<strong>1×1×4096</strong></li>
</ol>
<p>由于每个滤波核的大小和上一层的feature map大小一样，保证了转换后的卷积层的运算结果和全连接层是一样的。<br>
若后面再连接一个1×1×4096全连接层。则其对应的转换后的卷积层的参数为：</p>
<ol>
<li>共有4096组滤波器（<strong>通道数4096</strong>）</li>
<li>每个卷积核的大小为<strong>4096x1x1</strong></li>
<li>则输出为<strong>1×1×4096</strong></li>
</ol>
<h2 id="举例说明"><a class="markdownIt-Anchor" href="#举例说明"></a> 举例说明</h2>
<p>参考“ <a href="https://bbs.dian.org.cn/topic/589/rcnn%E7%B3%BB%E5%88%97%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E8%AF%A6%E8%A7%A3">RCNN系列目标检测详解</a>”，在Faster RCNN中，RPN网络的关键部分就是由两个1x1的卷积核完成的，其作用即为全连接。<br>
<img data-src="006y8mN6ly1g7lwj8tmefj311609y0tp.jpg" alt="Network Structure"></p>
]]></content>
      <tags>
        <tag>machine-learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Necessary information in an English Interview</title>
    <url>/2018/03/29/English-interview/</url>
    <content><![CDATA[<h1 id="useful-words"><a class="markdownIt-Anchor" href="#useful-words"></a> Useful Words</h1>
<ul>
<li>
<p>电信学院：School of Electronic Information and Communication</p>
</li>
<li>
<p>光电学院：School of Optical and Electronic Information</p>
</li>
<li>
<p>由…组成：be composed of/ be made up of</p>
</li>
<li>
<p>种子班：Undergraduate Program for Advanced Project-based Information Science Education (Seeds Class)</p>
<span id="more"></span>
</li>
<li>
<p>串联：series connection</p>
</li>
<li>
<p>并联：parallel connection</p>
</li>
<li>
<p><em>Transverse electromagnetic</em> (<em>TEM</em>) <em>modes</em>:neither electric nor magnetic field in the direction of propagation. The direction of it is perpendicular to electric field and magnetic field.</p>
<p>横电磁波：电场和磁场的振动在电磁波传播方向上都没有投影分量。（电场和磁场的振动方向都垂直于电磁波的传播方向）</p>
</li>
<li>
<p>KCL：Kirchhoff’s circuit laws. Kirchhoff’s circuit laws are two equalities that deal with the current and potential difference (commonly known as voltage) in the lumped element model of electrical circuits. They were first described in 1845 by German physicist Gustav Kirchhoff. <strong>At any node (junction) in an electrical circuit, the sum of currents flowing into that node is equal to the sum of currents flowing out of that node.</strong></p>
<p><em>The algebraic sum of currents in a network of conductors meeting at a point is zero.</em></p>
</li>
<li>
<p>KVL：The directed sum of the electrical potential differences (voltage) around any closed network is zero</p>
</li>
<li>
<p>戴维南电路：Thévenin’s theorem：Any linear electrical network with voltage and current sources and resistances only can be replaced at terminals A-B by an equivalent voltage source Vth in series connection with an equivalent resistance Rth.</p>
<p>The equivalent voltage Vth is the voltage obtained at terminals A-B of the network with terminals A-B open circuited.</p>
<p>The equivalent resistance Rth is the resistance that the circuit between terminals A and B would have if all ideal voltage sources in the circuit were replaced by a short circuit and all ideal current sources were replaced by an open circuit.</p>
</li>
<li>
<p>诺顿定理：Any linear electrical network with voltage and current sources and only resistances can be replaced at terminals A–B by an equivalent current source Ino in parallel connection with an equivalent resistance Rno.</p>
<p>This equivalent current Ino is the current obtained at terminals A-B of the network with terminals A-B short circuited.</p>
<p>This equivalent resistance Rno is the resistance obtained at terminals A-B of the network with all its voltage sources short circuited and all its current sources open circuited.</p>
</li>
</ul>
<h1 id="self-introduction"><a class="markdownIt-Anchor" href="#self-introduction"></a> Self Introduction</h1>
<p>I am Zhongyang Zhang, a Junior student from Electronic and Information Engineering of HUST. I’m from the school of electronic information and communication and my major is seed class. It might sound like a little puzzling, but in fact it is the name of Advanced Project-based Information Science Education Class. As for relevant courses, I’ve learned Electromagnetic Field and wave, communication Electronic Circuits last year.</p>
<p>Besides, I have the ability of quick learning. You know, the first program I’ve participated in after I’ve been a member of Seed Class is a project which need us to develop a iOS Software for a commercial company, although I’ve never developed a app since I only have a little knowledge on C language , I exerted myself and learned how to handle it well by studying objective C via internet. Also, I adapt myself to python and machine learning afterwards smoothly despite the fact that I didn’t satisfy much of the pre-requisite.</p>
<p>And also, I am familiar with hardware, too. I’ve learned how to draw a PCB board in my previous courses and I’m trying to make a game box for a certain game named “Dont stop！Quaver” recently.</p>
<p>My hobby is learning foreign language and management. I can speak fluent Japanese and I also learned basic French.</p>
]]></content>
      <tags>
        <tag>English</tag>
        <tag>interview</tag>
      </tags>
  </entry>
  <entry>
    <title>ACG相关AI项目-论文-代码-数据-资源</title>
    <url>/2020/07/06/acg-dl/</url>
    <content><![CDATA[<h2 id="论文"><a class="markdownIt-Anchor" href="#论文"></a> 论文</h2>
<p>[<a href>Paper</a>] [<a href>Code</a>] [20XX]</p>
<h3 id="自动勾线-线稿"><a class="markdownIt-Anchor" href="#自动勾线-线稿"></a> 自动勾线-线稿</h3>
<ol>
<li>
<p>Learning to Simplify: Fully Convolutional Networks for Rough Sketch Cleanup [<a href="http://www.f.waseda.jp/hfs/SimoSerraSIGGRAPH2016.pdf">Paper</a>] [<a href="https://github.com/bobbens/sketch_simplification">Code</a>] [<a href="https://medium.com/coinmonks/simplifying-rough-sketches-using-deep-learning-c404459622b9">Blog</a>] [2015]</p>
<ul>
<li>
<p>早稻田大学15年经典论文。</p>
</li>
<li>
<p>粗糙手稿映射到精描线稿。</p>
</li>
<li>
<p>使用的是自建数据集，给定精致线稿让画师去照着描粗稿，这样避免了从线稿描到精稿时候添加和大改了很多线条。数据集没有开源…不过似乎作者给了训练好的权重。</p>
<span id="more"></span>
</li>
<li>
<p>We found that the standard approach, which we denote as direct dataset construction, of asking artists to draw a rough sketch and then produce a clean version of the sketch ended up with a lot of changes in the figure, i.e., output lines are greatly changed with respect to their input lines, or new lines are added in the output. This results in very noisy training data that does not perform well. In order to avoid this issue, we found that the best approach is the inverse dataset construction approach, that is, given a clean simplified sketch drawing, the artist is asked to make a rough version of that sketch.</p>
</li>
</ul>
<img data-src="image-20200705025359787.png" alt="image-20200705025359787" style="zoom:50%;">
<img data-src="image-20200705025440435.png" alt="image-20200705025440435" style="zoom:50%;">
</li>
</ol>
<h3 id="自动线稿上色"><a class="markdownIt-Anchor" href="#自动线稿上色"></a> 自动线稿上色</h3>
<ol>
<li>
<p>Scribbler: Controlling Deep Image Synthesis with Sketch and Color [<a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Sangkloy_Scribbler_Controlling_Deep_CVPR_2017_paper.pdf">Paper</a>] [<a href>Code</a>] [2017]</p>
</li>
<li>
<p>User-Guided Deep Anime Line Art Colorization with Conditional Adversarial Networks [<a href="https://arxiv.org/pdf/1808.03240.pdf">Paper</a>] [<a href="https://github.com/orashi/AlacGAN">Code</a>] [2018]</p>
<ul>
<li>既支持直接从线稿转换为色稿，也支持用户交互画点生成色稿。</li>
<li>生成器和检测器的输入进行了创新。生成器的输入是线稿、用户色点图、还有一个线稿的特征Map。检测器的输入是两对：（真实色稿，线稿特征）与（生成色稿，线稿特征）。这样做的好处是避免了直接让判别器看到原始线稿，从而一定程度上避免了过拟合。</li>
<li>线稿是通过XDoG转换色稿得来。</li>
<li>Comment from <a href="https://www.reddit.com/r/AnimeResearch/comments/962ziu/userguided_deep_anime_line_art_colorization_with/">reddit</a>: I don’t have it locally but it should be easy to make an ‘illustration dataset’ simply by using a tag like <a href="https://danbooru.donmai.us/posts?utf8=%E2%9C%93&amp;tags=-monochrome+&amp;ms=1"><code>-monochrome</code></a> to filter out any line-art. It’s easy to make a line-art dataset because that’s also a tag: <code>lineart</code>. Finally, you don’t need to half-ass the pairs dataset with fake pairs using XDoG because you can just use <a href="https://danbooru.donmai.us/wiki_pages/21859">parent-child relationships</a> to find all sets of related images, and then extract all pairs of monochrome vs non-monochrome, which will usually give you sketch to completed image. Or there are tags just for this, like <a href="https://danbooru.donmai.us/posts?utf8=%E2%9C%93&amp;tags=colored+&amp;ms=1"><code>colored</code></a>, for human colorization of BW images (and you can again use the parent/child relationships to filter more).</li>
</ul>
<img data-src="image-20200705104853930.png" alt="image-20200705104853930" style="zoom:33%;">
<img data-src="image-20200705104922846.png" alt="image-20200705104922846" style="zoom:33%;">
<img data-src="image-20200705105004118.png" alt="image-20200705105004118" style="zoom:33%;">
</li>
<li>
<p>Line Art Correlation Matching Network for Automatic Animation Colorization</p>
</li>
</ol>
<h3 id="照片转动漫"><a class="markdownIt-Anchor" href="#照片转动漫"></a> 照片转动漫</h3>
<ol>
<li>CartoonGAN: Generative Adversarial Networks for Photo Cartoonization [<a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_CartoonGAN_Generative_Adversarial_CVPR_2018_paper.pdf">Paper</a>] [<a href>Code</a>] [2018]
<ul>
<li>Unpaired image dataset training.</li>
<li>Two loss: In generator, a semantic loss defined as an ℓ1 sparse regularization in the <strong>high-level feature maps</strong> of the VGG network. In discriminator, an edge-promoting adversarial loss for preserving <strong>clear edges</strong></li>
<li>Built a new set of data which is animation images with edge blurred. Traditional GAN discriminator only discriminate photo from carton(or real from false), but this discriminator has three classes: Normal Photo, Real Carton Image, and Blurred edge carton image.</li>
</ul>
</li>
</ol>
<h3 id="动漫图片embedding"><a class="markdownIt-Anchor" href="#动漫图片embedding"></a> 动漫图片Embedding</h3>
<ol>
<li>illustration2vec (i2v)。[<a href="https://www.gwern.net/docs/anime/2015-saito.pdf">Paper</a>] [<a href="https://github.com/rezoo/illustration2vec">Code</a>] [2015]
<ul>
<li>使用了VGG网络将任意动漫图片压缩为一个长度为4096的Vector。</li>
<li>同样，由于训练时Y为标签，这里可以使用该网络为动漫图片打标。</li>
<li>训练图片来自于Danbooru和Safebooru两个网站。共计使用了1,287,596张图片和它们的metadata。</li>
<li>标签分为四类：<code>General tags</code>, <code>copyright tags</code>,<code>character tags</code>和<code>rating tags</code>。第一个是图片本身的特征，如“武器”，“微笑”，第二个是版权方，如“VOCALOID”；第三个是角色名字，如“hatsune miku”最后一个类别表示是18禁、擦边球还是全年龄图片。</li>
</ul>
</li>
</ol>
<h3 id="简笔画转照片"><a class="markdownIt-Anchor" href="#简笔画转照片"></a> 简笔画转照片</h3>
<ol>
<li>
<p>Deep Learning for Free-Hand Sketch: A Survey and A Toolbox [<a href="https://arxiv.org/pdf/2001.02600.pdf">Paper</a>] [<a href="https://github.com/PengBoXiangShang/torchsketch/">Code</a>] [2020]</p>
<p><img data-src="image-20200705105458250.png" alt="image-20200705105458250"></p>
<p><img data-src="image-20200705105522568.png" alt="image-20200705105522568"></p>
</li>
</ol>
<h3 id="其他gan"><a class="markdownIt-Anchor" href="#其他gan"></a> 其他GAN</h3>
<ol>
<li>
<p>Style GAN [<a href="https://arxiv.org/pdf/1812.04948.pdf">Paper</a>] [<a href="https://github.com/NVlabs/stylegan">Code</a>] [2019]</p>
<ul>
<li>NVIDIA出品</li>
<li>它可以连续控制生成图片的各种独立参数！</li>
<li>之前的GAN都是Input使用一个随机噪声，而NVIDIA这篇这是在许多层中间都添加一波噪声。层数越靠后，这些噪声控制的特征就越细节。</li>
<li>gwern训练好的二次元StyleGAN模型：<a href="https://drive.google.com/file/d/1z8N_-xZW9AU45rHYGj1_tDHkIkbnMW-R/view">Link</a></li>
</ul>
<img data-src="image-20200705105910579.png" alt="image-20200705105910579" style="zoom:33%;">
<img data-src="v2-3fffd4e8d8e16d7da045de536f6d0e95_1440w.jpg" alt="img" style="zoom:33%;">
<img data-src="image-20200705105951584.png" alt="image-20200705105951584" style="zoom:33%;">
</li>
<li>
<p><a href="https://github.com/zhangqianhui/AdversarialNetsPapers">AdversarialNetsPapers 各种GAN的Papers</a></p>
</li>
<li>
<p><a href="https://github.com/tjwei/GANotebooks">GANotebooks 各种GAN的Jupyter Notebook教程</a></p>
</li>
<li>
<p><a href="https://github.com/jayleicn/animeGAN">animeGAN A simple PyTorch Implementation of GAN, focusing on anime face drawing.</a></p>
</li>
</ol>
<h2 id="数据集"><a class="markdownIt-Anchor" href="#数据集"></a> 数据集</h2>
<h3 id="纯动漫图片"><a class="markdownIt-Anchor" href="#纯动漫图片"></a> 纯动漫图片</h3>
<ol>
<li>
<p>Danbooru2019. [<a href="https://www.gwern.net/Danbooru2019">Release</a>] [<a href="https://github.com/fire-eggs/Danbooru2019">Code</a>] [2019]</p>
<ul>
<li>Original or 3x512x512</li>
<li>~3TB or 295GB</li>
<li>3.69M or 2828400 images</li>
<li>108M tag instances (of 392k defined tags, ~29/image).</li>
<li>Covering Danbooru from 24 May 2005 through 31 December 2019 (final ID: #3,734,659).</li>
<li>Image files &amp; a JSON export of the metadata.</li>
</ul>
</li>
<li>
<p>Anime Face Dataset [<a href="https://www.kaggle.com/splcher/animefacedataset">Link</a>][2019]</p>
<ul>
<li>数据来源：<a href="www.getchu.com">Getchu</a></li>
<li>包含图片数目： 63,632</li>
<li>只包含脸部截取图片</li>
<li>大小：395.95MB</li>
<li>每张图片分辨率：90 * 90 ~ 120 * 120</li>
</ul>
<img data-src="test.jpg" alt="anime girls" style="zoom:50%;">
</li>
</ol>
<h3 id="线稿-色稿对"><a class="markdownIt-Anchor" href="#线稿-色稿对"></a> 线稿-色稿对</h3>
<ol>
<li>Danbooru Sketch Pair 128x [<a href="https://www.kaggle.com/wuhecong/danbooru-sketch-pair-128x">Link</a>] [2019]
<ul>
<li>9.58GB</li>
<li>647K images. 323K sketch-color pairs</li>
<li>Image size: 3x128x128</li>
<li>有的是插画，有的是漫画。</li>
<li>博客：Sketch to Color Anime: An application of Conditional GAN. [<a href="https://medium.com/@raviranjankr165/sketch-to-color-anime-an-application-of-conditional-gan-e40f59c66281">Link</a>] [<a href="https://github.com/ravi-1654003/Sketch2Color-conditional-GAN">Code</a>] [2020]</li>
</ul>
</li>
</ol>
<h3 id="推荐与评价"><a class="markdownIt-Anchor" href="#推荐与评价"></a> 推荐与评价</h3>
<ol>
<li>
<p>Anime Recommendations Database [<a href="https://www.kaggle.com/CooperUnion/anime-recommendations-database">Link</a>] [2016]</p>
<ul>
<li>数据来源于：<a href="https://myanimelist.net/">Link</a></li>
<li>大小：107.14MB</li>
<li>This data set contains information on user preference data from 73,516 users on 12,294 anime.</li>
</ul>
<img data-src="image-20200705024244220.png" alt="image-20200705024244220" style="zoom: 33%;">
</li>
</ol>
<h2 id="博客"><a class="markdownIt-Anchor" href="#博客"></a> 博客</h2>
<ol>
<li><a href="https://zhuanlan.zhihu.com/p/24767059">GAN学习指南：从原理入门到制作生成Demo</a></li>
<li><a href="https://medium.com/@jonathan_hui/gan-whats-generative-adversarial-networks-and-its-application-f39ed278ef09">GAN — What is Generative Adversary Networks GAN?</a></li>
<li><a href="https://www.leiphone.com/news/201709/i9qlcvWrpitOacjf.html">可能是近期最好玩的深度学习模型：CycleGAN的原理与实验详解</a></li>
<li><a href="https://makegirlsmoe.github.io/main/2017/08/14/news-english.html">输入各种参数生成动漫人物头像官方博客</a></li>
<li><a href="https://www.jiqizhixin.com/articles/2017-08-20-4">宅男的福音：用GAN自动生成二次元萌妹子</a></li>
<li><a href="https://qiita.com/rezoolab/items/5cc96b6d31153e0c86bc">Chainerを使ってコンピュータにイラストを描かせる</a></li>
<li><a href="https://www.jqr.com/article/000215">旋转吧！换装少女：一种可生成高分辨率全身动画的GAN</a></li>
<li><a href="https://www.jianshu.com/p/f31d9fc1d677">不要怂，就是GAN</a></li>
<li><a href="https://medium.com/@jonathan_hui/gan-some-cool-applications-of-gans-4c9ecca35900">GAN — Some cool applications of GANs</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/30532830">眼见已不为实，迄今最真实的GAN：Progressive Growing of GANs</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/33752313">通俗理解生成对抗网络GAN</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/27012520">从头开始GAN</a></li>
<li><a href="https://junyanz.github.io/CycleGAN/">Cycle GAN 作者官网</a></li>
<li><a href="https://www.jiqizhixin.com/articles/2018-04-17-5">如何从零开始构建深度学习项目？这里有一份详细的教程</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/27145954">带你理解CycleGAN，并用TensorFlow轻松实现</a></li>
</ol>
<h2 id="其他资源"><a class="markdownIt-Anchor" href="#其他资源"></a> 其他资源</h2>
<h3 id="文字转语音"><a class="markdownIt-Anchor" href="#文字转语音"></a> 文字转语音</h3>
<ol>
<li><a href="http://sinsy.jp/">Sinsy</a>: アップロードされた楽譜(MusicXML)に基づいて任意の歌声を生成するHMM/DNN歌声合成システム，Sinsy（しぃんしぃ）です．
<ul>
<li>支持日语、中文、英语。</li>
<li>输入特定格式的乐谱，输出相当不错的唱词音频文件。</li>
<li><a href="https://pypi.org/project/sinsy-cli/">sinsy-cli</a>: 使用命令行调用Sinsy进行合成。安装：<code>pip install sinsy-cli</code></li>
<li>介绍博客：<a href="http://blog.pcedev.com/2016/02/18/hands-sinsy-solution-song-vocal-synthesis-using-open-source-software/">Hands on Sinsy, a free software solution for song vocal synthesis</a></li>
</ul>
</li>
<li><a href="https://www.animenewsnetwork.com/interest/2013-10-22/vocaloducer-automatically-creates-songs-from-lyrics">Vocaloducer</a>。</li>
</ol>
<h3 id="动漫人脸检测切割"><a class="markdownIt-Anchor" href="#动漫人脸检测切割"></a> 动漫人脸检测切割</h3>
<ol>
<li><a href="https://github.com/nagadomi/lbpcascade_animeface">自动化动漫人物脸部切割保存</a><br>
<img data-src="43184241-ed3f1af8-9022-11e8-8800-468b002c73d9.png" alt="result"></li>
</ol>
<h3 id="头像生成"><a class="markdownIt-Anchor" href="#头像生成"></a> 头像生成</h3>
<ol>
<li><a href="https://make.girls.moe/">输入各种参数生成动漫人物头像</a></li>
<li><a href="https://github.com/Aixile/chainer-cyclegan">Chainer-CycleGAN 动漫人物头发转银色</a></li>
</ol>
<h3 id="图像超分辨率"><a class="markdownIt-Anchor" href="#图像超分辨率"></a> 图像超分辨率</h3>
<ol>
<li><a href="http://waifu2x.udp.jp">Waifu2x 动漫图片无损放大</a></li>
</ol>
<h3 id="自动线稿上色-2"><a class="markdownIt-Anchor" href="#自动线稿上色-2"></a> 自动线稿上色</h3>
<ol>
<li>
<p><a href="https://github.com/pfnet/PaintsChainer">PaintsChainer</a>: Paints Chainer is a line drawing colorizer using chainer. Using CNN, you can colorize your sketch semi-automatically .</p>
<ul>
<li>作者提供了直接搭建网站server 的代码。</li>
<li>这里是搭建好的<a href="http://paintschainer.preferred.tech/">站点</a>。</li>
<li>该网站也提供草图或照片提取线稿功能。</li>
</ul>
<p><img data-src="sample.png" alt="image"></p>
</li>
</ol>
<h3 id="照片画风迁移"><a class="markdownIt-Anchor" href="#照片画风迁移"></a> 照片画风迁移</h3>
<ol>
<li>
<p><a href="https://deepart.io/">Repaint your picture in the style of your favorite artist</a></p>
<p><img data-src="ACG%E7%9B%B8%E5%85%B3AI%E9%A1%B9%E7%9B%AE-%E8%AE%BA%E6%96%87-%E4%BB%A3%E7%A0%81-%E6%95%B0%E6%8D%AE-%E8%B5%84%E6%BA%90/image-20200705105719731.png" alt="image-20200705105719731"></p>
</li>
</ol>
]]></content>
      <tags>
        <tag>deep-learning</tag>
        <tag>acg</tag>
        <tag>anime</tag>
        <tag>paper</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch Core Code Research</title>
    <url>/2019/12/11/Pytorch-Core-Code-Research/</url>
    <content><![CDATA[<h2 id="pytorch-release-version-composition"><a class="markdownIt-Anchor" href="#pytorch-release-version-composition"></a> Pytorch Release Version Composition</h2>
<p>The repository cloned from GitHub <a href="https://github.com/pytorch/pytorch">pytorch/pytorch</a> is different from the package we download using <code>pip install</code> or <code>conda install</code>. In fact, the former contains many C/C++ based files, which consist of the basic of Pytorch, while the latter is more concise and contains compiled libraries and dll files instead.</p>
<p>Here, let’s discuss the release version, or the installed package at first. The package has a lot of components, Here I only pick out some most important parts to do explanation.</p>
<p><img data-src="image-20191128191350467.png" alt="image-20191128191350467"></p>
<span id="more"></span>
<h4 id="nn"><a class="markdownIt-Anchor" href="#nn"></a> nn</h4>
<p>All deep learning layers’ python entrance are located here. They mainly collect parameters from init input and do some modification to the input data. After that it will send core computation operation together with parameters into <code>torch._C</code> based functions.</p>
<h4 id="autograd"><a class="markdownIt-Anchor" href="#autograd"></a> autograd</h4>
<p>Contains a series of base functions which serves for back propagation. Also, if you dig in, the core implementation is still from C libraries. Variable wrap is also put here, but now it is just omitted because of the merge of tensor and Variable.</p>
<h4 id="cuda"><a class="markdownIt-Anchor" href="#cuda"></a> CUDA</h4>
<p>Mainly these parts are contained in <code>cuda</code> folder: Stream, Event, Broadcast and Random.</p>
<ul>
<li>A CUDA stream is a linear sequence of execution that belongs to a specific device, independent from other streams.</li>
<li>CUDA events are synchronization markers that can be used to monitor the device’s progress, to accurately measure timing, and to synchronize CUDA streams.</li>
<li>Broadcast related functions mainly do the jobs to make sure operations run on different GPUs and gather correctly.</li>
</ul>
<h4 id="optim"><a class="markdownIt-Anchor" href="#optim"></a> optim</h4>
<p><code>torch.optim</code> is a package implementing various optimization algorithms. Most commonly used methods are already supported, like <code>adam</code>, <code>sgd</code> and <code>adagrad</code>.</p>
<h4 id="distributed"><a class="markdownIt-Anchor" href="#distributed"></a> distributed</h4>
<p>The <code>distributions</code> package contains parameterizable probability distributions and sampling functions. This allows the construction of stochastic computation graphs and stochastic gradient estimators for optimization.</p>
<h4 id="onnx"><a class="markdownIt-Anchor" href="#onnx"></a> onnx</h4>
<p>The <code>torch.onnx</code> module contains functions to export models into the ONNX IR format. These models can be loaded with the ONNX library and then converted to models which run on other deep learning frameworks.</p>
<h4 id="tensor"><a class="markdownIt-Anchor" href="#tensor"></a> tensor</h4>
<p>Most basic tensor class defined here. It inherit a super class from C lib, called <code>torch._C._TensorBase</code> . And it attaches a lot of method like <code>register_hook</code>,<code>resize</code>, <code>norm</code> to tensor class. All these method eventually call C based libraries.</p>
<h4 id="lib"><a class="markdownIt-Anchor" href="#lib"></a> lib</h4>
<p>The library where compiled C/C++ files located. There are <code>.dll</code> files as well as <code>.lib</code> files. According to the bug reports on google, I believe <code>.dll</code> files are specially compiled for the compatibility of windows and <code>.lib</code> can be used in linux and some of them are also usable in Windows.(If you find a more accurate explanation, please tell me:) These files included: <code>_C.lib</code>, <code>c10.lib</code>, <code>torch.lib</code>, <code>c10_cuda.lib</code>.</p>
<h4 id="functional"><a class="markdownIt-Anchor" href="#functional"></a> functional</h4>
<p>Functions related to tensor operation are all located here. In fact, again, they are wrappers of functions from C libraries. You can find functions like <code>tensordot</code>, <code>unique</code>, <code>split</code> in this file.</p>
<h4 id="utils"><a class="markdownIt-Anchor" href="#utils"></a> utils</h4>
<p>All kinds of utilities codes are located here. This include dataset related code <code>dataloader.py</code>, <code>dataset.py</code>, <code>sampler.py</code>, also include save and output related <code>checkpoint.py</code>. Some TensorBoard support can also be found here.</p>
<h2 id="how-pytorch-manage-its-inner-resource"><a class="markdownIt-Anchor" href="#how-pytorch-manage-its-inner-resource"></a> How Pytorch manage its inner resource</h2>
<h3 id="what-is-tensor"><a class="markdownIt-Anchor" href="#what-is-tensor"></a> What is Tensor</h3>
<p>In <a href="https://en.wikipedia.org/wiki/Mathematics">mathematics</a>, a <strong>tensor</strong> is an algebraic object that describes a <a href="https://en.wikipedia.org/wiki/Linear_mapping">linear mapping</a> from one set of algebraic objects to another. Objects that tensors may map between include, but are not limited to, <a href="https://en.wikipedia.org/wiki/Vector_(mathematics_and_physics)">vectors</a> and <a href="https://en.wikipedia.org/wiki/Scalar_(mathematics)">scalars</a>, and, recursively, even other tensors. The tensor is the central data structure in PyTorch.  It’s an n-dimensional data structure containing some sort of scalar type, e.g., floats, ints, et cetera. We can think of a tensor as consisting of some data, and then some metadata describing the size of the tensor, the type of the elements in contains (dtype), what device the tensor lives on (CPU memory,  CUDA memory)</p>
<p>![what is tensor](Simple Tutorials on Tensors.jpg)</p>
<h3 id="how-tensor-organizes"><a class="markdownIt-Anchor" href="#how-tensor-organizes"></a> How Tensor organizes</h3>
<p>TH library is responsible for the computation,storage and memory management of Tensor. It divide the “Tensor” into two separate parts: Storage and Access/View.</p>
<p>Storage: <strong>THStorage</strong>. It manage the way of storing the Tensor.</p>
<p>Access: <strong>THTensor</strong>. It provide a access to user.</p>
<p><img data-src="image-20191203093005864.png" alt="image-20191203093005864"></p>
<h4 id="data-storage"><a class="markdownIt-Anchor" href="#data-storage"></a> Data Storage</h4>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">THStorage</span></span><br><span class="line">&#123;</span><br><span class="line"> real *data;</span><br><span class="line"> <span class="type">ptrdiff_t</span> size;</span><br><span class="line"> <span class="type">int</span> refcount;</span><br><span class="line"> <span class="type">char</span> flag;</span><br><span class="line"> THAllocator *allocator;</span><br><span class="line"> <span class="type">void</span> *allocatorContext;</span><br><span class="line"> <span class="keyword">struct</span> <span class="title class_">THStorage</span> *view;</span><br><span class="line">&#125; THStorage;</span><br></pre></td></tr></table></figure>
<ul>
<li>All of the “Tensor” in CPU is in fact a C pointer pointing to a data structure in memory like this. And it use reference count to do memory management.</li>
<li><strong>refcount</strong>: Here we apply reference count method to do automatic garbage collection. When the reference number becomes 0, this struct will be freed automatically.</li>
</ul>
<h4 id="data-access"><a class="markdownIt-Anchor" href="#data-access"></a> Data Access</h4>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">THTensor</span></span><br><span class="line">&#123;</span><br><span class="line"> <span class="type">long</span> *size;</span><br><span class="line"> <span class="type">long</span> *stride;</span><br><span class="line"> <span class="type">int</span> nDimension;</span><br><span class="line"></span><br><span class="line"> <span class="comment">// Attention: storage-&gt;size might be bigger than the size of tensor.</span></span><br><span class="line"> THStorage *storage;</span><br><span class="line"> <span class="type">ptrdiff_t</span> storageOffset;</span><br><span class="line"> <span class="type">int</span> refcount;</span><br><span class="line"></span><br><span class="line"> <span class="type">char</span> flag;</span><br><span class="line"></span><br><span class="line">&#125; THTensor;</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>nDimension</strong>: The number of dimensions</li>
<li><strong>size</strong>: It contains the length information of all dimensions.</li>
<li><strong>refcount</strong>: Reference count</li>
<li><strong>storage</strong>: Pointer of this data structure</li>
<li><strong>stride</strong>: The size of each dimension.</li>
</ul>
<h4 id="memory-allocator"><a class="markdownIt-Anchor" href="#memory-allocator"></a> Memory Allocator</h4>
<h5 id="c10coreallocatorh"><a class="markdownIt-Anchor" href="#c10coreallocatorh"></a> <code>/c10/core/Allocator.h</code></h5>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;memory&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">C10_API</span> Allocator &#123;</span><br><span class="line">  <span class="keyword">virtual</span> ~<span class="built_in">Allocator</span>() = <span class="keyword">default</span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> DataPtr <span class="title">allocate</span><span class="params">(<span class="type">size_t</span> n)</span> <span class="type">const</span> </span>= <span class="number">0</span>;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> DeleterFnPtr <span class="title">raw_deleter</span><span class="params">()</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nullptr</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="type">void</span>* <span class="title">raw_allocate</span><span class="params">(<span class="type">size_t</span> n)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">auto</span> dptr = <span class="built_in">allocate</span>(n);</span><br><span class="line">    <span class="built_in">AT_ASSERT</span>(dptr.<span class="built_in">get</span>() == dptr.<span class="built_in">get_context</span>());</span><br><span class="line">    <span class="keyword">return</span> dptr.<span class="built_in">release_context</span>();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">raw_deallocate</span><span class="params">(<span class="type">void</span>* ptr)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">auto</span> d = <span class="built_in">raw_deleter</span>();</span><br><span class="line">    <span class="built_in">AT_ASSERT</span>(d);</span><br><span class="line">    <span class="built_in">d</span>(ptr);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>The <code>allocate</code> function is directly included from head file <code>memory</code>.</p>
<h5 id="atensrcththallocatorcpp"><a class="markdownIt-Anchor" href="#atensrcththallocatorcpp"></a> <code>/aten/src/TH/THAllocator.cpp</code></h5>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">at::DataPtr <span class="title">THMapAllocator::makeDataPtr</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *filename, <span class="type">int</span> flags, <span class="type">size_t</span> size, <span class="type">size_t</span>* actual_size_out)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">auto</span>* context = <span class="keyword">new</span> <span class="built_in">THMapAllocator</span>(filename, flags, size);</span><br><span class="line">  <span class="keyword">if</span> (actual_size_out) *actual_size_out = context-&gt;<span class="built_in">size</span>();</span><br><span class="line">  <span class="keyword">return</span> &#123;context-&gt;<span class="built_in">data</span>(), context, &amp;deleteTHMapAllocator, at::DeviceType::CPU&#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Default allocator is malloc/free allocator. malloc and realloc raise an error (using THError) on allocation failure.</p>
</blockquote>
<h3 id="understand-parameters"><a class="markdownIt-Anchor" href="#understand-parameters"></a> Understand Parameters</h3>
<p>It is hard and not straightforward enough to understand stride and storage offset, so let’s borrow some images from <a href="http://blog.ezyang.com/2019/05/pytorch-internals/">ezyang</a>, who is supposed to be an inner developer of Pytorch, to elaborate this problem.</p>
<p>A tensor is a mathematical concept. But to represent it on our computers, we have to define some sort of physical representation for them. The most common representation is to lay out each element of the tensor contiguously in memory (that’s where the term contiguous comes from), writing out each row to memory.</p>
<p><img data-src="image-20191128191750794.png" alt="image-20191128191750794"></p>
<p>Please notice the relationship of sizes and strides. If we get a tensor with a size of (D,H,W) and this tensor is directly defined by user rather than a slice or result of some operation, the stride of it will be (H*W, W, 1). You can compare and draw a conclusion yourself. Each stride element in a certain dimension will be the product of all the following dimensions, and the stride of the last dimension will be 1.</p>
<p>Physically, stride means how many blocks of memory computer need to skip to get to the starting position of the next corresponding dimension. And if we use a formula to compute the memory position of a <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>e</mi><mi>n</mi><mi>s</mi><mi>o</mi><mi>r</mi><mo stretchy="false">[</mo><mi>i</mi><mo separator="true">,</mo><mi>j</mi><mo separator="true">,</mo><mi>k</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">Tensor[i,j,k]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">s</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mopen">[</span><span class="mord mathnormal">i</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mclose">]</span></span></span></span>, it will be <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>t</mi><mi>o</mi><mi>r</mi><mi>a</mi><mi>g</mi><mi>e</mi><mi>O</mi><mi>f</mi><mi>f</mi><mi>s</mi><mi>e</mi><mi>t</mi><mo>+</mo><mi>i</mi><mo>∗</mo><mi>s</mi><mi>t</mi><mi>r</mi><mi>i</mi><mi>d</mi><mi>e</mi><mo stretchy="false">[</mo><mn>0</mn><mo stretchy="false">]</mo><mo>+</mo><mi>j</mi><mo>∗</mo><mi>s</mi><mi>t</mi><mi>r</mi><mi>i</mi><mi>d</mi><mi>e</mi><mo stretchy="false">[</mo><mn>1</mn><mo stretchy="false">]</mo><mo>+</mo><mi>k</mi><mo>∗</mo><mi>s</mi><mi>t</mi><mi>r</mi><mi>i</mi><mi>d</mi><mi>e</mi><mo stretchy="false">[</mo><mn>2</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">storageOffset + i * stride[0] + j * stride[1] + k * stride[2]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">s</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mopen">[</span><span class="mord">0</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.85396em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mopen">[</span><span class="mord">1</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mopen">[</span><span class="mord">2</span><span class="mclose">]</span></span></span></span>.</p>
<p>In the example image above, I’ve specified that the tensor contains 32-bit integers, so you can see that each integer lies in a physical address, each offset four bytes from each other. To remember what the actual dimensions of the tensor are, we have to also record what the sizes are as extra metadata.</p>
<p><img data-src="image-20191128192741907.png" alt="image-20191128192741907"></p>
<p>Then comes to the memory offset. What does this mean? As we has mentioned before, a tensor storage may support multiple tensor view, and if we sliced the first N elements, then we will start from N+1 memory position. The following examples will give a further explanation.</p>
<p><img data-src="image-20191128193018098.png" alt="image-20191128193018098"></p>
<p>You can see in the left example, we start at the third element block, so that means we skip two block, and here the offset is 2. Because of the slice, the two dimensional tensor becomes one dimensional tensor, and conjoint elements are continuous in physical storage, this means the strides is [1]. Size is the number of elements in this case and it is 2.</p>
<p>In the right example, conjoint elements are not continuous, but it do start from the beginning, so the strides is [2] and offset is 0. There are still two elements in total so the sizes don’t change.</p>
<p>What’s more, if you still find it somehow difficult to understand, you may try <a href="https://ezyang.github.io/stride-visualizer/index.html">this website</a> to playing with these parameters and see the dynamic process.</p>
<h3 id="tensor-implementation-dispatch"><a class="markdownIt-Anchor" href="#tensor-implementation-dispatch"></a> Tensor implementation dispatch</h3>
<p>As we know, although in Python, you can use any type of data as you wish, as the interpreter will take care of the rest of the things. However, since the basic kernels are written in C/C++, functions from Python need to be dispatched into same functions with different input and device type. To a C/C++ functions, a certain function cannot take in <code>int</code> and <code>float</code> Tensor as a same <code>X</code> at the same time, they need separate implementation.</p>
<p><img data-src="image-20191128221930437.png" alt="image-20191128221930437"></p>
<h3 id="how-to-dispatch"><a class="markdownIt-Anchor" href="#how-to-dispatch"></a> How to dispatch</h3>
<p>As we discussed above, the basic C/C++ implementation need to dispatch according to data and device type. But in code, how to actually do this work?</p>
<p><img data-src="image-20191128222130891.png" alt="image-20191128222130891"></p>
<p>There are basically three methods.</p>
<ol>
<li>Write these functions with different data and device type separately, and manually.</li>
<li>Using template function to build those dispatched function in the compiling time. But this only works in C++, while many code in Pytorch is still written in C.</li>
<li>Apply the magic item – Macro. By defining the function name as a Macro which takes in one or some parameters, like the data type name, we can compile this function in different types by <code>#define</code> and <code>#undef</code> multiple times, setting the variables in function name macro into various type name to compile the function into many copies which support different types.</li>
</ol>
<p>Here’s a simplified example:</p>
<h4 id="file-structure"><a class="markdownIt-Anchor" href="#file-structure"></a> File structure:</h4>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">.</span><br><span class="line">├── add.c <span class="comment"># Used to extend generic/add.c</span></span><br><span class="line">├── add.h <span class="comment"># Used to extend generic/add.h</span></span><br><span class="line">├── general.h <span class="comment"># Including other header files</span></span><br><span class="line">└── generic</span><br><span class="line"> ├── add.c <span class="comment"># Definition of generic function add</span></span><br><span class="line"> └── add.h <span class="comment"># Definition of generic type Vector</span></span><br></pre></td></tr></table></figure>
<h4 id="addh"><a class="markdownIt-Anchor" href="#addh"></a> add.h</h4>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// add.h</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;general.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CONCAT_2_EXPAND(A, B) A ## B</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CONCAT_2(A, B) CONCAT_2_EXPAND(A, B)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CONCAT_3_EXPAND(A, B, C) A ## B ## C</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CONCAT_3(A, B, C) CONCAT_3_EXPAND(A, B, C)</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> Vector_(NAME) CONCAT_3(Num, Vector_, NAME)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> Vector CONCAT_2(Num, Vector)</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> num float</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> Num Float</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;generic/add.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">undef</span> num</span></span><br><span class="line"><span class="meta">#<span class="keyword">undef</span> Num</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> num double</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> Num Double</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;generic/add.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">undef</span> num</span></span><br><span class="line"><span class="meta">#<span class="keyword">undef</span> Num</span></span><br></pre></td></tr></table></figure>
<h4 id="addc"><a class="markdownIt-Anchor" href="#addc"></a> add.c</h4>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// add.c</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;add.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> num float</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> Num Float</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;generic/add.c&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">undef</span> num</span></span><br><span class="line"><span class="meta">#<span class="keyword">undef</span> Num</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> num double</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> Num Double</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;generic/add.c&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">undef</span> num</span></span><br><span class="line"><span class="meta">#<span class="keyword">undef</span> Num</span></span><br></pre></td></tr></table></figure>
<h4 id="genericaddh"><a class="markdownIt-Anchor" href="#genericaddh"></a> generic/add.h</h4>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// generic/add.h</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">Vector</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">num *data;</span><br><span class="line"><span class="type">int</span> n;</span><br><span class="line">&#125; Vector;</span><br><span class="line"></span><br><span class="line"><span class="keyword">extern</span> <span class="type">void</span> <span class="title function_">Vector_</span><span class="params">(add)</span><span class="params">(Vector *C, Vector *A, Vector *B)</span>;</span><br></pre></td></tr></table></figure>
<h4 id="genericaddc"><a class="markdownIt-Anchor" href="#genericaddc"></a> generic/add.c</h4>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// generic/add.c</span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">Vector_</span><span class="params">(add)</span><span class="params">(Vector *C, Vector *A, Vector *B)</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="type">int</span> i, n;</span><br><span class="line">n = C-&gt;n;</span><br><span class="line"><span class="keyword">for</span>(i=<span class="number">0</span>;i&lt;n;i++)</span><br><span class="line">&#123;</span><br><span class="line">C-&gt;data[i] = A-&gt;data[i] + B-&gt;data[i];</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="an-example-finding-thstorage"><a class="markdownIt-Anchor" href="#an-example-finding-thstorage"></a> An Example finding THStorage</h2>
<p>I try to find the definition of THStorage, since it will give us a brief understand of the file management structure of pytorch, and we can also grab a basic idea of how those macros and includes are forming this huge project. We start from <code>torch/csrc/Storage.cpp</code>, and check step by step to the file included.</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">Storage.cpp                 -&gt;</span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;TH/TH.h&gt;</span>          -&gt;</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;TH/THStorageFunction.h&gt;</span>   -&gt;</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;TH/generic/THStorage.h&gt;</span>   -&gt;</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;c10/core/StorageImpl.h&gt;</span></span></span><br></pre></td></tr></table></figure>
<p>Find the macro definition in <code>TH/generic/THStorage.h</code>:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> THStorage at::StorageImpl</span></span><br></pre></td></tr></table></figure>
<p>Find the structure definition in <code>c10/core/StorageImpl.h</code>:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">namespace</span> c10 &#123;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">C10_API</span> StorageImpl <span class="keyword">final</span> : <span class="keyword">public</span> c10::intrusive_ptr_target &#123;</span><br><span class="line">...</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">  caffe2::TypeMeta  data_type_;  <span class="comment">// Data type</span></span><br><span class="line">  DataPtr data_ptr_;             <span class="comment">// Data pointer</span></span><br><span class="line">  <span class="type">int64_t</span> numel_;                <span class="comment">// Data number</span></span><br><span class="line">  <span class="type">bool</span> resizable_;</span><br><span class="line">  <span class="type">bool</span> received_cuda_;</span><br><span class="line">  Allocator* allocator_;         <span class="comment">// Data&#x27;s allocator</span></span><br><span class="line">&#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Therefore, the hidding real tpye of <code>THWStorage</code> is <code>at::StorageImpl</code>, and it is the implementation of data storage. Let’s look into the definition of <code>THPStorage_(pynew)</code> at first, when the value of  <code>cdata</code> is not provided, it need to create an implementation of class <code>THWStorage</code> using function <code>THWStorage_(NAME)</code>,  and the value of NAME can possibly be:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">new</span>                <span class="comment">// New a THStorage, if size not specified, size=0, that means using default Allocator</span></span><br><span class="line">free</span><br><span class="line">size</span><br><span class="line">get</span><br><span class="line">set</span><br><span class="line">data</span><br><span class="line">newWithSize        <span class="comment">// New THStorage，specify size but use default Allocator</span></span><br><span class="line">newWithAllocator   <span class="comment">// New THStorage，specify size and Allocator</span></span><br><span class="line">copy_functions</span><br><span class="line">copyByte</span><br><span class="line">...</span><br><span class="line">copyCudaByte</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>And also some macro definitions:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> THWStorage_(NAME) THStorage_(NAME)     <span class="comment">// torch/csrc/THP.h</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> THStorage_(NAME) TH_CONCAT_4(TH,Real,Storage_,NAME)   <span class="comment">// TH/THStorageFunctions.h</span></span></span><br></pre></td></tr></table></figure>
<p>The declaration of function <code>THStorage_(NAME)</code> lives in <code>TH/generic/THStorage.h</code>, <code>TH/generic/THStorageCopy.h</code> and the implementation part lies in corresponding cpp files.</p>
<p>(BTW, if using cuda, the declaration of  <code>#define THWStorage_(NAME) THCStorage_(NAME)</code>lie in <code>THC/generic/THCStorage.h</code> and <code>THC/generic/THCStorageCopy.h</code>)</p>
<p>Take THStorage_(newWithSize) function as an example, look into <code>TH/generic/THStorage.cpp</code> and we can find the definition:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">THStorage* <span class="title">THStorage_</span><span class="params">(newWithSize)</span><span class="params">(<span class="type">ptrdiff_t</span> size)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  THStorage* storage = c10::<span class="built_in">make_instrusive</span>&lt;at::StorageImpl&gt;(</span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> THQUANTIZED</span></span><br><span class="line">    caffe2::TypeMeta::<span class="built_in">Make</span>&lt;<span class="type">quantized_t</span>&gt;(),</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line">    caffe2::TypeMeta::<span class="built_in">Make</span>&lt;<span class="type">scalar_t</span>&gt;(),        <span class="comment">// New a scalar_t type</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">    size,</span><br><span class="line">    <span class="built_in">getTHDefaultAllocator</span>(),</span><br><span class="line">    <span class="literal">true</span>).<span class="built_in">release</span>();</span><br><span class="line">  <span class="keyword">return</span> storage;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>It’s not hard to infer from this code block that it new an <code>StorageImpl</code>, and add an intrusive pointer pointing to one of them, at last return a pointer pointing to <code>StorageImpl</code> and destroy the intrusive pointer. Macro THStorage is <code>at::StorageImpl</code>, so this method simply new a <code>StorageImpl and return a pointer pointing to it. According to the definition of </code>c10::make_instrusive`, this work will actually be done by the constructor of StorageImpl’ and it is:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">StorageImpl</span>(</span><br><span class="line">    caffe2::TypeMeta data_type,</span><br><span class="line">    int64_4 numel,</span><br><span class="line">    at::Allocator* allocator,</span><br><span class="line">    <span class="type">bool</span> resizable)</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>We will only traced here and this show a representative example of how pytorch inner code call and implement those method.</p>
<h2 id="autograd-2"><a class="markdownIt-Anchor" href="#autograd-2"></a> Autograd</h2>
<p>Autograd is a method which support automatic computation of gradient which will be used in the back propagation. Autograd depend directly on the computational graph. Computational graph is used for defining the pipeline of a model. It combines functions with variables and shows how they connect to each other.</p>
<p><img data-src="image-20191128215249350.png" alt="image-20191128215249350"></p>
<p>A directed graph with the following property:</p>
<ol>
<li>Edge: a function, or a function’s dependency</li>
<li>Points with input edges: a function (or operator)</li>
<li>Points with output edges: a variable</li>
</ol>
<p>Computational graph has two major types, they are dynamic and static computational graphs. TensorFlow applies static graph, it has the following characteristics:</p>
<ul>
<li>First define the structure of the graph, and then assign values to the leaf nodes (this is the origin of placeholder)</li>
<li>Then forward according to the assignment of leaf nodes</li>
</ul>
<p>Pytorch, on the other hand, utilize dynamic graph. The structure of the graph is established at the same time as the forward, so there is no need to use placeholder.</p>
<p>Here is an example inner code of autograd.</p>
<p><img data-src="image-20191128215538638.png" alt="image-20191128215538638"></p>
<p>Here we will elaborate these parameters which get involved in this process.</p>
<ul>
<li>
<p><strong>Data</strong>: It’s the data a variable is holding.</p>
</li>
<li>
<p><strong>requires_grad</strong>: This member, if true starts tracking all the operation history and forms a backward graph for gradient calculation.</p>
</li>
<li>
<p><strong>grad:</strong> grad holds the value of gradient. If requires_grad is False it will hold a None value. Even if requires_grad is True, it will hold a None value unless .backward() function is called from some other node.</p>
</li>
<li>
<p><strong>grad_fn:</strong> This is the backward function used to calculate the gradient.</p>
</li>
<li>
<p><strong>is_leaf</strong>: A node is leaf if :</p>
<ol>
<li>
<p>It was initialized explicitly by some function like x = torch.tensor(1.0) or x = torch.randn(1, 1) (basically all the tensor initializing methods discussed at the beginning of this post).</p>
</li>
<li>
<p>It is created after operations on tensors which all have requires_grad = False.</p>
</li>
<li>
<p>It is created by calling .detach() method on some tensor.</p>
</li>
</ol>
</li>
</ul>
<p><img data-src="image-20191128215740348.png" alt="image-20191128215740348"></p>
<h2 id="pytorch-source-code-composition"><a class="markdownIt-Anchor" href="#pytorch-source-code-composition"></a> Pytorch Source Code Composition</h2>
<p>Since different data type, different devices are supported, and python code call C/C++ based code, the source code structure is not easy to understand. Here is the most important parts in the root directory.</p>
<p><img data-src="image-20191128193909092.png" alt="image-20191128193909092"></p>
<p>And provide a more detailed directory comment as well as explanation below.</p>
<p><img data-src="image-20191128194349295.png" alt="image-20191128194349295"></p>
<h3 id="explanation-of-crucial-folders"><a class="markdownIt-Anchor" href="#explanation-of-crucial-folders"></a> Explanation of crucial folders</h3>
<h4 id="c10"><a class="markdownIt-Anchor" href="#c10"></a> C10</h4>
<p><strong>C</strong>affe <strong>Ten</strong>sor Library: Most basic tensor library. Codes here can be deployed to mobile devices as well as servers. It contains the core abstractions of PyTorch, including the actual implementations of the Tensor and Storage data structures.</p>
<h4 id="aten"><a class="markdownIt-Anchor" href="#aten"></a> ATen</h4>
<p><strong>A</strong> <strong>TEN</strong>sor library for C<ins>11, the C</ins> tensor library for Pytorch. It is a C++ library that implements the <strong>operations</strong> of Tensors. If you’re looking for where some kernel code lives, chances are it’s in ATen. ATen itself bifurcates into two neighborhoods of operators: the “native” operators, which are modern, C++ implementations of operators, and the “legacy” operators (TH, THC, THNN, THCUNN), which are legacy, C implementations. The legacy operators are the bad part of town; try not to spend too much time there if you can.</p>
<h4 id="caffe2"><a class="markdownIt-Anchor" href="#caffe2"></a> Caffe2</h4>
<p>This part is from the original Caffe2. After the merge of Pytorch and Caffe2, Caffe2 become a kind of backend in Pytorch.</p>
<h4 id="torch"><a class="markdownIt-Anchor" href="#torch"></a> Torch</h4>
<p>This is the part normally called by user when then use Pytorch to train or test their models. It contains what you are most familiar with: the actual Python modules that you import and use.</p>
<h4 id="torchcsrc"><a class="markdownIt-Anchor" href="#torchcsrc"></a> Torch/csrc</h4>
<p>The C++ code that implements what you might call the frontend of PyTorch. In more descriptive terms, it implements the binding code that translates between the Python and C++ universe, and also some pretty important pieces of PyTorch, like the autograd engine and the JIT compiler. It also contains the C++ frontend code.</p>
<h3 id="mechanism-inside-a-simple-call"><a class="markdownIt-Anchor" href="#mechanism-inside-a-simple-call"></a> Mechanism inside a simple call</h3>
<p><img data-src="image-20191128223910466.png" alt="image-20191128223910466"></p>
<h2 id="basic-condition-of-memory-management-in-pytorch"><a class="markdownIt-Anchor" href="#basic-condition-of-memory-management-in-pytorch"></a> Basic Condition of Memory Management in Pytorch</h2>
<ol>
<li>Every tensor will be assigned with a allocator when it is initialized.</li>
<li><code>c10/core/Allocator.h</code>: Pytorch default allocator class defined here.</li>
</ol>
<p>Some Policy in <code>c10/core/Allocator.h</code>:</p>
<ul>
<li>
<p>A DataPtr is a unique pointer (with an attached deleter and some context for the deleter) to some memory, which also records what device is for its data. nullptr DataPtrs can still have a nontrivial device; this allows us to treat zero-size allocations uniformly with non-zero allocations.</p>
</li>
<li>
<p>Choice of CPU here is arbitrary; if there’s an “undefined” device, we could use that too.</p>
</li>
<li>
<p>The deleter can be changed while running using function <code>compare_exchange_deleter</code>.</p>
</li>
<li>
<p>This context is used to generate DataPtr which have arbitrary <code>std::function</code> deleters associated with them.  In some user facing functions, we give a (user-friendly) interface for constructing tensors from external data which take an arbitrary <code>std::function</code> deleter.  Grep for InefficientStdFunctionContext to find these occurrences.</p>
<p>This context is inefficient because we have to do a dynamic allocation <code>InefficientStdFunctionContext</code>, on top of the dynamic allocation which is implied by <code>std::function</code> itself.</p>
</li>
</ul>
<ol start="3">
<li>There is a fake allocator in Aten(<code>aten/src/ATen/CPUFixedAllocator.h</code>), which just throws exceptions if some cpu fixed operation is actually used, like <code>cpu_fixed_malloc</code>, <code>cpu_fixed_realloc</code>, <code>cpu_fixed_free</code>.</li>
<li><code>c10/core/CPUAllocator.cpp</code> contains functions: <code>alloc_cpu</code>, <code>free_cpu</code>, <code>memset_junk</code>,  <code>alloc_cpu</code> even has the code dealing with NUMA machine. And there is a class <code>MemoryAllocationReporter</code> which is used to report C10’s memory allocation and deallocation status.</li>
<li><code>c10/core/Allocator.cpp</code>: Set and get allocator for different device type.</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">DeviceType::CPU</span><br><span class="line">DeviceType::CUDA</span><br><span class="line">DeviceType::OPENGL</span><br><span class="line">DeviceType::OPENCL</span><br><span class="line">DeviceType::MKLDNN</span><br><span class="line">DeviceType::IDEEP</span><br><span class="line">DeviceType::HIP</span><br><span class="line">DeviceType::FPGA</span><br><span class="line">DeviceType::MSNPU</span><br><span class="line">DeviceType::XLA</span><br></pre></td></tr></table></figure>
<ol start="6">
<li>
<p><code>c10/core/StorageImpl.h</code> &amp; <code>c10/core/Storage.h</code>: Mainly allocates memory buffer using given allocator and creates a storage with it. Mark.</p>
</li>
<li>
<p><code>c10/cuda/CUDACachingAllocator.cpp</code> is a caching allocator for CUDA. It has the following description:</p>
</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Yet another caching allocator for CUDA device allocations.</span><br><span class="line"></span><br><span class="line">- Allocations are associated with a stream. Once freed, blocks can be</span><br><span class="line">  re-allocated on the same stream, but not on any other stream.</span><br><span class="line">- The allocator attempts to find the smallest cached block that will fit the</span><br><span class="line">  requested size. If the block is larger than the requested size, it may be</span><br><span class="line">  split. If no block is found, the allocator will delegate to cudaMalloc.</span><br><span class="line">- If the cudaMalloc fails, the allocator will free all cached blocks that</span><br><span class="line">  are not split and retry the allocation.</span><br><span class="line">- Large (&gt;1MB) and small allocations are stored in separate pools.</span><br><span class="line">  Small requests are packed into 2MB buffers. Large requests will use the</span><br><span class="line">  smallest available free block or allocate a new block using cudaMalloc.</span><br><span class="line">  To reduce fragmentation, requests between 1MB and 10MB will allocate and</span><br><span class="line">  split a 20MB block, if no free block of sufficient size is available.</span><br><span class="line"></span><br><span class="line">With this allocator, allocations and frees should logically be considered</span><br><span class="line">&quot;usages&quot; of the memory segment associated with streams, just like kernel</span><br><span class="line">launches. The programmer must insert the proper synchronization if memory</span><br><span class="line">segments are used from multiple streams.</span><br><span class="line"></span><br><span class="line">The library provides a recordStream() function to help insert the correct</span><br><span class="line">synchronization when allocations are used on multiple streams. This will</span><br><span class="line">ensure that the block is not reused before each recorded stream completes</span><br><span class="line">work.</span><br></pre></td></tr></table></figure>
<h2 id="how-python-interact-with-cc"><a class="markdownIt-Anchor" href="#how-python-interact-with-cc"></a> How Python interact with C/C++</h2>
<h3 id="compile-c-program-to-so-library-and-call-it-in-python"><a class="markdownIt-Anchor" href="#compile-c-program-to-so-library-and-call-it-in-python"></a> Compile C program to .so library and call it in python</h3>
<h4 id="compile-as-shared-library"><a class="markdownIt-Anchor" href="#compile-as-shared-library"></a> Compile as shared library</h4>
<ol>
<li>Finish writing your C code.</li>
<li>Compile it into a <code>*.so</code> file.</li>
<li>Import <code>ctypes</code> in python file.</li>
<li>Load <code>*.so</code> file inside a python file.</li>
<li>*Define the input type of a C function.</li>
<li>Call function inside the <code>*.so</code> file.</li>
</ol>
<p><strong>function.c</strong></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">myFunction</span><span class="params">(<span class="type">int</span> num)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span> (num == <span class="number">0</span>)&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span>&#123;</span><br><span class="line">      <span class="keyword">if</span> ((num &amp; (num - <span class="number">1</span>)) == <span class="number">0</span>)</span><br><span class="line">          <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">      <span class="keyword">else</span></span><br><span class="line">          <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>Compile</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">gcc -fPIC -shared -o libfun.so function.c</span><br></pre></td></tr></table></figure>
<p><strong><a href="http://function.py">function.py</a></strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> ctypes </span><br><span class="line">NUM = <span class="number">16</span>      </span><br><span class="line">fun = ctypes.CDLL(libfun.so)   </span><br><span class="line">fun.myFunction.argtypes=[ctypes.c_int] </span><br><span class="line">returnVale = fun.myFunction(NUM)     </span><br></pre></td></tr></table></figure>
<h4 id="add-wrapper-in-c-file"><a class="markdownIt-Anchor" href="#add-wrapper-in-c-file"></a> Add wrapper in C++ file</h4>
<p>If this is a C++ file, you need to expose the function you want to use in a <code>extern &quot;C&quot;</code> wrapper.</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Foo</span>&#123;</span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="function"><span class="type">void</span> <span class="title">bar</span><span class="params">()</span></span>&#123;</span><br><span class="line">            std::cout &lt;&lt; <span class="string">&quot;Hello&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">// Since ctypes can only talk to C functions, you need </span></span><br><span class="line"><span class="comment">// to provide those declaring them as extern &quot;C&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> &#123;</span><br><span class="line">    <span class="function">Foo* <span class="title">Foo_new</span><span class="params">()</span></span>&#123; <span class="keyword">return</span> <span class="keyword">new</span> <span class="built_in">Foo</span>(); &#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">Foo_bar</span><span class="params">(Foo* foo)</span></span>&#123; foo-&gt;<span class="built_in">bar</span>(); &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>And then compile:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">g++ -c -fPIC foo.cpp -o foo.o</span><br><span class="line">g++ -shared -Wl,-install_name,libfoo.so -o libfoo.so  foo.o</span><br></pre></td></tr></table></figure>
<p>Afterwards, thing in Python code are similar as those in C.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> ctypes <span class="keyword">import</span> cdll</span><br><span class="line">lib = cdll.LoadLibrary(<span class="string">&#x27;./libfoo.so&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Foo</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.obj = lib.Foo_new()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">bar</span>(<span class="params">self</span>):</span><br><span class="line">        lib.Foo_bar(self.obj)</span><br><span class="line"><span class="comment"># Once you have that you can call it like</span></span><br><span class="line"></span><br><span class="line">f = Foo()</span><br><span class="line">f.bar() <span class="comment">#and you will see &quot;Hello&quot; on the screen</span></span><br></pre></td></tr></table></figure>
<h3 id="c-file-include-module-and-expose"><a class="markdownIt-Anchor" href="#c-file-include-module-and-expose"></a> C++ file include module and Expose</h3>
<p>Include &lt;boost/python.hpp&gt; the function in BOOST_PYTHON_MODULE</p>
<p>A C++ Function can be exposed to Python by writing a Boost.Python wrapper:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;boost/python.hpp&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">char</span> <span class="type">const</span>* <span class="title function_">greet</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">   <span class="keyword">return</span> <span class="string">&quot;hello, world&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">BOOST_PYTHON_MODULE(hello_ext)</span><br><span class="line">&#123;</span><br><span class="line">    using namespace boost::python;</span><br><span class="line">    def(<span class="string">&quot;greet&quot;</span>, greet);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>That’s it. We’re done. We can now build this as a shared library. The resulting DLL is now visible to Python. Here’s a sample Python session:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> hello_ext</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span> hello_ext.greet()</span><br><span class="line">hello, world</span><br></pre></td></tr></table></figure>
<h2 id="integrating-a-ccuda-operation-with-pytorch"><a class="markdownIt-Anchor" href="#integrating-a-ccuda-operation-with-pytorch"></a> Integrating a C++/CUDA Operation with PyTorch</h2>
<p>When we want to build a customized method or module, we can choose whether to build it in python or C++. The former is easier but the C++ version is faster and more efficient, especially when we want to build a frequently used or time consuming module. Here comes the explanation.</p>
<h4 id="cpu-integration"><a class="markdownIt-Anchor" href="#cpu-integration"></a> CPU Integration</h4>
<p>Besides integrate C++ file in python and use it in Pytorch, Pytorch itself provides us with two quite straightforward way to finish this job. They are Building with <code>setuptools</code> and JIT Compiling Extensions.</p>
<p>For the “ahead of time” flavor, we build our C++ extension by writing a <code>setup.py</code> script that uses setuptools to compile our C++ code. For the LLTM, it looks as simple as this:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> setuptools <span class="keyword">import</span> setup, Extension</span><br><span class="line"><span class="keyword">from</span> torch.utils <span class="keyword">import</span> cpp_extension</span><br><span class="line"></span><br><span class="line">setup(name=<span class="string">&#x27;lltm_cpp&#x27;</span>,</span><br><span class="line">      ext_modules=[cpp_extension.CppExtension(<span class="string">&#x27;lltm_cpp&#x27;</span>, [<span class="string">&#x27;lltm.cpp&#x27;</span>])],</span><br><span class="line">      cmdclass=&#123;<span class="string">&#x27;build_ext&#x27;</span>: cpp_extension.BuildExtension&#125;)</span><br></pre></td></tr></table></figure>
<p>The JIT compilation mechanism provides you with a way of compiling and loading your extensions on the fly by calling a simple function in PyTorch’s API called <code>torch.utils.cpp_extension.load()</code>. For the LLTM, this would look as simple as this:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.cpp_extension <span class="keyword">import</span> load</span><br><span class="line"></span><br><span class="line">lltm_cpp = load(name=<span class="string">&quot;lltm_cpp&quot;</span>, sources=[<span class="string">&quot;lltm.cpp&quot;</span>])</span><br></pre></td></tr></table></figure>
<h4 id="cuda-integration"><a class="markdownIt-Anchor" href="#cuda-integration"></a> CUDA Integration</h4>
<p>Integration of our CUDA-enabled op with PyTorch is again very straightforward. If you want to write a <code>setup.py</code> script, it could look like this:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> setuptools <span class="keyword">import</span> setup</span><br><span class="line"><span class="keyword">from</span> torch.utils.cpp_extension <span class="keyword">import</span> BuildExtension, CUDAExtension</span><br><span class="line"></span><br><span class="line">setup(</span><br><span class="line">    name=<span class="string">&#x27;lltm&#x27;</span>,</span><br><span class="line">    ext_modules=[</span><br><span class="line">        CUDAExtension(<span class="string">&#x27;lltm_cuda&#x27;</span>, [</span><br><span class="line">            <span class="string">&#x27;lltm_cuda.cpp&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;lltm_cuda_kernel.cu&#x27;</span>,</span><br><span class="line">        ])</span><br><span class="line">    ],</span><br><span class="line">    cmdclass=&#123;</span><br><span class="line">        <span class="string">&#x27;build_ext&#x27;</span>: BuildExtension</span><br><span class="line">    &#125;)</span><br></pre></td></tr></table></figure>
<p>Instead of <code>CppExtension()</code>, we now use <code>CUDAExtension()</code>. We can just specify the <code>.cu</code> file along with the <code>.cpp</code> files – the library takes care of all the hassle this entails for you. The JIT mechanism is even simpler:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.cpp_extension <span class="keyword">import</span> load</span><br><span class="line"></span><br><span class="line">lltm = load(name=<span class="string">&#x27;lltm&#x27;</span>, sources=[<span class="string">&#x27;lltm_cuda.cpp&#x27;</span>, <span class="string">&#x27;lltm_cuda_kernel.cu&#x27;</span>])</span><br></pre></td></tr></table></figure>
<h2 id="conclusion"><a class="markdownIt-Anchor" href="#conclusion"></a> Conclusion</h2>
<ul>
<li>Pytorch’s python part doesn’t have special care on memory management, means it just works in the way standard python programs work.</li>
<li>Current Pytorch source codes contains codes from multiple source, some of them are pure legacy, some come from caffe2, some serves as basic code, some are packed into dlls to serve python. Also, codes are different for those in CPU and CUDA, we need to focus on the right part if any optimization want to be made.</li>
<li>Almost all Pytorch core modules and functions are implemented in C++ based code and that will be much more efficient.</li>
<li>Every tensor is attached with a memory allocator, which can not only do the work of allocate and free, but also record the device on which it is located. Different kinds of allocator for different data type can be delivered as input parameter, this makes the code more compatible.</li>
<li>Pytorch combines multiple code dispatch method and they work well for C and C++ code.</li>
<li>Python can call compiled C file using ctypes, but Pytorch provides a toolset which makes it even easier.</li>
</ul>
<h2 id="reference"><a class="markdownIt-Anchor" href="#reference"></a> Reference</h2>
<ul>
<li><a href="http://blog.ezyang.com/2019/05/pytorch-internals/">PyTorch internals</a></li>
<li><a href="https://towardsdatascience.com/pytorch-autograd-understanding-the-heart-of-pytorchs-magic-2686cd94ec95">PyTorch Autograd</a></li>
<li><a href="https://pytorch.org/docs/stable/index.html">PYTORCH DOCUMENTATION</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/34629243">PyTorch源码浅析</a></li>
<li><a href="https://github.com/pytorch/pytorch">Pytorch GitHub Repo</a></li>
</ul>
<h2 id="slides"><a class="markdownIt-Anchor" href="#slides"></a> Slides</h2>
<p>![Final Report_1.jpg](Final Report_1.jpg)</p>
<p>![Final Report_1.jpg](Final Report_2.jpg)</p>
<p>![Final Report_1.jpg](Final Report_3.jpg)</p>
<p>![Final Report_1.jpg](Final Report_4.jpg)</p>
<p>![Final Report_1.jpg](Final Report_5.jpg)</p>
<p>![Final Report_1.jpg](Final Report_6.jpg)</p>
<p>![Final Report_1.jpg](Final Report_7.jpg)</p>
<p>![Final Report_1.jpg](Final Report_8.jpg)</p>
<p>![Final Report_1.jpg](Final Report_9.jpg)</p>
<p>![Final Report_1.jpg](Final Report_10.jpg)</p>
<p>![Final Report_1.jpg](Final Report_11.jpg)</p>
<p>![Final Report_1.jpg](Final Report_12.jpg)</p>
<p>![Final Report_1.jpg](Final Report_13.jpg)</p>
<p>![Final Report_1.jpg](Final Report_14.jpg)</p>
<p>![Final Report_1.jpg](Final Report_15.jpg)</p>
<p>![Final Report_1.jpg](Final Report_16.jpg)</p>
<p>![Final Report_1.jpg](Final Report_17.jpg)</p>
<p>![Final Report_1.jpg](Final Report_18.jpg)</p>
<p>![Final Report_1.jpg](Final Report_19.jpg)</p>
<p>![Final Report_1.jpg](Final Report_20.jpg)</p>
<p>![Final Report_1.jpg](Final Report_21.jpg)</p>
<p>![Final Report_1.jpg](Final Report_22.jpg)</p>
<p>![Final Report_1.jpg](Final Report_23.jpg)</p>
<p><strong>Zhongyang Zhang</strong></p>
]]></content>
      <tags>
        <tag>deep learning</tag>
        <tag>machine-learning</tag>
        <tag>C++</tag>
        <tag>pytorch</tag>
        <tag>C-lang</tag>
      </tags>
  </entry>
  <entry>
    <title>The introduction of American University</title>
    <url>/2018/07/29/american-u/</url>
    <content><![CDATA[<h1 id="the-introduction-of-american-university"><a class="markdownIt-Anchor" href="#the-introduction-of-american-university"></a> The introduction of American University</h1>
<h2 id="frequently-asked-question"><a class="markdownIt-Anchor" href="#frequently-asked-question"></a> Frequently Asked Question</h2>
<h3 id="录取委员会看中什么"><a class="markdownIt-Anchor" href="#录取委员会看中什么"></a> 录取委员会看中什么?</h3>
<p>​	博士研究生的录取其实看中的是研究经验。当然，托福和GRE分数，以及本科大学的排名也十分重要。对于GPA，相对前两者来说，其实并没有那么重要。</p>
<p>决定谁能得到这些就读机会的是每一个系的录取委员会。委员会成员每年由不同的教授组成，通常由教授阅读随即分配的申请资料，然后将申请者的质量做一个简单排序。然后这些被挑选出的候选人再拿到录取委员会之内进行投票。当然，每一个学校和每一个专业的做法都不太一样。</p>
<span id="more"></span>
<p>​	博士研究生和专业密切相关。因此委员会看中的是申请人对专业了解的情况。因此研究经验是最被看中的。你做过哪些研究，发表过哪些专业文章，逃不过教授的火眼金睛。教授会在看到这些经验的一瞬间，在心里有一个掂量。</p>
<p>有足够好的英语成绩(托福和GRE)是必备的。另外本科院校的排名和GPA也会被纳入考量因素。一句话，博士研究生的研究经验占据了整个申请的重中之重，学生在写个人申请时，也要重点陈述。其他条件，基本只是一些纳入考量的先决条件。</p>
<h3 id="套磁有没有用"><a class="markdownIt-Anchor" href="#套磁有没有用"></a> “套磁”有没有用?</h3>
<p>估计没有哪一个申请过美国大学的学生，尤其是申请博士研究生的学生不知道什么是“套磁”的。在申请的过程中，一些申请者会和教授写电子邮件，进行学术探讨，这样学生可以在申请的过程中给自己添加印象分。</p>
<p>纵教授对我说，他每天都接到好几十封套磁信。然而，“套磁信”到底有没有用?这是很多学生的困惑。对这个问题纵教授说，“我每天接到很多套磁信，但是其中大部分的内容都是普通的打个招呼，表个决心，普通的介绍情况，这样的套磁信不会引起教授任何兴趣。但是，有很多学生认认真真地阅读过教授的学术论文，本着讨论问题的方式给教授写信。提出有价值的问题，这种邮件，我都不忍心不回!”</p>
<p>纵教授的回答很能说明问题，毫无目的套磁基本无效。而针对教授的研究方向做过研究的人，会引起教授的注意。“不过，”纵教授告诉笔者，“即便是非常有研究方向的套磁，能够对申请起巨大帮助的几率也不大。因为套磁成功其实有三个条件。第一，你的邮件真的打动了教授，让教授愿意吸收你。第二，教授本人在录取委员会里，并有一定的发言权。第三，教授有研究经费并且愿意给你。而同时满足三个条件的并不多见。</p>
<p>“对于中国学生，套磁信也许并没有坏处。但是要真正的做一份成功的申请，还是要踏踏实实地把握好每一个细节!”</p>
<h3 id="中国学生的通病是什么"><a class="markdownIt-Anchor" href="#中国学生的通病是什么"></a> 中国学生的通病是什么?</h3>
<ol>
<li>
<p>中国学生的个人陈述一般都要有华丽的开篇和结尾。中间的用词也是复杂，有时候看到很多长句。而美国人写的个人陈述语言却相对简单。形成这个现象的原因一方面是中国学生用非母语写作，因此不可能和美国人一样自然。另一方面，中国人认为复杂的、华丽的英文就是好的，这是一个误区。其实简单朴实的语言更打动人。 写作中的逻辑性更加重要。</p>
</li>
<li>
<p>在面试中，中国学生面对不会的问题特别紧张，而且特别注意要对教授提供一个正确答案。往往在一个面试中，教授有时候会提出一些专业问题，而中国学生会很注重结果。一旦认为这个问题不懂，我面试就砸了。</p>
<p>事实并非如此。教授考察的是你面对问题的态度和解决问题的思路。如果你没有听清问题，甚至可以向教授提问，“你能帮我解释一下问题吗?”很多中国学生遇到不会的问题很少会说：“对不起，这个问题我没有研究过。”而是往往会尽量拼凑起有限的知识胡乱回答。而提供的答案往往和问题没有关系。“这些都是会减分的行为!”纵教授说。</p>
</li>
</ol>
<h2 id="diference-between-phd-and-master"><a class="markdownIt-Anchor" href="#diference-between-phd-and-master"></a> Diference between Ph.D and Master</h2>
<h3 id="内容来源"><a class="markdownIt-Anchor" href="#内容来源"></a> 内容来源：</h3>
<ol>
<li><a href="http://blog.sina.com.cn/s/blog_673097a30100jdru.html">水哥谈留学-美国理工申请，选硕士（MS）还是博士（PhD）</a> 来自：<a href="https://www.zhihu.com/people/caoxianshui">曹贤水</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/32678974">留学美国读CS的硕士比博士经济上更合算么？未必！</a> 来自：<a href="https://www.zhihu.com/people/qian-chen-23-70">Chen Qian </a> 助理教授 加州大学圣克鲁斯分校</li>
</ol>
<h3 id="overall-description"><a class="markdownIt-Anchor" href="#overall-description"></a> Overall Description</h3>
<p>申请MS，意味着很可能没有奖学金，意味着作为成年人，还要花家里十几万甚至几十万的存款；申请PhD，意味着自己要在未来5年-8年的时间活在一个充满实验，充满文献的环境中呆着，如果碰着个人品（RP）不好的教授，将会非常郁闷。申请MS，意味着可以早一点找工作，因为门槛低，找到好工作的机会在美国来说，比较容易；申请PhD，意味着一年几万美元的奖学金，学校给的多的话，还能买车、顺带养个老婆孩子啥的，回国还能有机会进入高校，要是混得好整一堆grant，小日子将很滋润。</p>
<h3 id="美国的硕士和博士培养的目标和思路是不同的"><a class="markdownIt-Anchor" href="#美国的硕士和博士培养的目标和思路是不同的"></a> 美国的硕士和博士培养的目标和思路是不同的！</h3>
<p>美国的4年本科习惯叫College，之后是graduate school（既研究生教育，其实国内也这么叫，只不过大家现在习惯把硕士研究生简化成研究生，博士研究生简化为博士。其他的Professional school，比如法学院，医学院，牙医学院，药学院啥的也是graduate school是有了Bachelor之后才能读的，这个就不展开了）。美国学校基本上把研究生教育分成两类，一类是硕士，一类是博士。记住，是并列的关系，而不会像国内，普遍是递进关系。</p>
<p>大家可以看看CMU的一个教授对PhD的描述：</p>
<blockquote>
<p>A Ph.D. is a long, in depth research exploration of one topic. By long we’re typically talking about 6 years. By in depth we mean that at the end of the Ph.D. you will be the world expert or close to it in your particular area. You will know more than your advisor about your particular research area. You will know more about your research than anyone at your school. By one we mean that by the last couple years of your Ph.D., you will typically be working on only one narrow problem. The Ph.D. is not about breadth, it is about depth.</p>
</blockquote>
<p>而Master呢，强调的是“breadth”。一个MS学生一年就得学6-8门课（总共27-36个学分左右），可一个PhD6年才会上不到10门课（上个一年左右，就开始自己的课题研究了，如果之前在国内读过硕士，老板觉得课程知识结构够了，甚至可以直接进入课题——这也让大家知道，所谓的美国不认中国硕士学位是个挺扯的说法，其实是人家很多很多博士项目本来就只要你有本科学位就可以直接申请，而不是硕士学位不受认可。。。要跑题了，说回来）。硕士以应用、就业为导向，而PhD以深入的学术研究为导向。所以培养的目标不一样，适合的人群就不一样。大家一定要根据自己的情况进行选择。</p>
<p>根据我这些年的总结，得出一个学位选择的三原则，送给大家：</p>
<ol>
<li>如果自己喜欢搞学术、适合PhD生活，那么首选PhD；</li>
<li>在不确定自己是不是足够喜欢MS or PhD的时候，同时家里又能够为自己提供30w左右的留学预算而不会严重影响到家庭的生活质量的情况下，首选MS；</li>
<li>不到万不得已的情况下，不要为了钱而选择PhD。</li>
</ol>
<p>第一条原则比较好理解，适合的、喜欢的才是最好的。自己喜欢，就不会觉得在5~8年甚至更长时间里在某一个细小问题上作深入的研究是件痛苦的事情，无法坚持，也就能够成功。而且这种适合是能够带来丰厚的物质回报的。因为经过这么长时间的研究，你肯定会成为这领域中的专家，人家值得在你身上花这么多钱。（当然，如果有回国当教授的打算，PhD也是必要的，否则将会无法和别人竞争）</p>
<p>第二条原则我要重点解释一下，我觉得对国内学生比较有意义。因为很多之所以申请PhD是因为觉得PhD比MS高一级，出来更好找工作（其实事实上在美国其实是反过来的），并不是因为自己喜欢。因为各种误解而做出错误选择的人非常多。我之所以总结出第二条原则，依据如下：</p>
<p>第一，选MS有利于帮助自己找到真正适合自己的方向。国内在基础教育阶段，对于学生的兴趣引导和启发比重是比较小的，更多的还是升学率的压力。所以很多学生是不太清楚自己到底喜欢做什么，擅长做什么。贸然选择PhD，很有可能会在一段时间后后悔自己的决定。而选择MS，接触到一个新的环境中的各种新的、丰富的信息，经过自己的尝试，找到最适合自己的方向的几率将更大。（这种情况我这些年见到很多。就像我一个学生去美国之后，后来过年打电话给我拜年时说多亏我当时力劝他申请硕士而不是博士，要不然他肯定会后悔）</p>
<p>第二，如果选择的是MS，一来在申请上，更容易去到一个更高的优秀学校平台。这样的话，学校的师资力量、氛围、校友圈，对未来的就业、职业发展有很好的帮助。因为同一所学校，硕士和博士录取的难度是不一样的，比如不少前20学校的CS专业，PhD国际学生也就招不到20个，每年申请的人有上千名，而qualified</p>
<p>candidates有上百人。。。竞争的惨烈程度性由此可见一般。而他们的MS一年却会招少则五六十，多则二三百，机会无疑要大很多。</p>
<p>第三，选择MS，不会损失太多时间和金钱。由于美国的自由性和研究生制度的特性，MS转PhD，PhD转MS是一件比在国内容易很多的事情。所以选择MS过去，无论是读完MS转去其他学校读PhD，还是在本校直接转PhD，都是比在国内以国际学生身份申请要容易的事情。（很多学校，第一年MS和PhD上的课程基本是差不多的，学分可以非常顺利转到PhD阶段）而且人在美国之后，拿到奖学金的机会会比在国内申请要多。因为有些奖学金是只对在读学生开放的，更重要的是你人在学校了，教授上过你的课，知道你的平时表现或者能见你面跟你具体面谈，和一个只能从6张纸上获取的信息靠谱程度，能一样吗。。。所以先用MS过去美国，在时间和金钱上并不会有什么损失。（这个是对想读PhD的学生说的，你要是只想MS，那么博士的这些优势本来就对你没意义）</p>
<p>第四，选择MS过去之后，自己在选择导师的时候更有主动权，“离婚率”会大大降低。有不少专业的PhD是没有设置rotation的（生物类的有不少好学校都是先rotation，但CS EE这类工程项目好多都是老板有项目直接定的），这样在申请的时候，或者刚到美国没多久就要制定导师了。虽然你们会花较多的时间去研究教授的研究方向和自己背景的匹配性，自己是不是感兴趣。但是教授的人品，性格，即使在他们的主页上，也是很难了解清楚的。如果一不小心选了一个人品不好的老板，那么有可能会导致几年的PhD生活过得极其郁闷和痛苦。而选择MS，那么自主权更多的就会在自己的手里，到学校之后，有更多的渠道去了解一个教授的人品、对待学生的态度这些很重要的信息。有了这些信息，错误“结合”的概率将大大降低。</p>
<p>关于第三原则，之所以会有这种现象，更多的是由于咱们国家的国情所导致的。绝大多数人出国都是为了奔一个好前程or“钱程”。我们强调，首先尽量在前两个原则就解决问题。如果没有资金支持，自己又真的不喜欢读PhD，或者感兴趣的专业奖学金无法拿到，要么选择能够给你全奖的MS（虽然很难，但是有机会；另外可以考虑加拿大、新加坡或者香港做跳板）。要么去美国读PhD，但尽量把PhD念完，认真做课题。如果真的要转去其他专业，也要把人做好一点，别让教授因此否定整个中国的学生，或者自己母校的学生。</p>
<p>曾经很多中国学生（包括清华北大等中国最优秀学校出去的学生）为了出国，为了奖学金，会选择PhD，在申请时会告诉教授自己多么多么喜欢PhD，喜欢教授所作的课题。而到了美国一两年之后，面对外面的花花世界，决定提前毕业，然后背着老板去找工作，一旦找到工作就放老板鸽子。美国人是比较强调自由的，会非常尊重学生们的选择，所以美国的PhD</p>
<p>candidates在读PhD的过程中，只要拿够足够的学分之后是可以拿着硕士学位毕业的。刚开始，美国的教授看到中国学生申请提前毕业，多数会尊重学生的选择，放学生走。可是后来当老美们发现这种现象越来越多，出现在中国学生身上的频率很高，并最终明白真正原因时，他们就会非常气愤。因为教授们从自己的项目经费里掏钱招PhD是来帮自己做课题的，好不容易培养2年，正准备出成果呢，结果学生放自己鸽子了，浪费了钱不说，更关键的是重新招人培养人周期很长，如果自己的成果一直出不来，就很难评上Tenure（终身教授）而如果一个教授在学校7年左右的时间不能成为Tenure的话，就得卷铺盖走人。所以有些教授明确在自己的主页中声明，不再招收中国学生。（请见ZZ一Michigan教授给清华PhD申请者的拒信 ）对于那些要转MS的学生，有些老板就让系里不给学位，不放人。我曾经在网上认识了一名国内的留学生。自己找到工作了想毕业，老板不放。于是两个人就僵持着。学生天天在家里睡大觉，老板也不让他毕业。所以说，希望大家一定让自己去适用前两个原则。这样才是符合留学的本意的。</p>
<h3 id="经济面建模"><a class="markdownIt-Anchor" href="#经济面建模"></a> 经济面建模</h3>
<p>作为一个科学工作者，当然说干就干，建一个模看看吧。于是我建了下面一个模型：</p>
<p>读CS的Master，设：</p>
<p>为期两年，每年的学费为$35K（我取了我们UCSC的数据，不过私立学校更贵，会到45K，有些学校更便宜，可能25K，取35K基本差不多）</p>
<p>每年的生活费20K（加州大学的数据，美国其他州会较低）</p>
<p>第三年参加工作，税后的收入70K（经统计，CS硕士学位的软件工程师平均工资税前89K(<a href="https://link.zhihu.com/?target=https%3A//www.payscale.com/research/US/Degree%3DMaster_of_Science_%28MS%29%252C_Computer_Science_%28CS%29/Salary">Master of Science (MS), Computer Science (CS) Degree Salary</a>)，因此70K不算低估），生活费用30K（工作基本在加州、纽约、西雅图等开销较高的地区）。每年的工资涨幅为5%（这个数据基本不改变最后的结果，设为10%也一样）</p>
<p>读CS的PhD，设：</p>
<p>为期五年，每年学费由学校或导师给交了，另有税后25K的生活补贴（加州标准，其他州可能只有20K，但生活费同样下降，因此没区别）</p>
<p>每年的生活费20K</p>
<p>第六年参加工作，税后的收入80K（经统计，CS博士学位的软件工程师平均工资税前106K(<a href="https://link.zhihu.com/?target=https%3A//www.payscale.com/research/US/Degree%3DDoctorate_%28PhD%29%252C_Computer_Science_%28CS%29/Salary">Doctorate (PhD), Computer Science (CS) Degree Salaries</a>)，因此80K不算高估）。生活费30K。每年的工资涨幅为6%（都PhD了，总要稍微比Master高那么一点点吧，当然这个数据不改变最后结果，设为10%也一样）</p>
<p>下面是我的博士生画的比较图：</p>
<p><img data-src="v2-b9f0316405ac67d864340615ee5e272c_hd.jpg" alt="img"></p>
<p>我们发现，<strong>CS PhD的净收入恒高于硕士</strong>。再考虑到通货膨胀率，其实第一年欠下的学费后面需要更多的钱才能补上，所以差距应该更明显。</p>
<h3 id="深度讨论"><a class="markdownIt-Anchor" href="#深度讨论"></a> 深度讨论</h3>
<ol>
<li>问： PhD看起来也没比Master多多少钱啊</li>
</ol>
<p>答：注意我的前提是“即使你只看钱”。你可能还看其他的价值，比如你至少比master多了一个phd degree啊。比如你的职业道路更广，可以进公司的研究所，进国家实验室，进大学做教授，可以海归青年千人，绿卡更容易拿到，等等。</p>
<ol start="2">
<li>问：我申Master可以申到CMU和USC，但是申PhD只能申到Texas A&amp;M或者UCSC</li>
</ol>
<p>答：在中国，可能985的学生和非985的学生在招聘、起薪上有很大区别。在美国，进公司主要靠自己刷题和面试。TAMU的phd只可能比CMU的master更好找工作。当然CMU的校友人脉大一点，但phd还有你的导师&amp;师兄师姐人脉啊，那可比校友人脉给力多了。</p>
<ol start="3">
<li>问：但我如果能去CMU，我爸妈在邻居面前更有面子啊</li>
</ol>
<p>答：下一题吧</p>
<ol start="4">
<li>问：什么样的条件可以伸到PhD全奖？</li>
</ol>
<p>答：985学校的（或准985，如北邮、西电），本科平均分85左右，基本申请10个以上的学校，就能申请到全奖。即使你不是985本科，没关系，去好的实验室做一流的科研、发表一些优秀的论文、GPA 90以上、有著名学者推荐，等等无数途径，也可以拿到phd全奖。——别问我具体怎么操作，超纲了。</p>
<ol start="5">
<li>问：读PhD碰到变态导师怎么办</li>
</ol>
<p>答：现在信息这么发达，去打听一下就知道导师人怎么样了啊。</p>
<ol start="6">
<li>问：我读了phd发现自己不适合怎么办</li>
</ol>
<p>答：那这时转硕士也是正确的选择</p>
<ol start="7">
<li>问：你是不是招不到好学生所以才写这篇文章来引诱学生读PhD啊</li>
</ol>
<p>答：我现在的学生很优秀，每年也有很多好学生申请我PhD，忍痛拒掉里面的大部分。只是看到母系的学生对phd不感兴趣，感到很可惜。</p>
<ol start="8">
<li>问：你是想劝大家都读PhD么</li>
</ol>
<p>答：当然不是，读博士要量力而行。我是想劝那些有能力、有动力读博士，但是因为“读硕士更划算”的言论而放弃的学生，读博士。</p>
<ol start="9">
<li>问：你的模型还有这里那里不大对，我来调整一下</li>
</ol>
<p>答：感谢！不过给人生建模本来就不大可能是非常准确的。这里只是提供一种可能，所以我的标题说的是“未必”。</p>
]]></content>
      <tags>
        <tag>university</tag>
        <tag>America</tag>
      </tags>
  </entry>
  <entry>
    <title>在动漫中大GAN一场吧！</title>
    <url>/2019/01/29/anime-gan/</url>
    <content><![CDATA[<p>GAN的一大应用场景就是逼真图片的生成，而这一点则与动漫二次元期望生成“老婆”的愿望一拍即合。于是近年，有许多动漫相关的、使用GAN的项目被开发了出来，作为一个资深动漫宅，这里给大家做了一个整理，欢迎补充~</p>
<h2 id="实例"><a class="markdownIt-Anchor" href="#实例"></a> 实例</h2>
<ol>
<li><a href="https://make.girls.moe/">输入各种参数生成动漫人物头像</a></li>
<li><a href="http://waifu2x.udp.jp">Waifu2x 动漫图片无损放大</a></li>
<li><a href="https://github.com/Aixile/chainer-cyclegan">Chainer-CycleGAN 动漫人物头发转银色</a></li>
<li><a href="https://github.com/miracleyoo/anime-2-cosplay">Turn your 2-D wife(anime image) to 3-D wife(cosplay image) or opposite using DCGAN!  </a></li>
</ol>
<span id="more"></span>
<h2 id="工具"><a class="markdownIt-Anchor" href="#工具"></a> 工具</h2>
<ol>
<li><a href="https://github.com/rezoo/illustration2vec">自动化动漫人物打标签</a></li>
<li><a href="https://github.com/nagadomi/lbpcascade_animeface">自动化动漫人物脸部切割保存</a><br>
<img data-src="006y8mN6ly1g7lw843oeij30qe0ak3zz.jpg" alt></li>
<li><a href="https://github.com/jayleicn/animeGAN">animeGAN A simple PyTorch Implementation of GAN, focusing on anime face drawing.</a></li>
<li><a href="https://github.com/tjwei/GANotebooks">GANotebooks 各种GAN的Jupyter Notebook教程</a></li>
<li><a href="https://github.com/zhangqianhui/AdversarialNetsPapers">AdversarialNetsPapers 各种GAN的Papers</a></li>
</ol>
<h2 id="引用"><a class="markdownIt-Anchor" href="#引用"></a> 引用</h2>
<ol>
<li><a href="https://zhuanlan.zhihu.com/p/24767059">GAN学习指南：从原理入门到制作生成Demo</a></li>
<li><a href="https://medium.com/@jonathan_hui/gan-whats-generative-adversarial-networks-and-its-application-f39ed278ef09">GAN — What is Generative Adversary Networks GAN?</a></li>
<li><a href="https://www.leiphone.com/news/201709/i9qlcvWrpitOacjf.html">可能是近期最好玩的深度学习模型：CycleGAN的原理与实验详解</a></li>
<li><a href="https://makegirlsmoe.github.io/main/2017/08/14/news-english.html">输入各种参数生成动漫人物头像官方博客</a></li>
<li><a href="https://www.jiqizhixin.com/articles/2017-08-20-4">宅男的福音：用GAN自动生成二次元萌妹子</a></li>
<li><a href="https://qiita.com/rezoolab/items/5cc96b6d31153e0c86bc">Chainerを使ってコンピュータにイラストを描かせる</a></li>
<li><a href="https://www.jqr.com/article/000215">旋转吧！换装少女：一种可生成高分辨率全身动画的GAN</a></li>
<li><a href="https://www.jianshu.com/p/f31d9fc1d677">不要怂，就是GAN</a></li>
<li><a href="https://medium.com/@jonathan_hui/gan-some-cool-applications-of-gans-4c9ecca35900">GAN — Some cool applications of GANs</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/30532830">眼见已不为实，迄今最真实的GAN：Progressive Growing of GANs</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/33752313">通俗理解生成对抗网络GAN</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/27012520">从头开始GAN</a></li>
<li><a href="https://junyanz.github.io/CycleGAN/">Cycle GAN 作者官网</a></li>
<li><a href="https://www.jiqizhixin.com/articles/2018-04-17-5">如何从零开始构建深度学习项目？这里有一份详细的教程</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/27145954">带你理解CycleGAN，并用TensorFlow轻松实现</a></li>
</ol>
]]></content>
      <tags>
        <tag>machine-learning</tag>
        <tag>deep-learning</tag>
        <tag>GAN</tag>
      </tags>
  </entry>
  <entry>
    <title>Anaconda2和3的并存一键安装</title>
    <url>/2018/08/13/anaconda-2et3/</url>
    <content><![CDATA[<p>首先贴上Conda官网教程的<a href="https://conda.io/docs/user-guide/tasks/manage-python.html">网址</a></p>
<p>确实还是官网教程最简单实用，许多百度甚至谷歌搜索出来的csdn博客等并不是最优解法，而且废话太多…</p>
<p>有效解决办法就是下面一句（已经装了Anaconda3想装一个2）：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda create -n py27 python=2.7 anaconda</span><br></pre></td></tr></table></figure>
<span id="more"></span>
<p>或是这一句（已经装了Anaconda2想装一个3）：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda create -n py36 python=3.6 anaconda</span><br></pre></td></tr></table></figure>
<h1 id="managing-python"><a class="markdownIt-Anchor" href="#managing-python"></a> Managing Python</h1>
<ul>
<li><a href="https://conda.io/docs/user-guide/tasks/manage-python.html#viewing-a-list-of-available-python-versions">Viewing a list of available Python versions</a></li>
<li><a href="https://conda.io/docs/user-guide/tasks/manage-python.html#installing-a-different-version-of-python">Installing a different version of Python</a></li>
<li><a href="https://conda.io/docs/user-guide/tasks/manage-python.html#using-a-different-version-of-python">Using a different version of Python</a></li>
<li><a href="https://conda.io/docs/user-guide/tasks/manage-python.html#updating-or-upgrading-python">Updating or upgrading Python</a></li>
</ul>
<p>Conda treats Python the same as any other package, so it is easy to manage and update multiple installations.</p>
<p>Anaconda supports Python 2.7, 3.4, 3.5 and 3.6. The default is Python 2.7 or 3.6, depending on which installer you used:</p>
<ul>
<li>For the installers “Anaconda” and “Miniconda,” the default is 2.7.</li>
<li>For the installers “Anaconda3” or “Miniconda3,” the default is 3.6.</li>
</ul>
<h2 id="viewing-a-list-of-available-python-versions"><a class="markdownIt-Anchor" href="#viewing-a-list-of-available-python-versions"></a> <a href="https://conda.io/docs/user-guide/tasks/manage-python.html#id1">Viewing a list of available Python versions</a></h2>
<p>To list the versions of Python that are available to install, in your Terminal window or an Anaconda Prompt, run:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda search python</span><br></pre></td></tr></table></figure>
<p>This lists all packages whose names contain the text <code>python</code>.</p>
<p>To list only the packages whose full name is exactly <code>python</code>, add the <code>--full-name</code> option. In your Terminal window or an Anaconda Prompt, run:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda search --full-name python</span><br></pre></td></tr></table></figure>
<h2 id="installing-a-different-version-of-python"><a class="markdownIt-Anchor" href="#installing-a-different-version-of-python"></a> <a href="https://conda.io/docs/user-guide/tasks/manage-python.html#id2">Installing a different version of Python</a></h2>
<p>To install a different version of Python without overwriting the current version, create a new environment and install the second Python version into it:</p>
<ol>
<li>
<p>Create the new environment:</p>
<ul>
<li>
<p>To create the new environment for Python 3.6, in your Terminal window or an Anaconda Prompt, run:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda create -n py36 python=3.6 anaconda</span><br></pre></td></tr></table></figure>
<p>NOTE: Replace <code>py36</code> with the name of the environment you want to create. <code>anaconda</code> is the metapackage that includes all of the Python packages comprising the Anaconda distribution. <code>python=3.6</code> is the package and version you want to install in this new environment. This could be any package, such as <code>numpy=1.7</code>, or <a href="https://conda.io/docs/user-guide/tasks/manage-pkgs.html#installing-multiple-packages">multiple packages</a>.</p>
</li>
<li>
<p>To create the new environment for Python 2.7, in your Terminal window or an Anaconda Prompt, run:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda create -n py27 python=2.7 anaconda</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li>
<p><a href="https://conda.io/docs/user-guide/tasks/manage-environments.html#activate-env">Activate the new environment</a>.</p>
</li>
<li>
<p>Verify that the new environment is your <a href="https://conda.io/docs/user-guide/tasks/manage-environments.html#determine-current-env">current environment</a>.</p>
</li>
<li>
<p>To verify that the current environment uses the new Python version, in your Terminal window or an Anaconda Prompt, run:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python --version</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="using-a-different-version-of-python"><a class="markdownIt-Anchor" href="#using-a-different-version-of-python"></a> <a href="https://conda.io/docs/user-guide/tasks/manage-python.html#id3">Using a different version of Python</a></h2>
<p>To switch to an environment that has different version of Python, <a href="https://conda.io/docs/user-guide/tasks/manage-environments.html#activate-env">activate the environment</a>.</p>
<h2 id="updating-or-upgrading-python"><a class="markdownIt-Anchor" href="#updating-or-upgrading-python"></a> <a href="https://conda.io/docs/user-guide/tasks/manage-python.html#id4">Updating or upgrading Python</a></h2>
<p>Use the Terminal or an Anaconda Prompt for the following steps.</p>
<p>If you are in an environment with Python version 3.4.2, the following command updates Python to the latest version in the 3.4 branch:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda update python</span><br></pre></td></tr></table></figure>
<p>The following command upgrades Python to another branch—3.6—by installing that version of Python:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda install python=3.6</span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>python</tag>
        <tag>anaconda</tag>
      </tags>
  </entry>
  <entry>
    <title>一部立体的史书，一众活着的人物——《进击的巨人》观后感</title>
    <url>/2019/08/13/anime-review-shingeki/</url>
    <content><![CDATA[<p>看完了这个已经更新到50集的大长篇之后，一直觉得应该写些什么下来，否则总是感觉像是少了些什么，或是因为怕时间尘封这个故事而不安。</p>
<p>《進撃の巨人》也是为数不多的仍没有看过的大制作长篇动漫了。直观的感受是其拥有一个完整的世界观，且这是一个不但有时间上的纵深，也有空间上的绵延的世界。有着自己的文字、地图的异世界动漫或是幻想风动漫其实并不少，但是其严密的逻辑却是十分罕见的。很显然，作者心中有着一个对这个世界详细的认知，从其历史、宗教、到居住于其中的居民的想法和舆论，似乎都是作者笔尖中自然流淌出来的一个个侧面，而宏大的世界俨然居于其中。</p>
<span id="more"></span>
<p>看了对漫画的解读后更觉其精妙之处。世界如此之大，但三季动漫都在三层厚厚的墙壁之中展开，其中有诸多谜团，有关键人物的细腻刻画，更有不少看似无法理解的行动方式。然而，这些都是以一个“墙内人”的视角展开的。作者和编剧没有为了讨好观众而开上帝视角，去带我们一览这个广袤的大地上究竟发生过什么，发生着什么，而是为你设置了重重限制。作为一个观众，你着急，着急无法知道事情的全貌；你想探索，但你探索的速度不会超过马蹄上的战士；你想看到全貌，但你能看到的只有三堵让人类徒显渺小的巨壁，以及其中百态。你甚至不能直接看到中枢机关的大人们在想什么，你在边陲小镇，你的视角随着无力的主角少年的成长而一步步抬高，随着他见证巨人的侵入，历史的转折，体会丧失至亲的悲痛；随着他流离失所，并最终在训练营中直面挑战，靠扎实的努力一点点获得力量；随着他加入调查兵团，出入玛利亚城墙去探索如浓厚黑夜般的未知而迷人的墙外世界。</p>
<p>你会感到如此的无力，对这个世界了解的如此之少。你如此地渴望自由，渴望亲手揭开重重谜团，渴望离答案更进一步。然而，世界展现给你的却又是如此贫乏，你始终是无知的，你能看到的仿佛只是高维向下的一个投影，它是那么的模糊，那么的暧昧，却又那么的引人入胜。</p>
<p>然而你感受到的并非是绝望。你仿佛寄宿与艾伦心中，你看不见世界的宽广，却能看到少年心中的渴望；你始终无法证明团长父亲最终的猜想，却时时处处可见他倔强的梦想。虽然在这里，人类是如此的卑微和渺小，渺小到被巨人攥在手心时完全无力反抗，只能任凭他们蹂躏，被拍扁，被踩碎，被生吞。但就是这么微不足道的人类研究出了对抗巨人的诸多方法，凭借自己的智慧和勇气不断与这种超自然的力量进行顽强斗争。</p>
<p>你已经成为了墙中世界的一份子。但你的思想并没有被墙所禁锢，而是和少年，和团长，和勇毅的各位战士们一起，用自己的脚步定义着世界的边界。</p>
<p>如几乎所有优秀的作品一样，这里的人物们都是生动而丰富的。这里除了看不出深度的一些工具人（如皇宫的大臣）并没有真正的“反派”，人物们有着自己仅此一份的经历、性格与梦想，他们或许是自私的、残酷的、冷血的、暴力的、极端的，但同时他们也可能在无意间展现出一瞥的温柔，就像没有关严的门门缝中钻入的阳光一般，也许并不足以使之变得温暖，但却能让人切切实实地看见他心中漂浮着的点点尘埃。</p>
<p>男主的少年是一个比较冲动和容易情绪化的人，虽然这并不会掩盖住他心中的坚毅、勇敢、责任与担当。其实男主的情绪化这点我一直在偷偷期待会不会随着其成长而改观，但直到现在，这点依旧没能得到很好的改观。他还是容易上头，容易冲动，容易变得消极，容易否定自己存在的意义，依旧是那个嘴硬的、需要三笠和阿尔明辅助才能坚持下去的小鬼。说实话，不少片段在看的时候真的有种老父亲恨铁不成钢的感觉，但是静下来想想，自己不也多多少少是这样吗？遇到困难时会犹豫不决，会焦虑，会莽撞，会想着逃避，会不知所措，会期待别的哪位能帮自己度过艰难的时期。但最后，他不也还是尽自己最大努力去做了吗？即使会有所谓的遗憾，也足以问心无愧了。</p>
<p>这部动漫最深刻的讨论，我觉得在于对失去和获得的论辩。“什么都无法舍弃的人，最终什么也成为不了”。整部动漫一帧帧都在讲述失去的故事。男主眼睁睁地看着巨人吃掉自己的母亲，却什么也做不了，只能像货物一样被叔叔扛着逃跑；阿尔明和当地的许多人一样，也失去了自己的至亲；三笠的家人被人口贩子残杀；团长小时候因为渴望知道为何人们忘记了历史而直接导致了父亲被杀害；调查军团的成员们每次出征都会损失惨重；几次为了配合或拯救男主都死掉了大量的士兵；面对女型巨人时整个利维班的覆灭、以及整个城市的毁灭。更不用提每次巨人出现时以各种残酷的死法失去生命的巨量士兵和平民了。与其他动漫不同的一点是，每个人的死都不是无意义的，每个生命的逝去都给人心灵以一记重锤，让人更加深刻地切身感受到了来自巨人的绝对威胁和来自王政与体制的深切恐怖。离去的他们在我看来都不是为死而存在的工具人，而是一个个在上一秒还鲜活的，有着自己故事与羁绊的、真实的人。全篇到处都在就失去与获得进行讨论，杀死巨人是不是绝对道义的？那如果巨人的来源实际是人答案又会怎么变化？如果直接去杀人又是如何？复仇与原谅，冷静与冲动，冷血与人性，信赖与独立，背叛与命令，选择与结果，这些元素贯穿始终，令人回味无穷。</p>
<p>本作对于人物情感的塑造几乎达到了我心中对“登峰造极”这个概念的定义。三笠对艾伦无条件的守护，驱使之的究竟是一种什么样的情感？恐怕是一种将对其救赎的感恩、对亲情的渴望以及强烈的守护的意志、基于经验的对艾伦的不放心以及不知何时萌芽起的隐蔽而醇厚的爱情被细心地化合后的产物吧。这种感情是非常动人的，而我也真的是非敬佩作者能把这种常人所无法经历和体验的情感予以如此细腻而真挚的表现。阿尔明对自己能力的否定，对自己无法勇敢地站出来应对挑战的自我厌恶，对三笠与艾伦那样凛凛身姿的发自心底的羡慕，对艾伦从巨人口中拯救自己的不解与痛彻心扉的懊悔，以及之后渐渐发现其实自己也是有只属于自己的长处并开始一点点悦纳自己、找到属于自己位置的改变。莱纳的人格分裂也意外的表现的十分真切而能引起我的共鸣。他本是“敌方”派来墙内执行任务的巨人，但是在长达三年的训练兵生涯中却因为共同经历的一切而不由自主地真的爱上了这个位置，爱上了身边的这样一群同伴们，甚至在紧急情况下不由自主地献身救人，也会从心底里觉得克里斯塔可爱。当后面身份暴露后，他告诉他的“俘虏”艾伦和尤弥尔自己有着两个人格，这三年里对同伴的关心和对军队的忠诚并不是伪装之时，我几乎在一瞬间就理解了他。因为爱一部动漫而否定其他作品是无意义的，但能让人如此集中而全身心地沐浴于这扑面而来的情感的暴风雨中，的确是第一次体验到的。</p>
<p>另外一个很优质的看点是本作中涉及到的高层的决策部分。这些人实际上可以说大多并非主角团人物，人物形象也并不必要很丰满，甚至在很多作品中都是以一种跑龙套的身份出场的工具人，所以想让他们迎合剧情，迎合主角们是相当简单的。但实际上这些对宏观政策及其结果的描写并没有被刻意忽略，而是被作者用一种雄浑的叙事史诗一样的手法毫无保留地展现了出来，平添了一种苍凉与壮阔之感。如果说对主角团的跟踪描写是用钢笔细描，那对这种大背景与大决策的描写则更像是在宣纸上挥动的毛笔的笔触，就那么粗线条地勾勒着，散开着，明明并没有过多细节，却又好像能从中看出一个个小人物的故事，看到他们的希望与绝望，看到“政策”这面毛玻璃下的点点殷红。玛利亚墙陷落后的向罗斯墙内的大移民，以及移民后的饥荒，再到为了缓解内部矛盾而将人口的两成派遣到墙外“夺回失地”的难民大军；为了捕获女型巨人而在希娜城墙内的城中展开的大规模破坏性作战行动；为了引诱罗德·雷伊斯而被当做诱饵的属城居民，他们都用自己的鲜血书写了这部史诗血红的一行。</p>
<p>除去高层的决策，被高墙保护着的底层的一个个小人物也是着实值得玩味一番的。“小人物”们各自的生存方式，各自的追求，各自面对人生的态度，各自对存在意义的解读，各自走过的路，与各自到达的终点，都是那么的丰满，那么的缤纷。静静地聆听这些人的故事像是在听一首织体绵薄的单调旋律，可能某个特定的小人物终其一生也不过是在桌子旁转来转去给客人倒酒添菜，这种生活似乎是单调至极的，但正是这些单调却稳定的旋律交织在一起，共同谱出了伟大时代撼动人心的交响。</p>
<p>艾伦的妈妈婚前无疑是一个平凡到平庸的女服务生，婚后也不过是变调成了一支并不起眼的家庭妇女，但正是她给了艾伦前进的明确到心痛的目标；当艾伦经历一系列挫折，直抵崩溃边缘，甚至开始怀疑自己存在的意义时，基斯教官转述于其母亲的“你存在即是价值”的一段对话可谓是给了艾伦最后的一个阵地。“不是特别的就不行吗，不被他人所承认就不行吗？我并不这样认为，至少我认为这孩子…就算没法成为伟大的人，没法比别人更优秀也没关系。因为你看，他多可爱，毕竟这孩子降生到了这个世界，所以他已经很伟大了。”这段自其生命伊始之时母亲的观点可谓是让人感觉如沐清风。在其母亲看来，自己并不期待艾伦“成功”，其存在本身已经带来足够的意义了。</p>
<p>其母卡露拉无疑是一个达观的普通人。虽然作品最初卡露拉不愿让艾伦太深究“墙外的世界”，更不愿让其立志加入调查兵团是有点让我反感的，毕竟，在内心深处，谁不想探索下未知的领域，又有谁不想成为“天选之子”呢？但看了《旁观者》一话中基斯教官曾经的故事后，我开始重新审视其母亲这个角色了。基斯教官是上一代的团长，他可以说是一个现代常说的“奋斗家”的典型。他曾是一个怀有近乎于中二的理想和好奇心的成年人，曾被仍是酒吧侍女的卡露拉说抱着不切实际的理想，但也曾被艾伦父亲格里沙称为“選ばれしもの”天选之人。他一路努力奋斗，并最终升任到了调查兵团团长，可他却从没有真正地胜利过。他在返城时人们微妙的目光中慢慢看清自己，意识到自己的平凡，并最终痛苦地回归到自己应有的位置。他似乎真的十分不受命运眷顾，身边满是特别之人：格里沙，埃尔文，以及后面他当教官时候的104期一众神仙学员。他试图延续卡露拉的遗志，让艾伦成为一个平凡但能悦纳自己的人，他劝说其父，他试图阻止艾伦成为士兵，怎料艾伦却又正是最特殊的人。</p>
<p>卡露拉可以说是一个完全接受了自己平凡的普通人，我们可以说她已经放弃了挣扎，不思进取，甚至是混吃等死，并给自己找了一串看似合理的诡辩似的存在主义的理由。但这难道不是一种合理的生活态度吗？说到底所谓的“进取心”究竟又意味着什么呢？想得到比现在更好的，想获得配得上自己心中预设位置的，想拿到更多、更优质的资源，想做出一番事业，想惠及自己家族后代，当然，也可能只是想满足心中那份初始的好奇心。但这一切对于一个普通人来讲并不总是自然而然的，追逐梦想是有代价的，而且根据时代和大环境的不同还很有可能血本无归。我们生活在中国，又碰上了一长串的偶然和机遇，最终我们发现，似乎前面大有可为，应当搏一搏，让单车变摩托。但同时，并非在所有国家，并非所有人都有这样的环境和机遇，尊重彼此的生活态度也许是对人基本的尊重。毕竟，你没有体会过别人的人生。基斯似的拼搏家实际和我们当下的态度很是相似，我也对他很有好感。然而其在剧中可以说是一个悲悯的角色。努力过后，被现实糊了一脸，最终“认清”了自己。哈哈。我觉得“认清”一词在某种程度上其实和“放弃挣扎”同义。如果他身边没有这么多大佬，如果他早生二十年，他还会不会最终“认清”自己呢？当然，还有像汉尼斯大叔这样的“彻底接受自己的平庸，但在关键时刻又会挺身而出”的角色。他接受甚至享受“家畜的安宁”，随和往来，不思进取，面对巨大的困难时会怂会溜，但也有勇敢的站出来“冲一把”为卡露拉复仇、搭救艾伦的勇气。</p>
<p>此外，还有像克里斯塔这样敢于完成自我蜕变，从消极否定自我到悦纳自我、尊重自我，并将其博爱施于众人的“牧场女王”；有尤弥尔这种被克里斯塔救赎，并用尽全力去爱护她的“隐藏的巨人”；有关键时刻敢于担当、有着自己独立见解的“人类最高领袖”萨克雷；有看似冷血战神，实则成长自一个有着灰色童年、由杀手带大的孤僻小孩的兵长利威尔·阿克曼…每一个人的故事都值得大书特书，他们都是一个个有着自己的成长轨迹和与之相符的世界观、有着自己独特思考回路的精彩而生动的人。</p>
<p>当然，作为一部被禁播的番剧，分析其被禁播的理由也是令人饶有兴味的。广电总局斥其暴力血腥；知乎上有人说这是因为该作中有着一种“为了完成伟大目标，不惜推翻王政”的价值观，这是我国政府不愿意看到的；也有人提到该作有右翼思想倾向的嫌疑，试图美化战争；当然，也有人指出这是一部青年漫，和传统上中国人倾向认为的“动漫服务于儿童”的思想相悖…众说纷纭。其实，我觉得单纯的去指责广电总局的行为和直接封杀这个我们试图批判的行为是极其类似的，而究其理由则才是我们应该做的。在我看来，上面的这些理由，或多或少都为这把火的到来添了些许柴草，毕竟，它们都是有道理的。另外我觉得有一点值得一提的是，作品中反映出来的价值观和我们当前的现代社会的主流价值观无法咬合。剧中描写的是一个面临着来自外部的极大恐惧和威胁的社会，是一个“剥夺或被剥夺”的社会，是一个很大程度上只能消极避战，苟且偷生的社会；是一个强调“若想有所得，必先有壮士断腕觉悟”的社会。这不是我们面前的社会。一些类似的被封禁的动漫在我看来也存在类似的问题：如果受众本身能够对其精神进行思辨，那这自然是一部值得吹爆的上上之作；但如果受众并非如此，甚至是一些判断能力和思考能力相对较弱的小学生、中学生，那他们会不会将剧中的一些和现实生活并不接轨的价值观直接拿来套用，这也许真的是一个值得警惕的问题。</p>
<p>故事仍在继续，正如历史的车轮滚滚向前。</p>
]]></content>
      <tags>
        <tag>anime</tag>
        <tag>anime-review</tag>
      </tags>
  </entry>
  <entry>
    <title>Attention 从分类到实现细节</title>
    <url>/2020/07/06/attention-wiki/</url>
    <content><![CDATA[<p>Attention的本质可以看做加权求和。</p>
<h2 id="attention-的-n-种类型"><a class="markdownIt-Anchor" href="#attention-的-n-种类型"></a> Attention 的 N 种类型</h2>
<p><img data-src="image-20200705230846450.png" alt="image-20200705230846450"></p>
<p>Attention 有很多种不同的类型：Soft Attention、Hard Attention、静态 Attention、动态 Attention、Self Attention 等等。上图为各种Attention的分类，下面是这些不同的 Attention 的解释。</p>
<p>由于这篇文章《<a href="https://zhuanlan.zhihu.com/p/35739040">Attention 用于 NLP 的一些小结</a>》已经总结的很好的，下面就直接引用了：</p>
<p>本节从计算区域、所用信息、结构层次和模型等方面对 Attention 的形式进行归类。</p>
<span id="more"></span>
<h3 id="1-计算区域"><a class="markdownIt-Anchor" href="#1-计算区域"></a> <strong>1. 计算区域</strong></h3>
<p>根据 Attention 的计算区域，可以分成以下几种：</p>
<p>1）<strong>Soft</strong> Attention，这是比较常见的 Attention 方式，对所有 key 求权重概率，每个 key 都有一个对应的权重，是一种全局的计算方式（也可以叫 Global Attention）。这种方式比较理性，参考了所有 key 的内容，再进行加权。但是计算量可能会比较大一些。</p>
<p>2）<strong>Hard</strong> Attention，这种方式是直接精准定位到某个 key，其余 key 就都不管了，相当于这个 key 的概率是 1，其余 key 的概率全部是 0。因此这种对齐方式要求很高，要求一步到位，如果没有正确对齐，会带来很大的影响。另一方面，因为不可导，一般需要用强化学习的方法进行训练。（或者使用 gumbel softmax 之类的）</p>
<p>3）<strong>Local</strong> Attention，这种方式其实是以上两种方式的一个折中，对一个窗口区域进行计算。先用 Hard 方式定位到某个地方，以这个点为中心可以得到一个窗口区域，在这个小区域内用 Soft 方式来算 Attention。</p>
<h3 id="2-所用信息"><a class="markdownIt-Anchor" href="#2-所用信息"></a> <strong>2. 所用信息</strong></h3>
<p>假设我们要对一段原文计算 Attention，这里原文指的是我们要做 attention 的文本，那么所用信息包括内部信息和外部信息，内部信息指的是原文本身的信息，而外部信息指的是除原文以外的额外信息。</p>
<p>1）<strong>General</strong> Attention，这种方式利用到了外部信息，常用于需要构建两段文本关系的任务，query 一般包含了额外信息，根据外部 query 对原文进行对齐。</p>
<p>简单判定依据：<strong>计算Attention时，有没有用到除了被Attention向量以外的向量。</strong></p>
<p>比如在阅读理解任务中，需要构建问题和文章的关联，假设现在 baseline 是，对问题计算出一个问题向量 q，把这个 q 和所有的文章词向量拼接起来，输入到 LSTM中进行建模。那么在这个模型中，文章所有词向量共享同一个问题向量，现在我们想让文章每一步的词向量都有一个不同的问题向量，也就是，在每一步使用文章在该步下的词向量对问题来算 attention，这里问题属于原文，文章词向量就属于外部信息。</p>
<p><img data-src="v2-1e08348b226f4e2f08c89ae6e5d7fcda_1440w.jpg" alt="img"></p>
<p>2）<strong>Self</strong> Attention，这种方式只使用内部信息，key 和 value 以及 query 只和输入原文有关，在 self attention 中，key=value=query。既然没有外部信息，那么在原文中的每个词可以跟该句子中的所有词进行 Attention 计算，相当于寻找原文内部的关系。</p>
<p>还是举阅读理解任务的例子，上面的 baseline 中提到，对问题计算出一个向量 q，那么这里也可以用上 attention，只用问题自身的信息去做 attention，而不引入文章信息。</p>
<p>同样是在Encoder-Decoder模型中，它的实现方法是Encoder部分堆叠了两层。</p>
<img data-src="v2-2c7e48868e98202b6c3af3a7aa4ea987_1440w.jpg" alt="img" style="zoom:50%;">
<h3 id="3-结构层次"><a class="markdownIt-Anchor" href="#3-结构层次"></a> <strong>3. 结构层次</strong></h3>
<p>结构方面根据是否划分层次关系，分为单层 attention，多层 attention 和多头 attention：</p>
<p>1）单层 Attention，这是比较普遍的做法，用一个 query 对一段原文进行一次 attention。</p>
<p>2）多层 Attention，一般用于文本具有层次关系的模型，假设我们把一个 document 划分成多个句子，在第一层，我们分别对每个句子使用 attention 计算出一个句向量（也就是单层 attention）；在第二层，我们对所有句向量再做 attention 计算出一个文档向量（也是一个单层 attention），最后再用这个文档向量去做任务。</p>
<p>3）多头 Attention，这是 Attention is All You Need 中提到的 multi-head attention，用到了多个 query 对一段原文进行了多次 attention，每个 query 都关注到原文的不同部分，相当于重复做多次单层 attention：$$head_i=Attention(q_i,K,V)$$</p>
<p>最后再把这些结果拼接起来：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mi>u</mi><mi>l</mi><mi>t</mi><mi>i</mi><mi>H</mi><mi>e</mi><mi>a</mi><mi>d</mi><mo stretchy="false">(</mo><mi>Q</mi><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo>=</mo><mi>C</mi><mi>o</mi><mi>n</mi><mi>c</mi><mi>a</mi><mi>t</mi><mo stretchy="false">(</mo><mi>h</mi><mi>e</mi><mi>a</mi><msub><mi>d</mi><mn>1</mn></msub><mo separator="true">,</mo><mi>h</mi><mi>e</mi><mi>a</mi><msub><mi>d</mi><mn>2</mn></msub><mo separator="true">,</mo><mi>h</mi><mi>e</mi><mi>a</mi><msub><mi>d</mi><mn>3</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><mi>h</mi><mi>e</mi><mi>a</mi><msub><mi>d</mi><mi>n</mi></msub><mo stretchy="false">)</mo><msup><mi>W</mi><mi>O</mi></msup></mrow><annotation encoding="application/x-tex">MultiHead(Q, K, V)=Concat(head_1,head_2,head_3,...,head_n)W^O</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord mathnormal">d</span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0913309999999998em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mord mathnormal">c</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord mathnormal">h</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">h</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">h</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">h</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">O</span></span></span></span></span></span></span></span></span></span></span></p>
<p><img data-src="v2-3cd76d3e0d8a20d87dfa586b56cc1ad3_1440w.jpg" alt="img"></p>
<h3 id="4-模型方面"><a class="markdownIt-Anchor" href="#4-模型方面"></a> <strong>4. 模型方面</strong></h3>
<p>从模型上看，Attention 一般用在 CNN 和 LSTM 上，也可以直接进行纯 Attention 计算。</p>
<h4 id="1cnnattention"><a class="markdownIt-Anchor" href="#1cnnattention"></a> <strong>1）CNN+Attention</strong></h4>
<p>CNN 的卷积操作可以提取重要特征，我觉得这也算是 Attention 的思想，但是 CNN 的卷积感受视野是局部的，需要通过叠加多层卷积区去扩大视野。另外，Max Pooling 直接提取数值最大的特征，也像是 hard attention 的思想，直接选中某个特征。</p>
<p>CNN 上加 Attention 可以加在这几方面：</p>
<p>a. 在卷积操作前做 attention，比如 Attention-Based BCNN-1，这个任务是文本蕴含任务需要处理两段文本，同时对两段输入的序列向量进行 attention，计算出特征向量，再拼接到原始向量中，作为卷积层的输入。</p>
<p>b. 在卷积操作后做 attention，比如 Attention-Based BCNN-2，对两段文本的卷积层的输出做 attention，作为 pooling 层的输入。</p>
<p>c. 在 pooling 层做 attention，代替 max pooling。比如 Attention pooling，首先我们用 LSTM 学到一个比较好的句向量，作为 query，然后用 CNN 先学习到一个特征矩阵作为 key，再用 query 对 key 产生权重，进行 attention，得到最后的句向量。</p>
<h4 id="2lstmattention"><a class="markdownIt-Anchor" href="#2lstmattention"></a> <strong>2）LSTM+Attention</strong></h4>
<p>LSTM 内部有 Gate 机制，其中 input gate 选择哪些当前信息进行输入，forget gate 选择遗忘哪些过去信息，我觉得这算是一定程度的 Attention 了，而且号称可以解决长期依赖问题，实际上 LSTM 需要一步一步去捕捉序列信息，在长文本上的表现是会随着 step 增加而慢慢衰减，难以保留全部的有用信息。</p>
<p>LSTM 通常需要得到一个向量，再去做任务，常用方式有：</p>
<p>a. 直接使用最后的 hidden state（可能会损失一定的前文信息，难以表达全文）</p>
<p>b. 对所有 step 下的 hidden state 进行等权平均（对所有 step 一视同仁）。</p>
<p>c. Attention 机制，对所有 step 的 hidden state 进行加权，把注意力集中到整段文本中比较重要的 hidden state 信息。性能比前面两种要好一点，而方便可视化观察哪些 step 是重要的，但是要小心过拟合，而且也增加了计算量。</p>
<h4 id="3纯-attention"><a class="markdownIt-Anchor" href="#3纯-attention"></a> <strong>3）纯 Attention</strong></h4>
<p>Attention is all you need，没有用到 CNN/RNN，乍一听也是一股清流了，但是仔细一看，本质上还是一堆向量去计算 attention。本文提出了Transformer。Transformer 也可以视为一种自带Attention机制的RNN。它使用了问题、键、值三个向量，让权重的计算变得更加细致。</p>
<p>Transformer可以说是集近些年的研究之于大成。里面涉及到很多很多技术点，包括：</p>
<ul>
<li>Feed Forward Network</li>
<li>ResNet的思想</li>
<li>Positional Embedding 解决输入时序问题</li>
<li>Layer Normalization</li>
<li>Decoder中的Masked Self-Attention</li>
</ul>
<p><img data-src="transformer_resideual_layer_norm_3.png" alt="img"></p>
<img data-src="self-attention-output.png" alt="img" style="zoom:50%;">
<img data-src="self-attention-matrix-calculation.png" alt="img" style="zoom:50%;">
<img data-src="self-attention-matrix-calculation-2.png" alt="img" style="zoom:50%;">
<h3 id="5-相似度计算方式"><a class="markdownIt-Anchor" href="#5-相似度计算方式"></a> <strong>5. 相似度计算方式</strong></h3>
<p>在做 attention 的时候，我们需要计算 query 和某个 key 的分数（相似度），常用方法有：</p>
<p>1）点乘：最简单的方法， <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mo stretchy="false">(</mo><mi>q</mi><mo separator="true">,</mo><mi>k</mi><mo stretchy="false">)</mo><mo>=</mo><msup><mi>q</mi><mi>T</mi></msup><mi>k</mi></mrow><annotation encoding="application/x-tex">s(q,k)=q^Tk</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.035771em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span></p>
<p>2）矩阵相乘： <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mo stretchy="false">(</mo><mi>q</mi><mo separator="true">,</mo><mi>k</mi><mo stretchy="false">)</mo><mo>=</mo><msup><mi>q</mi><mi>T</mi></msup><mi>W</mi><mi>k</mi></mrow><annotation encoding="application/x-tex">s(q,k)=q^TWk</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.035771em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span></p>
<p>3）cos 相似度： $$s(q,k)=\frac{q^T}{||q||·||k||}$$</p>
<p>4）串联方式：把 q 和 k 拼接起来， $$s(q,k)=W[q;k]$$</p>
<p>5）用多层感知机也可以： $$s(q,k)=v^T_atanh(Wq+Uk)$$</p>
<h2 id="encoder-decoder模型结构"><a class="markdownIt-Anchor" href="#encoder-decoder模型结构"></a> Encoder-Decoder模型结构</h2>
<p>以机器翻译模型为例：<a href="https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html">原文</a></p>
<p><img data-src="seq2seq.png" alt="img"></p>
<p><img data-src="image-20200705230609732.png" alt="image-20200705230609732"></p>
<ul>
<li>Encoder的输入是句子中每个词对应的数字编号的序列，输出的是RNN每一个Cell的相应Output Vector（或是一次只输入一个词的编号，然后每次得到一个Output，最后拼成一个List）。其RNN的初始Hidden Layer是随机初始化（Random、全0）的。</li>
<li>Decoder的第一个输入是句子起始符<SOS>，数字编码可以为0，然后Hidden Layer使用Encoder的最后一个Hidden Layer Value初始化。每次只输入一个Input数字编号，然后下一次的Input或使用上次的预测结果，或是使用Output Label的相应值。前者被称作<em>Teacher Forcing</em>，后者是<em>Without Teacher Forcing</em>。</SOS></li>
<li>Attention是加在Decoder上的。Decoder 的input会先做embedding，之后么embedding和Hidden Layer参数Concate到一起，再过一个FC（<strong>过FC就相当于乘上了一个变换矩阵了</strong>）就得到了Attention。这个算出来的Attention再和Encoder的output做一个<code>torch.bmm</code>矩阵乘法（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mi>B</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi><mi mathvariant="normal">_</mi><mi>S</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo>∗</mo><mn>1</mn><mo>∗</mo><mi>L</mi><mi>e</mi><mi>n</mi><mi>g</mi><mi>t</mi><mi>h</mi><mo stretchy="false">]</mo><mo>∗</mo><mo stretchy="false">[</mo><mi>B</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi><mi mathvariant="normal">_</mi><mi>S</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo>∗</mo><mi>L</mi><mi>e</mi><mi>n</mi><mi>g</mi><mi>t</mi><mi>h</mi><mo>∗</mo><mi>H</mi><mi>i</mi><mi>d</mi><mi>d</mi><mi>e</mi><mi>n</mi><mi mathvariant="normal">_</mi><mi>S</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[Batch\_Size*1*Length]*[Batch\_Size*Length*Hidden\_Size]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">c</span><span class="mord mathnormal">h</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mord mathnormal">e</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">L</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">c</span><span class="mord mathnormal">h</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mord mathnormal">e</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">L</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mord mathnormal">e</span><span class="mclose">]</span></span></span></span>），得到一个向量([<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi><mi mathvariant="normal">_</mi><mi>S</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo>∗</mo><mn>1</mn><mo>∗</mo><mi>H</mi><mi>i</mi><mi>d</mi><mi>d</mi><mi>e</mi><mi>n</mi><mi mathvariant="normal">_</mi><mi>S</mi><mi>i</mi><mi>z</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">Batch\_Size*1*Hidden\_Size</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.00444em;vertical-align:-0.31em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">c</span><span class="mord mathnormal">h</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mord mathnormal">e</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.00444em;vertical-align:-0.31em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mord mathnormal">e</span></span></span></span>])，这个数值即为该input过了Attention后的值。该值再和embedding后的值([<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi><mi mathvariant="normal">_</mi><mi>S</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo>∗</mo><mn>1</mn><mo>∗</mo><mi>H</mi><mi>i</mi><mi>d</mi><mi>d</mi><mi>e</mi><mi>n</mi><mi mathvariant="normal">_</mi><mi>S</mi><mi>i</mi><mi>z</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">Batch\_Size*1*Hidden\_Size</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.00444em;vertical-align:-0.31em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">c</span><span class="mord mathnormal">h</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mord mathnormal">e</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.00444em;vertical-align:-0.31em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mord mathnormal">e</span></span></span></span>]) 使用Concate拼到一起，过一个FC，输出一个([<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi><mi mathvariant="normal">_</mi><mi>S</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo>∗</mo><mn>1</mn><mo>∗</mo><mi>H</mi><mi>i</mi><mi>d</mi><mi>d</mi><mi>e</mi><mi>n</mi><mi mathvariant="normal">_</mi><mi>S</mi><mi>i</mi><mi>z</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">Batch\_Size*1*Hidden\_Size</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.00444em;vertical-align:-0.31em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">c</span><span class="mord mathnormal">h</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mord mathnormal">e</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.00444em;vertical-align:-0.31em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mord mathnormal">e</span></span></span></span>])的向量，它便是施加了Attention后的Input。这里本质上使用了前面提到的权值计算方法中的 <strong>串联方式</strong>。</li>
<li>简单说，decoder的input和hidden layer只是用来计算encoder各个cell的output的权重的。每个output有着hidden_size维度，他们最终按照attention作为加权求和。或是说：<strong>Decoder中每一个Cell，去Encoder中寻找最相关的记忆。</strong></li>
</ul>
<h2 id="网络结构"><a class="markdownIt-Anchor" href="#网络结构"></a> 网络结构</h2>
<h3 id="embedding"><a class="markdownIt-Anchor" href="#embedding"></a> <code>Embedding</code></h3>
<p><code>torch.nn.Embedding(*num_embeddings: int*, *embedding_dim: int*)</code></p>
<blockquote>
<p>To summarize <code>num_embeddings</code> is total number of unique elements in the vocabulary, and <code>embedding_dim</code> is the size of each embedded vector once passed through the embedding layer. Therefore, you can have a tensor of 10+ elements, as long as each element in the tensor is in the range <code>[0, 9]</code>, because you defined a vocabulary size of 10 elements.</p>
</blockquote>
<p>即第一个数<code>num_embedding</code>指的是你的输入中有多少可能的值，或者说语料库的大小；第二个数<code>embedding_dim</code>指的是给定一个input（一个digit），输出几个digit。</p>
<h3 id="bmm"><a class="markdownIt-Anchor" href="#bmm"></a> <code>BMM</code></h3>
<p><code>torch.bmm(*input*, *mat2*, *deterministic=False*, *out=None*) → Tensor</code></p>
<blockquote>
<p>Performs a batch matrix-matrix product of matrices stored in <code>input</code> and <code>mat2</code>.</p>
<p><code>input</code> and <code>mat2</code> must be 3-D tensors each containing the same number of matrices.</p>
<p>If <code>input</code> is a <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>b</mi><mo>×</mo><mi>n</mi><mo>×</mo><mi>m</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(b \times n \times m)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">m</span><span class="mclose">)</span></span></span></span> tensor, <code>mat2</code> is a <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>b</mi><mo>×</mo><mi>m</mi><mo>×</mo><mi>p</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(b \times m \times p)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mclose">)</span></span></span></span> tensor, <code>out</code> will be a <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>b</mi><mo>×</mo><mi>n</mi><mo>×</mo><mi>p</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(b \times n \times p)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mclose">)</span></span></span></span>tensor.</p>
</blockquote>
<p>简单说，这个函数的作用是在不动batch维度的情况下对其他维度执行矩阵乘法。</p>
<h2 id="self-attention-与-general-attention在实现上的区别"><a class="markdownIt-Anchor" href="#self-attention-与-general-attention在实现上的区别"></a> Self-Attention 与 General Attention在实现上的区别</h2>
<p>Self Attention 本质上是乘上一个和输入向量需要加Attention的维度等长的向量（<code>nn.Parameter(torch.Tensor(1, D), requires_grad=True)</code>），并做矩阵相乘。如输入是一个长为L的句子，句子中每个词的Embedding长度是D， batch为B，即(B, L, D)， 那么若是要对句子的长度维度做Attention，则需要乘一个shape为(B, D, 1)的向量，得到的Output shape为(B, L, 1)。之后还需做softmax，句子长度mask，结果除以单词个数保证所有weight加起来等于一，然后再使用这个output点乘input，即可得到和input shape相同，但被加了Attention后的值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Attention</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; Pytorch self-attention layer code inspired from:</span></span><br><span class="line"><span class="string">    Link:</span></span><br><span class="line"><span class="string">        https://discuss.pytorch.org/t/self-attention-on-words-and-masking/5671/4</span></span><br><span class="line"><span class="string">    Original Web Page:</span></span><br><span class="line"><span class="string">        https://www.kaggle.com/dannykliu/lstm-with-attention-clr-in-pytorch</span></span><br><span class="line"><span class="string">    Usage:</span></span><br><span class="line"><span class="string">        In __init__():</span></span><br><span class="line"><span class="string">            self.atten1 = Attention(hidden_dim*2, batch_first=True) # 2 is bidrectional</span></span><br><span class="line"><span class="string">        In forward():</span></span><br><span class="line"><span class="string">            x, _ = self.atten1(x, lengths)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, hidden_size, batch_first=<span class="literal">True</span>, device=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Attention, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line">        self.batch_first = batch_first</span><br><span class="line">        <span class="keyword">if</span> device <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            self.device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.device = device</span><br><span class="line"></span><br><span class="line">        self.att_weights = nn.Parameter(</span><br><span class="line">            torch.Tensor(<span class="number">1</span>, hidden_size), requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        stdv = <span class="number">1.0</span> / np.sqrt(self.hidden_size)</span><br><span class="line">        <span class="keyword">for</span> weight <span class="keyword">in</span> self.att_weights:</span><br><span class="line">            nn.init.uniform_(weight, -stdv, stdv)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_mask</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs, lengths</span>):</span><br><span class="line">        <span class="keyword">if</span> self.batch_first:</span><br><span class="line">            batch_size, max_len = inputs.size()[:<span class="number">2</span>]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            max_len, batch_size = inputs.size()[:<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># apply attention layer</span></span><br><span class="line">        weights = torch.bmm(inputs,</span><br><span class="line">                            self.att_weights  <span class="comment"># (1, hidden_size)</span></span><br><span class="line">                            .permute(<span class="number">1</span>, <span class="number">0</span>)  <span class="comment"># (hidden_size, 1)</span></span><br><span class="line">                            .unsqueeze(<span class="number">0</span>)  <span class="comment"># (1, hidden_size, 1)</span></span><br><span class="line">                            <span class="comment"># (batch_size, hidden_size, 1)</span></span><br><span class="line">                            .repeat(batch_size, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">                            )</span><br><span class="line"></span><br><span class="line">        attentions = torch.softmax(F.relu(weights.squeeze()), dim=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># create mask based on the sentence lengths</span></span><br><span class="line">        mask = torch.ones(attentions.size(), requires_grad=<span class="literal">True</span>).to(self.device)</span><br><span class="line">        <span class="keyword">for</span> i, l <span class="keyword">in</span> <span class="built_in">enumerate</span>(lengths):  <span class="comment"># skip the first sentence</span></span><br><span class="line">            <span class="keyword">if</span> l &lt; max_len:</span><br><span class="line">                mask[i, l:] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># apply mask and renormalize attention scores (weights)</span></span><br><span class="line">        masked = attentions * mask</span><br><span class="line">        _sums = masked.<span class="built_in">sum</span>(-<span class="number">1</span>).unsqueeze(-<span class="number">1</span>)  <span class="comment"># sums per row</span></span><br><span class="line"></span><br><span class="line">        attentions = masked.div(_sums)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># apply attention weights</span></span><br><span class="line">        weighted = torch.mul(</span><br><span class="line">            inputs, attentions.unsqueeze(-<span class="number">1</span>).expand_as(inputs))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># get the final fixed vector representations of the sentences</span></span><br><span class="line">        representations = weighted.<span class="built_in">sum</span>(<span class="number">1</span>).squeeze()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> representations, attentions</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>而General Attention的本质则是一个FC（即一个映射矩阵）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">EncoderRNN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_size, hidden_size</span>):</span><br><span class="line">        <span class="built_in">super</span>(EncoderRNN, self).__init__()</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line"></span><br><span class="line">        self.embedding = nn.Embedding(input_size, hidden_size)</span><br><span class="line">        self.gru = nn.GRU(hidden_size, hidden_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span>, hidden</span>):</span><br><span class="line">        embedded = self.embedding(<span class="built_in">input</span>).view(<span class="number">1</span>, <span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line">        output = embedded</span><br><span class="line">        output, hidden = self.gru(output, hidden)</span><br><span class="line">        <span class="keyword">return</span> output, hidden</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">initHidden</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> torch.zeros(<span class="number">1</span>, <span class="number">1</span>, self.hidden_size, device=device)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AttnDecoderRNN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, hidden_size, output_size, dropout_p=<span class="number">0.1</span>, max_length=MAX_LENGTH</span>):</span><br><span class="line">        <span class="built_in">super</span>(AttnDecoderRNN, self).__init__()</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line">        self.output_size = output_size</span><br><span class="line">        self.dropout_p = dropout_p</span><br><span class="line">        self.max_length = max_length</span><br><span class="line"></span><br><span class="line">        self.embedding = nn.Embedding(self.output_size, self.hidden_size)</span><br><span class="line">        self.attn = nn.Linear(self.hidden_size * <span class="number">2</span>, self.max_length)</span><br><span class="line">        self.attn_combine = nn.Linear(self.hidden_size * <span class="number">2</span>, self.hidden_size)</span><br><span class="line">        self.dropout = nn.Dropout(self.dropout_p)</span><br><span class="line">        self.gru = nn.GRU(self.hidden_size, self.hidden_size)</span><br><span class="line">        self.out = nn.Linear(self.hidden_size, self.output_size)</span><br><span class="line">	</span><br><span class="line">    <span class="comment"># input: (1)</span></span><br><span class="line">    <span class="comment"># hidden: (1, D)</span></span><br><span class="line">    <span class="comment"># encoder_outputs: (L, D)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span>, hidden, encoder_outputs</span>):</span><br><span class="line">        embedded = self.embedding(<span class="built_in">input</span>).view(<span class="number">1</span>, <span class="number">1</span>, -<span class="number">1</span>) <span class="comment"># (1, 1, D)</span></span><br><span class="line">        embedded = self.dropout(embedded) <span class="comment"># (1, 1, D)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># (1, 2D) -&gt; (1, L)</span></span><br><span class="line">        attn_weights = F.softmax(</span><br><span class="line">            self.attn(torch.cat((embedded[<span class="number">0</span>], hidden[<span class="number">0</span>]), <span class="number">1</span>)), dim=<span class="number">1</span>) </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># (1, 1, L) x (1, L, D) -&gt; (1, 1, D)</span></span><br><span class="line">        attn_applied = torch.bmm(attn_weights.unsqueeze(<span class="number">0</span>),</span><br><span class="line">                                 encoder_outputs.unsqueeze(<span class="number">0</span>)) </span><br><span class="line"></span><br><span class="line">        output = torch.cat((embedded[<span class="number">0</span>], attn_applied[<span class="number">0</span>]), <span class="number">1</span>) <span class="comment"># (1, 2D)</span></span><br><span class="line">        output = self.attn_combine(output).unsqueeze(<span class="number">0</span>) <span class="comment"># (1, 1, D)</span></span><br><span class="line"></span><br><span class="line">        output = F.relu(output) <span class="comment"># (1, 1, D)</span></span><br><span class="line">        output, hidden = self.gru(output, hidden) <span class="comment"># (1, D)</span></span><br><span class="line"></span><br><span class="line">        output = F.log_softmax(self.out(output[<span class="number">0</span>]), dim=<span class="number">1</span>) <span class="comment"># (1, output_size)</span></span><br><span class="line">        <span class="keyword">return</span> output, hidden, attn_weights</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">initHidden</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> torch.zeros(<span class="number">1</span>, <span class="number">1</span>, self.hidden_size, device=device)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">teacher_forcing_ratio = <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH</span>):</span><br><span class="line">    encoder_hidden = encoder.initHidden()</span><br><span class="line"></span><br><span class="line">    encoder_optimizer.zero_grad()</span><br><span class="line">    decoder_optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    input_length = input_tensor.size(<span class="number">0</span>)</span><br><span class="line">    target_length = target_tensor.size(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)</span><br><span class="line"></span><br><span class="line">    loss = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> ei <span class="keyword">in</span> <span class="built_in">range</span>(input_length):</span><br><span class="line">        encoder_output, encoder_hidden = encoder(</span><br><span class="line">            input_tensor[ei], encoder_hidden)</span><br><span class="line">        encoder_outputs[ei] = encoder_output[<span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    decoder_input = torch.tensor([[SOS_token]], device=device)</span><br><span class="line"></span><br><span class="line">    decoder_hidden = encoder_hidden</span><br><span class="line"></span><br><span class="line">    use_teacher_forcing = <span class="literal">True</span> <span class="keyword">if</span> random.random() &lt; teacher_forcing_ratio <span class="keyword">else</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> use_teacher_forcing:</span><br><span class="line">        <span class="comment"># Teacher forcing: Feed the target as the next input</span></span><br><span class="line">        <span class="keyword">for</span> di <span class="keyword">in</span> <span class="built_in">range</span>(target_length):</span><br><span class="line">            decoder_output, decoder_hidden, decoder_attention = decoder(</span><br><span class="line">                decoder_input, decoder_hidden, encoder_outputs)</span><br><span class="line">            loss += criterion(decoder_output, target_tensor[di])</span><br><span class="line">            decoder_input = target_tensor[di]  <span class="comment"># Teacher forcing</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># Without teacher forcing: use its own predictions as the next input</span></span><br><span class="line">        <span class="keyword">for</span> di <span class="keyword">in</span> <span class="built_in">range</span>(target_length):</span><br><span class="line">            decoder_output, decoder_hidden, decoder_attention = decoder(</span><br><span class="line">                decoder_input, decoder_hidden, encoder_outputs)</span><br><span class="line">            topv, topi = decoder_output.topk(<span class="number">1</span>)</span><br><span class="line">            decoder_input = topi.squeeze().detach()  <span class="comment"># detach from history as input</span></span><br><span class="line"></span><br><span class="line">            loss += criterion(decoder_output, target_tensor[di])</span><br><span class="line">            <span class="keyword">if</span> decoder_input.item() == EOS_token:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    encoder_optimizer.step()</span><br><span class="line">    decoder_optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loss.item() / target_length</span><br></pre></td></tr></table></figure>
<h2 id="reference"><a class="markdownIt-Anchor" href="#reference"></a> Reference</h2>
<ol>
<li><a href="https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html">NLP FROM SCRATCH: TRANSLATION WITH A SEQUENCE TO SEQUENCE NETWORK AND ATTENTION</a></li>
<li><a href="https://easyai.tech/ai-definition/attention/">Attention 机制 – EasyAI</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/35739040">Attention用于NLP的一些小结</a></li>
<li><a href="https://github.com/EvilPsyCHo/Attention-PyTorch">Attention-PyTorch</a></li>
<li><a href="https://github.com/AuCson/PyTorch-Batch-Attention-Seq2seq/blob/master/attentionRNN.py">Pytorch Batch Attention Seq-2-Seq</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/47282410">Attention机制详解（二）——Self-Attention与Transformer</a></li>
<li><a href="https://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer</a></li>
<li><a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/">Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention)</a></li>
<li><a href="https://www.zhihu.com/question/68482809">知乎：目前主流的attention方法都有哪些？</a></li>
</ol>
]]></content>
      <tags>
        <tag>machine-learning</tag>
        <tag>deep-learning</tag>
        <tag>attention</tag>
      </tags>
  </entry>
  <entry>
    <title>自动生成和安装requirements.txt依赖</title>
    <url>/2018/05/14/auto-env/</url>
    <content><![CDATA[<p>在查看别人的Python项目时，经常会看到一个requirements.txt文件，里面记录了当前程序的所有依赖包及其精确版本号。这个文件有点类似与Rails的Gemfile。其作用是用来在另一台PC上重新构建项目所需要的运行环境依赖。<br>
requirements.txt可以通过pip命令自动生成和安装</p>
<h3 id="生成requirementstxt文件"><a class="markdownIt-Anchor" href="#生成requirementstxt文件"></a> 生成REQUIREMENTS.TXT文件</h3>
<p><code>pip freeze &gt; requirements.txt</code></p>
<span id="more"></span>
<h3 id="安装requirementstxt依赖"><a class="markdownIt-Anchor" href="#安装requirementstxt依赖"></a> 安装REQUIREMENTS.TXT依赖</h3>
<p><code>pip install -r requirements.txt</code></p>
<p>这是发现的一个蛮好用的东西，转载自<a href="http://lazybios.com/2015/06/how-to-use-requirementstxt-file-in-python/">链接</a></p>
<p>然而要提醒的一点是，这个自动生成的会把你所有的包都生成进去，如果只有几个特定的包需要特意安装，那么只留下这几个就好，剩下的直接删掉。</p>
]]></content>
      <tags>
        <tag>python</tag>
        <tag>machine-learning</tag>
      </tags>
  </entry>
  <entry>
    <title>How are optimizer.step() and loss.backward() related?</title>
    <url>/2018/04/11/backwardAndStep/</url>
    <content><![CDATA[<p>今天和同学讨论的时候发现这个地方知识存在漏洞，赶紧补了一波。问题就是optimizer.step() 和 loss.backward()这两个总是出现在一起的两个pytorch函数各自执行的功能。</p>
<h2 id="简单的说"><a class="markdownIt-Anchor" href="#简单的说"></a> 简单的说，</h2>
<ul>
<li>loss.backward()根据这一轮的loss计算出了网络中所有需要计算的导数</li>
<li>optimizer.step()根据你选择的优化器，使用上面👆loss.backward()计算出的各个导数更新了网络中的各个权值</li>
</ul>
<span id="more"></span>
<h2 id="以下为论坛原文"><a class="markdownIt-Anchor" href="#以下为论坛原文"></a> 以下为论坛原文：</h2>
<p><code>loss.backward()</code> computes <code>dloss/dx</code> for every parameter <code>x</code> which has <code>requires_grad=True</code>. These are accumulated into <code>x.grad</code> for every parameter <code>x</code>. In pseudo-code:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">x.grad += dloss/dx</span><br></pre></td></tr></table></figure>
<p><code>optimizer.step</code> updates the value of <code>x</code> using the gradient <code>x.grad</code>. For example, the SGD optimizer performs:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">x += -lr * x.grad</span><br></pre></td></tr></table></figure>
<p><code>optimizer.zero_grad()</code> clears <code>x.grad</code> for every parameter <code>x</code> in the optimizer. It’s important to call this before <code>loss.backward()</code>, otherwise you’ll accumulate the gradients from multiple passes.</p>
<p>If you have multiple losses (loss1, loss2) you can sum them and then call backwards once:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">loss3 = loss1 + loss2</span><br><span class="line">loss3.backward()</span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>machine-learning</tag>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>模型训练结束后自动整理记录各项参数</title>
    <url>/2018/05/14/auto-param-table/</url>
    <content><![CDATA[<h3 id="模型训练完成后要注意及时记录保存各种参数网络结构分类存档以供后续对比出各种结论但问题是填写一把这个表格太慢了而且太难受了"><a class="markdownIt-Anchor" href="#模型训练完成后要注意及时记录保存各种参数网络结构分类存档以供后续对比出各种结论但问题是填写一把这个表格太慢了而且太难受了"></a> 模型训练完成后，要注意及时记录保存各种参数，网络结构，分类存档以供后续对比出各种结论，但问题是填写一把这个表格太慢了而且太难受了。。</h3>
<p>废话不多说，上脚本：</p>
<span id="more"></span>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def write_summary(net, opt, summary_info):</span><br><span class="line">    current_time = datetime.datetime.now().strftime(&quot;%Y-%m-%d_%H:%M:%S&quot;)</span><br><span class="line">    prefix   = &#x27;./source/summaries/&#x27;+net.model_name</span><br><span class="line">    if not os.path.exists(prefix): os.mkdir(prefix)</span><br><span class="line">    sum_path = prefix + &#x27;/MiracleYoo_&#x27;+current_time+&#x27;_&#x27;+net.model_name+&#x27;_Model_Testing_Record_Form.md&#x27;</span><br><span class="line">    with codecs.open(&#x27;./config.py&#x27;, &#x27;r&#x27;, encoding=&#x27;utf-8&#x27;) as f:</span><br><span class="line">        raw_data = f.readlines()</span><br><span class="line">        configs  = &#x27;&#x27;</span><br><span class="line">        for line in raw_data:</span><br><span class="line">            if line.strip().startswith(&#x27;self.&#x27;):</span><br><span class="line">                configs += line.strip().strip(&#x27;self.&#x27;)+&#x27;\n&#x27;</span><br><span class="line"></span><br><span class="line">    content = &#x27;&#x27;&#x27;</span><br><span class="line"># Model Testing Record Form</span><br><span class="line">| Item Name        | Information |</span><br><span class="line">| ---------        | ----------- |</span><br><span class="line">| Model Name       | %s          |</span><br><span class="line">| Tester&#x27;s Name    | Miracle Yoo |</span><br><span class="line">| Author&#x27;s Nmae    | Miracle Yoo |</span><br><span class="line">| Test Time        | %s          |</span><br><span class="line">| Test Position    | %s          |</span><br><span class="line">| Training Epoch   | %d          |</span><br><span class="line">| Highest Test Acc | %.4f        |</span><br><span class="line">| Loss of highest Test Acc| %.4f |</span><br><span class="line">| Last epoch test acc   | %.4f   |</span><br><span class="line">| Last epoch test loss  | %.4f   |</span><br><span class="line">| Last epoch train acc  | %.4f   |</span><br><span class="line">| Last epoch train loss | %.4f   |</span><br><span class="line">| Train Dataset Path    | %s     |</span><br><span class="line">| Test Dataset Path     | %s     |</span><br><span class="line">| Class Number     | %d          |</span><br><span class="line">| Framwork         | Pytorch     |</span><br><span class="line">| Basic Method     | Classify    |</span><br><span class="line">| Input Type       | Char        |</span><br><span class="line">| Criterion        | CrossEntropy|</span><br><span class="line">| Optimizer        | %s          |</span><br><span class="line">| Learning Rate    | %.4f        |</span><br><span class="line">| Embedding dimension   | %d     |</span><br><span class="line">| Data Homogenization   | True   |</span><br><span class="line">| Pretreatment|Remove punctuation|</span><br><span class="line">| Other Major Param |            |</span><br><span class="line">| Other Operation   |            |</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## Configs</span><br><span class="line">\```</span><br><span class="line">%s</span><br><span class="line">\```</span><br><span class="line"></span><br><span class="line">## Net Structure</span><br><span class="line">\```</span><br><span class="line">%s</span><br><span class="line">\```</span><br><span class="line">    &#x27;&#x27;&#x27;%(</span><br><span class="line">        net.model_name,</span><br><span class="line">        current_time,</span><br><span class="line">        opt.TEST_POSITION,</span><br><span class="line">        summary_info[&#x27;total_epoch&#x27;],</span><br><span class="line">        summary_info[&#x27;best_acc&#x27;],</span><br><span class="line">        summary_info[&#x27;best_acc_loss&#x27;],</span><br><span class="line">        summary_info[&#x27;ave_test_acc&#x27;],</span><br><span class="line">        summary_info[&#x27;ave_test_loss&#x27;],</span><br><span class="line">        summary_info[&#x27;ave_train_acc&#x27;],</span><br><span class="line">        summary_info[&#x27;ave_train_loss&#x27;],</span><br><span class="line">        os.path.basename(opt.TRAIN_DATASET_PATH),</span><br><span class="line">        os.path.basename(opt.TEST_DATASET_PATH),</span><br><span class="line">        opt.NUM_CLASSES,</span><br><span class="line">        opt.OPTIMIZER,</span><br><span class="line">        opt.LEARNING_RATE,</span><br><span class="line">        opt.EMBEDDING_DIM,</span><br><span class="line"></span><br><span class="line">        configs.strip(&#x27;\n&#x27;),</span><br><span class="line">        str(net)</span><br><span class="line">    )</span><br><span class="line">    with codecs.open(sum_path, &#x27;w+&#x27;, encoding=&#x27;utf-8&#x27;) as f:</span><br><span class="line">        f.writelines(content)</span><br></pre></td></tr></table></figure>
<p>记着把上面```前面的\去掉食用~<br>
这个表不全，后面会有补充，内容也可以根据你自己模型和项目的具体情况修改。</p>
<h2 id="演示效果如下"><a class="markdownIt-Anchor" href="#演示效果如下"></a> 演示效果如下：</h2>
<h1 id="model-testing-record-form"><a class="markdownIt-Anchor" href="#model-testing-record-form"></a> Model Testing Record Form</h1>
<table>
<thead>
<tr>
<th>Item Name</th>
<th>Information</th>
</tr>
</thead>
<tbody>
<tr>
<td>Model Name</td>
<td>TextCNNInc</td>
</tr>
<tr>
<td>Tester’s Name</td>
<td>Miracle Yoo</td>
</tr>
<tr>
<td>Author’s Nmae</td>
<td>Miracle Yoo</td>
</tr>
<tr>
<td>Test Time</td>
<td>2018-05-13_15:24:43</td>
</tr>
<tr>
<td>Test Position</td>
<td>Gangge Server</td>
</tr>
<tr>
<td>Training Epoch</td>
<td>100</td>
</tr>
<tr>
<td>Highest Test Acc</td>
<td>0.7102</td>
</tr>
<tr>
<td>Loss of highest Test Acc</td>
<td>0.1721</td>
</tr>
<tr>
<td>Last epoch test acc</td>
<td>0.6706</td>
</tr>
<tr>
<td>Last epoch test loss</td>
<td>0.1721</td>
</tr>
<tr>
<td>Last epoch train acc</td>
<td>0.8904</td>
</tr>
<tr>
<td>Last epoch train loss</td>
<td>1.2189</td>
</tr>
<tr>
<td>Train Dataset Path</td>
<td>knowledge&amp;log_data.txt</td>
</tr>
<tr>
<td>Test Dataset Path</td>
<td>yibot_two_year_test.txt</td>
</tr>
<tr>
<td>Class Number</td>
<td>2411</td>
</tr>
<tr>
<td>Framwork</td>
<td>Pytorch</td>
</tr>
<tr>
<td>Basic Method</td>
<td>Classify</td>
</tr>
<tr>
<td>Input Type</td>
<td>Char</td>
</tr>
<tr>
<td>Criterion</td>
<td>CrossEntropy</td>
</tr>
<tr>
<td>Optimizer</td>
<td>Adam</td>
</tr>
<tr>
<td>Learning Rate</td>
<td>0.0010</td>
</tr>
<tr>
<td>Embedding dimension</td>
<td>512</td>
</tr>
<tr>
<td>Data Homogenization</td>
<td>True</td>
</tr>
<tr>
<td>Pretreatment</td>
<td>Remove punctuation</td>
</tr>
<tr>
<td>Other Major Param</td>
<td></td>
</tr>
<tr>
<td>Other Operation</td>
<td></td>
</tr>
</tbody>
</table>
<h2 id="configs"><a class="markdownIt-Anchor" href="#configs"></a> Configs</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">USE_CUDA           = torch.cuda.is_available()</span><br><span class="line">RUNNING_ON_SERVER  = False</span><br><span class="line">NET_SAVE_PATH      = &quot;./source/trained_net/&quot;</span><br><span class="line">TRAIN_DATASET_PATH = &quot;../database/test_train/knowledge&amp;log_data.txt&quot;</span><br><span class="line">TEST_DATASET_PATH  = &quot;../database/test_train/yibot_two_year_test.txt&quot;</span><br><span class="line">NUM_EPOCHS         = 100</span><br><span class="line">BATCH_SIZE         = 8</span><br><span class="line">TOP_NUM            = 4</span><br><span class="line">NUM_WORKERS        = 1</span><br><span class="line">IS_TRAINING        = True</span><br><span class="line">ENSEMBLE_TEST      = False</span><br><span class="line">LEARNING_RATE      = 0.001</span><br><span class="line">RE_TRAIN           = False</span><br><span class="line">TEST_POSITION      = &#x27;Gangge Server&#x27;</span><br><span class="line">OPTIMIZER          = &#x27;Adam&#x27;</span><br><span class="line">USE_CHAR           = True</span><br><span class="line">USE_WORD2VEC       = True</span><br><span class="line">NUM_CLASSES        = 1890#len(get_labels2idx()[0])</span><br><span class="line">EMBEDDING_DIM      = 512</span><br><span class="line">VOCAB_SIZE         = 20029</span><br><span class="line">CHAR_SIZE          = 3403</span><br><span class="line">LSTM_HID_SIZE      = 512</span><br><span class="line">LSTM_LAYER_NUM     = 2</span><br><span class="line">TITLE_DIM          = 200</span><br><span class="line">SENT_LEN           = 20</span><br><span class="line">LINER_HID_SIZE     = 2000</span><br><span class="line">KERNEL_SIZE        = [1,2,3,4,5]</span><br><span class="line">DILA_TITLE_DIM     = 20</span><br></pre></td></tr></table></figure>
<h2 id="net-structure"><a class="markdownIt-Anchor" href="#net-structure"></a> Net Structure</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">TextCNNInc(</span><br><span class="line">  (encoder): Embedding(3394, 512)</span><br><span class="line">  (question_convs): ModuleList(</span><br><span class="line">    (0): Sequential(</span><br><span class="line">      (0): Conv1d(512, 200, kernel_size=(1,), stride=(1,))</span><br><span class="line">      (1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True)</span><br><span class="line">      (2): ReLU(inplace)</span><br><span class="line">      (3): MaxPool1d(kernel_size=20, stride=20, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">    )</span><br><span class="line">    (1): Sequential(</span><br><span class="line">      (0): Conv1d(512, 200, kernel_size=(3,), stride=(1,))</span><br><span class="line">      (1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True)</span><br><span class="line">      (2): ReLU(inplace)</span><br><span class="line">      (3): MaxPool1d(kernel_size=18, stride=18, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">    )</span><br><span class="line">    (2): Sequential(</span><br><span class="line">      (0): Conv1d(512, 200, kernel_size=(1,), stride=(1,))</span><br><span class="line">      (1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True)</span><br><span class="line">      (2): ReLU(inplace)</span><br><span class="line">      (3): Conv1d(200, 200, kernel_size=(3,), stride=(1,))</span><br><span class="line">      (4): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True)</span><br><span class="line">      (5): ReLU(inplace)</span><br><span class="line">      (6): MaxPool1d(kernel_size=18, stride=18, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">    )</span><br><span class="line">    (3): Sequential(</span><br><span class="line">      (0): Conv1d(512, 200, kernel_size=(3,), stride=(1,))</span><br><span class="line">      (1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True)</span><br><span class="line">      (2): ReLU(inplace)</span><br><span class="line">      (3): Conv1d(200, 200, kernel_size=(5,), stride=(1,))</span><br><span class="line">      (4): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True)</span><br><span class="line">      (5): ReLU(inplace)</span><br><span class="line">      (6): MaxPool1d(kernel_size=14, stride=14, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (fc): Sequential(</span><br><span class="line">    (0): Linear(in_features=800, out_features=2000, bias=True)</span><br><span class="line">    (1): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True)</span><br><span class="line">    (2): ReLU(inplace)</span><br><span class="line">    (3): Dropout(p=0.5)</span><br><span class="line">    (4): Linear(in_features=2000, out_features=2411, bias=True)</span><br><span class="line">  )</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>喵喵喵~</p>
]]></content>
      <tags>
        <tag>python</tag>
        <tag>machine-learning</tag>
      </tags>
  </entry>
  <entry>
    <title>What is a pipeline and baseline in machine learning algorithms?</title>
    <url>/2018/04/07/baseline-pipeline/</url>
    <content><![CDATA[<p><strong>This article is from Quora, and the original link is <a href="https://www.quora.com/What-is-a-pipeline-and-baseline-in-machine-learning-algorithms">here</a>.</strong></p>
<h2 id="先简单概括一下原文"><a class="markdownIt-Anchor" href="#先简单概括一下原文"></a> 先简单概括一下原文：</h2>
<ul>
<li>Pipeline指的是一整套流程，从得到数据，加工成能用的数据，通过一套算法进行训练直至最终输出的这个完整过程。</li>
<li>而与此相对，baseline指的是一个用作对比的非常simple的方案，通常是以一些市面上流行的基础算法为核心的方案，其作用就是为了让你有一个参照，看看自己到底做到了<strong>多好</strong></li>
</ul>
<span id="more"></span>
<h2 id="下面是prasoon-goyal大佬的原答案"><a class="markdownIt-Anchor" href="#下面是prasoon-goyal大佬的原答案"></a> 下面是<a href="https://www.quora.com/profile/Prasoon-Goyal">Prasoon Goyal</a>大佬的原答案：</h2>
<p>A machine learning algorithm usually takes clean (and often tabular) data, and learns some pattern in the data, to make predictions on new data. However, when ML is used in real-world applications, the raw information that you get from the real-world is often not ready to be fed into the ML algorithm. So you need to preprocess that information to create input data for the ML algorithm. Similarly, the output of the ML algorithm by itself is just some number in software, which will need to be processed to perform some action in the real-world.</p>
<p>Let’s take the example of self-driving cars. Say you have cameras mounted on a car, and you want to predict the optimal steering angle given the images from the camera and the speed of the car. Now once you have collected the data, you will have a set of images from the camera, and you will have the speed of the car at various time points. You will need to align the images with the speed of the car based on the timestamp. Secondly, if you are learning in the supervised setting, you would also have recorded the steering angles of the human drivers while collecting the above data. Again, these need to be aligned with the images and the speed data according to timestamp. What you have done so far is preprocessing — there is no machine learning yet. Now comes the machine learning part — say you train a neural network that is fed these images and corresponding speeds and is trained to predict the optimal steering angle. This is you ML algorithm. Once you’ve trained it, for new data, you perform the preprocessing by aligning camera images and speeds, and feed to the neural network. The neural network outputs a steering angle on a computer screen. Now you need to take this output and actually rewire your car in a way such that the steering wheel rotates based on this output. This part is again not ML.</p>
<p>So this entire framework from converting raw data to data usable by ML algorithm, training an ML algorithm, and finally using the output of the ML algorithm to perform actions in the real-world is the <strong>pipeline</strong>. It is called a pipeline because it is analogous to physical pipelines — just as a liquid passes through one pipe, entering the next, sequentially, our data goes through one stage, entering into the next, sequentially.</p>
<hr>
<p>Baseline, on the other hand, is a totally unrelated concept. Let’s say you want to do part-of-speech tagging — given an English text, tag each word as noun, pronoun, verb, etc. Note that this is non-trivial because a lot of words could belong to several parts-of-speech, based on the context, e.g. <em>building</em>.</p>
<p>Now, you train an ML model, and you get an accuracy of 80%. Is that good? You can’t answer that question unless you compare your accuracy to something else. That “something else” is the <strong>baseline</strong>. Sometimes, you pick a simple baseline. So for the example above, a simple baseline could be to just tag each word with its most common part-of-speech. Or you can use existing popular algorithms for that task as the baseline. The choice of the baseline depends on your objective. The goal is to either beat the baseline, if the goal of your work is to improve accuracy, or get results comparable to the baseline while improving some other aspect of the algorithm (like training time, prediction time, memory usage, etc.)</p>
]]></content>
      <tags>
        <tag>machine-learning</tag>
      </tags>
  </entry>
  <entry>
    <title>《没有色彩的多琦作和他的巡礼之年》读后感</title>
    <url>/2019/07/16/book-review-ironaki/</url>
    <content><![CDATA[<p>当世界各国的书，或更准确的说，小说，齐聚一堂时，我才如此清晰的意识到，文化认同感是多么的重要，以及，日本的文学与文化竟如此深刻地影响了我灵魂深处的某些东西，就宛如地震过后的路面一般，就那么存在着，仿佛它一开始就在那里。很难说这种影响是向着什么方向的，如果有方向的话。当然，也无从得知这种影响有没有可能被崭新地出现在我面前的其他文化所碾平，重新浇上沥青，再刻蚀。但只有一点是如此明亮而通透，就是作为“历史”，这种影响已经实实在在地改变了很多东西的形状，孕育了一众欢愉与烦恼，并将持续地以某种可见或不可见的方式决定着许多尚未诞生于此的事物。</p>
<span id="more"></span>
<p>意外的拿起这本村上君的书时，心中是着实充满着惊喜与意外，为又一次的相遇而感动。村上书中的人物总是能给人一种奇异而美妙的亲近感，总是能在意外的地方引起人的共鸣。这些人物性格各异，有着大相径庭的职业，其中的大多都是在终归和我无缘的地方做着那些理所当然要有人做但却从未被我考虑过的工作。奇怪的是，他们总能带给我一种“生活本应是这样”的近乎玄幻的体验。作经历的生活，作体验过的困苦与纠结，作感受过到的那般颜色稀疏、静如止水、只有不知为何泛起的薄暮与绝对的黑暗交替的日日夜夜，似乎都能像是立体电影一般拼命地从身体的每个毛孔渗入进来，不知不觉间，读者已彻底变成了事件的参与者，向前翻页的动作也具象化为了在混沌与希望中向前迈进的步子，只是单纯的希望触摸即将到来的时间，如同沙子从掌隙间流过那般自然。</p>
<p>作的巡礼也成了我继续向前探寻的自然延伸，但其间我的心理也在不断发生着变化。从一开始的急不可耐试图知道十六年前究竟发生过什么，到渐渐静下心来体味作当下那建立在尘封的记忆的盖子之上的平静生活；从试图对绿川所言进行逻辑与理性的考量，到把这当做一个单纯的故事，或曰事实来接受；从期待后文中找到强奸与勒死白根柚木的两个亦或是同一个凶手，到放弃对凶手本身的追溯，而是将感情逐渐聚焦于即将发生的故事、生者的自省上以及这个“事实”造成的影响上去了。事件已经发生，而它是怎么发生的，究竟是一个无差别杀人犯还是一个与白相识的密友做出了这般事端，都已经成为了名副其实的历史，而历史不是由点、由少数人组成的，而是由存活其间的一条条闪光的生命之线编织而成。不过一个事件的发生会将许多杂糅的东西聚合在一起，成为一个有机的整体。这包括事件成为事件之前的诸多些微的原因与征兆、事件发生这个事实与其过程、事件不同层次、不同作用的后续影响以及相关者心绪的点滴变化。而观察、追溯，甚至解开后用放大镜研究这些线束则是远为有趣的。</p>
<p>“我们可以给记忆盖上盖子，但是绝不可能掩盖历史。”</p>
<p>“说不定里面还有彻底凝固、再也打不开的盖子。”</p>
<p>喜欢极了这种对话，正如我对这种沉浸式体验的喜爱。当一个旁观者总会让人多多少少变得自傲，错误地认为自己无所不能，但作为一个亲历者，能体会到的东西则大不相同。一个显著的区别是没有一位令人尊敬的上帝在一旁耳语着告诉你一些或关键或无关紧要的信息，你知道的并不比你冯依的人物更多。有些东西是永远无从得知的，比如灰田最终为何突然消失，而绿川在演奏前煞有介事地放在钢琴上的小包里到底包裹着什么秘密，或是白究竟怀着什么样的心态见证着小团体同自己预想的一样逐渐走向分崩离析，又为何在遭受灾难后选择嫁祸于作，以及后面缘何只身一人来到了一座崭新的城市。当然，文中充满了暗示，这些暗示可以帮助我理解，或单纯的揣测这绵密繁复的生命之线中刻蚀着的纹样，却永远只能止步于揣测。我很无力的发现，我能做的只是接受一个又一个的假设，而这则源于令人绝望的信息不足。提前离开的白如理所当然的一般无法再吐露出任何信息，而我能做的，只是呆呆地凝望着这个尽最大努力拼出的、残破依旧的拼图，以及走好后面的路。</p>
<p>所有的一切都源自于这个多彩的小团体。我是先看了书籍的简介再开读的。这件事并不一定会发生，只是偶然读了简介，没有更多或更少。起先我对这个讲述小团体的主题是多少有些反感的，毕竟，我在绝大多数时候都是独立的，虽不像作一般完全没有朋友，自视为一个空荡荡的容器等待别人加入，但也长期保持并享受着这种“相对孤独”的状态。需要时，也会约一二朋友小聚，但对三人以上的场合，虽并非难以应对，但若非必要，倒也绝不会自发组织。所以我对人在“小团体”中的体会实际上是相对缺乏的，即使我并没有因此感到丝毫的不便。这种空缺就像繁忙路口中央突兀的出现的一口无盖之井，由于大家默认都会绕行，所以大抵也都对此视而不见，久而久之既不会感觉不便，也不会觉得有什么损失，但井就在那里。另外，小团体会让人不由自主的和“排他”“对立”，甚至“欺凌”联系在一起，这个发音总的来说还是令人不那么愉快的。但说来意外的是，就在不久前的旅行中，我实打实的体验了一把这种四五个人长期保持相同步调集体行动本身带来的实在感、愉悦感与安心感，也由衷的认同村上笔下的那种每个人都有自己角色，且愿将自己最好的一面贡献给小团体这种行为本身带来的“复杂的化学反应”的甘美。不得不承认，那确是十分美妙的事情。短短几天的经历便彻底颠覆了我之前的刻板印象，更何况作他们是将自己的几乎整个最为美好的青春特意抽出、然后共享的亲密无间小团体。</p>
<p>“到了后期，小团体存在的目标就是维持其存续”。书中大致有这样一句。为了这个存续本身，大家都默认了一些规则，甚至包括扼杀心中逐渐萌芽的、写作恬淡，读作浓烈的相互间的爱慕之情。黑是一个令我倍感痛心的角色。她似乎总是藏在白投下的阴影里，作为一个陪衬使得存在愈发突出着白的存在。五人组合中的三个男生无疑都是暗地里喜欢着白的，尽管作很肯定如果黑对他告白，他一定会很自然地接受，并开始一段不一定会结果，但注定有着其独特色彩的恋情。但没人愿意打破这个小团体的稳定性。也没人愿意站出来，道出小团体有一天终将进入新的阶段这一事实。分离才是真正的永恒，迟到的分离并不会带来永久，反而会如在作画终了也不愿抬起的画笔一般，最终将完美的画面浸淫成一种面目狰狞的形状。</p>
<p>本作对死亡边缘的景象描写的也十分真切，真切到栩栩如生，仿佛自己真的在人生的某一阶段受到过此般打击，一蹶不振到静默无声。“环顾四周，是一片布满岩石的荒凉大地。没有一滴水，不长一棵草。没有颜色，也没有像样的光。既没有太阳，又没有月亮和星星。只怕也没有方向。唯有不明底细的薄暮与深不见底的黑暗，隔一定时间交替轮换。对于拥有意识的人来说，那是终极的边境。但同时那里又是丰润之地。”作最终还是游出了那片苍茫夜色中的大海，即使他被人从甲板上唐突又不留情面地扔下了海，即使甚至没人知道他的消失。在孤独的终点，作看到的不仅仅是无边的黑暗，他也看到了那丰润之地。游泳，似乎使他的灵魂更加健壮。在感情没有经历过巨大的震动，不会轻易对何者动情这一点我也可以再作身上找到些许自己的影子。尽管近在咫尺，却终究无法拿出十分的激情去追逐，去渴求。如果说作是因为大二时被小团体抛弃所带来巨大的创伤所致，那自己又是缘何？静静期待着一个冲动，一个在特别的时光里突然涌现出的“巡礼之年”的冲动。</p>
<p>愿你我终有一天能找寻到可以互相放心地存放心灵与记忆碎片的对方，以及愿终有一天能够品味并享受孤独与陪伴各自独特的醇香。</p>
]]></content>
      <tags>
        <tag>book-review</tag>
      </tags>
  </entry>
  <entry>
    <title>MATLAB中创建高维数组</title>
    <url>/2018/08/23/build-3d-mat/</url>
    <content><![CDATA[<h1 id="问题"><a class="markdownIt-Anchor" href="#问题"></a> 问题</h1>
<p>如何在MATLAB中创建一个三维（更高维度）数组。</p>
<h1 id="解决方案"><a class="markdownIt-Anchor" href="#解决方案"></a> 解决方案</h1>
<ol>
<li>
<p>使用下标（循环）创建三维数组</p>
<span id="more"></span>
<h3 id="代码"><a class="markdownIt-Anchor" href="#代码"></a> 代码</h3>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="number">2</span></span><br><span class="line">	<span class="keyword">for</span> <span class="built_in">j</span>=<span class="number">1</span>:<span class="number">2</span></span><br><span class="line">		<span class="keyword">for</span> k=<span class="number">1</span>:<span class="number">2</span></span><br><span class="line">			A(<span class="built_in">i</span>,<span class="built_in">j</span>,k)=<span class="built_in">i</span>+<span class="built_in">j</span>+k;</span><br><span class="line">		<span class="keyword">end</span></span><br><span class="line">	<span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p>使用低维数组创建三维数组</p>
<p>先输入一个二维数组，然后通过第三维数组与其关系生成第三维数组。</p>
<h3 id="代码-2"><a class="markdownIt-Anchor" href="#代码-2"></a> 代码</h3>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">D2=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>;<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>;<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>];</span><br><span class="line">D3(:,:,<span class="number">1</span>)=D2;</span><br><span class="line">D3(:,:,<span class="number">2</span>)=<span class="number">2</span>*D2;</span><br><span class="line">D3(:,:,<span class="number">3</span>)=<span class="number">3</span>*D2;</span><br></pre></td></tr></table></figure>
<h3 id="查看结果"><a class="markdownIt-Anchor" href="#查看结果"></a> 查看结果</h3>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">输入：D2 并按【Enter】可以查看输入的二维数组。</span><br><span class="line">得到：</span><br><span class="line">D2 =</span><br><span class="line">     <span class="number">1</span>     <span class="number">2</span>     <span class="number">3</span></span><br><span class="line">     <span class="number">4</span>     <span class="number">5</span>     <span class="number">6</span></span><br><span class="line">     <span class="number">7</span>     <span class="number">8</span>     <span class="number">9</span></span><br><span class="line">输入：D3 并按【Enter】可以查看生成的三维数组。</span><br><span class="line">D3(:,:,<span class="number">1</span>) =</span><br><span class="line">     <span class="number">1</span>     <span class="number">2</span>     <span class="number">3</span></span><br><span class="line">     <span class="number">4</span>     <span class="number">5</span>     <span class="number">6</span></span><br><span class="line">     <span class="number">7</span>     <span class="number">8</span>     <span class="number">9</span></span><br><span class="line">D3(:,:,<span class="number">2</span>) =</span><br><span class="line">    <span class="number">2</span>     <span class="number">4</span>     <span class="number">6</span></span><br><span class="line">     <span class="number">8</span>    <span class="number">10</span>    <span class="number">12</span></span><br><span class="line">    <span class="number">14</span>    <span class="number">16</span>    <span class="number">18</span></span><br><span class="line">D3(:,:,<span class="number">3</span>) =</span><br><span class="line">     <span class="number">3</span>     <span class="number">6</span>     <span class="number">9</span></span><br><span class="line">    <span class="number">12</span>    <span class="number">15</span>    <span class="number">18</span></span><br><span class="line">    <span class="number">21</span>    <span class="number">24</span>    <span class="number">27</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p>使用创建函数创建三维数组</p>
<p>使用<code>cat</code>命令来创建高维数组。Cat命令的格式为<code>C=cat（dim,A1,A2,A3,A4……）</code>其中dim表示的是创建数组的维度，A1,A2,A3,A4表示的是各维度上的数组。</p>
<h3 id="代码-3"><a class="markdownIt-Anchor" href="#代码-3"></a> 代码</h3>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">D2=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>;<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>;<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>];</span><br><span class="line">C=<span class="built_in">cat</span>(<span class="number">3</span>,D2,<span class="number">2</span>D2,<span class="number">3</span>D2);</span><br></pre></td></tr></table></figure>
<h3 id="程序结果"><a class="markdownIt-Anchor" href="#程序结果"></a> 程序结果</h3>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">输入：C(:,:,<span class="number">1</span>) 并按【Enter】</span><br><span class="line">得到：</span><br><span class="line"><span class="built_in">ans</span> =</span><br><span class="line">     <span class="number">1</span>     <span class="number">2</span>     <span class="number">3</span></span><br><span class="line">     <span class="number">4</span>     <span class="number">5</span>     <span class="number">6</span></span><br><span class="line">     <span class="number">7</span>     <span class="number">8</span>     <span class="number">9</span></span><br><span class="line">输入：C(:,:,<span class="number">2</span>) 并按【Enter】</span><br><span class="line">得到：</span><br><span class="line"><span class="built_in">ans</span> =</span><br><span class="line">     <span class="number">2</span>     <span class="number">4</span>     <span class="number">6</span></span><br><span class="line">     <span class="number">8</span>    <span class="number">10</span>    <span class="number">12</span></span><br><span class="line">    <span class="number">14</span>    <span class="number">16</span>    <span class="number">18</span></span><br><span class="line">输入：C(:,:,<span class="number">3</span>) 并按【Enter】</span><br><span class="line">得到：</span><br><span class="line"><span class="built_in">ans</span> =</span><br><span class="line">     <span class="number">3</span>     <span class="number">6</span>     <span class="number">9</span></span><br><span class="line">    <span class="number">12</span>    <span class="number">15</span>    <span class="number">18</span></span><br><span class="line">    <span class="number">21</span>    <span class="number">24</span>    <span class="number">27</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p>利用【repmat】命令以及【reshape】命令在生成高维数组</p>
</li>
</ol>
]]></content>
      <tags>
        <tag>matlab</tag>
      </tags>
  </entry>
  <entry>
    <title>相机校准 相机标定 Intrinsic/Extrinsic Calibration详解 绝对Extrinsic矩阵测得实操 Event Camera/DVS</title>
    <url>/2022/11/04/camera-calibration/</url>
    <content><![CDATA[<p>先提一下本文的发表理由。因为实验需要用到一个DAVIS 346的Event Camera，且项目需要通过Motion Capture（Mocap）得到人体的3D准确标定，所以就研究了一下相机的Intrinsic和绝对Extrinsic标定。令人吃惊的是，网上其实并没有太多关于如何通过实验方法标定得到相对于坐标原点（O点，Origin）的Extrinsic Matrix的讲解，尤其是缺少中文教程。于是我就把参考各种英文资料（主要是一些大学的slides和有关采集Mocap数据集的文献）总结的一些理论推导和实验方法，以及实际能用的代码整理得到了本文。</p>
<span id="more"></span>
<p>首先是几张非常重要的Slides，后面都会refer到，可以先自行熟悉下。另外，本篇不是100%从零开始的教程，篇幅限制并无法展开所有的细节，若想深度理解，请自行结合几个大学（CMU，Stanford）相应的Slides一起学习。</p>
<img data-src="image-20221021152707045-1667622796441-1.png" alt="image-20221021152707045" style="zoom:33%;">
<p><img data-src="image-20221021165722788-1667622796442-2.png" alt="image-20221021165722788"></p>
<h2 id="coordinates"><a class="markdownIt-Anchor" href="#coordinates"></a> Coordinates</h2>
<ul>
<li>在整个相机的投影与校准过程中，一共涉及3个坐标系。它们分别是：
<ol>
<li>世界坐标系：以空间中某点为原点建立欧拉坐标系，设定xyz方向后形成的坐标系。</li>
<li>相机坐标系。该坐标系的原点是相机的焦点。焦点一般在相机内部，也可能落在的相机外部，这取决于focal length。坐标系的指向：x和y就是相平面的横纵坐标方向（相机视角方向），z是与xy平面垂直的方向，亦即镜头指向的前方。</li>
<li>图像坐标系（也可以分成两个：图像坐标系(m)和像素坐标系(pixel)）。值得注意的一点是每个像素并不是真正的一个点，pixel坐标系所代表的整数值是每个像素点的中心。</li>
</ol>
</li>
<li>考虑功能性，还有一个同质坐标系，用于实际运算。</li>
</ul>
<img data-src="image-20221021144051423-1667622796442-3.png" alt="image-20221021144051423" style="zoom: 25%;">
<h2 id="intrinsic"><a class="markdownIt-Anchor" href="#intrinsic"></a> Intrinsic</h2>
<ul>
<li>
<p>理想状况下（无Skewness和Distortion），Intrinsic 矩阵Encode的信息有：Focal Length、Image Sensor的长宽（in pixel），每像素代表的米数(pixel/m)，也即相机的分辨率。</p>
</li>
<li>
<p>非理想情况下，Skewness和Distortion也会被放到Intrinsic中。</p>
</li>
<li>
<p>关于当提高/降低分辨率时候的Intrinsic变化：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo separator="true">,</mo><mi>l</mi><mo separator="true">,</mo><msub><mi>c</mi><mi>x</mi></msub><mo separator="true">,</mo><msub><mi>c</mi><mi>y</mi></msub></mrow><annotation encoding="application/x-tex">k,l,c_x,c_y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>都要乘以分辨率提高的系数。</p>
<p><img data-src="image-20221026155238653-1667622796442-4.png" alt="image-20221026155238653"></p>
</li>
<li>
<p>参见Intrinsic的计算过程，由于计算时已经考虑了目标物体深度对成像位置的影响，所以Intrinsic其实是包含了透视(perspective)信息的。</p>
</li>
<li>
<p>Intrinsic可使相机坐标系转化为图片坐标系。</p>
</li>
</ul>
<h2 id="extrinsic"><a class="markdownIt-Anchor" href="#extrinsic"></a> Extrinsic</h2>
<ul>
<li>
<p>Extrinsic 可以看作是两个矩阵写在了一起：旋转矩阵R和平移矩阵T。前三列是R，最后一列是T。 其实，虽然经常写作<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mi>R</mi><mi mathvariant="normal">∣</mi><mi>T</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[R|T]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose">]</span></span></span></span>，但事实上还有一个相似变换S，这个S是个对角线矩阵，对角线上的值为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><msub><mi>S</mi><mi>x</mi></msub><mo separator="true">,</mo><msub><mi>S</mi><mi>y</mi></msub><mo separator="true">,</mo><msub><mi>S</mi><mi>z</mi></msub><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[S_x, S_y, S_z, 1]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.04398em;">z</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">1</span><span class="mclose">]</span></span></span></span>。S直接和R乘在一起，与T无关。</p>
<img data-src="image-20221026162455644-1667622796442-5.png" alt="image-20221026162455644" style="zoom:50%;">
</li>
<li>
<p>Extrinsic可使世界坐标系转化为相机坐标系。</p>
</li>
</ul>
<h2 id="skewness-and-distortion"><a class="markdownIt-Anchor" href="#skewness-and-distortion"></a> Skewness and Distortion</h2>
<ul>
<li>
<p>Skewness指的是相机Sensor的两个轴不垂直，即xy之间有一个小夹角。通常这不会发生，但如果有制造方面的问题，这也是可能的。</p>
</li>
<li>
<p>相机的Skewness</p>
</li>
<li>
<p>Skewness的解决方法是把这个夹角找到，并在Intrinsic中反映出来。</p>
<p><img data-src="image-20221026154924465-1667622796442-6.png" alt="image-20221026154924465"></p>
</li>
<li>
<p>Distortion包含：</p>
<ul>
<li><em>Radial Distortion</em> (径向畸变)：</li>
<li><em>Tangential distortion</em> (切向畸变)：本质上是相平面和相机坐标系存在一个夹角，即“图像Sensor和镜头截面不平行”。</li>
</ul>
</li>
<li>
<p>关于Distortion的计算：</p>
<p><img data-src="image-20221026163826434-1667622796442-7.png" alt="image-20221026163826434"></p>
</li>
</ul>
<h2 id="homogeneous-coordinates"><a class="markdownIt-Anchor" href="#homogeneous-coordinates"></a> Homogeneous Coordinates</h2>
<ul>
<li>同质坐标的主要用意是把本来在分母上的z（深度）给挪走，以便让投影这个Transformation从non-linear变成Linear。</li>
<li>注意同质坐标虽然在视觉效果上是在原本的坐标(u,v)或(x,y,z)下面加了一个1，但是实际上这个1在欧式坐标系中并不存在。当我们后面列出方程校准时，应该回到原本的欧式坐标系解。</li>
</ul>
<h2 id="imu"><a class="markdownIt-Anchor" href="#imu"></a> IMU</h2>
<ul>
<li>IMU输出三个方向角速度和三个轴向加速度的值，使用时也需要校准。</li>
<li>具体校准方法参见Kalibr和DV，因为我没用上，所以不多展开。</li>
</ul>
<h2 id="dvs"><a class="markdownIt-Anchor" href="#dvs"></a> DVS</h2>
<ul>
<li>DVS的校准主要分为两种方法：
<ul>
<li>一种是直接用paired的RGB进行校准，毕竟这里的RGB和DVS share同一组透镜。</li>
<li>如果没有这个RGB，就直接用accumulate的frame做校准。</li>
</ul>
</li>
</ul>
<h2 id="methods"><a class="markdownIt-Anchor" href="#methods"></a> Methods</h2>
<h3 id="解方程直接校准p矩阵"><a class="markdownIt-Anchor" href="#解方程直接校准p矩阵"></a> 解方程直接校准P矩阵</h3>
<ul>
<li>
<p>在Paper <em>DHP19: Dynamic Vision Sensor 3D Human Pose Dataset</em>里， 他们采用的方法是：直接在经过Mocap校准的空间中放置一系列Markers，然后在DVS的RGB（APS）输出frame中直接进行手动标注，得到其在image plane中的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>u</mi><mo separator="true">,</mo><mi>v</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(u, v)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">u</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mclose">)</span></span></span></span>坐标， 然后解方程。</p>
<img data-src="image-20221021155115039-1667622796442-8.png" alt="image-20221021155115039" style="zoom:40%;">
</li>
<li>
<p>上图中提到了一个点：从投影矩阵计算相机坐标系的原点，即相机的焦点位置的方法：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>=</mo><msup><mi>Q</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><msub><mi>c</mi><mn>4</mn></msub></mrow><annotation encoding="application/x-tex">C=Q^{-1}c_4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.008548em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。具体的推理其实很简单，主要就靠一个条件公式：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mi>C</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">PC=0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>，即原点的投影是0。</p>
</li>
<li>
<p>细节上，他们用了38个Marker，并8次改变它们的位置，通过最小平方法解得最接近的11个P中参数值。这里的最小平方法的意义在于通过增加数据点取平均P值来减小误差。其实11组式子就够了，但这里还是用了<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>8</mn><mo>×</mo><mn>38</mn><mo>×</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">8\times38\times2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">8</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">3</span><span class="mord">8</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span></span></span></span>个公式，就在于此。</p>
</li>
<li>
<p>具体的最小平方法介绍及代码：<a href="https://pythonnumericalmethods.berkeley.edu/notebooks/chapter16.04-Least-Squares-Regression-in-Python.html">Link</a></p>
</li>
<li>
<p>这个全矩阵P其实包含了Camera Intrinsic <em>K</em>， Camera Extrinsic <em>RT</em>, 以及Camera Skewness。</p>
</li>
<li>
<p>理论：</p>
<p><img data-src="image-20221026175034098-1667622796442-9.png" alt="image-20221026175034098"></p>
<img data-src="image-20221026175051047-1667622796442-10.png" alt="image-20221026175051047" style="zoom:50%;">
</li>
<li>
<p>代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Least Square Calibration for Camera Projection Matrix using Numpy</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">svd_calibration</span>(<span class="params">points_3d, points_2d</span>):</span><br><span class="line">    <span class="comment"># points_3d: 3D points in world coordinate</span></span><br><span class="line">    <span class="comment"># points_2d: 2D points in image coordinate</span></span><br><span class="line">    <span class="comment"># return: projection matrix</span></span><br><span class="line">    <span class="keyword">assert</span> points_3d.shape[<span class="number">0</span>] == points_2d.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">assert</span> points_3d.shape[<span class="number">1</span>] == <span class="number">3</span></span><br><span class="line">    <span class="keyword">assert</span> points_2d.shape[<span class="number">1</span>] == <span class="number">2</span></span><br><span class="line">    num_points = points_3d.shape[<span class="number">0</span>]</span><br><span class="line">    A = np.zeros((<span class="number">2</span> * num_points, <span class="number">12</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_points):</span><br><span class="line">        A[<span class="number">2</span> * i, <span class="number">0</span>:<span class="number">4</span>] = *(points_3d[i, :]), <span class="number">1</span></span><br><span class="line">        A[<span class="number">2</span> * i, <span class="number">8</span>:<span class="number">12</span>] = *(-points_2d[i, <span class="number">0</span>] * points_3d[i, :]), -points_2d[i, <span class="number">0</span>]</span><br><span class="line">        A[<span class="number">2</span> * i + <span class="number">1</span>, <span class="number">4</span>:<span class="number">8</span>] = *(points_3d[i, :]), <span class="number">1</span></span><br><span class="line">        A[<span class="number">2</span> * i + <span class="number">1</span>, <span class="number">8</span>:<span class="number">12</span>] = *(-points_2d[i, <span class="number">1</span>] * points_3d[i, :]), -points_2d[i, <span class="number">0</span>]</span><br><span class="line">    U, S, V = np.linalg.svd(A)</span><br><span class="line">    P = V[:，-<span class="number">1</span>].reshape((<span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line">    <span class="keyword">return</span> P</span><br><span class="line"></span><br><span class="line"><span class="comment"># OR</span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># Least Square Calibration for Camera Projection Matrix</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">least_square_calibrate_camera_projection_matrix_np</span>(<span class="params">x,y,z,u,v</span>):</span><br><span class="line">    <span class="comment"># x,y,z: 3D points in world coordinate</span></span><br><span class="line">    <span class="comment"># u,v: 2D points in image coordinate</span></span><br><span class="line">    <span class="comment"># return: projection matrix</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(x) == <span class="built_in">len</span>(y) == <span class="built_in">len</span>(z) == <span class="built_in">len</span>(u) == <span class="built_in">len</span>(v)</span><br><span class="line">    num_points = <span class="built_in">len</span>(x)</span><br><span class="line">    A = np.zeros((<span class="number">2</span> * num_points, <span class="number">12</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_points):</span><br><span class="line">        A[<span class="number">2</span> * i, <span class="number">0</span>:<span class="number">4</span>] = x[i], y[i], z[i], <span class="number">1</span></span><br><span class="line">        A[<span class="number">2</span> * i, <span class="number">8</span>:<span class="number">12</span>] = -u[i] * x[i], -u[i] * y[i], -u[i] * z[i], -u[i]</span><br><span class="line">        A[<span class="number">2</span> * i + <span class="number">1</span>, <span class="number">4</span>:<span class="number">8</span>] = x[i], y[i], z[i], <span class="number">1</span></span><br><span class="line">        A[<span class="number">2</span> * i + <span class="number">1</span>, <span class="number">8</span>:<span class="number">12</span>] = -v[i] * x[i], -v[i] * y[i], -v[i] * z[i], -v[i]</span><br><span class="line">    U, S, V = np.linalg.svd(A)</span><br><span class="line">    P = V[:，-<span class="number">1</span>].reshape((<span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line">    <span class="keyword">return</span> P</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>注意：SVD这里是用于解决Least Squares Problem的，如果直接用<code>np.linalg.lstsq</code>函数的话（b取全0），会解得一个全0矩阵（因为0永远是一个解）。</p>
</li>
<li>
<p>SVD的解法细节：</p>
<p><img data-src="image-20221027230723755-1667622796442-11.png" alt="image-20221027230723755"></p>
</li>
<li>
<p>解SVD的时候可以选择把P矩阵右下角<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mrow><mo stretchy="false">(</mo><mn>3</mn><mo separator="true">,</mo><mn>4</mn><mo stretchy="false">)</mo></mrow></msub></mrow><annotation encoding="application/x-tex">P_{(3,4)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.03853em;vertical-align:-0.3551999999999999em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">3</span><span class="mpunct mtight">,</span><span class="mord mtight">4</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3551999999999999em;"><span></span></span></span></span></span></span></span></span></span>设为1。不设是homogeneous解法，设了之后是inhomogeneous。</p>
</li>
</ul>
<h3 id="kalibr"><a class="markdownIt-Anchor" href="#kalibr"></a> kalibr</h3>
<ul>
<li>
<p><a href="https://github.com/ethz-asl/kalibr">Link</a></p>
</li>
<li>
<p>Used for:</p>
<ol>
<li><strong>Multi-Camera Calibration</strong>: Intrinsic and extrinsic calibration of a camera-systems with non-globally shared overlapping fields of view</li>
<li><strong>Visual-Inertial Calibration (CAM-IMU)</strong>: Spatial and temporal calibration of an IMU w.r.t a camera-system along with IMU intrinsic parameters</li>
<li><strong>Multi-Inertial Calibration (IMU-IMU)</strong>: Spatial and temporal calibration of an IMU w.r.t a base inertial sensor along with IMU intrinsic parameters (requires 1-aiding camera sensor).</li>
<li><strong>Rolling Shutter Camera Calibration</strong>: Full intrinsic calibration (projection, distortion and shutter parameters) of rolling shutter cameras.</li>
</ol>
</li>
<li>
<p>简单说就是主攻多相机/IMU系统。<a href="https://github.com/ethz-asl/kalibr/wiki/multiple-camera-calibration">多个相机</a>，<a href="https://github.com/ethz-asl/kalibr/wiki/Multi-IMU-and-IMU-intrinsic-calibration">多个IMU</a>，<a href="https://github.com/ethz-asl/kalibr/wiki/camera-imu-calibration">相机+IMU</a>等。</p>
</li>
<li>
<p>校准出来的Extrinsic结果并不是相对原点绝对的，而是多个设备间相对的。比如IMU+Cam校准出来的Extrinsic就是IMU相对于Cam坐标的变换。</p>
<p>引用一段<a href="https://github.com/ethz-asl/kalibr/wiki/yaml-formats">原话</a>：</p>
<blockquote>
<ul>
<li><strong>T_cn_cnm1</strong><br>
camera extrinsic transformation, always with respect to the last camera in the chain<br>
(e.g. cam1: T_cn_cnm1 = T_c1_c0, takes cam0 to cam1 coordinates)</li>
<li><strong>T_cam_imu</strong><br>
IMU extrinsics: transformation from IMU to camera coordinates (T_c_i)</li>
<li><strong>timeshift_cam_imu</strong><br>
timeshift between camera and IMU timestamps in seconds (t_imu = t_cam + shift)</li>
</ul>
</blockquote>
</li>
<li>
<p>综上所述，Kalibr并不是满足我们需求的校准方案。</p>
</li>
</ul>
<h3 id="dv-calibration"><a class="markdownIt-Anchor" href="#dv-calibration"></a> DV Calibration</h3>
<ul>
<li><a href="https://inivation.gitlab.io/dv/dv-docs/docs/tutorial-calibration/">Tutorial Link</a>, <a href="https://gitlab.com/inivation/dv/dv-imu-cam-calibration">Code Link</a></li>
<li>单个多个DVS都可以。</li>
<li>基于Kalibr的方案。</li>
<li>对于单个DVS，校准主要进行的是undistortion，且可以在校准后直接应用于相机后续的图像，让后面的record都不再有失真。</li>
<li>这里的校准可以有效应对之前Upal教授提出的扭曲问题，应在后续操作中应用。</li>
</ul>
<h3 id="opencv-camera-calibration"><a class="markdownIt-Anchor" href="#opencv-camera-calibration"></a> OpenCV Camera Calibration</h3>
<ul>
<li>
<p>这个校准会使用chessboard，而关于3d坐标，他们用了棋盘上两个相邻的点的实际距离是已知的这个特性（因为打印的标准棋盘，间距是固定的，如30mm），来提供相应的3D坐标信息。</p>
</li>
<li>
<p>这个校准会分别输出Intrinsic matrix (mtx), rotation matrix (R, rvecs), translation matrix (T, tvecs), Distortion coefficients (dist)。这些输出可以直接被用来纠偏。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># generate camera matrixes</span></span><br><span class="line">ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objpoints, imgpoints, gray.shape[::-<span class="number">1</span>], <span class="literal">None</span>, <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">img = cv.imread(<span class="string">&#x27;left12.jpg&#x27;</span>)</span><br><span class="line">h,  w = img.shape[:<span class="number">2</span>]</span><br><span class="line">newcameramtx, roi = cv.getOptimalNewCameraMatrix(mtx, dist, (w,h), <span class="number">1</span>, (w,h))</span><br><span class="line"></span><br><span class="line"><span class="comment"># undistort</span></span><br><span class="line">dst = cv.undistort(img, mtx, dist, <span class="literal">None</span>, newcameramtx)</span><br><span class="line"><span class="comment"># crop the image</span></span><br><span class="line">x, y, w, h = roi</span><br><span class="line">dst = dst[y:y+h, x:x+w]</span><br><span class="line">cv.imwrite(<span class="string">&#x27;calibresult.png&#x27;</span>, dst)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>关于OpenCV校准出来的Extrinsic Matrix，由于世界坐标系必定有一个原点，所以它们也是毫无疑问有一个原点的。但这个世界坐标系原点实际上只有参考意义（第一张校准图的左上角棋盘点），并无法直接使用。同时，相机坐标系的原点是相机的焦点，而这个焦点也是几乎不可预知和测量位置的（它可能在相机内部或外部，但校准并不会告诉你这个点位置，所以你也无法通过直接测量相机O点和实际世界O点之间的相对位置来纠正Extrinsic。）</p>
<blockquote>
<p><a href="https://www.appsloveworld.com/opencv/100/91/opencv-camera-calibration-world-coordinate-system-origin">Link</a>: I believe it used to be the position of the top-left corner of the checkerboard in the first calibration image, but it may have changed. You can visualized it by writing a few lines of code that project point (0,0,0) (in calibrated scene coordinates) in all the calibration images, then plotting its projected image coordinates on top of the image themselves.</p>
<p>You should really not depend on it being anything meaningful, and instead locate a separate feature in 3D and roto-translate the reference frame to it after calibration.</p>
</blockquote>
</li>
<li>
<p>实际上，不要想通过OpenCV的校准来直接得到有实际意义的Extrinsic，若想得到，请自行用前面提到的Method 1来实际label一些已知3D坐标的Markers对应的2D点，用Least Squares解得。</p>
</li>
<li>
<p>但是，OpenCV的校准可以提供有效的Distortion Coefficient和Intrinsic，并可直接被用于畸变补偿。</p>
</li>
</ul>
<h2 id="reference"><a class="markdownIt-Anchor" href="#reference"></a> Reference</h2>
<h3 id="blogswebsites"><a class="markdownIt-Anchor" href="#blogswebsites"></a> Blogs/Websites</h3>
<ul>
<li><a href="****https://pythonnumericalmethods.berkeley.edu/notebooks/chapter16.04-Least-Squares-Regression-in-Python.html****">Least Squares Regression in Python</a></li>
<li><a href="https://math.stackexchange.com/questions/974193/why-does-svd-provide-the-least-squares-and-least-norm-solution-to-a-x-b">Why does SVD provide the least squares and least norm solution to 𝐴𝑥=𝑏?</a></li>
<li><a href="https://math.stackexchange.com/questions/772039/how-does-the-svd-solve-the-least-squares-problem">How does the SVD solve the least squares problem?</a></li>
<li><a href="https://www.quora.com/What-is-the-real-world-coordinate-system-camera-calibration-refer-to-in-computer-vision">What is the “real world coordinate system” camera calibration refer to in computer vision?</a></li>
<li><a href="https://numpy.org/doc/stable/reference/generated/numpy.linalg.svd.html">numpy linalg svd</a></li>
<li><a href="https://docs.opencv.org/4.x/dc/dbb/tutorial_py_calibration.html">OpenCV Camera Calibration</a></li>
</ul>
<h3 id="slides"><a class="markdownIt-Anchor" href="#slides"></a> Slides</h3>
<ul>
<li><a href="https://s3.amazonaws.com/content.udacity-data.com/courses/ud810/slides/Unit-3/3C-L3.pdf#fromHistory">Udacity CS4495/6495 Introduction to Computer Vision 3C-L3 Calibrating cameras</a></li>
<li><a href="https://www.cs.cmu.edu/~16385/s17/Slides/11.1_Camera_matrix.pdf">CMU - Camera Matrix</a></li>
<li><a href="https://cvgl.stanford.edu/teaching/cs231a_winter1314/lectures/lecture2_camera_models.pdf">Stanford - Lecture 2</a></li>
<li><a href="https://cvgl.stanford.edu/teaching/cs231a_winter1314/lectures/lecture3_camera_calibration.pdf">Stanford - Lecture 3</a></li>
</ul>
<h3 id="papers"><a class="markdownIt-Anchor" href="#papers"></a> Papers</h3>
<ul>
<li><a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr98-71.pdf">A Flexible New Technique for Camera Calibration</a></li>
</ul>
]]></content>
      <tags>
        <tag>python</tag>
        <tag>camera calibration</tag>
        <tag>camera matrix</tag>
        <tag>CV</tag>
      </tags>
  </entry>
  <entry>
    <title>改变flask监听的主机地址和端口号</title>
    <url>/2018/08/27/change-flask-port/</url>
    <content><![CDATA[<h1 id="问题"><a class="markdownIt-Anchor" href="#问题"></a> 问题</h1>
<p>如何改变flask监听的主机地址和端口号。</p>
<h1 id="解决方案"><a class="markdownIt-Anchor" href="#解决方案"></a> 解决方案</h1>
<ol>
<li>
<p>在app.run()中修改配置</p>
</li>
<li>
<pre class="highlight"><code class="python"><span class="keyword">if</span> __name__== <span class="string">&#x27;__main__&#x27;</span>:
    app.run(
        host = <span class="string">&#x27;0.0.0.0&#x27;</span>,
        port = <span class="number">7777</span>,  
        debug = <span class="literal">True</span> 
    )
&lt;!--code￼<span class="number">0</span>--&gt;
</code></pre>
</li>
</ol>
]]></content>
      <tags>
        <tag>python</tag>
        <tag>web</tag>
        <tag>flask</tag>
      </tags>
  </entry>
  <entry>
    <title>cs231n-assignment1</title>
    <url>/2018/04/04/cs231n-assignment1/</url>
    <content><![CDATA[<h1 id="多分类svm"><a class="markdownIt-Anchor" href="#多分类svm"></a> 多分类SVM</h1>
<ul>
<li>
<p>Loss的理解：对于每一个样本，先计算其W.dot(x)后分到每一个类的可能性，假设这个样本为j，一共c个分类，那么就要使用每个分错的可能性减去分到正确类的可能性。如果这个值为负数，则归零，之后把这(c-1)个值求和即为我们要求的Loss。</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mi>i</mi></msub><mo>=</mo><msub><mo>∑</mo><mrow><mi>j</mi><mo mathvariant="normal">≠</mo><msub><mi>y</mi><mi>i</mi></msub></mrow></msub><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><msub><mi>s</mi><mi>j</mi></msub><mo>−</mo><msub><mi>s</mi><msub><mi>y</mi><mi>i</mi></msub></msub><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">L_i=\sum_{j\neq y_i}max(0,s_j-s_{y_i}+1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.185818em;vertical-align:-0.43581800000000004em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.18639799999999984em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight"><span class="mrel mtight"><span class="mord vbox mtight"><span class="thinbox mtight"><span class="rlap mtight"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="inner"><span class="mrel mtight"></span></span><span class="fix"></span></span></span></span></span><span class="mrel mtight">=</span></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.43581800000000004em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">a</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8694379999999999em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span>，而<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><msub><mi>L</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">L=\frac{1}{N}\sum^N_{i=1}L_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">L</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.326231em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.981231em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></p>
<p>这里的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>j</mi></msub><mo>−</mo><msub><mi>s</mi><msub><mi>y</mi><mi>i</mi></msub></msub><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">s_j-s_{y_i}+1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8694379999999999em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8694379999999999em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> 中的1其实是一个margin，表示如果 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">s_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 只比 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><msub><mi>y</mi><mi>i</mi></msub></msub></mrow><annotation encoding="application/x-tex">s_{y_i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 小一点，就没有必要去惩罚这一项了。</p>
<span id="more"></span>
</li>
<li>
<p>Loss中的正则项（Regularization）：为了保证模型不要过拟合训练数据。正则项通常有L1正则项和L2正则项，它们的工作原理是把W矩阵中每一项的绝对值/平方加和，乘上一个常数<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">λ</span></span></span></span> （正则化强度超参）后也放到Loss中，这样在降低loss的时候就会注意保证W中的数不要过大。</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><msub><mo>∑</mo><mrow><mi>j</mi><mo mathvariant="normal">≠</mo><msub><mi>y</mi><mi>i</mi></msub></mrow></msub><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo separator="true">;</mo><mi>W</mi><msub><mo stretchy="false">)</mo><msub><mi>y</mi><mi>i</mi></msub></msub><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo><mo>+</mo><mi>λ</mi><mi>R</mi><mo stretchy="false">(</mo><mi>W</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">L=\frac{1}{N}\sum^N_{i=1}\sum_{j\neq y_i}max(0,f(x_i;W)_{y_i}+1)+\lambda R(W)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">L</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.417049em;vertical-align:-0.43581800000000004em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.981231em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.18639799999999984em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight"><span class="mrel mtight"><span class="mord vbox mtight"><span class="thinbox mtight"><span class="rlap mtight"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="inner"><span class="mrel mtight"></span></span><span class="fix"></span></span></span></span></span><span class="mrel mtight">=</span></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.43581800000000004em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">a</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">λ</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mclose">)</span></span></span></span></p>
</li>
<li>
<p>L2 regularization: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo stretchy="false">(</mo><mi>W</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mo>∑</mo><mi>k</mi></msub><msub><mo>∑</mo><mi>l</mi></msub><msubsup><mi>W</mi><mrow><mi>k</mi><mo separator="true">,</mo><mi>l</mi></mrow><mn>2</mn></msubsup></mrow><annotation encoding="application/x-tex">R(W)=\sum_k \sum_l W_{k,l}^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2333239999999999em;vertical-align:-0.4192159999999999em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1863979999999999em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1863979999999999em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span></span></span></span></p>
<p>L1 regularization: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo stretchy="false">(</mo><mi>W</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mo>∑</mo><mi>k</mi></msub><msub><mo>∑</mo><mi>l</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>W</mi><mrow><mi>k</mi><mo separator="true">,</mo><mi>l</mi></mrow></msub><mi mathvariant="normal">∣</mi></mrow><annotation encoding="application/x-tex">R(W)=\sum_k \sum_l |W_{k,l}|</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0497100000000001em;vertical-align:-0.29971000000000003em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1863979999999999em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1863979999999999em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord">∣</span></span></span></span></p>
<p>Elastic net 弹性网络（L1+L2）: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo stretchy="false">(</mo><mi>W</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mo>∑</mo><mi>k</mi></msub><msub><mo>∑</mo><mi>l</mi></msub><mi>β</mi><msubsup><mi>W</mi><mrow><mi>k</mi><mo separator="true">,</mo><mi>l</mi></mrow><mn>2</mn></msubsup><mo>+</mo><mi mathvariant="normal">∣</mi><msub><mi>W</mi><mrow><mi>k</mi><mo separator="true">,</mo><mi>l</mi></mrow></msub><mi mathvariant="normal">∣</mi></mrow><annotation encoding="application/x-tex">R(W)=\sum_k\sum_l\beta W^2_{k,l}+|W_{k,l}|</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2333239999999999em;vertical-align:-0.4192159999999999em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1863979999999999em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1863979999999999em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord">∣</span></span></span></span></p>
<p>L1更倾向于选择值较小且较为稀疏的矩阵，而L2倾向于选择值较小且较平均的矩阵</p>
</li>
<li>
<p>SVM的“Kernel”的意思是一个映射函数。SVM的核心思想是找一个超平面把正负样本分开，而在很多情况下，并不存在这样一个平面。于是我们用一个函数把这些数据点映射到一个新的容易分开的空间中，这时候找一个平面来分开</p>
</li>
<li>
<p>SVM算法既可用于回归问题，比如SVR(Support Vector Regression, 支持向量回归）；也可以用于分类，比如SVC(Support Vector Classification,支持向量分类）</p>
</li>
</ul>
<h1 id="多项式softmax"><a class="markdownIt-Anchor" href="#多项式softmax"></a> 多项式Softmax</h1>
<ul>
<li>Softmax的Loss计算： <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mi>i</mi></msub><mo>=</mo><mo>−</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mfrac><msup><mi>e</mi><mrow><mi>s</mi><msub><mi>y</mi><mi>i</mi></msub></mrow></msup><mrow><msub><mo>∑</mo><mi>j</mi></msub><msup><mi>e</mi><msub><mi>s</mi><mi>j</mi></msub></msup></mrow></mfrac><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">L_i=-log(\frac{e^{sy_i}}{\sum_j e^{s_j}})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.588492em;vertical-align:-0.677512em;"></span><span class="mord">−</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.91098em;"><span style="top:-2.6447149999999997em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.14964714285714287em;"><span style="top:-2.1785614285714283em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.46032428571428574em;"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:0.19516666666666668em;"></span><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7789785714285715em;"><span style="top:-2.9714357142857146em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3448em;margin-left:0em;margin-right:0.1em;"><span class="pstrut" style="height:2.65952em;"></span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5091600000000001em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7385428571428572em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3448em;margin-left:-0.03588em;margin-right:0.1em;"><span class="pstrut" style="height:2.65952em;"></span><span class="mord mathnormal mtight">i</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.31472em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.677512em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span></span></span></li>
<li>Softmax方程本身是：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>Y</mi><mo>=</mo><mi>k</mi><mi mathvariant="normal">∣</mi><mi>X</mi><mo>=</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><msup><mi>e</mi><msub><mi>s</mi><mi>k</mi></msub></msup><mrow><msub><mo>∑</mo><mi>j</mi></msub><msup><mi>e</mi><msub><mi>s</mi><mi>j</mi></msub></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">P(Y=k|X=x_i)=\frac{e^{s_k}}{\sum_j e^{s_j}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.588492em;vertical-align:-0.677512em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.91098em;"><span style="top:-2.6447149999999997em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.14964714285714287em;"><span style="top:-2.1785614285714283em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.46032428571428574em;"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:0.19516666666666668em;"></span><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7789785714285715em;"><span style="top:-2.9714357142857146em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3448em;margin-left:0em;margin-right:0.1em;"><span class="pstrut" style="height:2.65952em;"></span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5091600000000001em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7385428571428572em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3448em;margin-left:0em;margin-right:0.1em;"><span class="pstrut" style="height:2.69444em;"></span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.34963999999999995em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.677512em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></li>
<li>由于各种可能的预测结果的softmax方程之和总为1，我们所需要做的只是不断优化target的值，其他不正确的score自然会降低的</li>
<li>Softmax也可以被称为交叉熵loss，因为信息熵的定义是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><msub><mi>P</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">-log(P_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">−</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> ，其中<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">P_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是概率</li>
</ul>
<h1 id="优化方式"><a class="markdownIt-Anchor" href="#优化方式"></a> 优化方式</h1>
<ol>
<li>随机搜索（Random Search）：不断的给W随意的赋值，Loss表现更低的话就把W换成这次赋值得到的W。</li>
<li>顺斜率搜索（Follow the slope）：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi>d</mi><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mrow><mi>d</mi><mi>x</mi></mrow></mfrac><mo>=</mo><mi>l</mi><mi>i</mi><msub><mi>m</mi><mrow><mi>h</mi><mo>→</mo><mi mathvariant="normal">∞</mi></mrow></msub><mfrac><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo>+</mo><mi>h</mi><mo stretchy="false">)</mo><mo>−</mo><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mi>h</mi></mfrac></mrow><annotation encoding="application/x-tex">\frac{df(x)}{dx}=lim_{h \to \infty} \frac{f(x+h)-f(x)}{h}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.355em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">x</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">x</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.355em;vertical-align:-0.345em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">i</span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mrel mtight">→</span><span class="mord mtight">∞</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">x</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">h</span><span class="mclose mtight">)</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">x</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></li>
<li>我们把Loss看做是W的函数，而我们要做的就是不断寻找在每个W点上L的梯度的值和方向，并且不断沿着梯度方向下降一段距离，这段距离就是学习率。</li>
<li>随机梯度下降（Stochastic Gradient Descent，SGD）：如果每个样本都算一次梯度，结果往往会有较大的随机性，而如果用一个小的batch作为基本单位，随机性就会减少不少</li>
<li>学习率如果太大容易引起振荡，很难收敛，而太小则速度太慢。往往会在最初步长大一些，后面慢慢收敛。</li>
</ol>
<h1 id="实践部分"><a class="markdownIt-Anchor" href="#实践部分"></a> 实践部分</h1>
<ul>
<li><code>W.dot(x)</code>的结果与<code>np.dot(W,x)</code>是相同的，都是W和x的矩阵相乘</li>
<li>实践中，在涉及到学习优化等和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">λ</span></span></span></span> 等带有学习速率之类超参数的问题时，常在前面乘上一个0.5，因为平方项求导的时候会出来一个2，0.5<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">λ</span></span></span></span> 就比较好。</li>
</ul>
<h1 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h1>
<ul>
<li>Ground-truth: 真实标签，X的真实分类等意思，可以略作GT</li>
<li>计算机视觉中的Bag of Words里面的words说的是一些底层的pattern，经常性的重复出现的模式，把这些当做“视觉词汇”来进行处理</li>
</ul>
]]></content>
      <tags>
        <tag>machine-learning</tag>
        <tag>CV</tag>
        <tag>cs231n</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch 的 Data Parallelism 多GPU训练</title>
    <url>/2018/08/22/data-parallelism/</url>
    <content><![CDATA[<h2 id="简单步骤"><a class="markdownIt-Anchor" href="#简单步骤"></a> 简单步骤</h2>
<ol>
<li>
<p>确定Device，看是否有可利用的GPU：<code>device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</code></p>
</li>
<li>
<p>正常定义并实例化模型和Dataloader</p>
</li>
<li>
<p>如果检测到的GPU多于一块，将模型并行化：</p>
<span id="more"></span>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> torch.cuda.device_count() &gt; <span class="number">1</span>:</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&quot;Let&#x27;s use&quot;</span>, torch.cuda.device_count(), <span class="string">&quot;GPUs!&quot;</span>)</span><br><span class="line">  model = nn.DataParallel(model)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>将模型部署到相应的设备上：<code>model.to(device)</code></p>
</li>
<li>
<p>运行模型（循环中将Input数据也加载到相应设备上）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> rand_loader:</span><br><span class="line">    <span class="built_in">input</span> = data.to(device)</span><br><span class="line">    output = model(<span class="built_in">input</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Outside: input size&quot;</span>, <span class="built_in">input</span>.size(),</span><br><span class="line">          <span class="string">&quot;output_size&quot;</span>, output.size())</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>得到结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">	In Model: <span class="built_in">input</span> size torch.Size([<span class="number">15</span>, <span class="number">5</span>]) output size torch.Size([<span class="number">15</span>, <span class="number">2</span>])</span><br><span class="line">	In Model: <span class="built_in">input</span> size torch.Size([<span class="number">15</span>, <span class="number">5</span>]) output size torch.Size([<span class="number">15</span>, <span class="number">2</span>])</span><br><span class="line">Outside: <span class="built_in">input</span> size torch.Size([<span class="number">30</span>, <span class="number">5</span>]) output_size torch.Size([<span class="number">30</span>, <span class="number">2</span>])</span><br><span class="line">	In Model: <span class="built_in">input</span> size torch.Size([<span class="number">15</span>, <span class="number">5</span>]) output size torch.Size([<span class="number">15</span>, <span class="number">2</span>])</span><br><span class="line">	In Model: <span class="built_in">input</span> size torch.Size([<span class="number">15</span>, <span class="number">5</span>]) output size torch.Size([<span class="number">15</span>, <span class="number">2</span>])</span><br><span class="line">Outside: <span class="built_in">input</span> size torch.Size([<span class="number">30</span>, <span class="number">5</span>]) output_size torch.Size([<span class="number">30</span>, <span class="number">2</span>])</span><br><span class="line">	In Model: <span class="built_in">input</span> size torch.Size([<span class="number">15</span>, <span class="number">5</span>]) output size torch.Size([<span class="number">15</span>, <span class="number">2</span>])</span><br><span class="line">	In Model: <span class="built_in">input</span> size torch.Size([<span class="number">15</span>, <span class="number">5</span>]) output size torch.Size([<span class="number">15</span>, <span class="number">2</span>])</span><br><span class="line">Outside: <span class="built_in">input</span> size torch.Size([<span class="number">30</span>, <span class="number">5</span>]) output_size torch.Size([<span class="number">30</span>, <span class="number">2</span>])</span><br><span class="line">	In Model: <span class="built_in">input</span> size torch.Size([<span class="number">5</span>, <span class="number">5</span>]) output size torch.Size([<span class="number">5</span>, <span class="number">2</span>])</span><br><span class="line">	In Model: <span class="built_in">input</span> size torch.Size([<span class="number">5</span>, <span class="number">5</span>]) output size torch.Size([<span class="number">5</span>, <span class="number">2</span>])</span><br><span class="line">Outside: <span class="built_in">input</span> size torch.Size([<span class="number">10</span>, <span class="number">5</span>]) output_size torch.Size([<span class="number">10</span>, <span class="number">2</span>])</span><br></pre></td></tr></table></figure>
</li>
</ol>
]]></content>
      <tags>
        <tag>machine-learning</tag>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>CS231N 第一课</title>
    <url>/2018/03/28/cs231n-01/</url>
    <content><![CDATA[<h1 id="cs231n"><a class="markdownIt-Anchor" href="#cs231n"></a> <a href="http://cs231n.stanford.edu">CS231N</a> 第一课</h1>
<h2 id="history"><a class="markdownIt-Anchor" href="#history"></a> History</h2>
<ul>
<li>
<p>在深度学习没有出现之前，处理图片的一个重要技术是分割图片。当时最好的算法有<a href="http://blog.sina.com.cn/s/blog_49b5f5080100lrxm.html">Normalized Cut</a>等。</p>
</li>
<li>
<p><a href="https://blog.csdn.net/abcjennifer/article/details/7639681">SIFT（Scale-invariant feature transform）</a>：一种检测局部特征的算法，该算法通过求一幅图中的特征点（interest points,or corner points）及其有关scale 和 orientation 的描述子得到特征并进行图像特征点匹配，获得了良好效果，主要可以应用与物体检测。通过提取一些不会根据拍摄者的角度、远近变化的特征来确定目标。</p>
<span id="more"></span>
</li>
<li>
<p>当前SIFT仍在某些领域无法被深度学习取代，如照相机中的拍摄全景图时，各个图片的拼接就是用的SIFT。</p>
</li>
<li>
<p>人脸检测技术在很早之前（几十年前）就已经有了，而且运算速度飞快，运用于早期的相机中。</p>
</li>
<li>
<p><a href="https://zhuanlan.zhihu.com/p/24916624">Faster RCNN（Regions with CNN Features）</a> ：适用于<a href="https://blog.csdn.net/xyy19920105/article/details/50817725">目标检测</a> 。</p>
</li>
<li>
<p><a href="http://www.image-net.org">ImageNet</a>：李菲菲组织的图片识别竞赛，在2012年被Hinton直接把准确率上升了10%。</p>
</li>
</ul>
<h2 id="image-classification"><a class="markdownIt-Anchor" href="#image-classification"></a> Image Classification</h2>
<ul>
<li>
<p>图像分类是计算机视觉的核心。生活中的绝大部分物体大致可以被分为1w类左右。定义分类本身是困难而容易产生歧义的，关键在于如何定义标准。</p>
</li>
<li>
<p>神经网络其实是很容易被欺骗的，比如通过改变少数个像素，便可以使得一个训练好的神经网络把猫的图像以高置信度判断为狗。</p>
</li>
<li>
<p>Semantic Gap：语义鸿沟。在一算计看来一个图片就是</p>
</li>
<li>
<p>计算机视觉中很难解决的问题：光照、变形、遮挡、背景嘈杂（背景和主物体特征相似）、同一个类别中有较大差异的个体（猫种类有很多种类的猫）、两个类之间差异小（狗和狼长的很相似）</p>
</li>
<li>
<p>数据驱动的方法：</p>
<ol>
<li>采集一个包括图片和相应标签的数据集</li>
<li>用机器学习的方法训练一个图片分类器</li>
<li>使用一个测试集评估这个分类器</li>
</ol>
</li>
<li>
<p>一个经典的图像分类的数据集：CIFAR-10数据集：共有10个类别，50000个训练图像和10000个测试图像</p>
</li>
<li>
<p>第一个分类器：最近邻分类器（Nearest Neighbor Classifier）：寻找训练集中和测试图像最为相似的图像，并依据它们的labels来判断该图像的label。</p>
</li>
<li>
<p>对于所有的机器学习模型，都有两种方法：</p>
<ol>
<li>非参数化方法：并不会把训练集转化为参数，如NNC</li>
<li>参数化方法：模型大小和训练数据量无关，如SVN，测试时性能更好</li>
</ol>
</li>
<li>
<p>近似最近邻法（Approximate Nearest Neighbor）：有一套库FLANN，现在已经被集成到OPENCV中</p>
</li>
<li>
<p>超参数：不是被数据驱动的参数，是不会再训练中被改变的</p>
<img data-src="/2018/03/28/cs231n-01/L1L2-Distance.png" class title="L1L2-Distance">
</li>
<li>
<p><a href="https://blog.csdn.net/holybin/article/details/27185659">交叉验证（Cross Validation）</a> ：交叉验证（Cross Validation）是用来验证分类器的性能一种统计分析方法，基本思想是把在某种意义下将原始数据（dataset）进行分组，一部分做为训练集（training set），另一部分做为验证集（validation set），首先用训练集对分类器进行训练，在利用验证集来测试训练得到的模型（model），以此来做为评价分类器的性能指标。</p>
</li>
<li>
<p>之所以叫模式识别，是因为在各层网络中，每层都会开始学习到一些特征，或称模式，比如第一层可能学习的是人的眼、嘴，后面的层学习到了人脸的轮廓。</p>
</li>
</ul>
]]></content>
      <tags>
        <tag>machine-learning</tag>
        <tag>CV</tag>
      </tags>
  </entry>
  <entry>
    <title>设计思维课程感想</title>
    <url>/2018/03/07/design-thinking/</url>
    <content><![CDATA[<p>本次课程时长并不算长，只有短短的32学时，共分了4个周六完成了课程。课程一开始，蔡老师就提醒我们，这门课并不是为了给我们讲述一个完整的设计思维的知识体系或是架构，一是时间不够，二是因为同学们来自各个专业，并不完全是设计专业的，所以也没有这个必要。那这门课究竟要讲什么呢？自然是方法。思维的方法，转变既定思维模式的方法，将一个给定的问题短时间内做一个清晰的分析的方法。另外这门课也可以被看做一个入门，一个通往这个对我来说崭新而又有趣的领域的大门。老师领进门，修行在个人。虽然说正如蔡老师所言，这门课程很难说有什么系统性，基本都是以互动和师生聊天似的交流构成的，但是这些交流中透露出的逻辑性和对问题分析的连贯性无疑是相当大的收获。</p>
<span id="more"></span>	
<p>一个问题给定了，要如何去思考它？在我看来，这便是这么课最为中心的问题。你站在谁的角度去看问题，决定了你思考的模式。首先是价值。你所要做的产品有着什么样的价值？拿老师第一节举过的例子雨伞来说，一把在平时看来普普通通的雨伞，其实竟然也有着这么多样的价值。最底层的是实用价值，即挡雨的功能，其次是作为一个装饰品的价值，因为雨伞也是一个随身携带的重要的装饰品，尤其是在像英国这样经常下雨的国度，雨伞的装饰价值就更高了。那么由此又可以引申出什么价值呢？仔细想来，既然是一个装饰品，那么就可以体现出人的个性，那这又是个性化的价值，其次伞的装饰和价位又可以显示出一个人的经济水平和审美能力，故也有着身份象征这样的价值。像这样不断挖掘下去，我惊奇的发现，生活中的一个个在之前看来朴实无华甚至不值一提的小物件竟然也有着这么丰富的属性和价值，这无疑扩大了我的眼界、开阔了我的思维方式。</p>
<p>又如蔡老师讲到的苹果公司的成功之道。虽然我每天都会和苹果公司的各种产品打交道，平时也是做互联网技术的，但是真当提到这个问题的时候无非也只是能想到乔帮主的种种大牛之处和诸如苹果的追求细节，精细的产品控制，流畅的系统和大量优质的应用云云，然而蔡老师则提出了在我看来一个相当新颖的说法：苹果公司之所以能够做到今天的规模，很大程度上是在依靠其固有的闭环生态圈。老师打了一个生动形象的比喻：这就像自己修了一堵围墙，然后把里面搞得相当不错后进去自己当了国王。尽管圈内有着种种制约和限制，但是由于几乎所有的交互、所有用户需要的数码电子设备在这里都有，而且简单好用，再加上数量庞大的优质App积累和自家的审核机制，苹果公司并不难坐稳这个金灿灿的王座。</p>
<p>说到苹果公司，蔡老师又提到了iPod的成功。iPod并不是唯一可以听歌的电子设备，在此之前也有很多类似于Walkman的产品，依靠放入唱片来听音乐。而iPod的伟大之处就在这里。它改变了一个产业。整个唱片业界在盗版的冲击下是一片低迷的景象，而iPod开启了一种崭新的模式：向电子版音乐收取版权费。音乐变得不再是一个依附于某种实体的东西，而做到了彻底的数字化——卖音乐时唱片厂商出售的东西不再是一个单纯的唱片或是磁带，而是单纯的数据！可以说苹果的iPod拯救了整个业界也不为过，这才是其畅销至今的本质原因。苹果公司把自己变成了大量唱片商 的合作方而非竞争方，这不但给自己带来了巨量的收益，也斩获了大量的重视用户，甚至有很多用户就是从iPod开始了解并爱上苹果的产品的。</p>
<p>空间的划分也是蔡老师的课程给我留下较为深刻的印象的一部分。课上老师给我们出了一道难题：如何定义一个空间？要用几个面才可以定义一个空间？当时我们纷纷拿现实中的各种具象事物来作类比，比如说根据足球场这个没有顶的空间定义说要至少有五个面；又有的同学说周边可以使一个曲面，所以只需要两个面就够了；更有同学说只需要一个面的。说只需要一个面的同学有两种解释，一种是说像是一个球体就只需要一个面也可以定义一个其包围的空间，另一种则是从雨伞得到的灵感，认为只需要一个面来分割空间，下面和上面就有了两个空间。蔡老师比较赞同最后一种说法。“空间是由分割定义的”，他说，本无一个确定的空间，但是哪怕只有一个分割出现了，这里就产生了空间。这种活跃的思考和讨论式的思维方式也是我很喜欢的。</p>
<p>蔡老师还和我们聊到了创业的话题。创业的本质是真正解决了目标用户群体的一个切切实实的痛点，而不是开发一个开发者认为的有用的功能。参加本次课程的一名同学就自己亲身参与了创业。蔡老师让他简单的描述这个产品的功能，结果不知道是由于紧张还是如何，描述了好几分钟也没能让老师搞明白本质到底是什么。他说这个项目比较难以理解，不容易讲清楚，但是蔡老师则表示了当场否定：“任何一款开发出来让别人用的产品如果不能在五分钟内让投资人搞明白这是怎么回事，首先在投资这一关就过不了。”在蔡老师的提示下，该同学重新整理了语言，简明扼要的说明了创业的内容：“ 一个供AI开发者使用的已经部署好了的平台。”蔡老师立即明白了其意思，他说：“这就像是我们搞设计的用的那种跑大型视频渲染的云平台嘛。”同时他表示这是有着切实需求的一个用户的痛点，确实值得一做。这种对问题的精简分析、类比熟悉事物进行快速准确的理解的能力在我看来也是一个做技术的同学应该掌握的重要技能。</p>
<p>说到AI，蔡老师有次课上还向我们介绍了一个阿里巴巴开发的人工智能海报设计系统：鲁班系统。仅仅双十一一天，鲁班系统就设计了10亿级别的海报，不但迅速而且质量相当不错，商家只需点击鼠标选择几个需要宣传的商品图标、写上一句标语，剩下的抠图、排版、背景、字体等一系列操作都将由系统自动完成。对于这个量级，如果让人类设计师来设计，即使24小时工作，一个超级大型的设计团队也要近百年才能设计完。这就是现实。“所以我们设计系的学生更要重视掌握方法而非工具。”蔡老师提到。“如果只是会用个工具，学生们恐怕还没有毕业就要失业了。”他忧心忡忡的提到。工具是为人服务的，如果你只掌握了工具的使用，而没有领会到设计的精髓，那么也确实没有什么用处了。</p>
<p>四个星期很快就过完了，蔡老师也给我们展示了一套他自己精练出的分析问题的方法，举了很多的实例让我们演练，可以说着实受益匪浅。虽然并没有完全地掌握这套设计思维的方法，但是我详细在之后的人生中，我也会继续给自己的自相装备上设计思维，用设计的眼光去看待一个更加多样的世界，并找机会继续学习，让设计思维真正成为自己的思维。</p>
]]></content>
      <tags>
        <tag>design-thinking</tag>
        <tag>essay</tag>
      </tags>
  </entry>
  <entry>
    <title>点石创校第一课理论部分笔记</title>
    <url>/2018/03/24/dianshi-01-theory/</url>
    <content><![CDATA[<h1 id="点石创校第一课理论部分笔记"><a class="markdownIt-Anchor" href="#点石创校第一课理论部分笔记"></a> 点石创校第一课理论部分笔记</h1>
<h2 id="书籍推荐"><a class="markdownIt-Anchor" href="#书籍推荐"></a> 书籍推荐</h2>
<ul>
<li>《从0到1》：在现今创业的大的浪潮中，在什么想法上你和身边其他人完全不一样。差异化是判断一个项目和一个创业者能力的最重要的点。<a href="https://pan.baidu.com/s/1HeoYvIRYPyr9Aa7-oO1-TQ">下载链接:</a> 密码:zbed</li>
<li>《蓝海战略》：蓝海市场：用户的某种渴望尚没有被满足的市场（或不准确的说，还没有被巨头们争夺的市场）</li>
</ul>
<span id="more"></span>
<h2 id="风险投资"><a class="markdownIt-Anchor" href="#风险投资"></a> 风险投资</h2>
<ul>
<li>PE：私募基金（<em>PE</em>，Private Equity），投资的主要是较为成熟的公司。它私募股权投资的一种，依据国外相关研究机构定义，是指通过向特定人群募集资金，对非上市企业进行的权益性投资，在交易实施过程中附带考虑了将来的退出机制，即通过上市、并购或管理层回购等方式，出售持股获利</li>
<li>VC：风险投资（<em>Venture Capital</em>），投资的是中小型企业，使用美元。是风险投资的简称，在我国是一个约定俗成的具有特定内涵的概念，其实把它翻译成创业投资更加合适，它是以权益资本的方式存在的一种私募股权投资形式。在国内用人民币投资的是创业投资</li>
<li>VC投资投资的是公司的成长性和内在价值；PE投资投资的是财务指标，上市可能。前者特点是低估值，单笔投资额度小，投资者可以主动控制；后者的特点是高估值，单笔投资额度大，投资者被动监督</li>
<li>最初投资的时候一般不太在意公司的章程，而后期一般比较在意，因为这些章程决定了各种法律责任和机制</li>
<li>公司是企业的一种组织形式。公司由股东组成。股东投钱注册成立一家公司，成立股东会，股东会选举产生董事会，董事会任命总经理。公司是由股东组成的，公司内部股东会拥有最高决策权，股东会选出来的董事会是执行者。谁出的钱多，谁是公司的大股东，谁拥有控股权和最高决定权。法人代表是指公司的法律责任由谁来承担，但是这个人和公司的拥有者并不一定是一个人</li>
<li>企业的组织形式有：
<ol>
<li>公司制</li>
<li>有限合伙制 -&gt; 普通合伙企业中所有合伙人的责任是一样的，而在有限合伙制中合伙人分为两种，一是普通合伙人，二是有限合伙人。前者只需要出1%的钱，后者出99%的钱；前者负责经营，是专业的人；后者主要负责出钱，没有太多专业知识。在这种组织形式中，普通合伙人说了算，负责决定投资谁。如：会计事务所，投资基金</li>
<li>信托制 -&gt; 受《信托法》保护</li>
</ol>
</li>
<li>公司的组成：人，钱，物</li>
<li>投资人把钱投资入一个壳中，这个壳中的资金交由管理人进行管理。根据投资人的资金来源不同，分为公募资金和私募资金；而这个壳子是指的是法律关系，即组织形式；管理人决定了投资对象和基金类别</li>
<li>投资人投资的是你公司的股权，并不是你个人或是你的项目</li>
<li>全球80%以上的私募基金采用的是有限合伙制，这是企业的第二种组织形式。</li>
<li>投资基金的合伙人可以赚的盈利的20%</li>
<li>公司发展：种子期（种子轮） -&gt; 初创期（天使轮） -&gt; 成长期 -&gt; 成熟期 -&gt; 扩张期</li>
<li>只投资前三个时期的是VC，投后面的交PE</li>
<li>投资人的投资目的只有一个：追求回报</li>
<li>好项目的评判标准：3年之内9~10亿美元以上</li>
<li>市场决定了一个项目的天花板，一个10亿的市场无法成长出一个50亿的企业</li>
<li>你的用户到底是谁？ -&gt; 用户与客户有什么区别，用户特征如何描述</li>
<li>精准寻找用户需求：刚性需求的定义，蓝海市场的定义</li>
<li>刚性需求：价格不敏感的需求，或是没有这个东西人/公司就会死掉的需求</li>
<li>满足精神和心理需求的是最高级别的需求，超越了刚性需求。比如小米，推出了“发烧友”的概念，偷换了概念，不说自己好，而是转而去强调你身边专业的人都在用小米；其又打出了1999这条线，强调性价比，其实是利用了人性的贪婪面。小米在2016年走错了一步，当年人均年收入超过6w$，人们开始更加重视精神消费，而小米没有跟上</li>
<li>二级市场投资的人并无法直接了解一个公司，无法知道到底是如何成功如何失败的；相反，一级市场中的投资人</li>
</ul>
<table>
<thead>
<tr>
<th>股东</th>
<th>员工</th>
<th>资产</th>
<th>现金流</th>
</tr>
</thead>
<tbody>
<tr>
<td>基因</td>
<td>肌肉</td>
<td>骨骼</td>
<td>血流</td>
</tr>
</tbody>
</table>
<ul>
<li>创业者的格局：
<ol>
<li>高度：高度是判断。站的是否足够高，是否能看到并且分析出发展的趋势，而这个分析的结果能够和投资人的判断相符合</li>
<li>广度：广度是经历。看得有多广，是能了解全国活着全球跟你在做同样事情的人，他们在做什么，怎么做</li>
<li>深度：深度是差别。这是优秀创业者和普通创业者不同之处。比如你是否知道并亲身体验过同行业其他人，其他公司的实际状况的时候，你的深度就上来了</li>
</ol>
</li>
</ul>
<h2 id="附录什么是-gp-lp-pe-vc-fof"><a class="markdownIt-Anchor" href="#附录什么是-gp-lp-pe-vc-fof"></a> 附录：<a href="https://www.zhihu.com/question/20062244">什么是 GP、LP、PE、VC、FOF？</a></h2>
<p>天使投资（Angel Investment）：大多数时候，天使投资选择的企业都会是一些非常非常早期的企业，他们甚至没有一个完整的产品，或者仅仅只有一个概念。（打个比方，我有个朋友，他的毕业设计作品是一款让人保持清醒的眼镜，做工非常粗糙，完全不能进入市场销售。但他凭借这个概念以及这个原型品在美国获得了天使投资，并且目前正在该天使投资的深圳某孵化器工作室进行开发研究。）</p>
<p>而天使投资的投资额度往往也不会很大，一般都是在5-100万这个范围之内，换取的股份则是从10%-30%不等。单纯从数字上而言，美国和中国投资额度基本接近。大多数时候，这些企业都需要至少5年以上的时间才有可能上市。</p>
<p>此外，部分天使投资会给企业提供一些指导和帮助，甚至会给予一定人脉上的支持。</p>
<p>如果你还不了解的话，创新工场一开始就在做天使投资的事情。</p>
<p>风险投资（Venture Capital）：一般而言，当企业发展到一定阶段。比如说已经有个相对较为成熟的产品，或者是已经开始销售的时候，天使投资那100万的资金对于他们来说已经犹如毛毛雨一般，无足轻重了。因此，风险投资成了他们最佳的选择。一般而言，风险投资的投资额度都会在200万-1000万之内。少数重磅投资会达到几千万。但平均而言，200万-1000万是个合理的数字，换取股份一般则是从10%~20%之间。能获得风险投资青睐的企业一般都会在3-5年内有较大希望上市。</p>
<p>如果需要现实例子的话，红杉资本可以算得上是VC里面最知名的一家公司了。后期创新工场给自己企业追加投资的时候，也是在做类似于风险投资的业务。</p>
<p>私募基金（Private Equity）：私募基金选择投资的企业大多数已经到了比较后期的地步，企业形成了一个较大的规模，产业规范了，为了迅速占领市场，获取更多的资源，他们需要大批量的资金，那么，这时候私募基金就出场了。大多数时候，5000万<sub>数亿的资金都是私募基金经常投资的数额。换取股份大多数时候不会超过20%。一般而言，这些被选择的公司，在未来2</sub>3年内都会有极大的希望上市成功。</p>
<p>去年注资阿里巴巴集团16亿美金的银湖资本（Silver Lake）和曾经投资过的Digital Sky Technology则是私募（尤其做科技类的）翘楚公司。而这16亿的资金也是历史上排名前几的一次注资了。</p>
]]></content>
      <tags>
        <tag>bussiness</tag>
        <tag>investment</tag>
      </tags>
  </entry>
  <entry>
    <title>点石创校第一课经验部分笔记</title>
    <url>/2018/03/24/dianshi-01-exp/</url>
    <content><![CDATA[<h2 id="项目介绍"><a class="markdownIt-Anchor" href="#项目介绍"></a> 项目介绍</h2>
<ul>
<li>
<p>**原则：**不要让观众死一个脑细胞</p>
</li>
<li>
<p>短句子，说人话。不用复杂的定语和倒装句，不用专业名词，要让在场的听众，老百姓们不懂项目中的具体细节</p>
</li>
<li>
<p>不要用容易引起误解或是听不清楚的词句，如P2P，容易被误解为P2B、B2B等</p>
</li>
<li>
<p>不要用目前有一定负面性质的字眼，比如目前的P2P，不说为好</p>
</li>
<li>
<p>不要说一些傲慢和现在还没有实现的话，比如“我们定义了…”</p>
</li>
<li>
<p>不要在如此短的时间里说“我们…”等无意义的话</p>
</li>
<li>
<p>要点出投资人关心的Point，如谁出钱，咋盈利</p>
<span id="more"></span>
</li>
</ul>
<h2 id="项目介绍视频"><a class="markdownIt-Anchor" href="#项目介绍视频"></a> 项目介绍视频</h2>
<ul>
<li>**重点：**为谁服务，怎么服务，谁掏钱</li>
<li>不要只讲愿景，不讲数据</li>
<li>片头和片尾不能完全一样，否则就是提供了重复的信息</li>
<li>视频中不要放一些链接、电话之类的东西，因为没人能记得住</li>
</ul>
<h2 id="商业计划书ppt"><a class="markdownIt-Anchor" href="#商业计划书ppt"></a> 商业计划书（PPT）</h2>
<ul>
<li>每页PPT中的文字不应超过四行，多于四行的部分要用形象的方法（图像、表格）展示</li>
<li>每页PPT中的字不应超过四种颜色</li>
<li>首页和后面的背景图要和自己的项目相关，不能用一个驴头不对马嘴的图放上去，即使它看上去很高级</li>
<li>要学会做证明题、不断证明自己的项目好、可靠、可靠在哪里</li>
<li>从第二页开始可以开始自问自答，也是做证明题的一部分</li>
<li>第三页一定要体现出自己是怎么做的，要有流程的，体现出自己的创新点、核心技术</li>
<li>不要说XXX擅长什么，因为都很年轻，要说负责什么，职位是什么</li>
<li>介绍团队，人少的时候最好把照片放上去，可以的话放工作地的合照</li>
<li>要突出团队成员有什么特点，什么优势</li>
<li>要点出团队成员、融资需求，不要把过多的时间放在背景介绍方面</li>
<li>不要用学究式的措辞，比如“包括但不限于…”，直接用“如：…”就够了</li>
<li>可以使用欲扬先抑的手段引起投资人的兴趣，比如可以先说：“现在互联网思维鼓励去中介化，而我们为什么要加一层？”，后面再解释具体原因</li>
<li>如果自己有核心技术，一定要强调出来</li>
<li>品牌的名字要统一，不能一会儿用中文一会儿用英文</li>
<li>不要既写公司总估值又写融资金额，只用写融资金额和出让股份就好</li>
<li>不要照着PPT念稿子，会给人以这不是你自己干出来的而是copy来的这样一种不自信感</li>
<li>如果有样机，一定要带着样机过来，一个样品胜过千言</li>
<li>要讲加速度不要讲纯速度。即使现在一个产品也没有卖出去，只要能期望很高的增长，也是没问题的；即使现在销量不错，之后如果增长不快只会带来劣势</li>
<li>标题：我们来自哪里？/我们是谁？-&gt; （市场痛点是什么？） -&gt; 我们想做什么？-&gt; 我们做成了什么？ -&gt; 我们要什么？</li>
</ul>
]]></content>
      <tags>
        <tag>bussiness</tag>
        <tag>bussiness-plan</tag>
      </tags>
  </entry>
  <entry>
    <title>点石创校第二课——唐顾问分享</title>
    <url>/2018/04/07/dianshi-02/</url>
    <content><![CDATA[<h2 id="问和说的技巧"><a class="markdownIt-Anchor" href="#问和说的技巧"></a> 问和说的技巧</h2>
<h3 id="提问"><a class="markdownIt-Anchor" href="#提问"></a> 提问</h3>
<ul>
<li>是什么？简单明了，言之有物（不要问一些大的空的问题，精简语言，直说重点）</li>
<li>为什么？事先功课和重要性</li>
<li>想什么？希望得到的内容</li>
</ul>
<span id="more"></span>
<h3 id="自我介绍"><a class="markdownIt-Anchor" href="#自我介绍"></a> 自我介绍</h3>
<ul>
<li>记住名字：要如何解释才能让别人一下子记住你的名字</li>
<li>以听为准：你要搞明白你的目标对象是谁，做好“用户调研”，从而“看人下菜”</li>
<li>场景带入：使用一些小故事，让别人乐于听并听进去</li>
<li>结构：要有逻辑，让整个演讲的过程有连续性</li>
<li>关键词与故事：你使用的关键词决定了你会给别人形成的印象</li>
<li>数据：如果有一些数据，可以让别人迅速形成一个对你强烈的印象</li>
</ul>
<h2 id="说写的艺术"><a class="markdownIt-Anchor" href="#说写的艺术"></a> 说写的艺术</h2>
<h3 id="说"><a class="markdownIt-Anchor" href="#说"></a> 说</h3>
<ul>
<li>先听后说：不懂装懂是个饭桶（在自己并没有搞的很懂的时候不要强行去引数据、用英语），他山之石可以攻玉（比如用“10个东京大学的大小”来解释华科的尺寸）</li>
<li>高人说的是大白话，最好是深入浅出，去繁出简</li>
</ul>
<h3 id="写"><a class="markdownIt-Anchor" href="#写"></a> 写</h3>
<ul>
<li>“活捉林志玲”：文章给谁看，想要说什么</li>
<li>喜欢的文稿：标题与内容，规律和经验，事实与数据，不足与问题</li>
<li>调味品（比如绝望坡的坡度数据等，无伤大雅的调剂）</li>
</ul>
<h2 id="火柴人意识常见问题"><a class="markdownIt-Anchor" href="#火柴人意识常见问题"></a> “火柴人意识”常见问题</h2>
<ul>
<li>自以为是：以自己为中心，不掂量一个机会的重量，内心深处认为世界围着自己转</li>
<li>不靠谱</li>
<li>自我管理（四象法5S管理）</li>
<li>成本意识（找对象游戏）</li>
<li>风险评估（从种树谈起）</li>
<li>解决问题（变议论为行动）</li>
</ul>
<h2 id="人情世故"><a class="markdownIt-Anchor" href="#人情世故"></a> 人情世故</h2>
<ul>
<li>做人做事：要先做事，先行动起来。先把事情做了，做人方面自然就显现出来了</li>
<li>学会吃小亏：你能算计到的那些小精明别人很大可能也算到了，别人知道你在精算就不想和你合作了。但是也要注意不能吃大亏。亏了100还可以翻本，亏了100万性质就不同了</li>
<li>感恩，寻找生命中的贵人：要大声对那些在你生命中大幅改变了你人生轨迹的人说谢谢，感谢别人</li>
<li>三个工具：
<ol>
<li>微笑！ -&gt; 微笑带来亲和力，增加机会</li>
<li>“Excuse me, thank you!”  -&gt; 多说谢谢会让人感觉到你的尊重</li>
<li>伸出手！-&gt;表态和做是两个事，即使心有余而力不足，至少态度上要给予表示</li>
</ol>
</li>
<li>两句话：相互吹捧，自我批评</li>
</ul>
<h2 id="成本与风控"><a class="markdownIt-Anchor" href="#成本与风控"></a> 成本与风控</h2>
<h3 id="成本"><a class="markdownIt-Anchor" href="#成本"></a> 成本</h3>
<ul>
<li>物质成本</li>
<li>时间成本</li>
<li>机会成本</li>
<li>风险成本</li>
</ul>
<h3 id="风控"><a class="markdownIt-Anchor" href="#风控"></a> 风控</h3>
<ul>
<li>6677：有6、7分把握就可以冲一冲了，如果一定要等到所有条件都具备了再想着去冲，那一定赢不了的</li>
</ul>
<h2 id="什么人能走得更远情怀梦想"><a class="markdownIt-Anchor" href="#什么人能走得更远情怀梦想"></a> 什么人能走得更远？情怀？梦想？</h2>
<ul>
<li>价值观和使命感</li>
<li>大海可渡的坚持</li>
<li>坚持为他人解决问题：创业不是说你要干什么，而是你能为别人提供什么</li>
<li>远大理想同脚踏实地工作作风的结合</li>
<li>对上负责对下负责的结合</li>
<li>高度的原则性通高度的灵活性的结合</li>
</ul>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<ul>
<li>事事有着落</li>
<li>有效率</li>
<li>身先士卒，感染他人</li>
<li>到前线去指挥炮火</li>
<li>花自己赚的钱</li>
</ul>
<h2 id="节点和系统"><a class="markdownIt-Anchor" href="#节点和系统"></a> 节点和系统</h2>
<ul>
<li>100个小时可以用来大致了解一个领域，理清脉络</li>
<li>10000个小时是不断填充知识，一步步完善自己的知识体系</li>
</ul>
<h2 id="终身学习"><a class="markdownIt-Anchor" href="#终身学习"></a> 终身学习</h2>
<ul>
<li>像小朋友般好奇</li>
<li>博大精深——技多不压身</li>
<li>融会贯通——自我见解</li>
<li>有字书与无字书</li>
<li>国际视野——外语很重要</li>
<li>新闻里有大财富</li>
</ul>
]]></content>
      <tags>
        <tag>investment</tag>
        <tag>management</tag>
      </tags>
  </entry>
  <entry>
    <title>龚阿玲——创业领导力课程</title>
    <url>/2018/04/08/dianshi-03/</url>
    <content><![CDATA[<ul>
<li>目前的商业模式中在争抢的最后一块阵地是你的时间。当前有太多的信息可以去获取，但是你收到的信息不一定都是你想看到的，而是app想让你看到的。当代的学习是在做减法，而非像之前信息匮乏的年代时的做加法。</li>
<li>如果只是转述别人的话，那你没有在学习。就像一个computer接受了输入，而没有做data processing，不能算是真正学到了东西。</li>
</ul>
<span id="more"></span>
<ul>
<li>学会找到真正的原因是很有必要的。比如“不想创业”-&gt;“害怕技术壁垒”-&gt;“害怕创业失败”-&gt;“家里没钱，输不起”-&gt;…</li>
<li>你小时候最想成为的那个人，最想干那种职业是会跟随你一生的。中途也许会有许多次你觉得自己的条件不具备等原因暂且搁置，但是这个想法本身是会一直伴你前行的。</li>
<li>合伙人找对了，成功的概率是相当之大的，只是时间的早晚问题；但是如果合伙人找错了，那亏损也是铁定的。</li>
<li>创业或是干其他事情之前要先想清楚自己想要的是什么，目标是什么。创业是一条路，一种手段和途径，你要先好好考量这个途径和你的目标之间是否匹配。</li>
<li>对于学生而言，也许成功的案例没有失败的案例对你更加有用。因为人往往是虚伪的，叙述自己成功的经历的时候往往会选择性的忽略一些关键的但是你并不具备的要素，而单纯的变成了一个个励志故事。</li>
<li>一个好的学校比一个好的专业可能给你带来的更多。专业可能更多是你的上一个阶段想干的事情，但是一个好的学校可能更多的告诉你你真的想干什么。一个综合大学可以给你的往往更多。跨界的人往往是更有创造力的，要多去认识不同专业的人。</li>
<li>能力很强没有用，怎样去运用你的能力最有用。投资人不愿意去投资一个工具，因为一个工具总是会被超越的；你的能力再强，总有比你更强的人。但是你的应用场景往往是不易复制的，学会如何用好你的能力往往更有价值。</li>
<li>中国人创业的内容更多是模式和内容，而非科技本身。中国人有很多点子和创意，但把你的点子证明给别人看，证明你的点子能给别人带来价值这件事情更加重要。怎么证明一个问题时对的比单纯的结论重要。</li>
<li>一个旁观者去评价好坏是没有意义的，而一个真正参与过、做过这个行业的人的判断更有价值。</li>
<li>拥有创业者领导力的创业领导者比创业者更有价值。后者只是一场创业游戏的参与者，好坏死活其实事前并无法预知。而一个创业领导者要做的事情是创造一个离开了你也能正常运转的公司。</li>
<li>据统计，男女生擅长的信息接收方式是有区别的。男生更偏向于使用视觉记忆，而女生更偏向于用听觉来获取信息。</li>
<li>找合伙人的时候除了要看他本人的意愿，也要先考察好他的另一半。如果其另一半不支持，家庭不乐意让他创业，最后结果往往也不会和你继续合作下去。</li>
<li>激励他人最关键的是要了解别人最需要的是什么。你认为别人需要的东西并不一定是别人也认同的。比如上司以为请吃饭请旅游能激励员工，但是员工也许想要的是经济上的补贴。</li>
<li>当前企业经营的理念、模式等等已经改变了太多，如果还按照上世纪的老课本来搞，只能大致看到上个时代的人是怎么失败的。比如现在的“羊毛出在狗身上”、当代成本与盈利模式都发生了翻天覆地的变化。现在的经济学管理学是建立在老的那一套生产模式上的，很多已经不合时宜的了。</li>
<li>动机：真实需求的动机（金钱，权利），爱好型的（比如因为xxx在那里）。从长远来看，反而是前者更能长远。</li>
<li>投资人不是你的朋友，是想占你便宜的人。一个好的投资人的角色不是一直陪你走下去，而是陪你走过特定的一段路的人。人要学会认清路上遇到的人们究竟在你的人生中扮演了什么样的角色。</li>
<li>客户说的“这个产品不错，如果开发出来了我一定会买”这种话并不是可信的，很多时候你花了时间做出来了，客户此时并不会去买单。</li>
<li>“一个疯子带一群傻子”是最好的初创期的结构。一个有梦想的领导带上一群能够绝对听你员工谁最好的。两个疯子干不成事，都是傻子跑不远。</li>
<li>能为你带来正现金流的是你的资产，会为你带来负现金流的是你的负债。比如一个房子，如果没能给你带来房租还要不断交物业费，其实在现阶段可以看做一个负债的。同理，朋友再多如果并不能给你带来成长其实并不能看做你的资源。</li>
<li>不要把人看做单纯的“人力资源”。人在生产中既扮演生产者又扮演机器。</li>
<li>你要找准你擅长的一个点，一个环节，一种背景。比如你擅长的是改革流程，那么你在一个初创公司里面就没有太大价值，因为他们还没有建立起来一套流程；反而是在一些已经发展的比较好，正有意改革的地方你的价值会最大化。</li>
<li>从打翻了的饮料的危机公关：Stop停止这件事情-&gt;叫相关的负责人-&gt;。。。</li>
<li><a href="www.adream.org">真爱梦想公益基金会</a></li>
</ul>
]]></content>
      <tags>
        <tag>investment</tag>
        <tag>management</tag>
      </tags>
  </entry>
  <entry>
    <title>点石创校第四课——OKR与管理</title>
    <url>/2018/05/14/dianshi-04/</url>
    <content><![CDATA[<h2 id="okr-introduction"><a class="markdownIt-Anchor" href="#okr-introduction"></a> OKR Introduction</h2>
<ul>
<li>传统的指令管理更加适用于劳动密集型的企业和员工整体文化水平不够高的企业。</li>
<li>目标管理的目标是激励成员，而不是为了考核而制定的三六九等，尤其是适用于创新企业和核心管理层</li>
<li>OKR制定流程：个人愿景（初心）-&gt;目标-&gt;关键结果-&gt;任务清单</li>
</ul>
<span id="more"></span>
<ul>
<li>找到个人的愿景是非常重要的，因为公司的愿景并没法直接激励到个人的</li>
<li>目标 一定要有激励作用，一般会设定一个完成度在60%~70%的目标是最有效的</li>
<li>OKR的制定中最重要的一环是OKR会议。这个问题的关键在于“平等协商，极度透明，求同存异”</li>
<li>OKR会议不是上级给下级布置任务的过程，而是一个平等协商的过程。上下级之间对同一个任务的理解也不一定是相同的，有时候上级对任务的难度有错误估计也是正常的，关键在于协商中的交流</li>
<li>目标的制定原则：具体的，可度量的，可实现的，高相关性的，时间点</li>
<li>每个层级都要制定自己的OKR，比如Dian团队要有团队OKR，项目组要由组长制定项目组的OKR，底层个人也要有自己的OKR，各司其职</li>
</ul>
<h2 id="homework"><a class="markdownIt-Anchor" href="#homework"></a> Homework</h2>
<ul>
<li>加入种子班的初心是什么</li>
<li>你在项目组中要完成的本季度目标有什么</li>
<li>要完成每个目标的关键结果有哪些</li>
</ul>
]]></content>
      <tags>
        <tag>investment</tag>
        <tag>management</tag>
      </tags>
  </entry>
  <entry>
    <title>Cascade, Recursive, Residual and Dense 辨析</title>
    <url>/2020/08/05/cascade-recursive/</url>
    <content><![CDATA[<h2 id="cascade"><a class="markdownIt-Anchor" href="#cascade"></a> Cascade</h2>
<p>相当于Progressive Optimization，每个阶段都会输出一个和最终结果形状相同的Matrix，如目标分布的图像、BBox等，然后下一个block的作用则是输入这个Matrix和前面提取的Features，输出Refined后的Matrix，该步骤不断重复。核心是逐步优化。</p>
<span id="more"></span>
<h2 id="recursive"><a class="markdownIt-Anchor" href="#recursive"></a> Recursive</h2>
<p>相当于把一块Conv block重复了好多次，每次的权重是共享的。核心作用是节省内存和参数量、节省运算时间。同时它也含有时域特征。</p>
<h2 id="residual"><a class="markdownIt-Anchor" href="#residual"></a> Residual</h2>
<p>保留一条“信息高速公路”，使得前一轮的输出可以直接点加到经过了新一轮的Block卷积过后的结果上。核心作用是解决梯度消失问题，同时在网络的各层保留了不同层级的信息。变形有如Residual in Residual。</p>
<p><img data-src="v2-862e1c2dcb24f10d264544190ad38142_1440w.jpg" alt="img"></p>
<blockquote>
<p>ResNet网络的短路连接机制（其中+代表的是元素级相加操作）</p>
</blockquote>
<h2 id="dense"><a class="markdownIt-Anchor" href="#dense"></a> Dense</h2>
<p>每个Conv Block的输出会在Channel维上和后面所有Conv Block的输出Concate到一起。注意和Residual结构的区别，前者是直接逐点相加，而Dense则是并到Channel维度上。</p>
<p><img data-src="v2-2cb01c1c9a217e56c72f4c24096fe3fe_1440w.jpg" alt="img"></p>
<blockquote>
<p>DenseNet网络的密集连接机制（其中c代表的是channel级连接操作）</p>
</blockquote>
<p><img data-src="v2-0a9db078f505b469973974aee9c27605_1440w.jpg" alt="img"></p>
<blockquote>
<p>DenseNet的前向过程</p>
</blockquote>
<p><img data-src="v2-c81da515c8fa9796601fde82e4d36f61_1440w.jpg" alt="img"></p>
<blockquote>
<p>原图</p>
</blockquote>
]]></content>
      <tags>
        <tag>deep-learning</tag>
      </tags>
  </entry>
  <entry>
    <title>密苏里科技大学EMC Lab暑研 第十周</title>
    <url>/2018/09/22/emc-lab-note-10w/</url>
    <content><![CDATA[<p>跌宕起伏而收获满满的一周。</p>
<p>本周伊始，在和张岭学长仔细讨论并规划了PCB电路板优化布局的方案之后，我开始了向深度强化学习的进一步迈进。针对Jim和Zurab教授提出的一些新的优化问题，我有针对性的编写了数份代码。但好景不长，由于这些代码有很多公共部分，而这些公共部分的代码需要不断地迭代更新，这无疑会造成巨大的麻烦以及潜在的错误可能。为了应对这个问题，我利用了Python类这个魔法棒将这些工程代码神奇的合为一体，每次只需在config表中改变一个参数即可。我和学长都对这个项目充满了期待，甚至觉得这是一个学科中里程碑式的进步。</p>
<span id="more"></span>
<p>同时，之前经过多周研讨的通过深度学习对Linux系统中受到干扰端口的特定项目终于拉开了帷幕。在Pommerenke教授的指导下，我和刘晓瑞学长迅速对数据的类型和协议达成了共识，迈出了项目的第一步。次日早上，学长将处理好的数据交付于我后，经过一天的奋力战斗，在天黑之前完成了整个代码框架的搭建。经过简单的几轮训练后，训练集和测试集上的准确率竟然都达到了惊人的100%。虽然再经过了之前贝贝组的“100%大乌龙”事件后我已经不敢轻易相信如此高的准确率，但是经过了仔细的分析后还是确认了这次的结果有很大可能性是真正的100%。首先是训练集和测试集表现一致，另外是与巨大的数据量相对的只有3类的分类数目，和学长对大量数据进行了优质的打标。这次成功我认为很大程度上得益于之前的不懈积累，因为绝大部分代码都直接源于之前辛苦构建的深度学习模板代码，而它们的高质量和稳定性也使我可以更加集中注意力于数据的处理和模型的构建而不必分心于其他功能性代码，模板代码提供的诸多方便的功能也使得开发进度大大加快。</p>
<p><img data-src="006tNbRwly1fwqax86xqej30e612mjtm.jpg" alt="img"></p>
<p>更加令人兴奋不已的是，正在参加会议的Pommerenke教授将我的成果分享给了Google的相关部门研究人员之后，他们表示十分感兴趣并且希望将同样的方法应用到Android系统的电子噪音干扰的特定上，以加强其稳定性。Pommerenke教授也提出了一些新的要求，十分期待该项目的后续进展。</p>
<p>但几乎与此同时，在对PCB电路板优化布局项目的进一步思考中，我发现了一个令人无比沮丧的问题：我们的目标和方法存在着不可调和的冲突。深度强化学习虽然不需要预处理好的数据输入，但是每次计算reward时都需要调用相关仿真代码来判定这次的步骤对最终的阻抗是否产生了正向的影响，而这个过程需要耗费巨量的时间。从某种意义上来讲，这也是对数据的需求。而优化布局这个问题的目标则是用最少的仿真数来获得全局的最优值。为了训练好一个接受高维input的网络，我们需要对每个点都进行多次的训练，而当网络训练好的时候，我们早已找到了全局最优值，并且是以远高于之前方法的代价找到的。此时，神经网络已经没有意义了。</p>
<p>我当即和张岭学长进行了商讨，虽然很不甘心，但是还是决定放弃了使用深度强化学习来解决PCB电路板优化布局问题的念头，并把问题向Zurab教授做了如实的汇报。希望下周能够想出更好的解决办法。</p>
<p>另外就是论文了。本周终于在张岭和孙泽两位学长的指导下完成了初步的论文的修改工作。本周主要加入了孙泽学长负责的粒子仿真部分的介绍和公式推导，并且使用了Zotero这个软件成功的完成了文献的收集到引用一条龙的工作，掌握了公式的编号等问题的解决方法，总体来说还是收获颇丰的。</p>
<p>下周就要考GRE了，尽力准备吧！(๑´ ω｀๑)</p>
]]></content>
      <tags>
        <tag>essay</tag>
        <tag>EMC</tag>
        <tag>abroad</tag>
      </tags>
  </entry>
  <entry>
    <title>EMD, EEMD与CEEMD</title>
    <url>/2020/03/12/eemd/</url>
    <content><![CDATA[<h2 id="emd"><a class="markdownIt-Anchor" href="#emd"></a> EMD</h2>
<p>EMD: Empirical Mode Decomposition</p>
<h3 id="特征"><a class="markdownIt-Anchor" href="#特征"></a> 特征</h3>
<ol>
<li>自适应。与小波分析相比，克服了基函数无自适应性的问题，解决了全局最优小波基在局部并非最优的问题，有基函数自适应特性。</li>
<li>可以直接进行分解，不需要预分析和研究。</li>
</ol>
<span id="more"></span>
<h3 id="内涵模态分量"><a class="markdownIt-Anchor" href="#内涵模态分量"></a> 内涵模态分量</h3>
<p>内涵模态分量（Intrinsic Mode Functions, IMF）就是原始信号被EMD分解之后得到的各层信号分量。EMD的提出人黄锷认为，任何信号都可以拆分成若干个内涵模态分量之和。而内涵模态分量有两个约束条件：</p>
<p>1）在整个数据段内，极值点的个数和过零点的个数必须相等或相差最多不能超过一个。</p>
<p>2）在任意时刻，由局部极大值点形成的上包络线和由局部极小值点形成的下包络线的平均值为零，即上、下包络线相对于时间轴局部对称。</p>
<p>啥意思？</p>
<p>用不严谨的语言和灵魂画师来解释一下：</p>
<p>1）图线要反复跨越x轴，像这样：</p>
<p><img data-src="v2-0e5b832aee81e8a9068c9665e6eb2a3a_1440w.jpg" alt="img"></p>
<p>在整个数据段内，极值点的个数和过零点的个数必须相等或相差最多不能超过一个</p>
<p>而不能像这样某次穿过零点后出现多个极点：</p>
<p><img data-src="v2-921bc09334db7a4e443578091117788f_1440w.jpg" alt="极点数目偏多"></p>
<p>2）包络线要对称，像这样：</p>
<p><img data-src="v2-8826ddaefd1cebee1841bf5ff083c494_1440w.jpg" alt="包络线对称"></p>
<p>而不能像这样：</p>
<p><img data-src="v2-deb9cd0d0dcb8a154f8621276cce9972_1440w.jpg" alt="包络线不对称"></p>
<p>洗洗眼睛，看个正常点的例子吧：</p>
<p><img data-src="v2-a609c2680a2f4c525648a414d9b0a358_1440w.jpg" alt="EMD分解"></p>
<p>上图由7张图片组成，其中第1张为原始信号，后边依次为EMD分解之后得到的6个分量，分别叫做IMF1~IMF5，最后一张图为残差，每一个IMF分量代表了原始信号中存在的一种内涵模态分量。可以看出，每个IMF分量都是满足这两个约束条件的。</p>
<h3 id="分解步骤"><a class="markdownIt-Anchor" href="#分解步骤"></a> 分解步骤</h3>
<p>1）根据原始信号上下极值点，分别画出上、下包络线。</p>
<p><img data-src="v2-c18c7b4e6d60711351a4d55cb8271320_1440w.jpg" alt="img">上、下包络线</p>
<p>2）求上、下包络线的均值，画出均值包络线。</p>
<p><img data-src="v2-d56c460e9dd9e245521140497afddb39_1440w.jpg" alt="img">均值包络线</p>
<p>3）原始信号减均值包络线，得到中间信号。</p>
<p><img data-src="v2-e74e49a23dda87df74a562809257ddda_1440w.jpg" alt="img">原始信号减均值包络线</p>
<p>4）判断该中间信号是否满足IMF的两个条件，如果满足，该信号就是一个IMF分量；如果不是，以该信号为基础，重新做1）~4）的分析。IMF分量的获取通常需要若干次的迭代。</p>
<p><img data-src="v2-8b6643d803c3bdfb47639e65a75d4c8d_1440w.jpg" alt="img">不满足约束2，需要继续迭代</p>
<p>使用上述方法得到第一个IMF后，用原始信号减IMF1，作为新的原始信号，再通过1）~4）的分析，可以得到IMF2，以此类推，完成EMD分解。</p>
<p><img data-src="v2-f735266df804d187b1d173fe6f1bb168_1440w.jpg" alt="img">迭代分解结果</p>
<p>上述例子中的图来自<a href="http://perso.ens-lyon.fr/patrick.flandrin/emd.ppt">http://perso.ens-lyon.fr/patri</a></p>
<h2 id="eemd"><a class="markdownIt-Anchor" href="#eemd"></a> EEMD</h2>
<p>EEMD: Ensemble Empirical Mode Decomposition</p>
<p>简单的说，EEMD是在EMD的基础上，对原始信号进行了N次添加各异等幅白噪声并分别进行EMD分解后，对每个IMF中间分量进行平均。</p>
<p>其原理是通过加入白噪声来改变信号极值点的分布，得到符合信号特征的上下包络线，消除模态混叠效应。加入的白噪声通过多次平均消除。</p>
<h2 id="ceemd"><a class="markdownIt-Anchor" href="#ceemd"></a> CEEMD</h2>
<p>CEEMD是在EEMD的基础上，把随机添加的N组白噪声改为了N/2组正噪声和N/2组负噪声，依旧是最后进行平均。</p>
<p>根据 Yeh 等人的研究，在加入相同数量以及相同幅值的白噪声时，EEMD 剩余噪声会随着集成平均的次数而逐渐减小。CEEMD 的剩余噪声一直维持在一个较小的程度，不论集成平均次数多少。在一定程度上使用 CEEMD方法进行信号分解，可以使用相对较少的集成平均次数，从某种意义上来说，CEEMD在保证小剩余噪声干扰的情况下，能够节省计算时间。</p>
<p><img data-src="931855-20190117162939850-50932674.png" alt="img"><img data-src="931855-20190117163017276-1187230461.png" alt="img"></p>
<h2 id="python库"><a class="markdownIt-Anchor" href="#python库"></a> Python库</h2>
<p>EMD, EEMD, CEEMDAN and some visualization support are contained in this repository.</p>
<p>We can use <code>pip install EMD-signal</code> to install this library.</p>
<h2 id="引用"><a class="markdownIt-Anchor" href="#引用"></a> 引用</h2>
<ol>
<li><a href="https://www.cnblogs.com/Dinging006/p/10282993.html">EMD——EEMD——CEEMD语音增强算法基础</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/40005057">这篇文章能让你明白经验模态分解（EMD）——基础理论篇</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/44833026">这篇文章能让你明白经验模态分解（EMD）——IMF的物理含义</a></li>
<li><a href="https://www.researchgate.net/publication/220531146_Ensemble_Empirical_Mode_Decomposition_a_Noise-Assisted_Data_Analysis_Method">Ensemble Empirical Mode Decomposition: a Noise-Assisted Data Analysis Method</a></li>
</ol>
]]></content>
      <tags>
        <tag>signal-processing</tag>
        <tag>audio</tag>
      </tags>
  </entry>
  <entry>
    <title>密苏里科技大学EMC Lab暑研 第十一周</title>
    <url>/2018/09/29/emc-lab-note-11w/</url>
    <content><![CDATA[<p>文 | 张中洋</p>
<p>温馨有趣的一周。</p>
<p>周五在导师Pommorenke家举行了一次火锅party，参与者有我们Lab的一些博士生、实习生，以及MST大学中和小帕熟识的一些中国学生，以及其儿子的一些同学。小帕有两个女儿、一个儿子，他们各自都选择在自己喜欢的填空下走着自己的路：小帕的儿子十分阳光活泼，预计留在美国继续学业；大女儿会说法语德语和英语，和男朋友在一起；而小女儿酷爱读书，喜欢在图书馆呆着，由于认为美国的医生太过重视钱而不足够关心人，她在下周四即将前往德国追求其理想中的医者仁心。小帕和其小女儿都能够说一口流利的中文，小女儿还在台湾交换留学过一年，可谓一家的中国通。最开始其实我是不太适应这种party的，感觉到的只有身处人群中的孤独，但是渐渐内心的感觉也开始发生了微妙的变化，感觉这也许是一个很棒的事情。最重要的一点是其给了我们一个以工作以外身份示人的机会。大家吃在一起，玩在一起，聊在一起，带来的是食物和酒，带走的是回忆的碎片和美好的瞬间。</p>
<span id="more"></span>
<p>周六MST大学举办了一个各国文化节一样的活动，各个国家的国旗飘扬，大家身着各自的民族服饰，在街上举行了盛大的Parade，还有各个国家的学生联合摆摊出来向群众们售卖特色食品，舞台上学生们的纵情高歌起舞，草地上的罗拉群众们悠闲的聊天，共同在这秋日清爽的蓝天暖阳下构筑了一道靓丽的风景线。</p>
<p><img data-src="006tNbRwgy1fwqb02u6o4j30de0a2qbs.jpg" alt="image-20181030155634727"></p>
<p>周三晚上到了杰弗逊城住下，等待着次日的考试。这次考试并没有考好，原因也很显然，这回并没有做好足够的准备。还是希望下次能够拿出足够的时间准备的。当日去了州立博物馆，那里的穹顶很是恢弘壮观。</p>
<p><img data-src="006tNbRwgy1fwqb082jauj30de0a2gtn.jpg" alt="image-20181030155642677"></p>
]]></content>
      <tags>
        <tag>essay</tag>
        <tag>EMC</tag>
        <tag>abroad</tag>
      </tags>
  </entry>
  <entry>
    <title>密苏里科技大学EMC Lab暑研 第十二周</title>
    <url>/2018/10/06/emc-lab-note-12w/</url>
    <content><![CDATA[<p>世界线临近收束的一周。</p>
<p>在过去的三个月里，一同来到Lab这个大家庭的近二十名实习生分别度过了各自不同但却又都独一无二的时光，但无论如何，在回国这个收束点面前，一切都会无可避免的向着相同的方向归结。这段时光中的或起、或落、或精彩、或失落，都将会化为时光中的闪光、记忆中的碎片，并融合进自己人生的拼图中，拼接出只属于自己的形状。</p>
<span id="more"></span>
<p>在最后的时间里，人往往并不愿意面对即将到来的或新或旧的生活和步步迫近的分离与再会，直到某个宁静的雨夜，黑暗中倏然而逝的车灯光给人会心一击。未来这个庞大无比的词也许是无可避免的命运之链的下一环，也许是有待自己一番探索的未知黑洞，然而所有从未来发出的光都会被锁链牢牢缠住、被黑洞重新拉回，时光的追溯者们用渴望而急切的目光看向其中，却空余怅然于心。开拓者们扛起已然和自己手融为一体的劳具，继续向前。</p>
<p>在这三个月里，我参与了四个项目，和实验室的许多导师建立起了联系，并提供了力所能及的些许帮助，也在很早就拿到了导师的内诺，所以对于最终答辩，我并不是很紧张的。整理散落在时光中的碎片，编一叶扁舟，承载着众多思绪随急流至终点。在此过程中，我的导师、我的两位mentor都给了我莫大的帮助，尤其是岭神，给了我从生活到学术的全方面支持，我十分感谢他的悉心指导，所谓恩人莫过于此。</p>
<p><img data-src="006tNbRwgy1fwqb1gsp3dj31k81604jn.jpg" alt="image-20181006230705572"></p>
<p><img data-src="006tNbRwgy1fwqb1jm9rpj31km15gx09.jpg" alt="image-20181006230728367"></p>
<p>今天，周六，学长带我们去了圣路易的机车历史博物馆。从锈迹斑斑、百岁高龄的见证了历史的诸多篇章的火车，到充满了机械元素的蒸汽机车，再到最高时速80码的保养完好的列车、层满载牛奶的运输车、曾盛满冰块用来运送生鲜的列车都被安放在一条条不再有终点站的铁轨上，静静地玩味着老后才能品味到的宁静、观察着每一个走近它、走进它的观者。我们有幸碰到了一位颇具长者风范、特立独行而阅历丰富的工作人员，他为我们详细地介绍了一辆辆列车的故事和它们曾经的事业，活力四射的语调中饱含着对着一辆辆车的热爱与熟识。列车虽已退役，但仍有记得它们故事的人在；讲述者也许也有其终点，但一个个片段却会继续留在听者的记忆深处，想来这也许就是“历史”的意义吧。</p>
<p><img data-src="006tNbRwgy1fwqb1ls5f5j31400u00z7.jpg" alt="WechatIMG3"></p>
<p><img data-src="006tNbRwgy1fwqb1e24zqj30wc16kqnv.jpg" alt="image-20181006230631504"></p>
<p>在历史的铁轨尽头矗立，在未来的信号灯的指引下向前，手持铁镐，一同开拓吧！</p>
<p><img data-src="006tNbRwgy1fwqb1o4axij30i00sg7nm.jpg" alt="相关图片"></p>
]]></content>
      <tags>
        <tag>essay</tag>
        <tag>EMC</tag>
        <tag>abroad</tag>
      </tags>
  </entry>
  <entry>
    <title>密苏里科技大学EMC Lab暑研 第二周</title>
    <url>/2018/07/26/emc-lab-note-2w/</url>
    <content><![CDATA[<p>​	本周是2018年华中科技大学同学来密苏里科技大学进行暑研的第二周。如果用一个词来概括本周的感觉，那“渐臻佳境”将会是一个不错的选择。第一周生活划下的略显杂乱的轨迹线在此延长、伸展、放射，形成了一道优美而有序的线条。</p>
<p>​	首先是生活方面，由于初来乍到的我们没有合适的厨具、没有料理的原料，而且更扎心的是一起生活的四个小伙伴都不会做饭，所以我们几乎吃遍了罗拉城中心地带的各种中餐厅日料店，更是消耗掉了几大包泡面。而在即将毕业学长的帮助下，我们凑 齐了厨具，去沃尔玛购买到了原料，并且下载了“下厨房”App开始了零基础的料理学习。每天一到饭点，大家就会齐心协力烹制一道道虽然简单但是却也可口的饭菜。能够自己做饭无疑大幅降低了我们在吃饭方面的开销，同时也为之后的留学生活打下了必要的基础。</p>
<span id="more"></span>
<p><img data-src="006tKfTcly1ftqbfpfa9uj31kw1kw4qp.jpg" alt="IMG_1977"></p>
<p>​	之后便是学习研究方面。在研究方面，由于之前在Dian团队打下了坚实的编程与算法的基础、培养了必要的快速学习能力，整体来说我进入状态还是相对较快的。我做的第一个项目是用matlab通过智能算法优化限定条件下ESM放射源扫描中的采样点选取问题。通过将近一周的不断优化，同时也得益于学长和各位导师们耐心的指导和激烈的讨论，在我们所特定的条件下，目前已经取得了相当不错的结果。</p>
<p><img data-src="006tKfTcly1ftqaz36trlj31kw0l47wh.jpg" alt="image-20180728165436778"></p>
<p>​	这个项目稍微告一段落后，紧接着张岭学长结合范教授得到知道，给我安排了另外一个更具有挑战性的任务，这个任务将主要通过深度学习方法完成，如果效果达到预期，其将作为一个大型仿真项目的一部分被整合。</p>
<p>​	本周的活动依旧丰富。我们和实验室的导师以及学长们一同踢了足球，参加了野外烧烤、去电影院观看了刚刚上映的碟中谍。由于这里的电影院支持躺着观影，所以观影体验确实是相当不错的。不过看了这种没有字幕的电影，不由感到应该赶紧提高自己这依旧令人捉急的英语听力了。虽然平时和教授们讨论以及购物等场景还是能够应付的，不过到了更加复杂的生活场景中时还是会感到差的很远。长路漫漫，且行且思！</p>
<p><img data-src="006tKfTcly1ftqbiogksaj31kw16o4qq.jpg" alt="IMG_1975"></p>
<h5 id="躺着的电影院"><a class="markdownIt-Anchor" href="#躺着的电影院"></a> “躺着的”电影院</h5>
<p><img data-src="006tKfTcly1ftqbifpudoj31kw0w01l0.jpg" alt="IMG_2090"></p>
<h5 id="夕阳下的合影"><a class="markdownIt-Anchor" href="#夕阳下的合影"></a> 夕阳下的合影</h5>
<p><img data-src="006tKfTcly1ftqbixud7tj31kw11oe84.jpg" alt="IMG_2087"></p>
<h5 id="足球场风采"><a class="markdownIt-Anchor" href="#足球场风采"></a> 足球场风采</h5>
<p>下周我们将和实验室的导师学长们一同去加州参加一个领域内的研讨会，十分期待！</p>
<p>2018.7.28</p>
]]></content>
      <tags>
        <tag>essay</tag>
        <tag>EMC</tag>
        <tag>abroad</tag>
      </tags>
  </entry>
  <entry>
    <title>密苏里科技大学EMC Lab暑研 第一周</title>
    <url>/2018/07/19/emc-lab-note-1w/</url>
    <content><![CDATA[<p>本周是2018年华中科技大学同学来密苏里科技大学进行暑研的第一周。同学们兵分两路，先后抵达密苏里州首府圣路易斯。学长们不辞辛苦，在深夜驱车至圣路易斯机场将我们安全送达住处，并在之后的日子里帮助我们解决了平时的绝大部分交通以及日常用餐问题，这令我们不胜感激。</p>
<span id="more"></span>
<p>在本次暑研中，我、王晓纤、彭哲坤、张秀珍四位由csc资助的同学选择了11日的班机出行，并提前在密苏里科技大学附近预定了4间单人公寓。到达罗拉城最初的几日，由于13个小时的时差原因，我们在白天的精神状态一直不算很好。在此期间，我们去沃尔玛采购了各自的生活必需品以及公共的卫生用品以及必要的厨具。另外魏鹏宇学长由于即将要去苹果公司工作，遂将他自己的绝大部分厨具和一部分生活用品无偿赠与了我们几个同学，这令我们十分感动。这里的学长学姐们在生活和学习的方方面面都给予了我们莫大的帮助，从带我们品尝罗拉的各色美食、游玩附近风景，到为我们详细讲解论文、回答略显幼稚的问题，这些点点滴滴都是我们值得珍藏的回忆。<img data-src="006tNc79ly1fthxanudkqj31kw23vx6r.jpg" alt="IMG_1391"></p>
<p>这个远离都市喧嚣的宁静小城可谓是做学术理想之处，而EMC Lab则更是这里的学术圣地。进门右转，长长的走廊两侧墙上挂满了前辈们的论文，一纸一文、一词一句都是前人留下的足迹，值得我们不懈追寻。环顾四周，更是能够感受到这里浓厚的学术氛围。学生、教授，无论是哪位都在专心致志的做着自己手头的工作；或软或硬，但都深深投入其中。每天晚上12点出门时，望着停车场依旧停着的整整齐齐的汽车，我好像渐渐能够理解这里为何能够成为全美EMC行业之领军了。</p>
<p>罗拉的环境优美，气候宜人。这里的天似乎总是很低，低到让人想伸手去采摘天边懒洋洋地飘着的云；这里的空气也似乎总是那么清新，净到每晚都能看到高挂的满天星河。这里的湖水甚为清澈，时而有垂钓者傍湖而渔，鸟击水而鸣。落日十分更是十分动人，被落霞渲染的五光十色的云朵配上波光粼粼的湖面或是曲折蜿蜒的公路，再佐以一望无际的草地带来的开阔视野，可谓是蔚为壮观。<img data-src="006tNc79ly1fthxbh1shvj31kw16o4qq.jpg" alt="IMG_1955"></p>
<p>Lab同样也有着丰富的活动。足球、篮球、乒乓球、保龄球等轮番登场，学习工作之余的运动着实令人倍感舒畅。在这里的第一场球赛是在“真草”上进行的，这无疑也是一次久违的体验。虽然由于平日久坐之故，时至后半场队员们大多体力槽告急，之后也过了几天才养好身上“像是被毒打了一顿”的酸爽，整场比赛给人的感觉还是相当富有青春活力而令人激动的。<img data-src="006tNc79ly1fthxb423dtj31kw16okjm.jpg" alt="IMG_1808"></p>
<p>学长学姐们还在上周末带我们去了一次“大城市”圣路易斯，在那里我们既品尝了美味的西餐和地道的川菜，又参观了当地极具特色的博物馆、逛了精致的衣妆百货满满的大商城。整个旅程是相当惬意而愉快的。<img data-src="006tNc79ly1fthxbx6pf8j31kw16o1l2.jpg" alt="IMG_1782"></p>
<p>学习研究方面，负责指导我的张岭学长给出了两个题目，一个是用机器学习方法解决一个三维电路板的电源相关调参问题，另一个是自行设计算法取样以更加有效的测量电路板上的放射源分布。当前已经在第二个问题上取得了阶段性的进展，希望后续能够进一步优化算法，得到更加优秀的结果。</p>
<p>2018.7.21</p>
]]></content>
      <tags>
        <tag>essay</tag>
        <tag>EMC</tag>
        <tag>abroad</tag>
      </tags>
  </entry>
  <entry>
    <title>密苏里科技大学EMC Lab暑研 第三周</title>
    <url>/2018/08/04/emc-lab-note-3w/</url>
    <content><![CDATA[<p>机翼拂过地表的风，穿过天边的云，越过无垠的大海与起伏的丘陵；极目远眺，无数的灯火点缀着这片宁静的夜。Los Angeles，我们的脚尖轻触这片多情的地，任生命的画卷被这座城浸染。</p>
<p>纵横交错的路携手含情脉脉的灯，编织出了一条条闪烁的金线；从高空俯瞰，这座四四方方的城市好似一块硕大无朋的电路板，流动的车与人则好似股股电流，于其间不知疲倦的穿梭往复。短短五天的洛杉矶之行，就此宣告拉开了帷幕。</p>
<span id="more"></span>
<p>本次出行是参加IEEE组织的EMC行业相当于年会的Symposium，既有学界各路大佬牛人宣讲其paper，也有业界各大公司商行来此做Exhibition，推广宣传其软硬件产品。我们一行人中，既有来做报告的导师及PhD的学长学姐，也有来做会议志愿者的实习生和研究生们，大家搭乘飞机，于周日晚抵达洛杉矶。</p>
<p><img data-src="006tKfTcly1fty8o7ib95j31kw16rtyp.jpg" alt="IMG_2164"></p>
<p>洛杉矶长滩海滩</p>
<p>细数起这几天的经历，惊喜地发现了诸多人生中的“第一次”。大到第一次在大型Symposium上做志愿者、第一次不靠别人引荐在宴会和Gala Banquet上和来自各个国家的大佬们“Social”、第一次真正意义上交到外国朋友、第一次用日语和一桌日本教授愉快交流、第一次拿到别人的名片，小到第一次住motel、第一次在美国搭乘Uber出行，第一次游玩环球影城，第一次吃甜甜圈状的汉堡。</p>
<p><img data-src="006tKfTcly1fty8oh72bxj30u0140wjy.jpg" alt="IMG_2755"></p>
<p>环球影城标志</p>
<p><img data-src="006tKfTcly1fty8ovh6e7j31420u0tc6.jpg" alt="IMG_2757"></p>
<p>哈利波特小城</p>
<p><img data-src="006tKfTcly1fty8p1s5lcj31420u0juy.jpg" alt="IMG_2758"></p>
<p>与“哈式”工作人员合影</p>
<p><img data-src="006tKfTcly1ftymtaeda3j31kw16r4qp.jpg" alt="IMG_2826"></p>
<p>玛丽皇后号</p>
<p>这片陌生的土地也告诉了我许多熟悉的道理：外语口语只有多用才能产生自信、努力工作将会得到赏识、只有大胆追求机会才会来临、陌生人通过交流会变成可爱可敬的人。刚来到这里时其实胆怯和保守心理还是占据上风的，尽量避免和陌生人产生不必要的会话，尽量少搭话防止打扰大佬们，展会上展示的东西都是我不清楚的而且也不会去买所以还是别去以防尴尬，社交晚会很庸俗尽量远离为好等等。但这些天中不断发生着的A到Z，都渐渐扭转了我之前执拗而有失偏颇的想法。大佬们虽然确实很优秀，但他们也并不会因此就鄙视别人，拒绝谈话；虽然展会上展出的东西的确你都不会买，但那也不是想卖给个人的，去转转还是挺有趣的；社交晚宴确实挺吵闹，但就是在那里我终于和同为实习生的3位韩国小哥成为了朋友，并得以认识了不少来自世界各地的有趣而有料的教授和会社人；多张口问别人问题、与人交流并不会因为poor的口语而被嘲笑，而是渐渐增强了自信，更敢于和别人用各种外语交流了。</p>
<p><img data-src="006tKfTcly1ftymw51rhqj31kw16onpd.jpg" alt="IMG_2879"></p>
<p>志愿者证与在Banquet收到的名片</p>
<p><img data-src="006tKfTcly1fty8pf5qmpj31kw16r4qp.jpg" alt="IMG_2868"></p>
<p>在玛丽皇后展馆中和韩国小哥们合影</p>
<p>当然，除了成长，洛杉矶也给我们带来了实实在在的堪称享受的娱乐活动。长滩午后海滨的慵懒与放松，环球影城各种项目带来的好莱坞级别级别的感官刺激、身临其境的电影艺术体验、从历史到当代最先进电影技术带来的思想碰撞，玛丽皇后号上对沧桑历史的认知和顶级banquet带来的极致奢华的体验，如果平日里的成长与体验是沙漠中的风对岩石的雕琢，那相信这些天来所有经历过的这一切会像地震和火山喷发般以极其浓缩的能量剧烈地塑造我心中的版图，撼动地基深厚的偏见的高山，并用喷薄而出的养分造就一片片新的沃土。</p>
<p>新的一周又即将来临，命运石之门又会带来些什么惊喜呢？</p>
<p>2018.8.3</p>
]]></content>
      <tags>
        <tag>essay</tag>
        <tag>EMC</tag>
        <tag>abroad</tag>
      </tags>
  </entry>
  <entry>
    <title>密苏里科技大学EMC Lab暑研 第四周</title>
    <url>/2018/08/11/emc-lab-note-4w/</url>
    <content><![CDATA[<p>本周是效率拔群的一周。从洛杉矶回来后，马上着手了走之前和张岭学长讨论的机器学习项目，并已经取得了很好的效果，这令我们十分振奋。这个项目是波音公司主导的一个研究型项目，我负责的是将之前使用传统方法由瞬时二极管中的电荷和空穴分布求解出器件中各店电压分布的过程用深度学习予以优化。</p>
<span id="more"></span>
<p>真正令人着迷的也许不是后面的实现过程，尽管这个过程也同样有趣，而是与学长们讨论的这个过程。如何定义问题，如何将一个复杂的问题拆分成一个个容易着手的点，又怎样将一个抽象的问题合理地转化为一组组“Input”“Output”“Loss Function”，这个激烈讨论的过程着实酣畅淋漓，也给予了后续的过程一个很扎实的开端。同时感觉自己真的非常非常幸运，能够遇到一个可以理解自己的优秀mentor，做着自己享受的工作并持续学习着令人激动的新知，并得到效果相当不错的结果。从讨论问题的着力点到着手搭建深度学习代码框架，思考模型结构并实现，不断的尝试与摸索更好的解决方案，直到最后学习了优质而简洁的模型及结果可视化工具，整个过程都如此的流畅而舒展。</p>
<p>仔细想来，不吹不黑，这种面对新问题时能够沉着冷静分析并自信于高质量实现的态度绝对是在Dian团队这一年来的真实项目锻炼中不知不觉中学到的。在团队里学到的不仅仅是实实在在、能够拿来用的机器学习知识和编程技能，更重要的是敢于系统分析问题的能力。每当想起这里，无不庆幸于当初能够加入种子班、感恩于团队导师和学长们的指导。</p>
<p>真正令人意外的事情在训练出来的结果不但很好的对上了各个时间点的趋势，还完美的消除了数据自身存在的噪音，这想必也是来源于大量数据的训练造成的泛化性提高以及网络出色的拟合能力。<img data-src="0069RVTdly1fu6fan9edsj31520nwtfo.jpg" alt="2091533836248_.pic_hd"></p>
<p>除了项目，上周末的娱乐活动也是极其精彩刺激的。学长们带我们去了邻市的专业射击店，在这里，我们体验了从2.2mm的手枪和猎枪到5.56mm的步枪、甚至是7.62mm的AKM步枪。尽管之前已经在游戏中无数次体验射击，但是真正的射击带给人的那种源于危险的一丝丝紧张、源自渴望正中靶心的注意力高度集中、手指扣动扳机的瞬间扑面而来的巨大爆破声响和随之而来反作用力造成的切切实实的冲击，以及命中时迸发出的激动与兴奋等等对我而言都是无比新鲜的。<img data-src="0069RVTdly1fu6fsd78s6j31kw23v1ky.jpg" alt="IMG_2990"></p>
<p><img data-src="0069RVTdly1fu6frhczdbj31kw23vkjl.jpg" alt="IMG_2965"></p>
<p>另外值得一提的是我们四位住在一起的小伙伴们从下厨的门外汉也开始一点一滴地学会了许多好吃的菜的做法，这无疑令我们的生活满意度更上了一层楼。</p>
<p><img data-src="0069RVTdly1fu6fvbr7irj31kw23vnpe.jpg" alt="IMG_3016"></p>
]]></content>
      <tags>
        <tag>machine-learning</tag>
        <tag>essay</tag>
        <tag>EMC</tag>
        <tag>abroad</tag>
      </tags>
  </entry>
  <entry>
    <title>密苏里科技大学EMC Lab暑研 第五周</title>
    <url>/2018/08/18/emc-lab-note-5w/</url>
    <content><![CDATA[<p>辛苦而刺激的一周。</p>
<p>上周完成了深度学习模型的搭建之后，本周开始了复杂而艰难的测试工作。之所以如此复杂，是因为模型验证只能建立在连续模拟得出的曲线之上。而想要得到足够的验证数据，必须把之前学长所搭建的MATLAB仿真代码和自己基于Python的深度学习代码进行结合。大致的方法有三：</p>
<span id="more"></span>
<ol>
<li>
<p>将3500行MATLAB代码直接翻译成Python代码。</p>
<ul>
<li>
<p>优点：最直观，适配性最强，GitHub有相关转换脚本</p>
</li>
<li>
<p>缺点：耗时大，暗bug难以调试</p>
</li>
</ul>
</li>
<li>
<p>将Matlab代码拆分成几个大函数，封装好后用Python运行这些文件</p>
<ul>
<li>
<p>优点：大大降低工作量，而且能够保证封装的文件运行得到正确的结果</p>
</li>
<li>
<p>缺点：调用泊松方程部分知识一个小调用，整个Main文件大体还要改，list等的传参也很成问题</p>
</li>
</ul>
</li>
<li>
<p>将机器学习部分做成Linux服务器端，在Matlab端只调用接口</p>
<ul>
<li>
<p>优点：快速，可复用</p>
</li>
<li>
<p>缺点：同样的问题时学习成本较高。有做不出来的可能，耗时较长</p>
</li>
</ul>
</li>
</ol>
<p>起初我尝试了第一种方法，借助GitHub上开源的MATLAB转Python的东风，只用了几个小时便完成了大致的转换，本来信心满满准备着手测试时，却意外的发现尽管大部分语法都得到了正确的转换，但是还是有许许多多细节问题需要一步步调整。整个调试持续了整整三天，当最终可以运行是却再次发现了两个问题：</p>
<ol>
<li>运行速度相较于MATLAB原生程序慢了太多。MATLAB上只要0.4秒的程序转成了Python竟然需要上千秒。经过仔细的分析，原因主要有两个：一是MATLAB本身就对矩阵运算进行的大量的优化，而Python想要实现相似功能只能借助第三方库函数。二是自动转换脚本为了保证数组下标等的正确性引入了一个新的类matlab array。每个数组都会被初始化为一个实例，而这本身就是很耗时间的。三是其中涉及了很多类型转换，而数组有很大很多，不少数组都有多达数万个元素，拷贝式的转换会消耗掉巨量的时间。</li>
<li>结果不正确。有部分函数和方法MATLAB和Python的解读不同。这种问题大部分是可以被发现的，但是实际上debug的难度随着代码长度和复杂度而急剧上升，尤其是原来的代码本身就较为dirty，而不是结构化的运算时。另外还有部分不仔细分析调试断点根本无法发现的隐藏式的bug，这些都使得这个庞然大物似的代码极难调试。</li>
</ol>
<p>之后，我试着只手动重写main程序，其他的模块全部封装化，但结果依旧不理想。由于程序不断地在MATLAB和Python解释环境中切换，这必然涉及到大量的传参，而MATLAB和Python之间的传参甚至比普通的类型转换更加耗时，往往一个循环要消耗数百秒。Python中一个MATLAB的函数调用传参转换花的时间和本身花去的时间之比根据参数数量和大小甚至可以达到了1:200以上。这无疑是一个令人震惊的比例。但是如果希望通过不断调用MATLAB函数并将长达400行左右的main函数通过Python执行，大量的传参就是无法避免的。</p>
<p>于是，经过充分的思考后，我果断放弃了之前五天的成果，选择了下一种方法：只在Python中控制主循环以及几个关键而小的变量，把之前的main长长的代码拆成了数个代码块，打包成一个个可供Python调用的函数，并把函数文件间的沟通“大任”从Python主程序转移到了中间mat文件。每个MATLAB脚本执行之前都会Load之前存下的中间变量并在结尾储存当前所有的中间变量。通过这种方法，Python中每个循环的执行速度也由直接传参的数百秒降低到了可以接受的0.5秒。之后便是把自己的机器学习代码写了一个简单而迅速的接口，替换掉了原有的泊松方程求解部分。预计下种可以出来正式的拟合曲线。</p>
<p>说完上面洋溢着满满技术味的本周进展情况，下面就是精彩刺激的“绝地求生”“荒野行动”了。本周五lab组织全员参与了独木舟漂流活动。活动描述很简单：三个人一条小舟，带上充饥的食品，从漂流的起点划到终点。但是到了现场才发现：这个活动和最初我们的印象完全不一样。首先漂流并不是简单的顺水漂下，而是真正用桨把一个铁质的小舟划起来。环境也让人感到十分惊异：和国内经过开发的景点完全不同，河岸两边都是茂密的森林，整个旅程中的大半时间都处在“前无古人后无来者”的状态，紧张刺激的同时又的确充满了危险的气息。其次是水道的状态：急流、险滩、暗礁、巨大树枝、深浅水域、搁浅地带等都给划行造成了巨大的困难。而最关键的三点是：</p>
<ol>
<li>我们三名来自种子班的同学被分配到了同一条船上，但我们都没有划船的经验</li>
<li>整个水道流域很长，当我们划了4个半小时被告知还有一半的时候真的对绝望有了很好的理解</li>
<li>没人救援。虽然同行的人很多，但是因为几名教授和学长为了增加旅程的乐趣用各种方法翻过路的船，而我们都是新手，为了避免不断被翻船选择了等到所有人走了之后再动身</li>
</ol>
<p>我们三人在一天中划行了整整7个小时，可谓是相当“勇猛”了。实际上，最快的组4个小时便到达了终点，而我们则因为中途被翻了4次船、等待翻船大佬们先行和由于对划船不熟练造成的转向、撞暗礁和其他各种障碍物、搁浅等原因而延误了很久。不过令人欣慰的是我们在这个过程中在热心老外的指导下成功学会了配合划船，而且由于我们选用了隔水性能很好的保鲜袋，至少保证了一天的食物这两点。</p>
<p>一路上虽然非常辛苦，甚至都多多少少受了些伤，但是泛舟于丛林深处、玩味夏日的蓝天与翠林、感受“蝉噪林逾静，鸟鸣山更幽”的静谧还是让人十分愉快而放松的。在回来的路上，我们还有幸看到了天空中高挂的彩虹，可谓是美妙的一天。<img data-src="006tNbRwgy1fuejycdf41j31400u0q7a.jpg" alt="IMG_3058"></p>
<p>另外真的多谢早早划完全程还不断担心我们几个的诸位学长老师，当划到最后筋疲力尽时候看到专程从岸边跑回来瞭望我们的教授们时，当最终上岸被学长们热情迎接时，真的感觉非常非常的温暖。谢谢大家！</p>
<p>此外，本周我们还有幸看到了英仙座流星雨，尽管是在我们的公寓后的停车场的简单肉眼观测，但是还是感到了无比的梦幻而美好。漫天星海中的那靓丽的一闪而过，恍若樱花般灿烂而短暂，尽管只消一瞬，但却永驻观者心间。“Wish upon the shooting star”。<img data-src="006tNbRwgy1fuejz7guf0j30u01o0ad9.jpg" alt="IMG_3045"></p>
<p>本周厨艺依旧在稳步进步，现在已经渐渐能够烧制一些可口的饭菜了，幸福指数又能++了。</p>
]]></content>
      <tags>
        <tag>matlab</tag>
        <tag>essay</tag>
        <tag>EMC</tag>
        <tag>abroad</tag>
      </tags>
  </entry>
  <entry>
    <title>密苏里科技大学EMC Lab暑研 第六周</title>
    <url>/2018/08/27/emc-lab-note-6w/</url>
    <content><![CDATA[<p>开疆拓土、高歌猛进的一周。</p>
<p>本周尝试了许多新技术，学到了很多新操作，其中有的像是“夙愿”的愿望也在最近被实现了。最关键的是，本周的进展相当成功。简单列举一下最近在技术方面的成果：</p>
<span id="more"></span>
<ol>
<li>MATLAB和Python的联合编程被堪称完美的实现了出来，整个速度相比之前版本快了近400倍</li>
<li>机器学习代码在网络服务器端待机提供服务的接口即将出炉</li>
<li>Python多线程操作深入到机器学习的高IO操作部分使得整个过程远为流畅</li>
<li>Pytorch框架下多GPU分布式计算也被成功应用到了自己的代码上，并和多线程一起提高了训练速度高达6倍</li>
<li>入门强化学习初见成效，弄懂了一些基本原理</li>
<li>初步了解了GAN和风格迁移的原理并研究了Pytorch实现的代码</li>
<li>个人博客的阅读人数和打赏等功能的添加</li>
<li>对搭载Linux系统的GPU服务器做了较为详尽的调研并推荐给了导师</li>
<li>编写仿真数据生成模块，通过同时执行6个MATLAB进程，并控制CPU核心的使用在一天之内仿真得到了之前要跑一周仿真才能得到的2.6G的数据</li>
<li>重新编写可复用易复用的MATLAB读取仿真数据并生成数据集的代码替换掉之前的可读性复用性差的代码</li>
<li>配置了命令行下百度云高速下载器方便远程传输大型数据集</li>
<li>修复了Lab公用机1号机Win10系统的开始菜单及其他一些系统组件无法显示的问题</li>
<li>收集整理从入门Python到深度强化学习的各种资源并制作成PDF与学长们分享</li>
</ol>
<p>另外，最近还养成了每天练习英语口语和法语的习惯，希望可以一直坚持下去。英语口语一直是我的硬伤，虽说能够使用英语和导师进行一些基本的学术交流，但是自知蹩脚的口语迟早会成为前进路上的一块绊脚石，应该尽早除掉。下个月可能还会考一次GRE，希望最近能多抽出些时间把之前没有背完的单词给背完，强化一下verbal部分吧。</p>
]]></content>
      <tags>
        <tag>essay</tag>
        <tag>EMC</tag>
        <tag>abroad</tag>
      </tags>
  </entry>
  <entry>
    <title>密苏里科技大学EMC Lab暑研 第七周</title>
    <url>/2018/09/04/emc-lab-note-7w/</url>
    <content><![CDATA[<p>拨云见日的一周。</p>
<p>千淘万漉虽辛苦，吹尽狂沙始到金。经过近一个月的钻研与打磨，通过深度学习方法解泊松方程的任务终于结出了翘首以盼的成果。在这个项目中，我运用了深度学习的方法，将二极管内部微观连续仿真中的传统迭代式泊松方程求解器用深度学习的方法进行了替换。在这个项目中，理论方面值得一提的几点是边界条件的精确拟合、避免连续仿真中的累计误差以及作为结果的I-V Curve的精确拟合；而在技术方面，我也更进一步弄清楚了MATLAB与Python的联合编程方法、Python多线程编程的方法、Python通过Flask搭建提供深度学习服务的服务端的方法、Pytorch多GPU并行计算的方法等，可谓是收获颇丰。而当最终结果和传统方法得出的结果取得了几乎完全一致的解法时，心中的激动之情是的确难以抑制的。</p>
<span id="more"></span>
<p>另外一件令我印象深刻的事是在学长们的帮助下修订组会PPT。虽然我也很习惯于做PPT，但是有许多理念性的问题依然存在着不足之处。比如我们应该站在听众的角度讲解自己做出的项目，要讲明白自己项目的原因和起源；也要点明之前别人做过的类似的项目和自己项目的不同之处，以及自己项目的“亮点”在哪里。当然，能用图片解释的项目原理都尽量使用流程图解释，而非大段文字…… 这些细节都让人感到一股专业感和对听众的尊重。最后就是当英文还不是很熟悉时提前预讲一遍是很重要的，因为这样能够先踩一遍本应踩到的雷，也会使你的演讲过程更加连贯。</p>
<p>下周我的mentor将会有一场博士的Qualify考试，而我也将在他给出的指导的基础上将前期的工作做整理成论文，希望可以顺利进行。在当前项目的基础上进一步优化项目，跑出更多数据、学习强化学习将是之后的目标。</p>
]]></content>
      <tags>
        <tag>essay</tag>
        <tag>EMC</tag>
        <tag>abroad</tag>
      </tags>
  </entry>
  <entry>
    <title>密苏里科技大学EMC Lab暑研 第八周</title>
    <url>/2018/09/08/emc-lab-note-8w/</url>
    <content><![CDATA[<p>文 | 张中洋</p>
<p>繁复缠绕而精彩纷呈的一周。</p>
<p>上个周六，在张岭学长热心而细心的帮助下，我们完成了论文的大纲部分，之后便正式开始了论文的撰写。万事开头难，一开始我想按照普通的论文行文的顺序写，即先写背景介绍Introduction部分，然而参考其他论文我发现其中涉及到了大量的引用文献，而这让我感觉有点难以下笔。没有调查就没有发言权，的确是这样，由于没有经过足够的文献调查，所以很难向前推进。</p>
<span id="more"></span>
<p>向学长请教之后，他告诉我先把原理、实验过程、结果部分写完，之后再进行系统的相关文献调查，完成Introduction部分也许是更为明智的选择。按照这个思路开始写之后，之后的过程就变得容易了起来，这些自己已经很熟悉的原理结果等很快将文章的主题架构支撑了起来，再将格式予以整理后，整篇文章的框架已经略显充实。希望下周能够尽快将介绍以及引用部分完成，并和学长一同将初稿做出来交予导师修改。</p>
<p>本周另外一件大事是完成了数字图像处理的课程设计任务。虽然在校期间已经完成了数据收集以及通过animation图像对cosplay进行打分的大部分任务，但是出来的效果一直不够理想，而且用到的原理也不够新颖和出色。恰巧上周我对对抗生成网络GAN有了一个初步的了解并研究了一部分代码，我便转变了思路决定把项目主题改由用动漫图片生成cosplay图片。任务刚开始可谓是进行的很顺利，由于对框架和模型已经比较熟悉了，只用了一天的时间就搭好了能够运行训练和测试的深度学习程序，但问题是训练的效果一直无法得到有效的保障，而且对于训练数据的增强方面也和之前做过的分类网络差别很大，由于使用了随机旋转，所以第一次训练出来的图像总是有种扭曲的感觉。之后经过对整个数据处理流程的优化和网络的改造，终于得出了还不错的训练结果——已经可以由动漫图片生成cosplay图片啦！虽然受限于机器运算速度等问题训练轮数依旧不足，图像依旧有着多少的模糊，但是生成的图像已经可以大致分辨出来人物了。第一次做GAN，感觉还是很有趣的。</p>
<p><img data-src="006tNc79ly1fvawrm7yk5j31841tg45o.jpg" alt="Work Flow"></p>
<p>下周来参加本次暑期实习的浙大同学们就要回国了，想来的确十分不舍这段共度的美好时光，也希望他们能一路平安，顺利回国继续学业。我们的日程也已过大半，只有一个月就要归国了，不由感叹时光之易逝，更要充实的度过余下的时光。</p>
]]></content>
      <tags>
        <tag>machine-learning</tag>
        <tag>essay</tag>
        <tag>EMC</tag>
        <tag>abroad</tag>
      </tags>
  </entry>
  <entry>
    <title>密苏里科技大学EMC Lab暑研 第九周</title>
    <url>/2018/09/15/emc-lab-note-9w/</url>
    <content><![CDATA[<p>文 | 张中洋</p>
<p>由繁入简的一周。</p>
<p>本周的主要任务是构建基于强化学习算法Policy Gradient的针对Toy Problem的健壮代码以及之前项目论文的继续。下一个任务将是基于强化学习的PCB板过孔及电容的数目、位置、大小等参数的优化，我和张岭学长准备首先采用Policy Gradient算法对一些简单函数写一个示例代码，以确保后续研究的可行性。由于之前已经有了大量的相关编程经验，整个过程也进行的十分平稳而顺利，目前已经基本完成了所有的代码框架构建工作并得到了一部分“可人”的测试结果。其实之前并没有正式接受过深度强化学习的项目，所以从学习基础理论知识到亲自动手实践，甚至做出相当的优化的这个过程还是十分令人享受的。其中也发现了深度强化学习和传统深度学习的一些极大不同之处，如score并不像深度学习的loss一般整体上四平八稳的下降，而是像是有着周期性上升下降规律的波形一般起伏不定；又如模型的设计本身不是最重要的部分了，而对于reward这个新的变量的定义和整体“策略”的制定更加重要。</p>
<span id="more"></span>
<p><img data-src="006tNc79ly1fvawo5ni4uj31kw0pvdm3.jpg" alt="image-20180915154540586"></p>
<p><img data-src="006tNc79ly1fvawo6zen0j30tm0qwafz.jpg" alt="image-20180915154628840"></p>
<p>单论编程方面，我的代码风格从刚开始入门机器学习时的简陋和不完备到之前一段时间的事无巨细、极力做到缜密但却又失之简约和易懂的特性，再到最近的层层封装，充分使用Python的各种高级特性，在保证了缜密性和完备性的同时渐渐做到了最大程度的解耦合和易读性，这些变化让我感到十分开心。是可谓由简入繁易，由繁入简难。如果说“由简入繁”是较为单纯的经验和代码积累，那么“由繁入简”则是在对高级用法的理解的基础上的再次进化了。</p>
<p>有趣的是我发现Pytorch在今年4月更新版本之后引入了许多新的特性，这些新特性无疑再次提高了其易用程度，在代码对各种设备的兼容性方面也做出了显著的提升，希望Pytorch和Python能越来越好！</p>
<p>论文也终于进入了修改阶段，希望下周能给出一版像样的稿子交由老师修改。</p>
]]></content>
      <tags>
        <tag>machine-learning</tag>
        <tag>essay</tag>
        <tag>EMC</tag>
        <tag>abroad</tag>
      </tags>
  </entry>
  <entry>
    <title>密苏里科技大学EMC LAB工作日志 Day1</title>
    <url>/2018/07/29/emclab-day1/</url>
    <content><![CDATA[<h1 id="gan网络"><a class="markdownIt-Anchor" href="#gan网络"></a> GAN网络</h1>
<ul>
<li>基本架构：</li>
</ul>
<p><img data-src="../../../../%E5%9B%BE%E7%89%87/Markdown_Image_Temp/v2-61e1b1a6d1feb23a7d3c52966d11be08_hd.png" alt="img"></p>
<ul>
<li>如何训练GAN网络？</li>
</ul>
<p><img data-src="006tKfTcly1ft8wo4ne7uj30k00cajsu.jpg" alt="img"></p>
<ul>
<li>GAN的优点：</li>
</ul>
<span id="more"></span>
<blockquote>
<ol>
<li>从实际结果来看,GAN看起来能产生更好的生成样本</li>
<li>GAN框架可以训练任何生成网络(理论上，然而在实践中,很难使用增强学习去训练有离散输出的生成器),大多数其他架构需要生成器有一些特定的函数形式,就像输出层必须是高斯化的. 另外所有其他框架需要生成器整个都是非零权值(put non-zero mass everywhere),然而,GANs可以学习到一个只在靠近真实数据的地方(神经网络层)产生样本点的模型( GANs can learn models that generate points only on a thin manifold that goes near the data.)</li>
<li>没有必要遵循任何种类的因子分解去设计模型,所有的生成器和鉴别器都可以正常工作</li>
<li>相比PixelRNN, GAN生成采样的运行时间更短,GANs一次产生一个样本,然而PixelRNNs需要一个像素一个像素的去产生样本;</li>
<li>相比VAE, GANs没有变分下界,如果鉴别器训练良好,那么生成器可以完美的学习到训练样本的分布.换句话说,GANs是渐进一致的,但是VAE是有偏差的</li>
<li>相比深度玻尔兹曼机, GANs没有变分下界,也没有棘手的配分函数,样本是一次生成的,而不是重复的应用马尔科夫链来生成的</li>
<li>相比GSNs, GANs产生的样本是一次生成的,而不是重复的应用马尔科夫链来生成的;</li>
<li>相比NICE和Real NVE,GANs没有对潜在变量(生成器的输入值)的大小进行限制;</li>
</ol>
</blockquote>
<h1 id="玻尔兹曼机"><a class="markdownIt-Anchor" href="#玻尔兹曼机"></a> 玻尔兹曼机</h1>
<ul>
<li>玻尔兹曼机的定义：</li>
</ul>
<blockquote>
<p>玻尔兹曼机(Boltzmann Machine)可以看做是一个随机动力系统(Stochas- tic Dynamical System)，每个变量的状态都以一定的概率受到其它变量的影 响。玻尔兹曼机可以用概率无向图模型来描述。</p>
</blockquote>
<ul>
<li>玻尔兹曼机的特点</li>
</ul>
<p><img data-src="../../../../%E5%9B%BE%E7%89%87/Markdown_Image_Temp/image-20180713160524512.png" alt="image-20180713160524512"></p>
<ul>
<li>受限玻尔兹曼机：</li>
</ul>
<p><img data-src="../../../../%E5%9B%BE%E7%89%87/Markdown_Image_Temp/image-20180713160614434.png" alt="image-20180713160614434"></p>
<ul>
<li>玻尔兹曼机与受限玻尔兹曼机的区别：是否是全连接的。前者是所有节点全连接，后者只要求不同层之间的节点与另一层中所有节点连接。</li>
<li>玻尔兹曼机可以解决的问题：</li>
</ul>
<blockquote>
<ol>
<li>搜索问题。当给定变量之间的 连接权重，需要找到一组二值向量，使得整个网络的能量最低。</li>
<li>学习问题。当给一组定部分变量的观测值时，计算一组最优的权重。</li>
</ol>
</blockquote>
<h1 id="深度信念网络"><a class="markdownIt-Anchor" href="#深度信念网络"></a> 深度信念网络</h1>
<ul>
<li>
<p>定义：深度信念网络(Deep Belief Network，DBN)是一种深层的概率有向图模 型，其图结构由多层的节点构成。每层节点的内部没有连接，相邻两层的节点 之间为全连接。网络的最底层为可观测变量，其它层节点都为隐变量。最顶部 的两层间的连接是无向的，其他层之间的连接是有向的。</p>
<p><img data-src="../../../../%E5%9B%BE%E7%89%87/Markdown_Image_Temp/image-20180713162115387.png" alt="image-20180713162115387"></p>
</li>
<li>
<p>训练方式：在预训练阶段，采用逐层训练的方式，将深度信念网络的训练简化为对多个受限玻尔兹曼机的训练。</p>
</li>
</ul>
]]></content>
      <tags>
        <tag>machine-learning</tag>
        <tag>GAN</tag>
        <tag>Missouri U of S&amp;T</tag>
      </tags>
  </entry>
  <entry>
    <title>Face Recognition, Landmark and Relevant Other Feature Extraction</title>
    <url>/2020/03/06/face-features/</url>
    <content><![CDATA[<h2 id="some-facts">Some Facts</h2>
<ol type="1">
<li>The output of face detector is not always the same, it can be a square, a rectangle, or an oval bounding box.</li>
<li>Most of the landmark detectors need to take in an square bounding box for the detection.</li>
<li>Although the bounding box shape is different, they roughly have the same shape center. For the square and rectangle, they have the same bounding box center, and the edge length of the square box is roughly the same as the mean value of the two edge lengths of the rectangle. Here is a sample.</li>
</ol>
<span id="more"></span>
<figure>
<img data-src="A48432AC-5A9B-48D6-A502-0777810A592A.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<blockquote>
<p>White: Dlib Result</p>
<p>Green: RetinaFace Result</p>
<p>Red: RetinaFace Transferred Result (Same center, length=(width+height)/2)</p>
</blockquote>
<ol start="4" type="1">
<li>Many face detection and alignment models has an absolute detectable face size range in pixel. If the input image contains a face too big, some network cannot generate correct face bounding box or landmark, like RetinaFace, SFD, Hrnet. On the other hand, if the input image contains faces too small(also in absolute pixel), other network like MTCNN and other traditional method will fail.</li>
</ol>
<h2 id="libraries-and-papers">Libraries and Papers</h2>
<h3 id="face-detection">Face Detection</h3>
<h4 id="datasets">Datasets</h4>
<table>
<colgroup>
<col style="width: 7%">
<col style="width: 46%">
<col style="width: 46%">
</colgroup>
<thead>
<tr class="header">
<th>Name</th>
<th>Site</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Wider Face</td>
<td><a href="http://shuoyang1213.me/WIDERFACE/">Link</a></td>
<td><strong>32,203</strong> images, <strong>393,703</strong> faces labeled with a high degree of variability in scale, pose and occlusion</td>
</tr>
<tr class="even">
<td>FFDB</td>
<td><a href="http://vis-www.cs.umass.edu/fddb/">Link</a></td>
<td><strong>5171</strong> faces, in which <strong>2845</strong> images from the <a href="http://tamaraberg.com/faceDataset/index.html">Faces in the Wild</a> data set</td>
</tr>
<tr class="odd">
<td>AFLW</td>
<td><a href="https://www.tugraz.at/institute/icg/research/team-bischof/lrs/downloads/aflw/">Link</a></td>
<td><strong>25k faces</strong> are annotated with up to <strong>21 landmarks</strong> per image</td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h4 id="researches">Researches</h4>
<table>
<colgroup>
<col style="width: 21%">
<col style="width: 16%">
<col style="width: 21%">
<col style="width: 1%">
<col style="width: 17%">
<col style="width: 21%">
</colgroup>
<thead>
<tr class="header">
<th>Name</th>
<th>Paper</th>
<th>Code</th>
<th>Year</th>
<th>Accuracy</th>
<th>Pre-trained Model</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a href="https://www.paperswithcode.com/paper/190500641">RetinaFace</a></td>
<td><a href="https://arxiv.org/pdf/1905.00641v2.pdf">Link</a></td>
<td><a href="https://github.com/deepinsight/insightface">Original</a><br><a href="https://github.com/biubug6/Pytorch_Retinaface">Pytorch</a></td>
<td>2019</td>
<td>Wider Face (Hard): 0.914</td>
<td>104M(Resnet)<br><a href="https://drive.google.com/drive/folders/1oZRSG0ZegbVkVwUd8wUIQx8W7yfZ_ki1">2M(MobileNet0.25)</a></td>
</tr>
<tr class="even">
<td><a href="https://www.paperswithcode.com/paper/dsfd-dual-shot-face-detector">DFSD</a></td>
<td><a href="https://arxiv.org/pdf/1810.10220v3.pdf">Link</a></td>
<td><a href="https://github.com/TencentYoutuResearch/FaceDetection-DSFD">Link</a></td>
<td>2018</td>
<td>FDDB: 0.991<br>Wider Face: 0.960, 0.953, 0.900</td>
<td><a href="https://drive.google.com/file/d/1WeXlNYsM6dMP3xQQELI-4gxhwKUQxc3-/view">459MB</a></td>
</tr>
<tr class="odd">
<td><a href="SFD/S3FD">SFD/S3FD</a></td>
<td><a href="https://arxiv.org/pdf/1708.05237.pdf">Link</a></td>
<td><a href="https://github.com/sfzhang15/SFD">Original</a><br><a href="https://github.com/yxlijun/S3FD.pytorch">Pytorch</a></td>
<td>2017</td>
<td>FDDB: 0.983<br>Wider Face: 0.928, 0.913, 0.840</td>
<td><a href="https://pan.baidu.com/s/1epyTAUc6qSt3oZ7veK4oEw">85.7M</a></td>
</tr>
<tr class="even">
<td><a href="https://www.paperswithcode.com/paper/joint-face-detection-and-alignment-using">MTCNN</a></td>
<td><a href="https://arxiv.org/abs/1604.02878">Link</a></td>
<td><a href="https://github.com/kuaikuaikim/DFace">Original</a><br><a href="https://github.com/ipazc/mtcnn">Pip Version</a></td>
<td>2016</td>
<td>Wider Face: 0.851, 0.820, 0.607</td>
<td><a href="https://github.com/ipazc/mtcnn/blob/master/mtcnn/data/mtcnn_weights.npy">2.85M</a></td>
</tr>
</tbody>
</table>
<h5 id="retinaface-pros-cons">RetinaFace Pros &amp; Cons:</h5>
<p>RetinaFace can generate an accurate rectangle face bounding box together with a 5-points facial landmark. It supports two backbone kernels: Resnet and MobileNet. The first one is more accurate but relatively slow, the MobileNet version is fast and really small.</p>
<p>RetinaFace focus more on the detection of the relatively small faces, and it can do a good(best) job on wider face dataset hard level. However, when the input is an image contain a really large face(About ${short_face_edge}&gt;700pixel $ ), RetinaFace tend to fail. Since there is also other people asking the same question on the issue of its GitHub page, I tend to think this is a design defects of RetinaFace.</p>
<p>Since the game streamers' face videos can be relatively large, I think this may become a fatal drawback. There are three possible solutions:</p>
<ol type="1">
<li>Scale the input image to make sure the largest face short edge is smaller than 700, recommend around 500.</li>
<li>Wait for the author to change or change the pyramid weights parameters. This is delicate and success is not guaranteed.</li>
</ol>
<p><img data-src="image-20200306140736438.png" alt="image-20200306140736438" style="zoom:50%;"></p>
<h5 id="other-models">Other Models</h5>
<p>DFSD can behave well on both easy, medium and hard level of Wider Face dataset. The only drawback is that it is much too large and slow. Not to mention real-time, it is even too heavy for GPU prediction when the input is a video and we also need to predict other features.</p>
<p>SFD has the similar problem as RetinaFace. It will also fail at big face cases.</p>
<p>MTCNN is just really small and easy to use. It is wrapped finely into a pip package and we can use one line to do face detection here. It behaves much worse in small faces, but better when the input face is big compared to other method. In fact, MTCNN might be a good choice for our project, since it is friendly to big face and fast enough.</p>
<h4 id="wrapped-libraries">Wrapped Libraries</h4>
<table>
<thead>
<tr class="header">
<th>Name</th>
<th>Site</th>
<th>Year</th>
<th>Language</th>
<th>Pip (Name)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Dlib</td>
<td><a href="http://dlib.net/">Link</a></td>
<td>2006-&gt;now</td>
<td>C++ &amp; Python</td>
<td>√ dlib</td>
</tr>
<tr class="even">
<td>OpenFace V1</td>
<td><a href="http://cmusatyalab.github.io/openface/">Home Page</a><br><a href="https://github.com/cmusatyalab/openface">GitHub</a></td>
<td>2016</td>
<td>Python &amp; Lua</td>
<td>× conda</td>
</tr>
<tr class="odd">
<td>OpenFace V2</td>
<td><a href="https://github.com/TadasBaltrusaitis/OpenFace">Link</a></td>
<td>2018</td>
<td>C++</td>
<td>× compile locally</td>
</tr>
<tr class="even">
<td>facenet-pytorch</td>
<td><a href="https://pypi.org/project/facenet-pytorch/">Link</a></td>
<td>2017</td>
<td>Python(PT)</td>
<td>√ facenet-pytorch</td>
</tr>
<tr class="odd">
<td>MTCNN</td>
<td><a href="https://pypi.org/project/mtcnn/">Link</a></td>
<td>2016</td>
<td>Python(TF)</td>
<td>√ mtcnn</td>
</tr>
</tbody>
</table>
<h5 id="comment">Comment</h5>
<ol type="1">
<li>OpenFace V1 uses face detection model from dlib and OpenCV.</li>
<li>OpenFace V2 also used MTCNN as core face detector.</li>
</ol>
<h3 id="face-landmark">Face Landmark</h3>
<h4 id="datasets-1">Datasets</h4>
<table>
<colgroup>
<col style="width: 4%">
<col style="width: 44%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th>Name</th>
<th>Site</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>300-W</td>
<td><a href="https://ibug.doc.ic.ac.uk/resources/300-W/">Link</a></td>
<td>68 points. Bounding boxes calculated by the boundary of all <strong>68</strong> points.</td>
</tr>
<tr class="even">
<td>WFLW</td>
<td><a href="https://wywu.github.io/projects/LAB/WFLW.html">Link</a></td>
<td>Wider Facial Landmarks in-the-wild (WFLW) contains <strong>10000</strong> faces (7500 for training and 2500 for testing) with <strong>98</strong> fully manual annotated landmarks. Rich attribute annotations included, i.e., occlusion, pose, make-up, illumination, blur and expression.</td>
</tr>
<tr class="odd">
<td>COFW</td>
<td><a href="http://www.vision.caltech.edu/xpburgos/ICCV13/">Link</a></td>
<td>All images were hand annotated using the same <strong>29</strong> landmarks as in LFPW. Both the landmark positions and their occluded/unoccluded state are annotated. The faces are occluded to different degrees, with large variations in the type of occlusions encountered. COFW has an average occlusion of over <strong>23%</strong>. To increase the number of training images, and since  COFW has the exact same landmarks as LFPW, for training  we use the original non-augmented 845 LFPW faces + 500 COFW faces (<strong>1345</strong> total), and for testing the remaining <strong>507</strong> COFW faces.</td>
</tr>
<tr class="even">
<td>AFLW</td>
<td><a href="https://www.tugraz.at/institute/icg/research/team-bischof/lrs/downloads/aflw/">Link</a></td>
<td>Annotated Facial Landmarks in the Wild (AFLW) provides a large-scale collection of annotated face images gathered from the web, exhibiting a large variety in appearance (e.g., pose, expression, ethnicity, age, gender) as well as general imaging and environmental conditions. In total about <strong>25k faces</strong> are annotated with up to <strong>21 landmarks</strong> per image.</td>
</tr>
</tbody>
</table>
<h5 id="attention">Attention</h5>
<ol type="1">
<li>The bounding box of 300-W dataset is not human labeled. It is the smallest rectangle which can accurately include every 68 points.</li>
</ol>
<p><img data-src="figure_4_n_2.png" alt="img" style="zoom:15%;"></p>
<h4 id="researches-1">Researches</h4>
<table>
<colgroup>
<col style="width: 28%">
<col style="width: 28%">
<col style="width: 28%">
<col style="width: 1%">
<col style="width: 13%">
</colgroup>
<thead>
<tr class="header">
<th>Name</th>
<th>Paper</th>
<th>Code</th>
<th>Year</th>
<th>Accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a href="https://www.paperswithcode.com/paper/adaptive-wing-loss-for-robust-face-alignment">AWing</a></td>
<td><a href="https://arxiv.org/pdf/1904.07399v2.pdf">Adaptive Wing Loss for Robust Face Alignment via Heatmap Regression</a></td>
<td><a href="https://github.com/protossw512/AdaptiveWingLoss">Link</a></td>
<td>2019</td>
<td>300-W: 3.07</td>
</tr>
<tr class="even">
<td><a href="https://www.paperswithcode.com/paper/look-at-boundary-a-boundary-aware-face">LAB</a></td>
<td><a href="https://wywu.github.io/projects/LAB/LAB.html">Look at Boundary</a></td>
<td><a href="https://github.com/wywu/LAB">Link</a></td>
<td>2018</td>
<td>300-W: 3.49</td>
</tr>
<tr class="odd">
<td><a href="https://www.paperswithcode.com/paper/style-aggregated-network-for-facial-landmark">SAN</a></td>
<td><a href="https://arxiv.org/pdf/1803.04108v4.pdf">Style Aggregated Network</a></td>
<td><a href="https://github.com/D-X-Y/landmark-detection">Link</a></td>
<td>2018</td>
<td>300W NME: 3.98</td>
</tr>
<tr class="even">
<td>HRNet</td>
<td><a href="https://arxiv.org/abs/1908.07919">Deep High-Resolution Representation Learning</a></td>
<td><a href="https://github.com/HRNet/HRNet-Facial-Landmark-Detection">Link</a></td>
<td>2019</td>
<td>300-W: 3.32</td>
</tr>
<tr class="odd">
<td>FAN</td>
<td><a href="https://arxiv.org/abs/1703.07332">Face Alignment Network</a></td>
<td><a href="https://github.com/1adrianb/face-alignment">Link</a></td>
<td>2017</td>
<td>300-W: Acc(7% threshold)66.9%</td>
</tr>
<tr class="even">
<td><a href="https://www.paperswithcode.com/paper/deep-alignment-network-a-convolutional-neural">DAN-Menpo</a></td>
<td><a href="https://arxiv.org/pdf/1706.01789v2.pdf">Deep Alignment Network</a></td>
<td><a href="https://github.com/MarekKowalski/DeepAlignmentNetwork">Link</a></td>
<td>2017</td>
<td>300-W: 3.44</td>
</tr>
</tbody>
</table>
<p>The accuracy on 300-W is based on <strong>FULLSET (PUBLIC)</strong>.</p>
<h4 id="overview-on-researches">Overview on researches</h4>
<ol type="1">
<li>FAN is the final method I choose now. It cannot only generate 2D but also accurate 3D landmark, which is quite important for us considering the head pose and eye gaze can also be deduced from here.</li>
<li>Although HRNet seems to be good, it will crash completely when the input face is large(About <span class="math inline">\({face\_min\_edge} &gt; 250\)</span>). Not really recommended if no extra operation added. But this can also be fixed by resize before sending to our pipeline, since our target is a single big-face player. When the input face size is limited, the result is quite decent.</li>
</ol>
<h4 id="wrapped-libraries-1">Wrapped Libraries</h4>
<table>
<thead>
<tr class="header">
<th>Name</th>
<th>Site</th>
<th>Year</th>
<th>Language</th>
<th>Pip (Name)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Dlib</td>
<td><a href="http://dlib.net/">Link</a></td>
<td>2006-&gt;now</td>
<td>C++ &amp; Python</td>
<td>√ dlib</td>
</tr>
<tr class="even">
<td>OpenFace V1</td>
<td><a href="http://cmusatyalab.github.io/openface/">Home Page</a><br><a href="https://github.com/cmusatyalab/openface">GitHub</a></td>
<td>2016</td>
<td>Python &amp; Lua</td>
<td>× conda</td>
</tr>
<tr class="odd">
<td>OpenFace V2</td>
<td><a href="https://github.com/TadasBaltrusaitis/OpenFace">Link</a></td>
<td>2018</td>
<td>C++</td>
<td>× compile locally</td>
</tr>
<tr class="even">
<td>face-alignment</td>
<td><a href="https://github.com/1adrianb/face-alignment">Link</a></td>
<td>2017</td>
<td>Python &amp; Lua</td>
<td>√ face-alignment</td>
</tr>
</tbody>
</table>
<h3 id="eye-blinking">Eye Blinking</h3>
<h4 id="datasets-2">Datasets</h4>
<table style="width:100%;">
<colgroup>
<col style="width: 19%">
<col style="width: 40%">
<col style="width: 40%">
</colgroup>
<thead>
<tr class="header">
<th>Name</th>
<th>Site</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Closed Eyes In The Wild (CEW)</td>
<td><a href="http://parnec.nuaa.edu.cn/xtan/data/ClosedEyeDatabases.html">Link</a></td>
<td>2423 subjects, among which 1192 subjects with both eyes closed are collected directly from Internet, and 1231 subjects with eyes open are selected from the Labeled Face in the Wild (LFW [2]) database. Cropped coarse faces resized to the 100×100 and extract eye patches of 24×24 centered at the localized eye position.</td>
</tr>
<tr class="even">
<td>EBV</td>
<td><a href="https://drive.google.com/file/d/1jJTImI-QkmGYFS-0UmE1qvqbwoYOCPnR/view?usp=sharing">Link</a></td>
<td>It contains <strong>11376</strong> video clips, each clip has around <strong>15</strong> image series, whether contains a blink or not. The video fps they use is <strong>30</strong>.</td>
</tr>
<tr class="odd">
<td>Eyeblink8</td>
<td><a href="https://www.blinkingmatters.com/research">Link</a></td>
<td>8 videos with 4 individuals (1 wearing glasses). Videos are recorded in a home environment. 408 eye blinks on 70 992 annotated frames with resolution 640x480.</td>
</tr>
<tr class="even">
<td>MRL</td>
<td><a href="http://mrl.cs.vsb.cz/eyedataset">Link</a></td>
<td>Infrared images in low and high resolution, all captured in various lightning conditions and by different devices. Approximately 15 000 annotation for pupil points (images).</td>
</tr>
<tr class="odd">
<td>RT-BENE</td>
<td><a href="https://zenodo.org/record/3685316#.XmL4pJP0lQI">Link</a></td>
<td>Annotations of the eye-openness of more than 200,000 eye images, including more than 10,000 images where the eyes are closed.</td>
</tr>
</tbody>
</table>
<h4 id="researches-2">Researches</h4>
<table>
<thead>
<tr class="header">
<th>Name</th>
<th>Paper</th>
<th>Code</th>
<th>Description</th>
<th>Pre-trained Model</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>In Ictu Oculi</td>
<td><a href="https://arxiv.org/abs/1806.02877">Link</a></td>
<td><a href="https://github.com/danmohaha/WIFS2018_In_Ictu_Oculi">Link</a></td>
<td>Using Blink to detect Fake Video.</td>
<td><a href="https://drive.google.com/file/d/1OJZ4mvZefwMJ7Knpsf_RFhCsA4xbAOMc/view">429M</a></td>
</tr>
<tr class="even">
<td>RT-GENE &amp; RT-BENE</td>
<td><a href="http://openaccess.thecvf.com/content_ECCV_2018/html/Tobias_Fischer_RT-GENE_Real-Time_Eye_ECCV_2018_paper.html">Link</a></td>
<td><a href="https://github.com/Tobias-Fischer/rt_gene">Link</a></td>
<td>Robust gaze estimation in natural environments.</td>
<td></td>
</tr>
</tbody>
</table>
<h4 id="my-update">My Update</h4>
<ol type="1">
<li>Build a new Resnet18-LSTM based eye blink detection network, which reaches 99.8% accuracy on both training and testing set the same as "In Ictu Oculi" paper proposed.</li>
<li>Build a new mixed dataset which has three classes: open, closed, and not-eye. Not-eye class includes hand, cup, microphone, hat, fast food, and bedroom background. They are frequently appearing objects in the gamer's streaming video. In many cases, part of the face are covered by this kind of things, but the face landmark detector can still give a predicted landmark. For example, one's left eye may be shield by a microphone constantly due to the camera angle, but we can still get the useful information from his right eye. So in these cases, the new dataset will be more representative.</li>
<li>All of these new 6-classes images are collected from google image. Total number is <strong>2738</strong>, image number of each class is roughly balanced. I did a manual selecting to make sure the image is usable and representative of that classes. Every collected image will be resized to <strong>48, 64, and 128</strong>(the short edge), and then randomly crop three <strong>(32,32)</strong> images from each resized image. At last, <strong>32855</strong> images are collected.</li>
<li>EBV dataset from the author "In Ictu Oculi" is used as base dataset. It contains <strong>11376</strong> video clips, each clip has around <strong>15</strong> image series, whether contains a blink or not. The video fps they use is <strong>30</strong>. I build the new dataset by inserting 1, 2, or 3 continuous background images into the video clip image folder. The insert position is random, and the proportion of inserting 0,1,2,3 background images is: 40%, 10%, 30%, 20%. The inserted images is also randomly selected continuous images from all generated <strong>32855</strong> images. Training and validation set separation is the same as original dataset.</li>
<li>A new "Robust-Eye-Blink" network is trained based on this new dataset, and after sufficient training, it can reach 99.7% at both train and test dataset.</li>
</ol>
<h3 id="head-pose">Head Pose</h3>
<h4 id="calculation">Calculation</h4>
<p>3D Facial Landmark -&gt; <a href="https://en.wikipedia.org/wiki/Rotation_matrix">Rotation matrix</a> -&gt; <a href="https://en.wikipedia.org/wiki/Euler_angles">Euler angles</a> -&gt; <a href="https://carsexplained.wordpress.com/2017/02/21/fundamentals-of-car-science-pitch-and-roll/">(yaw, pitch, roll)</a></p>
<p><img data-src="1*U4ZQ8UjzouVMRo2Fgsz7UA.png" alt="yaw pitch roll of head" style="zoom:50%;"></p>
<p>Visualization of yaw, pitch and roll: <a href="http://www.ctralie.com/Teaching/COMPSCI290/Materials/EulerAnglesViz/">Link</a></p>
<p><strong>Euler angles:</strong></p>
<figure>
<img data-src="300px-Eulerangles.svg.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<h5 id="implementation">Implementation</h5>
<p><img data-src="image-20200306134751864.png" alt="image-20200306134751864" style="zoom:40%;"></p>
<p>Use the 3D landmark computed, and set the vector from 1 to 17 as the x axis, and 9 to 28 as the y axis, then the z axis is computed by set it perpendicular to both x and y, pointing out of front face.</p>
<p>Now, the head pose detection part has been wrapped into a module, we can get the pose within one line.</p>
<h4 id="code-reference">Code Reference</h4>
<ol type="1">
<li><a href="https://github.com/jerryhouuu/Face-Yaw-Roll-Pitch-from-Pose-Estimation-using-OpenCV">Face-Yaw-Roll-Pitch-from-Pose-Estimation-using-OpenCV</a></li>
<li><a href="https://gist.github.com/crmccreary/1593090">euler_angles_from_rotation_matrix</a></li>
</ol>
<h3 id="emotion">Emotion</h3>
<h4 id="can-facial-expression-really-tell-emotion">Can facial expression really tell emotion</h4>
<h5 id="cons">Cons</h5>
<ol type="1">
<li>Facial expression is not universal, it also depend on culture and education. Like in Asia, people tend to convey more emotion in their eyes, but in western culture, people use their mouth to deliver more information.</li>
<li>Human can easily trick the face expression to emotion system, since what they show is not necessarily what they feel.</li>
<li>One certain facial expression can have multiple possible meanings, and this tend to depend on things near the face, namely the context. Like a soccer player win the game and shouting, without the context, you will judge him as angry or so.</li>
<li>The current facial expression classification method usually classify all of the emotion into several classes, like 6 or 7. But the fact is that each big emotion contain multiple sub-emotions which is more delicate. They can overlap or differ.</li>
<li>After reading 1000 papers, they find there was little to no evidence that people can reliably infer someone else’s emotional state from a set of facial movements.</li>
</ol>
<h5 id="pros">Pros</h5>
<ol type="1">
<li>It is actually accurate. Affectiva has reached an accuracy of more than 90%.</li>
<li>Most of the culture share the similar facial expression.</li>
</ol>
<h4 id="datasets-3">Datasets</h4>
<table>
<colgroup>
<col style="width: 29%">
<col style="width: 35%">
<col style="width: 35%">
</colgroup>
<thead>
<tr class="header">
<th>Name</th>
<th>Site</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>FER2013</td>
<td><a href="https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data">Kaggle Link</a></td>
<td>48x48 pixel grayscale images of faces. (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral). The training set consists of 28,709 examples. The public test set consists of 3,589 examples. The final test set consists of another 3,589 examples.</td>
</tr>
<tr class="even">
<td><a href="https://ieeexplore.ieee.org/document/5543262">CK+</a></td>
<td><a href="http://www.consortium.ri.cmu.edu/ckagree/">Link</a></td>
<td>Posed Facial Expressions: 593 sequences from 123 subjects.</td>
</tr>
</tbody>
</table>
<h4 id="wrapped-libraries-2">Wrapped Libraries</h4>
<table>
<thead>
<tr class="header">
<th>Name</th>
<th>Site</th>
<th>Year</th>
<th>Language</th>
<th>Pip/Pt model</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Facial-Expression-Recognition</td>
<td><a href="https://github.com/WuJie1010/Facial-Expression-Recognition.Pytorch">Link</a></td>
<td>2018</td>
<td>Python(PT)</td>
<td><a href="https://drive.google.com/file/d/1Oy_9YmpkSKX1Q8jkOhJbz3Mc7qjyISzU/view">76M</a></td>
</tr>
</tbody>
</table>
<h4 id="reference">Reference</h4>
<ol type="1">
<li><a href="https://www.nature.com/articles/d41586-020-00507-5">Why faces don’t always tell the truth about feelings</a></li>
</ol>
<p>By Zhongyang Zhang</p>
]]></content>
      <tags>
        <tag>python</tag>
        <tag>machine-learning</tag>
        <tag>deep-learning</tag>
        <tag>face-detection</tag>
        <tag>face-alignment</tag>
        <tag>face-features</tag>
        <tag>face-expression</tag>
        <tag>eye-blink</tag>
        <tag>head-pose</tag>
      </tags>
  </entry>
  <entry>
    <title>《流浪地球》影评</title>
    <url>/2019/07/06/film-review-the-wandering-earth/</url>
    <content><![CDATA[<p>看完电影，深觉《流浪地球》实为一部填补了国内电影科幻、尤其是硬科幻板块长期空缺的电影，应该称之为“起点”而非单纯的“里程碑”。对于这样一个新生儿，鼓励还是应该大于批评的，个人而言也确实希望其能得到一个不错的票房，从而更好的支持这个刚刚起步的航母！虽说剧本进行了较大的改编，甚至可以说只是借用了原作的壳子，但整体的感觉是可以接受的，毕竟用一部电影的时间用来刻画一个长时间线上的恢弘故事很容易造成纵深不够的问题，很多场景也确实不太好拍出。选择在这样一个背景下的一个关键节点，描述一个在大时代中小人物的思考、选择与结果还是较为现实和有表现力的。特效方面很明显是下功夫了的，个人感觉并没有喧宾夺主，而是较为合适的起到了渲染气氛的作用，突出了末世苍凉的大背景，尤其是一些从微观渐渐拉伸到远景的镜头做的很精彩，值得充分肯定。做为一个东方科幻电影，也较为合适的做到了区分化，没有盲目照搬类似的美国科幻，而是将着力点放到了中国式的对家庭、故土、思念的执着上，很赞！</p>
<span id="more"></span>
<p>但问题也是存在的：首先也正是在上个点上有用力稍微过猛的感觉，一定程度上影响到了剧情的合理性；另外剧中人物关键时刻感情化因素比较多（这个不好说是好是坏，个人觉得对严谨性有伤，但是剧情确实需要不多说了），男主和其爸爸存在隔阂的原因也有样板化之嫌，没有很好的表现出来。其次是一些科幻片中常出现的漏洞问题，如没备份直接被一瓶酒烧了的人工智能（这……）、规划混乱的地下城、“便利”的身份管理系统、以及作为一个十余年经验的宇航员被关到冬眠箱想出去时候不是迅速按照紧急方案打开箱子（别告诉我就是进去就出不来了），而是一顿暴力乱锤😂，竟然还真的给锤开了（惊了）等，还有一个刚被剥夺了全部权限的人进入“神圣的”主控室竟然畅通无阻（至少要给装个进入权限管理吧），还能进去一顿操作（当时就怕主角进去直接砸主控室……没想到是先砸摄像头再把AI烧了），最后联合国给的回复竟然加入了“作为个人”的考量，嘛啊这种设定确实是剧情需要可以理解，但是总觉得作为关键环节设定有点小随意了。还有就是人物的设定部分有点乱（或者是我没看明白），部分人物的性格没有表现好，比如妹妹整个过程中作用有限，而且作为为数不多进行描述的女性写的实在有点弱了，意义似乎只是被救和后面的呼唤大家帮助。而且呼唤帮助部分有点意义不明，大家的作用好像仅限于人海推“针”部分，但这个部分本身有点意义不明，甚至是为了把这波人用上才进行的设定的感觉（嘛啊虽然看的时候还是真香的被感动到了hhh）。还有那个程序员前后人物性格波动剧烈，不太看得透具体想刻画一个什么样的人物，以及其它队员甚至是爷爷的人物形象都不够丰满，有种为了重伤和死亡而存在的龙套感，这里其实可以做得更好些。</p>
<p>总体上来说，虽然有一些小问题，但并不碍其成为中国科幻电影“起点”和其确为一用心良作这一事实。支持，鼓励，但同时也指出其可以改进之处，希望中国科幻电影以此为始、更进一步、越来越好！！！</p>
]]></content>
      <tags>
        <tag>film-review</tag>
      </tags>
  </entry>
  <entry>
    <title>尝试使用 Hexo 博客</title>
    <url>/2018/03/07/first-post/</url>
    <content><![CDATA[<p>本次试验使用Hexo部署一个个人博客系统，总结几点：</p>
<ol>
<li>Hexo是要安装在本地的，服务器端安装的是Nginx服务器</li>
<li>Nginx服务器的主目录下面的<code>/etc/nginx/nginx.conf.default</code> 和<code>etc/nginx/nginx.conf</code>不是一个东西，以后者为主，修改配置也是在后者里面修改的，改前面的文件没用</li>
<li>更换主题时要先在本地进行<code>hexo clean ; hexo genarate</code>操作再<code>hexo deploy</code>才会生效</li>
<li>可以通过<code>hexo s —debug</code>在本地测试运行服务器</li>
<li>可以通过修改本地主目录下的<code>_config.yml</code>文件来确保必须先写草稿再进行发布。新建文章的方式为<code>hexo new first-post</code>，发布方式为<code>hexo publish name_of_file</code></li>
<li>更换主题后，要先进入主题的主目录下，输入<code>npm install</code>命令后会自动安装所有需要的包</li>
</ol>
]]></content>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>C语言如何获得精确时间</title>
    <url>/2018/08/01/get-pre-time/</url>
    <content><![CDATA[<h1 id="c语言如何获得精确时间"><a class="markdownIt-Anchor" href="#c语言如何获得精确时间"></a> C语言如何获得精确时间</h1>
<h2 id="精确到秒"><a class="markdownIt-Anchor" href="#精确到秒"></a> 精确到秒</h2>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;time.h&gt;</span>  </span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">time_t</span> t_start, t_end;</span><br><span class="line">    t_start = time(<span class="literal">NULL</span>) ;</span><br><span class="line">    sleep(<span class="number">3000</span>);</span><br><span class="line">    t_end = time(<span class="literal">NULL</span>) ;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;time: %.0f s\n&quot;</span>, difftime(t_end,t_start)) ;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<span id="more"></span>
<h2 id="精确到微秒"><a class="markdownIt-Anchor" href="#精确到微秒"></a> 精确到微秒</h2>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/timeb.h&gt;</span></span></span><br><span class="line"> </span><br><span class="line"><span class="type">long</span> <span class="type">long</span> <span class="title function_">getSystemTime</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">timeb</span> <span class="title">t</span>;</span></span><br><span class="line">    ftime(&amp;t);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1000</span> * t.time + t.millitm;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">long</span> <span class="type">long</span> start=getSystemTime();</span><br><span class="line">    sleep(<span class="number">3</span>);</span><br><span class="line">    <span class="type">long</span> <span class="type">long</span> end=getSystemTime();</span><br><span class="line"> </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;time: %lld ms\n&quot;</span>, end-start);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>time</tag>
        <tag>C-lang</tag>
      </tags>
  </entry>
  <entry>
    <title>Quick Tutorial on how to find e-books, movies and musics</title>
    <url>/2018/12/12/get-resource/</url>
    <content><![CDATA[<h2 id="1-download-a-chrome-or-use-your-safari"><a class="markdownIt-Anchor" href="#1-download-a-chrome-or-use-your-safari"></a> 1. Download a chrome, or use your safari</h2>
<ul>
<li>If you don’t have a chrome, <a href="https://www.google.com/chrome/">install</a> it!</li>
<li>This tutorial is based on chrome, you can do almost the same on safari.</li>
</ul>
<span id="more"></span>
<h2 id="2-add-tampermonkey-on-chrome-webapp"><a class="markdownIt-Anchor" href="#2-add-tampermonkey-on-chrome-webapp"></a> 2. Add TamperMonkey on Chrome WebApp</h2>
<ul>
<li>Click <a href="https://chrome.google.com/webstore/category/extensions">This Link</a> to access chrome web app page, or simply click here:</li>
</ul>
<p><img data-src="006tNbRwgy1fxvw2cf5ktj31di0u0afi.jpg" alt></p>
<ul>
<li>Search <strong>TamperMonkey</strong> in the search box which located at the left top corner of the page.</li>
<li>Click <strong>Add to Chrome</strong> button on the right on the div.</li>
<li>Wait until the installation finished, during the process some verification is needed.</li>
</ul>
<p><img data-src="006tNbRwly1fxvw6lcz9tj32760l8q51.jpg" alt></p>
<ul>
<li>After installation, you can see this icon showing on your tab bar.</li>
</ul>
<p><img data-src="006tNbRwgy1fxvwcf8s9dj327y0qq773.jpg" alt></p>
<ul>
<li>Click this icon, and go into the script searching page by clicking <strong>“Get new scripts”</strong> button.</li>
</ul>
<p><img data-src="006tNbRwgy1fxvwemi0bqj30ai0ggaa8.jpg" alt></p>
<ul>
<li>Then you will be in this page, choose to visit <strong>“GreasyFork”</strong> Website.</li>
</ul>
<p><img data-src="006tNbRwgy1fxvwfoidyyj31d80u042t.jpg" alt></p>
<ul>
<li>Search “豆瓣资源大师” in the searching box.</li>
</ul>
<p><img data-src="006tNbRwgy1fxvwhys9xcj31da0u078u.jpg" alt></p>
<ul>
<li>Visit the next page shown.</li>
</ul>
<p><img data-src="006tNbRwly1fxvwiu64hxj32700pg423.jpg" alt></p>
<ul>
<li>Click “Install this script” button to install this script.</li>
</ul>
<p><img data-src="006tNbRwgy1fxvwkir266j31260u00x2.jpg" alt></p>
<ul>
<li>Ok, the installation stage is finished, you can start download resources!</li>
</ul>
<h2 id="3-browse-httpdoubancom-to-search-and-download-your-resource"><a class="markdownIt-Anchor" href="#3-browse-httpdoubancom-to-search-and-download-your-resource"></a> 3. Browse <a href="http://douban.com/">http://douban.com/</a> to search and download your resource!</h2>
<ul>
<li>For example, you want to get a book associated with <strong>machine learning</strong>, you just need to search it in douban books.</li>
</ul>
<p><img data-src="006tNbRwly1fxvwomvv7aj30u00xhadu.jpg" alt></p>
<ul>
<li>
<p>Then, if you want to download the machine learning book with flowers on its cover 😃, click it and go into the item page. Notice, the scrip installed just now uses multi-thread and is memory-consuming, so your browser may be stuck there for a little while, that’s normal and don’t shut down the tab!</p>
</li>
<li>
<p>Then you will notice that on the right of the page, you can see resources from any website. The script will detect whether the resource exists, and display the result in different color. Light blue ones mean that you can find resources by visiting this link, while yellow ones tell you that this certain resource doesn’t exist here. And these websites are classified, so if you have a certain preference, just follow the label and you will get what you want!</p>
</li>
</ul>
<p><img data-src="006tNbRwgy1fxvwvabpr4j30ws0u0105.jpg" alt></p>
<h2 id="4-also-you-can-search-for-movies-and-music-in-the-same-way"><a class="markdownIt-Anchor" href="#4-also-you-can-search-for-movies-and-music-in-the-same-way"></a> 4. Also, you can search for movies and music in the same way!</h2>
]]></content>
      <tags>
        <tag>tech</tag>
        <tag>tool</tag>
      </tags>
  </entry>
  <entry>
    <title>Git Submodule 攻略</title>
    <url>/2020/10/22/git-sub-module/</url>
    <content><![CDATA[<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Add submodule</span></span><br><span class="line">git submodule add</span><br><span class="line"></span><br><span class="line"><span class="comment"># Clone a project with submodules</span></span><br><span class="line">git <span class="built_in">clone</span> --recursive</span><br><span class="line"></span><br><span class="line"><span class="comment"># Update when submodeule remote repo changed</span></span><br><span class="line">git submodule update --remote</span><br><span class="line"></span><br><span class="line"><span class="comment"># When cloned without recursive</span></span><br><span class="line">git submodule init</span><br><span class="line">git submodule update</span><br><span class="line"></span><br><span class="line"><span class="comment"># Push submodule change to its remote origin master</span></span><br><span class="line"><span class="built_in">cd</span> &lt;submodule_name&gt;</span><br><span class="line">git add -A .</span><br><span class="line">git commit -m <span class="string">&quot;xxx&quot;</span></span><br><span class="line">git checkout &lt;detached branch name/number&gt;</span><br><span class="line">git merge master</span><br><span class="line">git push -u origin master</span><br></pre></td></tr></table></figure>
<span id="more"></span>
<h2 id="定义"><a class="markdownIt-Anchor" href="#定义"></a> 定义</h2>
<p><code>git submodule</code>允许用户将一个 Git 仓库作为另一个 Git 仓库的子目录。 它能让你将另一个仓库克隆到自己的项目中，同时还保持提交的独立性。</p>
<h2 id="作用"><a class="markdownIt-Anchor" href="#作用"></a> 作用</h2>
<p>在我这里，它的作用非常明确，即给在各个项目中都会用到的代码段一个公共栖息地，做到“一处改，处处改”。</p>
<h2 id="常用命令"><a class="markdownIt-Anchor" href="#常用命令"></a> 常用命令</h2>
<h3 id="添加"><a class="markdownIt-Anchor" href="#添加"></a> 添加</h3>
<p><code>git submodule add</code></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 直接clone，会在当前目录生成一个someSubmodule目录存放仓库内容</span></span><br><span class="line">git submodule add https://github.com/miracleyoo/someSubmodule</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定文件目录</span></span><br><span class="line">git submodule add https://github.com/miracleyoo/someSubmodule  src/submodulePath</span><br></pre></td></tr></table></figure>
<p>添加完之后，子模块目录还是空的（似乎新版不会了），此时需要执行：</p>
<p><code>git submodule update --init --recursive</code></p>
<p>来真正将子模块中的内容clone下来。同时，如果你的主目录在其他机器也有了一份clone，它们也需要执行上面的命令来把远端关于子模块的更改实际应用。</p>
<h3 id="clone时子模块初始化"><a class="markdownIt-Anchor" href="#clone时子模块初始化"></a> Clone时子模块初始化</h3>
<p><code>clone</code>父仓库的时候加上<code>--recursive</code>，会自动初始化并更新仓库中的每一个子模块</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> --recursive</span><br></pre></td></tr></table></figure>
<p>或：</p>
<p>如果已经正常的<code>clone</code>了，那也可以做以下补救：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git submodule init</span><br><span class="line">git submodule update</span><br></pre></td></tr></table></figure>
<p>正常<code>clone</code>包含子模块的函数之后，由于.submodule文件的存在<code>someSubmodule</code>已经自动生成，但是里面是空的。上面的两条命令分别：</p>
<ol>
<li>初始化的本地配置文件</li>
<li>从该项目中抓取所有数据并检出到主项目中。</li>
</ol>
<h3 id="更新"><a class="markdownIt-Anchor" href="#更新"></a> 更新</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git submodule update --remote</span><br></pre></td></tr></table></figure>
<p>Git 将会进入所有子模块，分别抓取并更新，默认更新master分支。</p>
<p>不带<code>--remote</code>的<code>update</code>只会在本地没有子模块或它是空的的时候才会有效果。</p>
<h3 id="推送子模块修改"><a class="markdownIt-Anchor" href="#推送子模块修改"></a> 推送子模块修改</h3>
<p>这里有一个概念，就是主repo中的子模块被拉到本地时默认是一个子模块远程仓库master分支的<code>detached branch</code>。这个分支是master的拷贝，但它不会被推送到远端。如果在子模块中做了修改，并且已经<code>add</code>，<code>commit</code>，那你会发现当你想要<code>push</code>的时候会报错：<code>Updates were rejected because a pushed branch tip is behind its remote</code>。这便是所谓的<code>detached branch</code>的最直接的体现。</p>
<p>解决方法是：在子模块中先<code>git checkout master</code>，然后在<code>git merge &lt;detached branch name/number&gt;</code>，最后<code>git push -u origin master</code>即可。</p>
<p>这里解释一下<code>&lt;detached branch name/number&gt;</code>这个东西可以使用<code>git branch</code>命令查看。如果你使用的是<code>zsh</code>，那么问题就更简单了，直接在命令提示符处就可以找到。</p>
<p><img data-src="image-20200704184550817.png" alt="image-20200704184550817"></p>
<p><img data-src="image-20200704184656815.png" alt="image-20200704184656815"></p>
<h2 id="参考"><a class="markdownIt-Anchor" href="#参考"></a> 参考</h2>
<ol>
<li>
<p><a href="https://juejin.im/post/5d5ca6e06fb9a06b1a568e32">来说说坑爹的 git submodule</a></p>
</li>
<li>
<p><a href="https://juejin.im/post/5ca47a84e51d4565372e46e0">Git submodule使用指南（一）</a></p>
</li>
<li>
<p><a href="https://github.blog/author/jaw6/">Working with submodules</a></p>
</li>
<li>
<p><a href="https://stackoverflow.com/questions/18770545/why-is-my-git-submodule-head-detached-from-master">Why is my Git Submodule HEAD detached from master?</a></p>
</li>
</ol>
]]></content>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>用Python抢救你的Hexo博客图床链接到本地</title>
    <url>/2019/10/02/hexo-image-migrator/</url>
    <content><![CDATA[<h2 id="问题背景"><a class="markdownIt-Anchor" href="#问题背景"></a> 问题背景</h2>
<p>由于近期各大免费图床纷纷加入了防盗链机制（如新浪）并停止对个人博客用的图床链接进行访问授权，博客上的图片出现了大面积的无法显示（如本博客），严重影响了博客的浏览体验。然而现在直接使用文中链接尚还可以将图片下载到本地，但这也并无法得到任何官方保障，所以当务之急是把所有图床照片下载到本地，用hexo原生的图片插入格式进行插入。</p>
<p>而在免费图床渐渐不再可用的现在，当务之急其实已经不是再次更换图床，而是把这些图片抢救到本地，并直接将原图部署到服务器上；或是自己搭建图床。为了节省时间和成本，我这里采用了直接将原图部署到服务器上的操作。</p>
<span id="more"></span>
<h2 id="这个问题可以拆解为以下几点"><a class="markdownIt-Anchor" href="#这个问题可以拆解为以下几点"></a> 这个问题可以拆解为以下几点：</h2>
<ol>
<li>在_post文件夹中建立与markdown文件同名文件夹用于存放图片。</li>
<li>遍历文件夹中文件并用正则匹配的方式匹配得到待替换的链接。</li>
<li>下载所有图片文件并存储到相应位置。</li>
<li>将原文件中的<code>![name](link)</code>替换为可在网页上显示的语句。</li>
</ol>
<p>于是我为了方便使用python写了一个脚本，使得上面这几步可以自动完成。下面贴上主要代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    names=os.listdir(root)</span><br><span class="line">    files=[i <span class="keyword">for</span> i <span class="keyword">in</span> names <span class="keyword">if</span> i.endswith(<span class="string">&#x27;.md&#x27;</span>) <span class="keyword">and</span> <span class="keyword">not</span> os.path.isdir(os.path.join(root, i)) <span class="keyword">and</span> <span class="keyword">not</span> i.startswith(<span class="string">&#x27;.&#x27;</span>)]</span><br><span class="line">    file_paths = [os.path.join(root, i) <span class="keyword">for</span> i <span class="keyword">in</span> files]</span><br><span class="line">    dirs=[i <span class="keyword">for</span> i <span class="keyword">in</span> names <span class="keyword">if</span> os.path.isdir(os.path.join(root, i)) <span class="keyword">and</span> <span class="keyword">not</span> i.startswith(<span class="string">&#x27;.&#x27;</span>)]</span><br><span class="line">    dir_paths = [os.path.join(root, i) <span class="keyword">for</span> i <span class="keyword">in</span> dirs]</span><br><span class="line">    <span class="built_in">print</span>(files)</span><br><span class="line">    <span class="keyword">for</span> file_iter <span class="keyword">in</span> files:</span><br><span class="line">        name_temp = os.path.splitext(os.path.split(file_iter)[-<span class="number">1</span>])[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> name_temp <span class="keyword">not</span> <span class="keyword">in</span> dirs:</span><br><span class="line">            dir_temp = os.path.join(root, name_temp)</span><br><span class="line">            os.mkdir(dir_temp)</span><br><span class="line">        download(os.path.join(root,file_iter))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对每个文件中的链接分别进行下载和替换链接处理</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">download</span>(<span class="params">file_path</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;==&gt; Now dealing with file:&quot;</span>, file_path)</span><br><span class="line">    dir_name = os.path.splitext(os.path.split(file_path)[-<span class="number">1</span>])[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># filename = &quot;test&quot;</span></span><br><span class="line">    name = file_path.split(<span class="string">u&quot;/&quot;</span>)</span><br><span class="line">    filename = name[-<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">with</span> codecs.<span class="built_in">open</span>(file_path, encoding=<span class="string">&quot;UTF-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        text = f.read()</span><br><span class="line">    <span class="comment"># regex</span></span><br><span class="line">    result = re.findall(<span class="string">&#x27;!\[(.*)\]\((.*)\)&#x27;</span>, text)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, content <span class="keyword">in</span> <span class="built_in">enumerate</span>(result):</span><br><span class="line">        image_quote = content[<span class="number">0</span>]</span><br><span class="line">        image_url = content[<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="comment"># download img</span></span><br><span class="line">            img_data = requests.get(image_url).content</span><br><span class="line">            <span class="comment"># img name spell</span></span><br><span class="line">            image_name = image_url.strip(<span class="string">&quot;/&quot;</span>).split(<span class="string">&quot;/&quot;</span>)[-<span class="number">1</span>]</span><br><span class="line">            image_path = os.path.join(root, dir_name, image_name)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;==&gt;&quot;</span>, image_path, <span class="string">&#x27;~~~&#x27;</span>, image_url)</span><br><span class="line">            <span class="comment"># write to file</span></span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(image_path, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> handler:</span><br><span class="line">                handler.write(img_data)</span><br><span class="line"></span><br><span class="line">            text=text.replace(<span class="string">&quot;![&quot;</span>+image_quote+<span class="string">&quot;](&quot;</span>+image_url+<span class="string">&quot;)&quot;</span>, <span class="string">&quot;![&quot;</span>+image_quote+<span class="string">&quot;](&quot;</span>+image_name+<span class="string">&#x27;)&#x27;</span>)</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">    <span class="keyword">with</span> codecs.<span class="built_in">open</span>(file_path, mode=<span class="string">&quot;w+&quot;</span>, encoding=<span class="string">&quot;UTF-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(text)</span><br></pre></td></tr></table></figure>
<p>如有需求，推荐查看更加详细的使用说明和注意事项。项目在<a href="https://link.zhihu.com/?target=https%3A//github.com/miracleyoo/hexo-migrator">Github</a>上，并附有step-by-step的说明，即使没有编程基础也可以轻易上手。</p>
<p>如果有帮助到你，欢迎Star支持一下hhh~ 😃</p>
]]></content>
      <tags>
        <tag>python</tag>
        <tag>tool</tag>
        <tag>blog</tag>
      </tags>
  </entry>
  <entry>
    <title>How to make a good paper presentation Slides</title>
    <url>/2018/10/27/good-ppt/</url>
    <content><![CDATA[<ol>
<li>
<p>多插图，三张图往往可以表达清楚一篇文章的基本思路。如果需要展示结果，另外加图或是表格。</p>
</li>
<li>
<p>首页干净整洁，标题要大而清晰，同时要有作者，演讲者名字，可能的话添加机构图标。</p>
</li>
<li>
<p>整个PPT配色要统一，最好使用机构标志色。如学校图标使用的深红色，那这里也可以用深红作为深色、强调色。</p>
</li>
<li>
<p>中英文统一。如果使用中文那么统一使用中文，反之亦然。</p>
<span id="more"></span>
</li>
<li>
<p>如果放一张较为复杂的图，要用红黄圈圈箭头把重要部分、需要关注的点标记出来，同时旁边可以加一些注释。</p>
</li>
<li>
<p>Background页面最好有一个概述图，而非只有文字，以期帮助观众理解。</p>
</li>
<li>
<p>能画图说明的问题不要放大段文字。</p>
</li>
<li>
<p>如果有很多结果，请选择部分最终要的结果，而非全部截取，“伤其十指不如断其一指”。同理，论文本身内容较多，内容选取方面也要做到精选，而非全放。</p>
</li>
<li>
<p>要主动发现论文的缺点和不足之处在哪里，只有明确了其局限，才能做出超越其本身的成果，即创新。</p>
</li>
<li>
<p>结尾要有Q&amp;A以及Thanks页面。</p>
</li>
</ol>
]]></content>
      <tags>
        <tag>paper</tag>
        <tag>ppt</tag>
      </tags>
  </entry>
  <entry>
    <title>“Hi there” の “there” って何？</title>
    <url>/2018/03/08/hi-there/</url>
    <content><![CDATA[<h1 id="hi-there-の-there-って何"><a class="markdownIt-Anchor" href="#hi-there-の-there-って何"></a> “Hi there” の “there” って何？</h1>
<p>“Hi there” というフレーズを耳にしたことはありますか？</p>
<p>私はニュージーランドに来てから初めて知ったのですが、お店やカフェなどでは店員さんに “Hi there!” と声をかけられることがとっても多いんです。</p>
<p>なぜこんなところに “there” が出てくるのでしょうか？この “there” ってどんな意味なのでしょうか？</p>
<span id="more"></span>
<h2 id="謎の挨拶-hi-there"><a class="markdownIt-Anchor" href="#謎の挨拶-hi-there"></a> 謎の挨拶 “Hi there”</h2>
<p>“Hi there” は “Hi” がついていることからも想像できると思いますが、挨拶の1つです。<br>
トーンにもよりますが、たいてはとってもフレンドリーな感じで、店員さんからよく耳にします。例えば、こんなふうです。</p>
<p>カフェのレジで注文の順番待ちをしていて、ついに自分の番になったらレジの店員さんから、</p>
<ul>
<li>Hi there. What would you like?</li>
</ul>
<p>と言われたりします。<br>
また、洋服屋さんに入って商品を見てウロウロしていると、店員さんが寄ってきて、</p>
<ul>
<li>Hi there. Do you need any help at all?</li>
<li>Hi there. <a href="https://kiwi-english.net/23950">Are you alright?</a></li>
</ul>
<p>のように声をかけられることもあります。</p>
<h4 id="スポンサーリンク"><a class="markdownIt-Anchor" href="#スポンサーリンク"></a> スポンサーリンク</h4>
<p>いずれにしても、”Hi” や “Hello” の代わりに “Hi there”、”Hello there” が使われているだけで、大した意味の違いはありません。<br>
では、なぜ “there” が登場するのでしょうか？</p>
<h2 id="there-はそこではない"><a class="markdownIt-Anchor" href="#there-はそこではない"></a> “there” は「そこ」ではない</h2>
<p>“there” には「そこ（に、で）」という意味がありますよね。</p>
<p>なので、私は最初は “Hi there＝Hi そこのあなた” と言われているのかと思っていましたが、実はちょっと違うんです。</p>
<p>この “there” は、こんな意味で使われています↓</p>
<blockquote>
<ul>
<li>used to attract somebody’s attention（<a href="https://kiwi-english.net/14950">オックスフォード現代英英辞典</a>）</li>
<li>used as an indefinite substitute for a name（<a href="https://www.merriam-webster.com/dictionary/there">Merriam-Webster Dictionary</a>）</li>
</ul>
</blockquote>
<p>この “there” に特に意味はなく、相手の注意を引くための呼びかけとして使われているんですね。”Hi there＝やぁ” ぐらいの感じでしょうか。</p>
<p>そして、興味深いのは2つ目の “substitute for a name” という解釈です。</p>
<h2 id="英語では挨拶に相手の名前を入れることが多い"><a class="markdownIt-Anchor" href="#英語では挨拶に相手の名前を入れることが多い"></a> 英語では挨拶に相手の名前を入れることが多い</h2>
<p>私は、”substitute for a name” という解釈を見た時に、とてもしっくりきたのを覚えています。</p>
<p>例えば、”Hi John” や “Hello Diana” みたいな感じですね。相手の名前を知っている場合には、”Hi/Hello” の後ろに相手の名前を入れて挨拶するのが普通です。</p>
<p>でも、店員さんはもちろんお客さん1人1人の名前を知っているわけではありません。そこで “Hi there” や “Hello there” という挨拶を使うことが多いのかもしれません。</p>
<p>“Hi/Hello there” は知っている人に対しても使うことがあるそうですが、私はこの使い方はほとんど耳にしたことがなく、店員さんなどの面識のない人からのフレンドリーな挨拶として耳にすることが圧倒的に多いです。</p>
<p>そして、これはメールでも同じで、面識のない人からのメールやメールマガジンなどでは、”Hi” や “Hello” のカジュアル＆フレンドリーな挨拶として “Hi there” という書き出しをとてもよく目にします。</p>
<h2 id="there-に深い意味はない"><a class="markdownIt-Anchor" href="#there-に深い意味はない"></a> “there” に深い意味はない</h2>
<p>“Hi there” の “there” には、特に深い意味はないので「”there” って何？」と悩まなくても大丈夫です。</p>
<p>単なる “Hi” や “Hello” と意味的には変わらないので、”Hi there” と言われたら “Hi” や “Hello” で返したらOK。</p>
<p>こんな “there” の使い方もあるんだなぁと何かの参考にしてもらえると嬉しいです。</p>
]]></content>
      <tags>
        <tag>learn-English</tag>
      </tags>
  </entry>
  <entry>
    <title>华彩人生——华科模拟器游戏介绍</title>
    <url>/2018/06/18/hua-cai-ren-sheng/</url>
    <content><![CDATA[<h1 id="华彩人生华科模拟器"><a class="markdownIt-Anchor" href="#华彩人生华科模拟器"></a> 华彩人生——华科模拟器</h1>
<p>华彩人生 – 一款为华科（华中科技大学）量身打造的游戏；一款在华科这片神奇土地上展开的奇幻RPG游戏；一款高仿真的华科模拟器。想要了解华科的同学请务必来玩哦~相信不会让你失望！ 引擎：RPGMaker MV</p>
<h3 id="声明"><a class="markdownIt-Anchor" href="#声明"></a> 声明</h3>
<ul>
<li>
<p>游戏在线体验请走这里<a href="https://miracleyoo.github.io/HCRS-Online/">在线游戏</a>成品游戏下载请移步<a href="https://pan.baidu.com/s/1YMZMC7-RC8dQWvwbvfjTJQ">Windows版本</a>/<a href="https://github.com/miracleyoo/HCRS-Online/">Web版本</a>。</p>
<span id="more"></span>
</li>
<li>
<p>请注意，因为游戏较大，所以在线体验时很可能会出现</p>
<ol>
<li>“Now Loading”时间较长</li>
<li>“Failed to load Game Font”</li>
<li>“cannot read _actorCMData of null”等问题，请不要着急，请在网速好的地方稍等一会儿，重新加载一遍即可。</li>
</ol>
</li>
<li>
<p>如果出现“Your Browser does not support Web Audio API”，请更换浏览器使用。（Safari、Chrome等主流浏览器都提供支持）</p>
</li>
<li>
<p>本游戏制作组织为华中科技大学Dian团队707工作组，总监制、总策划为707组组长张中洋（miracleyoo）。</p>
</li>
<li>
<p>本游戏的目的是宣传华中科技大学，可以使玩家在游戏过程中熟悉华科的地图，了解华科地标建筑等；但同时，本游戏也兼具强大的可玩性，可供在校同学、毕业校友、以及所有对华科或是本作品有兴趣的同学享用。</p>
</li>
<li>
<p>本游戏使用的游戏引擎为RPGMaker MV，同时参考了<strong>atelierrgss</strong>制作的部分插件，在此一并表示感谢。</p>
</li>
<li>
<p>参与本次游戏制作的成员有Dian团队队员： 张中洋、伍瀚缘、朱晓光、黄涛、孙紫檀、张子孺、田祺云。对整个制作流程中诸位的贡献与付出致以诚挚的感谢。</p>
</li>
<li>
<p>开发者名单简介<a href="https://www.bilibili.com/video/av25115108/">视频</a>。游戏宣传<a href="https://www.bilibili.com/video/av25150711/">视频</a>（震撼！推荐！）</p>
</li>
<li>
<p>如果您在游戏过程中发现bug或有想要提出的建议，请直接提出issue或邮件联系我。</p>
</li>
<li>
<p>如果您准备基于本项目进行改编或是再开发，请务必联系作者张中洋(<a href="mailto:miracleyoo@163.com">miracleyoo@163.com</a>)，并注明出处。</p>
</li>
</ul>
<h3 id="游戏特征"><a class="markdownIt-Anchor" href="#游戏特征"></a> 游戏特征</h3>
<ul>
<li>游戏结合了传统的文字类游戏和RPG游戏的优点，既有文字类游戏式的引导和介绍，又有RPG游戏式的广阔地图可供探索。</li>
<li>游戏有多达7条支线可供选择，每一条都经过精心设计，既有相似之处，又各有特色。</li>
<li>游戏主地图为华科手绘画风地图，只标注了主要建筑物，便于玩家熟悉地图。</li>
<li>游戏中有大量对建筑物和游戏玩法等进行介绍的NPC，相信你可以快速上手。</li>
<li>游戏整体画风偏可爱，同时配有放松愉悦的背景音乐，游戏体验良好。</li>
<li>游戏战斗部分下足了功夫，采用了半回合制战斗模式，紧张刺激；同时界面友好，操作简单，你可以很快上手战斗并不断取得成就。</li>
<li>游戏的平衡性经过了仔细的调节，你可以动用你的智慧击败同级别甚至稍高级的怪物，同时会有随机道具掉落，供你后续战斗中使用。</li>
<li>游戏中设置很多彩蛋供你探索，这些彩蛋既有趣，又会提供给你不少有趣的“华科知识”。</li>
<li>游戏设有真正可投入使用的华科全校车系统，站点依据实际站点设置。</li>
<li>游戏中的网吧和KTV都可以进入。实际上，随着你去网吧的次数越多，你吃鸡的水平也会越高，但同时，会有你意想不到发展出现。</li>
<li>游戏中标有华科主要的一些食堂，它们可用于加蓝，并且会随机掉落具有该食堂特色的道具；两个校医院可用于战斗后回复血量使用。</li>
</ul>
<h3 id="游戏宣传"><a class="markdownIt-Anchor" href="#游戏宣传"></a> 游戏宣传</h3>
<p>你看过什么形式的华科宣传？文章？NONONO，太过枯燥；海报？NONONO，信息太少；短视频？NONONO，记不牢靠。<br>
为何无论看了这么多宣传，你还是会迷路？为什么都说华科食堂好吃，你却还是满脸茫然？为什么华科无论是体育设施还是人文美景都质量上乘，你却很久不知其存在？<br>
答：有趣的宣传太抽象，有货的宣传太无聊！<br>
就不能有一个既有趣又有货的介绍吗？？？<br>
当然可以！这就是我们的“华科模拟器”！<br>
在这里，你将化身为游戏中一个即将入学华科的新生，面临从你踏进校门的那一刻开始将要面对的一个又一个选择，真实展现你将要面临的丰富多彩的华科生活。<br>
游戏采用经典的打怪升级模式，促使玩家在探索和搜寻中不断加深对华科的了解。<br>
路边的NPC会给予玩家对重要建筑物的详细介绍，只有方位？Certainly Not！从位置到特色到学生评价都有机的融入其中。<br>
而对华科各个食堂特色的介绍更是“辨析”了华科引以为豪的诸多食堂。介绍可以详细到每一层，而同样，每个食堂可以随机获得的道具：特色食品也各有千秋。<br>
本游戏内核强势弘扬华科价值观——“不学习，就凉凉”，如果你在游戏中经常混迹网吧KTV或被朋友劝说开黑吃鸡，那么，嗯，你就成了一个学渣。<br>
本游戏有精心制作的多条支线，这不但给了你很大的自由选择空间，更提供了一个让你了解华科各种类型建筑的机会——</p>
<ul>
<li>轻音乐线：华科的各种艺术类建筑，雕塑，校史馆，水池湖泊甚至森林公园都会成为相应关键怪物的触发点，这也让你在搜寻和问路的过程中更加深入的了解了华科。</li>
<li>网球线：华科的各类体育场馆、操场、篮球场、网球场等都成了活跃的中心，你也可以借此机牢记它们的位置，并在现实生活中也可以来痛快“打”球。</li>
<li>学霸线：华科的各类教学楼、实验室、学院大楼都会留下你的足迹。开学？相信来之前你已经成为了一名老司机。</li>
</ul>
<p>听说你来学校一学期还不知道校车站位置？不如来这里实实在在搭乘一波！你有理由相信真是的华科校车系统和它一样给力！<br>
当然，华科近邻森林公园，而公园里究竟又隐藏着什么等待着你的探索？如果你已经迫不及待了，那就赶紧来下载我们的游戏，亲自体验一番吧！~</p>
<h3 id="游戏截图"><a class="markdownIt-Anchor" href="#游戏截图"></a> 游戏截图</h3>
<p><img data-src="006tNbRwgy1fuen6a1f5ij31a612a4qq.jpg" alt="WX20180618-140837@2x"></p>
<p><img data-src="../../../../../Desktop/%E5%8D%8E%E5%BD%A9%E4%BA%BA%E7%94%9F/%E6%B8%B8%E6%88%8F%E6%88%AA%E5%9B%BE/WX20180618-141546@2x.png" alt="WX20180618-141546@2x"></p>
<p><img data-src="../../../../../Desktop/%E5%8D%8E%E5%BD%A9%E4%BA%BA%E7%94%9F/%E6%B8%B8%E6%88%8F%E6%88%AA%E5%9B%BE/WX20180618-142254@2x.png" alt="WX20180618-142254@2x"></p>
<p><img data-src="../../../../../Desktop/%E5%8D%8E%E5%BD%A9%E4%BA%BA%E7%94%9F/%E6%B8%B8%E6%88%8F%E6%88%AA%E5%9B%BE/WX20180618-142718@2x.png" alt="WX20180618-142718@2x"></p>
<p><img data-src="../../../../../Desktop/%E5%8D%8E%E5%BD%A9%E4%BA%BA%E7%94%9F/%E6%B8%B8%E6%88%8F%E6%88%AA%E5%9B%BE/WX20180618-142840@2x.png" alt="WX20180618-142840@2x"></p>
<p><img data-src="../../../../../Desktop/%E5%8D%8E%E5%BD%A9%E4%BA%BA%E7%94%9F/%E6%B8%B8%E6%88%8F%E6%88%AA%E5%9B%BE/WX20180618-143132@2x.png" alt="WX20180618-143132@2x"></p>
]]></content>
      <tags>
        <tag>game</tag>
        <tag>rpg maker</tag>
      </tags>
  </entry>
  <entry>
    <title>提供一个基于官方模板优化升级后的毕设Word模板</title>
    <url>/2019/05/02/hust-paper-template/</url>
    <content><![CDATA[<p>由于毕设查重等会使用到word版本，且最终提交也要有word，而经过15级的测试，现有的几乎所有pdf转word方法都有着或多或少的问题，改起来非常麻烦。</p>
<p>经过对官方word模板的研究以及与Latex效果的对比，最终制作该模板，供大家后面使用。</p>
<p>先放上<a href="https://github.com/miracleyoo/HUST-Grad-Paper-Word-Template">项目地址</a>，欢迎大家使用、提建议、完善和维护。</p>
<span id="more"></span>
<h2 id="下面是项目介绍"><a class="markdownIt-Anchor" href="#下面是项目介绍"></a> 下面是项目介绍：</h2>
<p>本项目为华科（华中科技大学）本科生毕业设计论文的进阶优化版Word模板。它源于官方但高于官方，由于官方的Word模板难以使用且问题多多，自动化程度低，故有本项目。</p>
<p>本项目虽为基于华中科技大学设计的，但除去封面和标题格式等有略微改动，其它大部分也可以供其它学校同学借鉴参考。</p>
<p>如有格式问题或其它建议，欢迎提出issue！</p>
<h2 id="本项目优化内容"><a class="markdownIt-Anchor" href="#本项目优化内容"></a> 本项目优化内容：</h2>
<ul>
<li>页码的优化。本项目对封面、原创性声明页、摘要页等进行分节，使得页码编号与正文区分开来。同时优化了页码的显示。</li>
<li>封面的优化。封面原模板上填写部分为下划线，不方便使用且存在手动居中、横线长度有微妙差等问题。本项目改用表格线显示。</li>
<li>分级标题的优化。各级标题采用了Word样式，并与多级列表进行了绑定设置。只要使用“标题1”“标题2”“标题3”“标题4”等样式，就可以保证格式的正确性，并能自动链接到目录。</li>
<li>数学公式的优化。此处建议使用**<a href="http://www.mathtype.cn/">Mathtype</a>**。Mathtype会自动安装Word插件，方便一键转换Latex公式、支持行内公式、行间公式、公式编号格式设置、公式交叉引用等，十分方便。</li>
<li>图表题注与交叉引用的示例与注意事项。使用题注和交叉引用可以容易地进行全局更新，避免由于中间插入新的图表而全局更改或误改漏改。</li>
<li>参考文献引用。此处推荐使用**<a href="https://www.zotero.org/">Zotero</a>**，这是一个开源免费的论文引用工具，且设有Chrome以及Chrome的插件支持，并能够自动获取文章各种相关信息。有Word插件支持，且可以导出bib文件，对Latex也很友好。</li>
<li>对内容的提示。对各章节的大致内容进行了适当的提示。</li>
</ul>
<h2 id="注意事项"><a class="markdownIt-Anchor" href="#注意事项"></a> 注意事项：</h2>
<ul>
<li>注意最好不要修改几个标题样式和多级列表设置，以免造成混乱。</li>
<li>若使用自动引文管理软件，请在导出Bibliography时选择Chinese Std GB/T 7714-2005 (numeric, Chinese) 格式。</li>
<li>请注意每次更改后随时更新目录。</li>
<li>请注意每章后插入分页符。</li>
<li>请注意为每张图和表插入题注。图的题注在下，表的题注在上。</li>
<li>注意有的引文可能没有自动标出时间，此时要自行排查一下。格式只要使用Zotero，选对样式，一般不会有问题。</li>
</ul>
<p>祝大家都能顺利高效完成毕设论文写作！</p>
]]></content>
      <tags>
        <tag>paper</tag>
        <tag>word</tag>
        <tag>template</tag>
      </tags>
  </entry>
  <entry>
    <title>日系绘画构图</title>
    <url>/2020/09/12/illustration-composition/</url>
    <content><![CDATA[<p><strong>构图法+出镜比例+人物动态=好的构图</strong></p>
<h2 id="常见单人构图"><a class="markdownIt-Anchor" href="#常见单人构图"></a> 常见单人构图</h2>
<h3 id="对称构图"><a class="markdownIt-Anchor" href="#对称构图"></a> 对称构图</h3>
<p>主要包含：左右对称，对角线对称</p>
<p>相对比较中规中矩，但是同样的，限制会比较大，也需要更多细节上的<strong>不对称</strong>来中和构图上的对称。这些不对称元素往往来自于：人物动态、道具、背景元素。</p>
<img data-src="image-20200912154217731.png" alt="image-20200912154217731" style="zoom:50%;">
<span id="more"></span>
<h3 id="九宫格构图"><a class="markdownIt-Anchor" href="#九宫格构图"></a> 九宫格构图</h3>
<p>将重要的点置于九宫格的焦点上，起到强化关键要素的作用，如脸部、关节等。</p>
<p><img data-src="image-20200912153443124.png" alt="image-20200912153443124"></p>
<h3 id="黄金比例构图"><a class="markdownIt-Anchor" href="#黄金比例构图"></a> 黄金比例构图</h3>
<p>B格较高，人物的人体曲线和黄金分割线契合，螺旋正中央缩于人物脸部。该构图较为有特色，有着不对称的美感。</p>
<img data-src="image-20200912153516507.png" alt="image-20200912153516507" style="zoom:50%;">
<h3 id="好用技巧"><a class="markdownIt-Anchor" href="#好用技巧"></a> 好用技巧</h3>
<ol>
<li>
<p>人物动态和道具都可以被用来表达动态。如果人体动态比较复杂灵动，衣物可以相对简单点；而如果人物动态想画的简单保守一点，可以使用道具（长而飘逸的头发、大而舞动的裙摆、长长的布料…）</p>
<img data-src="image-20200912172118092.png" alt="image-20200912172118092" style="zoom:50%;">
</li>
<li>
<p>利用人物动作带来动态感（风）-&gt; 头发和裙摆随风飘动，人物跳起来或浮于空中。这样可以让画面看起来更有活力和生命力。</p>
</li>
</ol>
<img data-src="image-20200912172201727.png" alt="image-20200912172201727" style="zoom:50%;">
<ol>
<li></li>
</ol>
<h2 id="出镜比例"><a class="markdownIt-Anchor" href="#出镜比例"></a> 出镜比例</h2>
<p>一般的人物在插画中的出镜比例为：</p>
<ol>
<li>
<p>腰部以上：刻画部分更少，但是相对的，对头部和上身衣物的刻画就会要求更高。</p>
<img data-src="image-20200912153749506.png" alt="image-20200912153749506" style="zoom:50%;">
</li>
<li>
<p>大腿以上：可以刻画几乎全部的人物动态。</p>
<p>特点：方便表现躯干动态，方便表达透视。</p>
<img data-src="image-20200912153853701.png" alt="image-20200912153853701" style="zoom:50%;">
</li>
<li>
<p>全身：由于人体是一个细长的物体，如果要展现全身并主要由人物填满画面的话，需要作出很大的动作（弯曲）和大角度的透视。</p>
<img data-src="image-20200912153932298.png" alt="image-20200912153932298" style="zoom:50%;">
</li>
</ol>
<p>竖版插图（A4）三种比例都很多，而横版插图（1080p）则偏全身。</p>
<h2 id="常见双人构图"><a class="markdownIt-Anchor" href="#常见双人构图"></a> 常见双人构图</h2>
<p>无论使用什么构图，两个人之间一定是有某种较为亲近的关系的。由于有不止一个人，此时的人物动态自由度会相对降低，而对构图法的依赖更高，同时也需要更加灵活准确的透视。相比单人，画面会更加丰富，也会侧重边线人物之间的联系、互动。</p>
<h3 id="平分型"><a class="markdownIt-Anchor" href="#平分型"></a> 平分型</h3>
<p>偏实用型。</p>
<p>往往会有某种形式的肢体接触，这样让全图显得更加自然。如果两个人站在一起又没有任何互动，画面会比价奇怪。</p>
<p>如果两个人的身高体型都近似，那自然是最好；如果身高体型有别，那么则需要通过某些部分（探出的头部，飘逸的头发、突出的膝盖、背包等道具）来平衡画面。</p>
<p>特点：画面易于平衡、容易理解好上手。对动态要求不高。</p>
<img data-src="image-20200912155936519.png" alt="image-20200912155936519" style="zoom:50%;">
<img data-src="image-20200912161613370.png" alt="image-20200912161613370" style="zoom:50%;">
<h3 id="八卦型"><a class="markdownIt-Anchor" href="#八卦型"></a> 八卦型</h3>
<p>偏静谧美型，强调双人关系。</p>
<p>特点：两人之间往往会有交叉关系。构图有特征，画面不容易单调。</p>
<p>要求：对人物动态要求比较高。</p>
<img data-src="image-20200912161749570.png" alt="image-20200912161749570" style="zoom:50%;">
<img data-src="image-20200912161941253.png" alt="image-20200912161941253" style="zoom:50%;">
<h3 id="空间构图"><a class="markdownIt-Anchor" href="#空间构图"></a> 空间构图</h3>
<p>偏氛围。</p>
<p>特点：两个人物由与摄像机镜头的远近产生了远近、大小的区别。让画面的空间感更足，从而对动态要求不高。</p>
<img data-src="image-20200912162117364.png" alt="image-20200912162117364" style="zoom:50%;">
<h2 id="常见多人构图"><a class="markdownIt-Anchor" href="#常见多人构图"></a> 常见多人构图</h2>
<p>普通插画中使用相对较少，多用于动画海报、游戏登录界面。</p>
<h3 id="没有绝对主角的时候"><a class="markdownIt-Anchor" href="#没有绝对主角的时候"></a> 没有绝对主角的时候</h3>
<h4 id="并排构图及其变形"><a class="markdownIt-Anchor" href="#并排构图及其变形"></a> 并排构图及其变形</h4>
<p>人物基本分布在同一距离，处于同一直/曲线上。</p>
<p>特点：</p>
<ol>
<li>有着明显走势（为了让画面有序）</li>
<li>集中</li>
</ol>
<p><img data-src="image-20200912162754564.png" alt="image-20200912162754564"></p>
<img data-src="image-20200912162706717.png" alt="image-20200912162706717" style="zoom:80%;">
<h3 id="有绝对主角"><a class="markdownIt-Anchor" href="#有绝对主角"></a> 有绝对主角</h3>
<p>以主角为中心扩散。</p>
<img data-src="日系绘画构图/image-20200912163421619.png" alt="image-20200912163421619" style="zoom:50%;">]]></content>
      <tags>
        <tag>art</tag>
        <tag>painting</tag>
      </tags>
  </entry>
  <entry>
    <title>Multi-Spectral Imaging 数据采集前期调研</title>
    <url>/2020/10/16/hsi-pre-data-collection/</url>
    <content><![CDATA[<h2 id="equipment"><a class="markdownIt-Anchor" href="#equipment"></a> Equipment</h2>
<h3 id="flir-blackfly-s-rgb-camera"><a class="markdownIt-Anchor" href="#flir-blackfly-s-rgb-camera"></a> FLIR Blackfly S RGB Camera</h3>
<ol>
<li>
<p>Spectral Range:</p>
<ul>
<li>Blue: 460 nm</li>
<li>Green: 530 nm</li>
<li>Red: 625 nm</li>
</ul>
</li>
<li>
<p>Resolution: 720 × 540</p>
</li>
<li>
<p>FPS: 522</p>
<span id="more"></span>
</li>
<li>
<p>Dimensions [W x H x L]: 29 mm × 29 mm × 30 mm</p>
</li>
<li>
<p>Official Link: <a href="https://www.flir.com/products/blackfly-s-usb3/">Link</a></p>
</li>
</ol>
<h3 id="ximea-mq022hg-im-sm5x5-nir-multispectral-camera"><a class="markdownIt-Anchor" href="#ximea-mq022hg-im-sm5x5-nir-multispectral-camera"></a> XIMEA MQ022HG-IM-SM5X5-NIR Multispectral Camera</h3>
<ol>
<li>Spectral Range: 665~975nm</li>
<li>Resolution:
<ul>
<li>Original: 2048 × 1088</li>
<li>Spatial: 409 × 217</li>
</ul>
</li>
<li>FPS: up to 170 cubes/sec</li>
<li>Sensor size: 2/3&quot;</li>
<li>Dimensions WxHxD: 26 x 26 x 31 mm</li>
<li>Pixel size: 5.5 µm</li>
<li>Python multispectral processing lib: <a href="http://www.spectralpython.net/#documentation">Link</a></li>
<li>Camera control official python lib: <a href="https://www.ximea.com/support/wiki/apis/Python">Link</a></li>
<li>Official brief specification: <a href="https://www.ximea.com/files/brochures/xiSpec-Hyperspectral-cameras-2015-brochure.pdf">Link</a></li>
<li>Official Page: <a href="https://www.ximea.com/en/products/hyperspectral-cameras-based-on-usb3-xispec/mq022hg-im-sm5x5-nir">Link</a></li>
</ol>
<table>
<thead>
<tr>
<th>Full Specifications:</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Part Number</strong></td>
<td>MQ022HG-IM-SM5X5-NIR</td>
</tr>
<tr>
<td><strong>Resolution</strong></td>
<td>Original: 2048 × 1088 Spatial: 409 × 217</td>
</tr>
<tr>
<td><strong>Frame rates</strong></td>
<td>up to 170 cubes/sec</td>
</tr>
<tr>
<td><strong>Sensor type</strong></td>
<td>CMOS, Hyperspectral filters added at wafer-level</td>
</tr>
<tr>
<td><strong>Sensor model</strong></td>
<td>IMEC SNm5x5</td>
</tr>
<tr>
<td><strong>Sensor size</strong></td>
<td>2/3&quot;</td>
</tr>
<tr>
<td><strong>Sensor active area</strong></td>
<td>25 Bands</td>
</tr>
<tr>
<td><strong>Readout Method</strong></td>
<td>Snapshot Mosaic</td>
</tr>
<tr>
<td><strong>Pixel size</strong></td>
<td>5.5 µm</td>
</tr>
<tr>
<td><strong>ADC -Bits per pixel</strong></td>
<td>8, 10 bit RAW pixel data</td>
</tr>
<tr>
<td><strong>Data interface</strong></td>
<td>USB 3.1 Gen1 or PCI Express (xiX camera model)</td>
</tr>
<tr>
<td><strong>Data I/O</strong></td>
<td>GPIO IN, OUT</td>
</tr>
<tr>
<td><strong>Power consumption</strong></td>
<td>1.6 Watt</td>
</tr>
<tr>
<td><strong>Lens mount</strong></td>
<td>C or CS Mount</td>
</tr>
<tr>
<td><strong>Weight</strong></td>
<td>32 grams</td>
</tr>
<tr>
<td><strong>Dimensions WxHxD</strong></td>
<td>26 x 26 x 31 mm</td>
</tr>
<tr>
<td><strong>Operating temperature</strong></td>
<td>50 °C</td>
</tr>
<tr>
<td><strong>Spectral range</strong></td>
<td>665-975 nm</td>
</tr>
<tr>
<td><strong>Customs tariff code</strong></td>
<td>8525.80 30 (EU) / 8525.80 40 (USA)</td>
</tr>
<tr>
<td><strong>ECCN</strong></td>
<td>EAR99</td>
</tr>
</tbody>
</table>
<h3 id="seek-compact-pro-thermal-camera"><a class="markdownIt-Anchor" href="#seek-compact-pro-thermal-camera"></a> Seek Compact Pro Thermal Camera</h3>
<ol>
<li>Seek Compact Pro: 7500~14000 nm</li>
<li>Resolution:  <strong>320 x 240</strong></li>
<li>Field of view: <strong>32°</strong></li>
<li>Frame rate: <strong>&lt; 9 Hz</strong></li>
<li>Focusable lens</li>
<li>Platform: Android or iOS (Linux 3rd-party binary library)</li>
<li>Specification Sheet: <a href="https://www.thermal.com/uploads/1/0/1/3/101388544/compactpro-sellsheet-website.pdf">Link</a></li>
</ol>
<h2 id="introduction"><a class="markdownIt-Anchor" href="#introduction"></a> Introduction</h2>
<p>Full spectrum:</p>
<p><img data-src="2880px-EM_spectrum.svg.png" alt="img"></p>
<p><img data-src="2880px-EM_Spectrum_Properties_edit_zh.svg.png" alt="img"></p>
<p><img data-src="Atmospheric_electromagnetic_opacity.svg" alt="img"></p>
<p><img data-src="200px-Light_spectrum.svg.png" alt="img"></p>
<h3 id="different-infrared"><a class="markdownIt-Anchor" href="#different-infrared"></a> <strong>Different Infrared:</strong></h3>
<table>
<thead>
<tr>
<th style="text-align:center">Division name</th>
<th style="text-align:center">Abbreviation</th>
<th style="text-align:center">Wavelength</th>
<th style="text-align:center">Frequency</th>
<th style="text-align:center">Photon energy</th>
<th style="text-align:center">Temperature[<a href="https://en.wikipedia.org/wiki/Infrared#cite_note-%E2%80%A0-15">i]</a></th>
<th style="text-align:center">Characteristics</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Near-infrared</td>
<td style="text-align:center">NIR, IR-A <em><a href="https://en.wikipedia.org/wiki/DIN">DIN</a></em></td>
<td style="text-align:center">0.75–1.4 <a href="https://en.wikipedia.org/wiki/%CE%9Cm">μm</a></td>
<td style="text-align:center">214–400 <a href="https://en.wikipedia.org/wiki/Terahertz_(unit)">THz</a></td>
<td style="text-align:center">886–1653 <a href="https://en.wikipedia.org/wiki/MeV">meV</a></td>
<td style="text-align:center">3,864–2,070 <a href="https://en.wikipedia.org/wiki/Kelvin">K</a> (3,591–1,797 <a href="https://en.wikipedia.org/wiki/Celsius">°C</a>)</td>
<td style="text-align:center">Defined by water absorption,[<em><a href="https://en.wikipedia.org/wiki/Wikipedia:Please_clarify">clarification needed</a></em>] and commonly used in <a href="https://en.wikipedia.org/wiki/Fiber_optic">fiber optic</a> telecommunication because of low attenuation losses in the SiO2 glass (<a href="https://en.wikipedia.org/wiki/Silica">silica</a>) medium. <a href="https://en.wikipedia.org/wiki/Image_intensifier">Image intensifiers</a> are sensitive to this area of the spectrum; examples include <a href="https://en.wikipedia.org/wiki/Night_vision">night vision</a> devices such as night vision goggles. <a href="https://en.wikipedia.org/wiki/Near-infrared_spectroscopy">Near-infrared spectroscopy</a> is another common application.</td>
</tr>
<tr>
<td style="text-align:center">Short-wavelength infrared</td>
<td style="text-align:center">SWIR, IR-B <em>DIN</em></td>
<td style="text-align:center">1.4–3 μm</td>
<td style="text-align:center">100–214 THz</td>
<td style="text-align:center">413–886 meV</td>
<td style="text-align:center">2,070–966 <a href="https://en.wikipedia.org/wiki/Kelvin">K</a> (1,797–693 <a href="https://en.wikipedia.org/wiki/Celsius">°C</a>)</td>
<td style="text-align:center">Water absorption increases significantly at 1450 nm. The 1530 to 1560 nm range is the dominant spectral region for long-distance telecommunications.</td>
</tr>
<tr>
<td style="text-align:center">Mid-wavelength infrared</td>
<td style="text-align:center">MWIR, IR-C <em>DIN</em>; MidIR.[<a href="https://en.wikipedia.org/wiki/Infrared#cite_note-rdmag20120908-16">15]</a> Also called intermediate infrared (IIR)</td>
<td style="text-align:center">3–8 μm</td>
<td style="text-align:center">37–100 THz</td>
<td style="text-align:center">155–413 meV</td>
<td style="text-align:center">966–362 <a href="https://en.wikipedia.org/wiki/Kelvin">K</a> (693–89 <a href="https://en.wikipedia.org/wiki/Celsius">°C</a>)</td>
<td style="text-align:center">In guided missile technology the 3–5 μm portion of this band is the atmospheric window in which the homing heads of passive IR ‘heat seeking’ missiles are designed to work, homing on to the <a href="https://en.wikipedia.org/wiki/Infrared_signature">Infrared signature</a> of the target aircraft, typically the jet engine exhaust plume. This region is also known as thermal infrared.</td>
</tr>
<tr>
<td style="text-align:center">Long-wavelength infrared</td>
<td style="text-align:center">LWIR, IR-C <em>DIN</em></td>
<td style="text-align:center">8–15 μm</td>
<td style="text-align:center">20–37 THz</td>
<td style="text-align:center">83–155 meV</td>
<td style="text-align:center">362–193 <a href="https://en.wikipedia.org/wiki/Kelvin">K</a> (89 – −80 <a href="https://en.wikipedia.org/wiki/Celsius">°C</a>)</td>
<td style="text-align:center">The “thermal imaging” region, in which sensors can obtain a completely passive image of objects only slightly higher in temperature than room temperature - for example, the human body - based on thermal emissions only and requiring no illumination such as the sun, moon, or infrared illuminator. This region is also called the “thermal infrared”.</td>
</tr>
<tr>
<td style="text-align:center"><a href="https://en.wikipedia.org/wiki/Far_infrared">Far infrared</a></td>
<td style="text-align:center">FIR</td>
<td style="text-align:center">15–1000 μm</td>
<td style="text-align:center">0.3–20 THz</td>
<td style="text-align:center">1.2–83 meV</td>
<td style="text-align:center">193–3 <a href="https://en.wikipedia.org/wiki/Kelvin">K</a> (−80.15 – −270.15 <a href="https://en.wikipedia.org/wiki/Celsius">°C</a>)</td>
<td style="text-align:center">(see also <a href="https://en.wikipedia.org/wiki/Far-infrared_laser">far-infrared laser</a> and <a href="https://en.wikipedia.org/wiki/Far_infrared">far infrared</a>)</td>
</tr>
</tbody>
</table>
<h2 id="thermal"><a class="markdownIt-Anchor" href="#thermal"></a> Thermal</h2>
<h3 id="dataset"><a class="markdownIt-Anchor" href="#dataset"></a> Dataset</h3>
<ol>
<li>
<p><a href="https://www.flir.com/oem/adas/adas-dataset-form/">FREE FLIR Thermal Dataset for Algorithm Training</a></p>
<p><img data-src="image-20200716161001770.png" alt="image-20200716161001770"></p>
<p><img data-src="image-20200716161013251.png" alt="image-20200716161013251"></p>
</li>
<li>
<p><a href="https://soonminhwang.github.io/rgbt-ped-detection/">KAIST Multispectral Pedestrian Detection Benchmark</a> [2018] <a href="https://www-users.cs.umn.edu/~jsyoon/JaeShin_homepage/kaist_multispectral.pdf">Paper</a></p>
<p>Contain day and night scenarios. Human with bounding box. RGB-Thermal pair.</p>
<p>The KAIST Multispectral Pedestrian Dataset consists of 95k color-thermal pairs (640x480, 20Hz) taken from a vehicle. All the pairs are manually annotated (person, people, cyclist) for the total of 103,128 dense annotations and 1,182 unique pedestrians.</p>
<p><img data-src="teaser.png" alt="teaserImage"></p>
</li>
</ol>
<h2 id="real-multispectral"><a class="markdownIt-Anchor" href="#real-multispectral"></a> Real-Multispectral</h2>
<ol>
<li>
<p><a href="https://sites.google.com/site/hyperspectralcolorimaging/dataset">Hyperspectral Images Database</a> [2017]</p>
<p><strong>Visible Range MSI</strong></p>
<p>NUS hyperspectral images database: 52 Outdoor Scene, 35 Indoor Scene, 33 Individual Fruit Scene, 11 Group Fruit Scene, 13 Real vs Fake Fruit Scene, 44 color Charts &amp; Patches Scene.</p>
</li>
</ol>
<p>It consists of various indoor and outdoor scenes taken with a SPECIM hyperspectral camera and multiple consumer cameras. For consumer cameras, camera-specific RAW format that is free of any manipulation, is available. For easier classification, this hyperspectral camera dataset has been categorized into the following categories:</p>
<ul>
<li><a href="https://sites.google.com/site/hyperspectralcolorimaging/dataset/general-scenes">General Scenes (Outdoor &amp; Indoor)</a></li>
<li><a href="https://sites.google.com/site/hyperspectralcolorimaging/dataset/fruits">Fruits</a></li>
<li><a href="https://sites.google.com/site/hyperspectralcolorimaging/dataset/color-patches">Color Charts and Patches</a></li>
</ul>
<p>Additionally, our spectral data can be visualized using the professional software by <a href="http://scyllarus.research.nicta.com.au/">Scyllarus Matlab/C++ toolbox</a>.</p>
<p>Relevant Code <a href="https://github.com/trangreyle/gene-color-mapping">GitHub</a></p>
  <img data-src="image-20200729094343425.png" alt="image-20200729094343425" style="zoom: 50%;">
  <img data-src="image-20200729094355733.png" alt="image-20200729094355733" style="zoom:50%;">
  <img data-src="image-20200729094407105.png" alt="image-20200729094407105" style="zoom:50%;">
  <img data-src="image-20200729094457881.png" alt="image-20200729094457881" style="zoom:50%;">
<ol start="2">
<li>
<p><a href="https://biic.wvu.edu/data-sets/multispectral-dataset">Multispectral Dataset from west virginia university</a></p>
<ol>
<li>SWIR Biometrics Dataset: <strong>SWIR</strong></li>
<li>WVU Multispectral Face Database: Three types of camera are used: <strong>RGB, Multi(RGB+NIR), SWIR</strong></li>
<li>Multispectral Imaging (Iris) Database:</li>
</ol>
</li>
<li>
<p><a href="https://www.mi.t.u-tokyo.ac.jp/static/projects/mil_multispectral/">Multispectral Image Recognition</a></p>
<ol>
<li>Multi-spectral Object Detection</li>
</ol>
<p><strong>RGB, Near-infrared (NIR), Mid-wavelength infrared (MIR), and Far infrared (FIR)</strong> from the left. Objects are labeled and bounding box predicted.</p>
<p><img data-src="det_result.png" alt="img"></p>
<ol start="2">
<li>Multi-spectral Semantic Segmentation</li>
</ol>
<p>RGB-Thermal dataset with semantic segmentation</p>
<p><img data-src="predictionExamples_good.png" alt="img"></p>
</li>
<li>
<p><a href="https://projects.ics.forth.gr/cvrl/msi/">Multispectral Imaging (MSI) datasets</a>: Painting multispectral images. Not paired. Not ordinary objects.</p>
<p><img data-src="image-20200727175214182.png" alt="image-20200727175214182"></p>
</li>
<li>
<p><a href="https://www.cs.columbia.edu/CAVE/databases/multispectral/">CAVE Multispectral Image Database</a></p>
<p><strong>Visible Range MSI:</strong> <strong>400nm to 700nm</strong></p>
<p>It only has 32 multispectral &amp; RGB image pairs… Be careful to use it. Each image has 31 bands, and they are separated.</p>
<table>
<thead>
<tr>
<th>Camera</th>
<th><a href="http://www.ccd.com/alta_u260.html">Cooled CCD camera (Apogee Alta U260)</a></th>
</tr>
</thead>
<tbody>
<tr>
<td>Resolution</td>
<td>512 x 512 pixel</td>
</tr>
<tr>
<td>Filter</td>
<td><a href="http://www.cri-inc.com/products/varispec.asp">VariSpec liquid crystal tunable filter</a></td>
</tr>
<tr>
<td>Illuminant</td>
<td>CIE Standard Illuminant D65</td>
</tr>
<tr>
<td>Range of wevelength</td>
<td>400nm - 700nm</td>
</tr>
<tr>
<td>Steps</td>
<td>10nm</td>
</tr>
<tr>
<td>Number of band</td>
<td>31 band</td>
</tr>
<tr>
<td>Focal length</td>
<td>f/1.4</td>
</tr>
<tr>
<td>Focus</td>
<td>Fixed (focused using 550nm image)</td>
</tr>
<tr>
<td>Image format</td>
<td>PNG (16bit)</td>
</tr>
</tbody>
</table>
<p><img data-src="teaser-20200727174750119.png" alt="img"></p>
</li>
<li>
<p><a href="http://www.cvc.uab.es/color_calibration/Bristol_Hyper/">Bristol Hyperspectral Images Database</a> [1995]</p>
<p><strong>Visible Range MSI</strong></p>
<p>The database consists of <strong>29 scenes</strong>, each composed by <strong>31 spectrally filtered images</strong> (256 x 256 x 256 grey levels). Each scene has been compressed (zipped) and can be downloaded separately by clicking on the corresponding picture. Please bear in mind that all individual images have a 32 bytes header. To download the whole database at once, just click <a href="http://www.cvc.uab.es/color_calibration/Bristol_Hyper/brelstaff.tar.gz">here</a>.</p>
<p>There is some code and miscellaneous files <a href="http://www.cvc.uab.es/color_calibration/Bristol_Hyper/src/Src.zip">here</a> (these need to be run in order to make use of the images as physical measurements). A more complete description on how the images were gathered and some issues on the camera’s technicalities can be found <a href="http://www.cvc.uab.es/color_calibration/Bristol_Hyper/2-TECH.pdf">here</a>.</p>
<img data-src="image-20200729095320320.png" alt="image-20200729095320320" style="zoom:50%;">
</li>
<li>
<p><a href="http://vision.seas.harvard.edu/hyperspec/">Harvard Real-World Hyperspectral Images</a> [2011]</p>
<p><strong>Visible Range MSI:</strong> <strong>420nm to 720nm</strong></p>
<p>The camera uses an integrated liquid crystal tunable filter and is capable of acquiring a hyperspectral image by sequentially tuning the filter through a series of <strong>31 narrow wavelength bands</strong>, each with approximately 10nm bandwidth and centered at steps of 10nm from <strong>420nm to 720nm</strong>.</p>
<p>The captured dataset includes images of both indoor and outdoor scenes featuring a diversity of objects, materials and scale.</p>
<p>This is a database of <strong>50</strong> hyperspectral images of indoor and outdoor scenes under daylight illumination, and an additional <strong>25</strong> images under artificial and mixed illumination. The images were captured using a commercial hyperspectral camera (Nuance FX, CRI Inc) with an integrated liquid crystal tunable filter capable of acquiring a hyperspectral image by sequentially tuning the filter through a series of thirty-one narrow wavelength bands, each with approximately 10nm bandwidth and centered at steps of 10nm from 420nm to 720nm. The camera is equipped with an apo-chromatic lens and the images were captured with the smallest viable aperture setting, thus largely avoiding chromatic aberration. All the images are of static scenes, with labels to mask out regions with movement during exposure.</p>
<p>This database is available for non-commercial research use. The data is available as a series of MATLAB .mat files (one for each image) containing both the images data and masks. Since the size of the download is large (around 5.5 + 2.2 GB), we ask that you send an e-mail to the authors at <strong>ayanc[at]eecs[dot]harvard[dot]edu</strong> for the download link. If you use this data in an academic publication, kindly cite the following paper:</p>
<img data-src="image-20200729100019504.png" alt="image-20200729100019504" style="zoom:50%;">
</li>
<li>
<p><a href="http://colour.cmp.uea.ac.uk/datasets/multispectral.html">UAE multispectral image database</a></p>
<p><strong>Visible Range MSI:</strong> <strong>400nm to 700nm</strong></p>
<p>Wavelength range from 400nm to 700nm at 10nm steps (31 samples). The image matrix for each object is 31xWIDTHxHEIGHT. The images have been captured in a VeriVide viewing booth with a black cloth background under CIE illuminant D75. Each image has been captured twice: once with a white tile and once without. The illuminant has been estimated from the white tile and the spectral data divided by this estimate, in order to arrive at reflectance measurements. The images below are displayed sRGB values rendered under a neutral daylight (D65).</p>
<img data-src="image-20200729100842353.png" alt="image-20200729100842353" style="zoom:33%;">
</li>
<li>
<p><a href="http://personalpages.manchester.ac.uk/staff/david.foster/default.html">Manchester hyperspectral images Dataset<strong>s</strong></a></p>
<p><strong>Visible Range MSI:</strong>  400, 410, …, 720 nm</p>
<p>Multiple MSI datasets included:</p>
<img data-src="image-20200729101027937.png" alt="image-20200729101027937" style="zoom:50%;">
<ul>
<li>
<p><a href="https://personalpages.manchester.ac.uk/staff/david.foster/Time-Lapse_HSIs/Time-Lapse_HSIs_2015.html">Time-Lapse Hyperspectral Radiance Images of Natural Scenes 2015</a></p>
<img data-src="image-20200729101135099.png" alt="image-20200729101135099" style="zoom:33%;">
</li>
<li>
<p><a href="https://personalpages.manchester.ac.uk/staff/david.foster/Local_Illumination_HSIs/Local_Illumination_HSIs_2015.html">Hyperspectral Images for Local Illumination in Natural Scenes 2015</a></p>
<img data-src="image-20200729101232518.png" alt="image-20200729101232518" style="zoom:50%;">
</li>
<li>
<p><a href="https://personalpages.manchester.ac.uk/staff/david.foster/Hyperspectral_images_of_natural_scenes_02.html">Hyperspectral Images of Natural Scenes 2002</a></p>
<img data-src="image-20200729101343922.png" alt="image-20200729101343922" style="zoom:50%;">
</li>
<li>
<p><a href="https://personalpages.manchester.ac.uk/staff/david.foster/Hyperspectral_images_of_natural_scenes_04.html">Hyperspectral Images of Natural Scenes 2004</a></p>
<img data-src="image-20200729101441578.png" alt="image-20200729101441578" style="zoom:50%;">
</li>
</ul>
</li>
<li>
<p><a href="https://pythonhosted.org/bob.db.cbsr_nir_vis_2/">BOB NIR+VIS Face Database</a> [2013]</p>
<p>It consists of 725 subjects in total. There are [1-22] VIS and [5-50] NIR face images per subject. The eyes positions are also distributed with the images.</p>
<img data-src="database.png" alt="_images/database.png" style="zoom:33%;">
</li>
<li>
<p><a href="http://icvl.cs.bgu.ac.il/hyperspectral/">ICVL hyperspectral database</a></p>
</li>
</ol>
<p><strong>RGB+NIR Range MSI:</strong>  Images were collected at 1392×1300 spatial resolution over 519 spectral bands (<strong>400-1,000nm</strong> at roughly 1.25nm increments)</p>
<p>The database images were acquired using a Specim PS Kappa DX4 hyperspectral camera and a rotary stage for spatial scanning. At this time it contains 201 images and will continue to grow progressively. For your convenience, <strong>.mat</strong> files are provided, downsampled to 31 spectral channels from 400nm to 700nm at 10nm increments.</p>
   <img data-src="image-20200729102126434.png" alt="image-20200729102126434" style="zoom:50%;">
<ol start="11">
<li>
<p><a href="http://colorimaginglab.ugr.es/pages/Data">University of Granada hyperspectral image database</a></p>
<p><strong>RGB+NIR Range MSI:</strong> Most of the images have spatial resolution of 1000 × 900 pixels. The spectral range is from <strong>400 nm to 1000</strong> nm in 10 nm intervals, resulting in total 61 channels.</p>
<img data-src="image-20200729102332515.png" alt="image-20200729102332515" style="zoom:50%;">
</li>
<li>
<p><a href="http://www.cs.cmu.edu/~ILIM/projects/IM/MSPowder/">SWIRPowder</a>: A 400-1700nm Multispectral Dataset with 100 Powders on Complex Backgrounds</p>
<p><strong>SWIR(Multi)+RGB+NIR</strong></p>
<p><img data-src="result.png" alt="img"></p>
<p><img data-src="illustration_1.png" alt="img"></p>
</li>
<li>
<p><a href="http://www.ok.sc.e.titech.ac.jp/res/MSI/MSIdata31.html">TokyoTech 31-band Hyperspectral Image Dataset</a> [2015]</p>
<p><strong>Visible Range MSI:</strong> <strong>420nm to 720nm</strong></p>
<p>Colorful objects with rich textures 30 scenes from 420nm to 720nm at 10nm intervals</p>
<p><img data-src="MSimage.png" alt="MSimage"></p>
<p><img data-src="image-20200729094232057.png" alt="image-20200729094232057"></p>
</li>
</ol>
<h2 id="reference"><a class="markdownIt-Anchor" href="#reference"></a> Reference</h2>
<ul>
<li><a href="https://jbthomas.org/TechReport/CIC-shortcourseSFA-2017.pdf">Spectral Filter Arrays Technology</a></li>
<li><a href="https://en.wikipedia.org/wiki/Infrared">Infrared WiKi</a></li>
</ul>
<h2 id="electromagnetic-wave-classification"><a class="markdownIt-Anchor" href="#electromagnetic-wave-classification"></a> Electromagnetic Wave Classification</h2>
<p>γ = <a href="https://zh.wikipedia.org/wiki/%E4%BC%BD%E9%A6%AC%E5%B0%84%E7%B7%9A">伽马射线</a><br>
<strong><a href="https://zh.wikipedia.org/wiki/X%E5%B0%84%E7%B7%9A">X射线</a>：</strong><br>
HX = 硬<a href="https://zh.wikipedia.org/wiki/X%E5%B0%84%E7%B7%9A">X射线</a><br>
SX = 软X射线<br>
<strong><a href="https://zh.wikipedia.org/wiki/%E7%B4%AB%E5%A4%96%E7%B7%9A">紫外线</a>：</strong><br>
EUV = 极端<a href="https://zh.wikipedia.org/wiki/%E7%B4%AB%E5%A4%96%E7%B7%9A">紫外线</a><br>
NUV = 近紫外线<br>
<strong><a href="https://zh.wikipedia.org/wiki/%E7%B4%85%E5%A4%96%E7%B7%9A">红外线</a>：</strong><br>
NIR = 近<a href="https://zh.wikipedia.org/wiki/%E7%B4%85%E5%A4%96%E7%B7%9A">红外线</a><br>
MIR =中红外线<br>
FIR = <a href="https://zh.wikipedia.org/wiki/%E9%81%A0%E7%B4%85%E5%A4%96%E7%B7%9A">远红外线</a></p>
<p>Typically we define near infrared (<em>NIR</em>) from 780 nm to 1400 nm and shortwave infrared (<em>SWIR</em>) from 1400 nm to 3000 nm.</p>
<p><strong><a href="https://zh.wikipedia.org/wiki/%E5%BE%AE%E6%B3%A2">微波</a>：</strong><br>
EHF = <a href="https://zh.wikipedia.org/wiki/%E6%A5%B5%E9%AB%98%E9%A0%BB">极高频</a><br>
SHF = <a href="https://zh.wikipedia.org/wiki/%E8%B6%85%E9%AB%98%E9%A0%BB">超高频</a><br>
UHF = <a href="https://zh.wikipedia.org/wiki/%E7%89%B9%E9%AB%98%E9%A0%BB">特高频</a><br>
<strong><a href="https://zh.wikipedia.org/wiki/%E7%84%A1%E7%B7%9A%E9%9B%BB%E6%B3%A2">无线电波</a>：</strong><br>
VHF = <a href="https://zh.wikipedia.org/wiki/%E7%94%9A%E9%AB%98%E9%A0%BB">甚高频</a><br>
HF = <a href="https://zh.wikipedia.org/wiki/%E9%AB%98%E9%A0%BB">高频</a><br>
MF = <a href="https://zh.wikipedia.org/wiki/%E4%B8%AD%E9%A0%BB">中频</a><br>
LF = <a href="https://zh.wikipedia.org/wiki/%E4%BD%8E%E9%A0%BB">低频</a><br>
VLF = <a href="https://zh.wikipedia.org/wiki/%E7%94%9A%E4%BD%8E%E9%A2%91">甚低频</a><br>
ULF = <a href="https://zh.wikipedia.org/wiki/%E7%89%B9%E4%BD%8E%E9%A0%BB">特低频</a><br>
ELF = <a href="https://zh.wikipedia.org/wiki/%E6%A5%B5%E4%BD%8E%E9%A0%BB">极低频</a></p>
]]></content>
      <tags>
        <tag>hsi</tag>
        <tag>data</tag>
        <tag>camera</tag>
        <tag>optics</tag>
      </tags>
  </entry>
  <entry>
    <title>日系人体绘画总结</title>
    <url>/2020/08/21/illustration-human-body/</url>
    <content><![CDATA[<h2 id="日系画风与现实的区别"><a class="markdownIt-Anchor" href="#日系画风与现实的区别"></a> 日系画风与现实的区别</h2>
<ul>
<li>真实的“<strong>三庭五眼</strong>”：
<ul>
<li>三庭：<strong>d(发际线, 眉骨) = d(眉骨, 鼻底) = d(鼻底, 下巴)</strong></li>
<li>五眼：<strong>眼宽=眼间距=眼睛到面部轮廓的距离</strong></li>
</ul>
</li>
<li>眼睛的长度相对真实比例更长的，并不符合三庭五眼中的五眼比例。而是眼睛宽度和眼间距大体相同且较长，而眼睛两边到脸部轮廓的距离更短。</li>
</ul>
<img data-src="Screenshot%2520-%25202020-06-12%252022.46.34.png" alt="Screenshot - 2020-06-12 22.46.34" style="zoom:50%;">
<span id="more"></span>
<h2 id="日系男生与女生刻画的特点与区别"><a class="markdownIt-Anchor" href="#日系男生与女生刻画的特点与区别"></a> 日系男生与女生刻画的特点与区别</h2>
<h3 id="女生"><a class="markdownIt-Anchor" href="#女生"></a> 女生</h3>
<ul>
<li>头部的高宽比偏小，脸部偏短。</li>
<li>面部相对较圆，使用更多的曲线。</li>
<li>五官相对下移，留出更高的额头放刘海。</li>
<li>眼睛是刻画的重点，它很大。</li>
<li>眼型偏圆的居多。</li>
<li>弱化鼻子、嘴巴、<strong>眉毛</strong>等的刻画。</li>
<li>眉毛和眼睛间距较大。</li>
<li>表情方面更多的表现出萌、可爱、甜美，总体偏美型。</li>
</ul>
<h3 id="男生"><a class="markdownIt-Anchor" href="#男生"></a> 男生</h3>
<ul>
<li>头部的高宽比更大，脸部较长，或是更偏向真实比例。</li>
<li>面部外轮廓使用更多的直线、锐利的线条。</li>
<li>脸型更方正/直。</li>
<li>眼睛相对女生来说较小，或说较细，高度较低，但长度还是相对真实比例更长的，并不符合三庭五眼中的五眼比例，而是眼睛宽度和眼间距大体相同且较长，而眼睛两边到脸部轮廓的距离更短。</li>
<li>眼型偏平行四边形的居多。</li>
<li>同样眉毛也被着重刻画，意在表现男生的英气、帅气等。</li>
<li>眉毛和眼睛间距小。</li>
<li>弱化鼻子和嘴巴的刻画，但又比女生强一点，女生往往可以归结为一个点，而男生还是要刻画的。中老年男人鼻子甚至非常明显。</li>
<li>表情方面更偏向于酷、帅、冷、不耐烦的感觉。</li>
</ul>
<h2 id="日系年龄对面部画法的影响"><a class="markdownIt-Anchor" href="#日系年龄对面部画法的影响"></a> 日系年龄对面部画法的影响</h2>
<h3 id="男生-2"><a class="markdownIt-Anchor" href="#男生-2"></a> 男生</h3>
<ul>
<li>年轻人的用线会相对圆润，越年长线条越锋利。</li>
<li>年长者的面部转折点会更向上部靠拢，五官也相对向上。</li>
<li>年长者的眼睛更窄，同样是更加锐利的感觉；而年轻人可以稍微眼睛大一点，高一点，圆一点。</li>
<li>年长者的眉毛会更尖锐有力。</li>
<li>年长者的下巴会更宽一些。</li>
</ul>
<img data-src="image-20200613182651960.png" alt="image-20200613182651960" style="zoom:50%;">
<h3 id="女生-2"><a class="markdownIt-Anchor" href="#女生-2"></a> 女生</h3>
<ul>
<li>同样，年长者最重要的是脸部转折点上移。</li>
<li>年长者五官上移。</li>
<li>年长者眼睛变窄。</li>
<li>曲线更加有力。</li>
</ul>
<img data-src="image-20200613184807549.png" alt="image-20200613184807549" style="zoom:50%;">
<h3 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h3>
<ul>
<li>在年龄变化的刻画上，更加着重地去刻画性别的特点，卡点和转折更重。</li>
</ul>
<img data-src="image-20200613185226577.png" alt="image-20200613185226577" style="zoom:50%;">
<ul>
<li>角色设定是一个把文字设定转为标签化的预设人体特征的过程。比如不同的眼型、不同的睫毛表现、不同的眉毛表现、不同的面部外轮廓等。</li>
</ul>
<h2 id="眉眼结构"><a class="markdownIt-Anchor" href="#眉眼结构"></a> 眉眼结构</h2>
 <img data-src="image-20200614093652461.png" alt="image-20200614093652461" style="zoom:50%;">
<ul>
<li>男生眉毛粗，离眼睛近。画的时候要压低、往下放。</li>
<li>女生眉毛细，离眼睛远。画的时候要提高、往上走。女生眉毛很多时候更像是一条线。</li>
<li>眉眼的侧视图大致是正视图宽度的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.190108em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>。</li>
</ul>
<img data-src="image-20200614094501368.png" alt="image-20200614094501368" style="zoom:50%;">
<h2 id="口鼻的画法"><a class="markdownIt-Anchor" href="#口鼻的画法"></a> 口鼻的画法</h2>
<ul>
<li>嘴角处要卡点（加重），无论嘴多么小，改卡点的都要卡。嘴的中间要相对画的较虚，若隐若现感觉。</li>
<li>与真实的人不同，日系画法中往往不刻画上嘴唇，但有时还是会把下嘴唇用一根线带过。</li>
<li>张开的嘴最好画出牙齿和舌头。</li>
<li>微笑最好画出左右斜向下箭头的形状。同理，微微噘嘴要画出左右斜向上箭头的形状。</li>
<li>侧面张开的嘴是梯形的。</li>
<li>鼻尖也需要卡点。</li>
<li>男性的鼻子长，嘴巴宽；女性的鼻子小、短，嘴巴窄。</li>
<li>虽然女生鼻子很多都是一个点，但这个点是有方向和轻重的。方向是面部朝向，而轻重则是点的起笔重（上方），落笔轻（下方）。</li>
</ul>
<h3 id="男性口鼻示例"><a class="markdownIt-Anchor" href="#男性口鼻示例"></a> 男性口鼻示例</h3>
<img data-src="image-20200614150816122.png" alt="image-20200614150816122" style="zoom:50%;">
<h3 id="女性口鼻示例"><a class="markdownIt-Anchor" href="#女性口鼻示例"></a> 女性口鼻示例</h3>
<img data-src="image-20200614150929840.png" alt="image-20200614150929840" style="zoom:50%;">
<h2 id="面部示例"><a class="markdownIt-Anchor" href="#面部示例"></a> 面部示例</h2>
<h3 id="女生-3"><a class="markdownIt-Anchor" href="#女生-3"></a> 女生</h3>
<img data-src="image-20200614204900408.png" alt="image-20200614204900408" style="zoom:50%;">
<h3 id="男生-3"><a class="markdownIt-Anchor" href="#男生-3"></a> 男生</h3>
<img data-src="image-20200615124628061.png" alt="image-20200615124628061" style="zoom:50%;">
<h2 id="整体注意事项"><a class="markdownIt-Anchor" href="#整体注意事项"></a> 整体注意事项</h2>
<ol>
<li>绘制步骤：找参考-&gt;打型-&gt;细化-&gt;调整</li>
<li>画的过程中要不断重复一下几个检查：
<ul>
<li>头部的角度</li>
<li>角色性格相对应的五官形状</li>
<li>不断放大缩小去看位置和透视</li>
</ul>
</li>
</ol>
<h2 id="头发的绘制"><a class="markdownIt-Anchor" href="#头发的绘制"></a> 头发的绘制</h2>
<ol>
<li>
<p>绘制的顺序：</p>
<ol>
<li>观察参考</li>
<li>确定发心（刘海中心点）或发中线位置</li>
<li>分块画草图</li>
<li>细化</li>
</ol>
</li>
<li>
<p>头发多样性的体现：</p>
<ol>
<li>粗细变换</li>
<li>不能过于对称（粗细、位置高低、头发的根数）</li>
<li>头发的方向（发旋、贴头弯曲、呆毛和不规则发）</li>
<li>动态变化</li>
</ol>
<img data-src="Screenshot%2520-%25202020-07-08%252023.03.30.png" alt="Screenshot - 2020-07-08 23.03.30" style="zoom:50%;">
</li>
<li>
<p>头发的最大分块可分为：前发（刘海）、中发（一般到脸或肩的侧面头发）和后发。前中都可以没有，但后发一定有。</p>
</li>
<li>
<p>各种发型可以看做各种前中后发的组合。</p>
</li>
<li>
<p>后发不能紧贴头皮，要预留一定距离、体现蓬松感。</p>
</li>
<li>
<p>好的发型的绘制其剪影也是很好看的。</p>
</li>
<li>
<p>注意发梢在脖子周围行程一个圆，而不是直线。这点在短发情况下尤其明显。</p>
</li>
<li>
<p>颈部后面会有短小的头发。</p>
<img data-src="image-20200709105324243.png" alt="image-20200709105324243" style="zoom:33%;">
</li>
<li>
<p>发梢是头发的灵魂。不同种类的头发其发梢差距由其之大，比如直线型、尖锐型、折叠型等。</p>
</li>
<li>
<p>发梢部分，尤其是后发，尽量往里收，除非发型就是翘的。</p>
<img data-src="image-20200709095740444.png" alt="image-20200709095740444" style="zoom:50%;">
</li>
<li>
<p>长卷发会偏向成熟魅力的气质、长直发偏向冷酷高贵、短直发更多偏向清纯感和学生感、短卷发偏可爱活力。</p>
</li>
<li>
<p>卷发的基础是一撮头发，每一撮头发的基础是S型线，分清楚里外。先画大的S，最后画装饰线。</p>
<img data-src="image-20200709102107872.png" alt="image-20200709102107872" style="zoom:50%;">
</li>
<li>
<p>画长发，尤其是长卷发，最重要的是即使线条乱，也不能被线条带节奏，要搞清楚每一片头发的从属关系。</p>
<img data-src="image-20200709102245876.png" alt="image-20200709102245876" style="zoom:33%;">
</li>
</ol>
<h3 id="辫子"><a class="markdownIt-Anchor" href="#辫子"></a> 辫子</h3>
<ol>
<li>
<p>绘制辫子的时候要尤其注意线条的虚实，营造穿插感。加细节的时候一定要注意碎发也要顺着辫子的大体走势绘制。</p>
<img data-src="image-20200709104609283.png" alt="image-20200709104609283" style="zoom:50%;">
</li>
<li>
<p>马尾辫：年龄越大、马尾越低。马尾朝向斜向上的辫子要先上升后下降。</p>
</li>
<li>
<p>相较于披散发，辫子的翻转更多。</p>
</li>
<li>
<p>辫子中，总会有一些短的、碎的头发丝无法被扎到辫子主流中，他们构成了有效的细节。</p>
<p><img data-src="image-20200709105414092.png" alt="image-20200709105414092"></p>
</li>
</ol>
<h3 id="男性头发"><a class="markdownIt-Anchor" href="#男性头发"></a> 男性头发</h3>
<ol>
<li>
<p>男性头发如果是向外翘，显得有攻气；向内卷，显得温柔和受气。</p>
<img data-src="image-20200709121121242.png" alt="image-20200709121121242" style="zoom:50%;">
</li>
<li>
<p>长发的男性角色，可以直接参照女性头发画法。</p>
</li>
</ol>
<h3 id="发型设计"><a class="markdownIt-Anchor" href="#发型设计"></a> 发型设计</h3>
<ol>
<li>
<p>设计流程：</p>
<ol>
<li>分块</li>
<li>分组（使用不同的元素）</li>
<li>组合设计</li>
<li>不同的发型出来上がり～</li>
</ol>
<img data-src="image-20200709113650623.png" alt="image-20200709113650623" style="zoom:50%;">
</li>
</ol>
<h2 id="发饰与其他装饰道具的绘制"><a class="markdownIt-Anchor" href="#发饰与其他装饰道具的绘制"></a> 发饰与其他装饰道具的绘制</h2>
<h3 id="蝴蝶结和蝴蝶结类似物分类"><a class="markdownIt-Anchor" href="#蝴蝶结和蝴蝶结类似物分类"></a> 蝴蝶结和蝴蝶结类似物分类</h3>
<ol>
<li>固定形状的，即卖的时候就是打好的那种蝴蝶结。实心、较大，常用作头饰和领结。</li>
<li>手打的空心蝴蝶结。同样较大，除了头饰和领结，还可以用作围裙后面等。</li>
<li>飘带。由一根细长扁平的带子打出来的蝴蝶结。易随风飘动，且由于体积较小，需仔细控制。</li>
<li>小型点缀式的蝴蝶结。用作小型装饰物，出现在头上（发卡）、衣服上、口袋上等等。</li>
<li>以上的组合和变形。</li>
</ol>
<img data-src="image-20200719014529861.png" alt="image-20200719014529861" style="zoom: 60%;">
<img data-src="image-20200719014444973.png" alt="image-20200719014444973" style="zoom:50%;">
<img data-src="image-20200719014416132.png" alt="image-20200719014416132" style="zoom:50%;">
<img data-src="image-20200719014348797.png" alt="image-20200719014348797" style="zoom:50%;">
<img data-src="image-20200719014322885.png" alt="image-20200719014322885" style="zoom:68%;">
<h3 id="发库"><a class="markdownIt-Anchor" href="#发库"></a> 发库：</h3>
<ol>
<li>注意不能沿着头部轮廓画。</li>
<li>应该先找出来面部竖直轮廓线，然后保证发库与它垂直。</li>
<li>尤其注意透视现象，发库的末端结束于耳朵后面。</li>
</ol>
<p><img data-src="image-20200719103005141.png" alt="image-20200719103005141"></p>
<h3 id="帽子"><a class="markdownIt-Anchor" href="#帽子"></a> 帽子</h3>
<ol>
<li>
<p>偏头顶（正）：棒球帽、礼帽、田园风</p>
</li>
<li>
<p>后脑勺：贝雷帽、太阳帽</p>
</li>
<li>
<p>棒球帽的画法：</p>
<ul>
<li>帽子的中线与头部中线平齐</li>
<li>注意帽子的外形</li>
<li>适当的给帽檐增加厚度</li>
</ul>
<img data-src="image-20200719104600298.png" alt="image-20200719104600298" style="zoom:33%;">
</li>
<li>
<p>太阳帽的画法：</p>
<ul>
<li>位置偏脑后</li>
<li>*帽檐的形状</li>
<li>适当的装饰：缎带、蝴蝶结、鲜花等</li>
<li>画的时候即使后面的帽檐部分被脑袋遮挡，还是要先画出来、确保左右是连着的线。</li>
</ul>
</li>
</ol>
<h3 id="眼镜"><a class="markdownIt-Anchor" href="#眼镜"></a> 眼镜</h3>
<ol>
<li>
<p>可爱风：镜框偏大、偏圆、可以抹除上眼镜框。这样的好处是可以避免眼镜挡住眼睛。</p>
<p><img data-src="image-20200719110203120.png" alt="image-20200719110203120"></p>
</li>
<li>
<p>成熟风：眼型本来就偏小，眼镜也就偏窄。</p>
<p><img data-src="image-20200719110140108.png" alt="image-20200719110140108"></p>
</li>
<li>
<p>性感风：无镜框、偏窄。</p>
<p><img data-src="image-20200719110242408.png" alt="image-20200719110242408"></p>
</li>
<li>
<p>搞事派：镜片反光。。。如柯南开始推理、坂本大佬等。</p>
<p><img data-src="image-20200719110419553.png" alt="image-20200719110419553"></p>
</li>
<li>
<p>画法要点：</p>
<ul>
<li>两个关键支点：鼻梁、耳朵</li>
<li>眼镜中线呈直线型：镜片透视保持一致</li>
<li>在画眼睛之前先画出来一个能包裹住两个镜片的矩形外框</li>
</ul>
</li>
</ol>
<h2 id="表情"><a class="markdownIt-Anchor" href="#表情"></a> 表情</h2>
<h3 id="分类"><a class="markdownIt-Anchor" href="#分类"></a> 分类</h3>
<ol>
<li>
<p>微笑（尴尬而不失礼貌的）</p>
<img data-src="image-20200724113228668.png" alt="image-20200724113228668" style="zoom:50%;">
<ol>
<li>口型就外八字点两点就好，注意卡点</li>
</ol>
</li>
<li>
<p>开口笑</p>
<img data-src="image-20200724113253860.png" alt="image-20200724113253860" style="zoom:50%;">
<ol>
<li>开口是梯形类似物</li>
<li>开口的大小要多尝试，因为不同人物适合的大小并不相同</li>
</ol>
</li>
<li>
<p>狂笑</p>
<img data-src="image-20200724113443615.png" alt="image-20200724113443615" style="zoom:50%;">
</li>
<li>
<p>闭眼笑</p>
<ol>
<li>眼睛即使闭上了也不是一条单调的线，而是有形状有细节的</li>
<li>那条线在之前上下眼睑中间</li>
</ol>
</li>
<li>
<p>怒（攻气、傲慢、盛气凌人）</p>
<img data-src="image-20200724113521388.png" alt="image-20200724113521388" style="zoom:50%;">
<ol>
<li>眼角上扬</li>
<li>眉毛外八字，也是上扬</li>
<li>嘴中间向上弯曲（即曲线向上凸）</li>
</ol>
</li>
<li>
<p>哀（受气、可怜）</p>
<img data-src="image-20200724113548199.png" alt="image-20200724113548199" style="zoom:50%;">
<ol>
<li>眼角向下撇</li>
<li>眉毛正八字</li>
<li>嘴会很小</li>
</ol>
</li>
<li>
<p>三无少女</p>
<img data-src="image-20200724113639102.png" alt="image-20200724113639102" style="zoom:50%;">
<ol>
<li>无口无心无表情</li>
<li>嘴部很小很小，一般就是一个点</li>
<li>由于本来角色就不怎么有表情，所以眼睛和眉毛移一直都是放松状态</li>
</ol>
</li>
<li>
<p>邪魅一笑（色气）</p>
<img data-src="image-20200724111805983.png" alt="image-20200724111805983" style="zoom:42%;">
<ol>
<li>面部红晕</li>
<li>特制笑容</li>
</ol>
</li>
<li>
<p>微微哭泣</p>
<img data-src="image-20200724112336854.png" alt="image-20200724112336854" style="zoom:33%;">
<ol>
<li>委屈+抿嘴</li>
<li>少量眼角泪花</li>
<li>面颊红晕</li>
</ol>
</li>
<li>
<p>大哭</p>
<img data-src="image-20200724110336117.png" alt="image-20200724110336117" style="zoom:33%;">
<ol>
<li>委屈加强版，眉毛继续八字</li>
<li>眼睛高度减小，下眼睑向上挤压</li>
<li>有眼泪元素</li>
<li>嘴张开，露牙齿</li>
<li>面颊红晕</li>
</ol>
</li>
<li>
<p>害羞</p>
<ol>
<li>大片的面部红晕，可以覆盖眼睛下面一长条包括鼻子位置</li>
</ol>
</li>
<li>
<p>傲娇</p>
<img data-src="image-20200724112224823.png" alt="image-20200724112224823" style="zoom:33%;">
<ol>
<li>害羞+怒</li>
<li>可以用微汗点缀</li>
<li>小虎牙</li>
</ol>
</li>
<li>
<p>病娇（诡异）</p>
<img data-src="image-20200724110015171.png" alt="image-20200724110015171" style="zoom:33%;">
<ol>
<li>眼球和上眼睑不是连着的，之间隔着一点眼白</li>
<li>嘴部有不对称元素</li>
<li>视角可偏仰视</li>
</ol>
</li>
</ol>
<h3 id="复杂表情构成"><a class="markdownIt-Anchor" href="#复杂表情构成"></a> 复杂表情构成</h3>
<ol>
<li>基础表情（不同程度的笑、哭、哀）</li>
<li>不同角度、身体转向（比如表现委屈、惹人怜爱、哭泣可以采用俯视，而表现惊悚和恶役则可使用仰视，元气可爱灵动可用各种侧视图等）</li>
<li>肢体动作（如手部动作）</li>
</ol>
<h3 id="漫画与插画的区别"><a class="markdownIt-Anchor" href="#漫画与插画的区别"></a> 漫画与插画的区别</h3>
<ul>
<li>相较于漫画，插画更偏向于整体人物的唯美性，表情一般不会很夸张，笑脸会占据大半。</li>
<li>漫画则相对束缚较小，可以画各种各样奇奇怪怪的夸张表情来凸显人物心情和推动剧情。</li>
</ul>
<img data-src="image-20200724120144027.png" alt="image-20200724120144027" style="zoom:50%;">
<h2 id="衣物的画法"><a class="markdownIt-Anchor" href="#衣物的画法"></a> 衣物的画法</h2>
<h3 id="衣服的分类"><a class="markdownIt-Anchor" href="#衣服的分类"></a> 衣服的分类</h3>
<p><strong>女生：</strong> 制服（JK）、女仆装、泳装、和风服饰（和服、浴衣）、LOLITA、idol（舞台装）</p>
<p><strong>男生：</strong> 衬衫、西服、卫衣、T恤</p>
<h3 id="画法要点"><a class="markdownIt-Anchor" href="#画法要点"></a> 画法要点</h3>
<ol>
<li>注意与人物形体的关系，不要直接画衣服</li>
<li>受力情况</li>
<li>搭配、元素组合</li>
<li>设计（饰品）</li>
<li>参与构图</li>
</ol>
<h3 id="衣褶"><a class="markdownIt-Anchor" href="#衣褶"></a> 衣褶</h3>
<h4 id="衣褶的成因"><a class="markdownIt-Anchor" href="#衣褶的成因"></a> 衣褶的成因</h4>
<ul>
<li>衣褶是受支撑点和地心引力的拉力影响而形成的褶皱。</li>
<li>如果没有内部结构就没有布纹衣褶的存在。</li>
<li>拉伸的力抹平衣褶，收缩的力形成衣褶。</li>
</ul>
<img data-src="image-20200726104737094.png" alt="image-20200726104737094" style="zoom:33%;">
<h4 id="衣褶多的地方"><a class="markdownIt-Anchor" href="#衣褶多的地方"></a> 衣褶多的地方</h4>
<ul>
<li>和内部支撑物之间空间较大的地方（宽松领口、古人衣服、宽松袖子、卫衣腰部）（相反：紧身衣、内衣、丝袜）</li>
<li>受到收缩外力明显的地方（腰带处、袖口、撸起来的袖子、关节内缩侧）（相反：关节绷紧侧）</li>
</ul>
<img data-src="Screenshot%2520-%25202020-07-26%252010.48.59.png" alt="Screenshot - 2020-07-26 10.48.59" style="zoom:50%;">
<ul>
<li>
<p>人体中衣褶多的位置列举：</p>
<ul>
<li>领口</li>
<li>腋下</li>
<li>弯曲的胳膊腿的内侧</li>
<li>腰部</li>
<li>裆部（裤褶、裙褶）</li>
<li>裤脚</li>
<li>其他所有的有转折的地方</li>
<li>妹子胸部下部</li>
<li>腰带、绳带处</li>
<li>扣子处</li>
</ul>
<img data-src="image-20200726110314572.png" alt="image-20200726110314572" style="zoom:33%;">
</li>
</ul>
<h3 id="褶皱理论"><a class="markdownIt-Anchor" href="#褶皱理论"></a> 褶皱理论</h3>
<h4 id="一点支撑"><a class="markdownIt-Anchor" href="#一点支撑"></a> 一点支撑</h4>
<p>褶皱形状：放射状</p>
<p><img data-src="image-20200726111529235.png" alt="image-20200726111529235"></p>
<h5 id="常见位置"><a class="markdownIt-Anchor" href="#常见位置"></a> 常见位置</h5>
<ul>
<li>肩部</li>
<li>胸部中下侧</li>
<li>绳带</li>
<li>膝盖</li>
<li>手肘</li>
</ul>
<h4 id="两点支撑"><a class="markdownIt-Anchor" href="#两点支撑"></a> 两点支撑</h4>
<p>两点支撑可以看做两个一点支撑去掉内侧的线然后连起来。</p>
<img data-src="image-20200726112319409.png" alt="image-20200726112319409" style="zoom:40%;">
<h5 id="常见位置-2"><a class="markdownIt-Anchor" href="#常见位置-2"></a> 常见位置：</h5>
<ul>
<li>领口</li>
<li>腰部（胯）</li>
<li>宽松的XX（袖子、裤子、腰）</li>
</ul>
<img data-src="image-20200726112701126.png" alt="image-20200726112701126" style="zoom:33%;">
<img data-src="image-20200726112803185.png" alt="image-20200726112803185" style="zoom:33%;">
<h3 id="褶皱画法"><a class="markdownIt-Anchor" href="#褶皱画法"></a> 褶皱画法</h3>
<h4 id="穿插"><a class="markdownIt-Anchor" href="#穿插"></a> 穿插</h4>
<p>简单的说，穿插就是A插到了B里面。由于褶皱弯曲，有时候会鼓起来突出一块，其效果就是下游的布料插进了上游的布料所形成的褶子里面。</p>
<img data-src="image-20200726120758174.png" alt="image-20200726120758174" style="zoom:50%;">
<img data-src="image-20200726120727471.png" alt="image-20200726120727471" style="zoom:50%;">
<p>由于视角的不同，让穿插呈现出2中绘制结构。</p>
<p>运用范围：衣袖、腰部、手肘（弯曲）、腿部（弯曲）。。。</p>
<h4 id="堆叠"><a class="markdownIt-Anchor" href="#堆叠"></a> 堆叠</h4>
<p>堆叠，即把过长的部分堆起来。其形如阶梯，但各阶形异。论其走线，莫有完全平行者，目之所及，皆为交错向下；间有内陷，若小水洼。</p>
<img data-src="image-20200726141313049.png" alt="image-20200726141313049" style="zoom:50%;">
<h4 id="裁缝线"><a class="markdownIt-Anchor" href="#裁缝线"></a> 裁缝线</h4>
<ul>
<li>
<p>作用：分摊拉力。假设如果没有裁缝线时只有几个大的衣褶纹路，此时加上一根裁缝线，则在原来的褶皱纹路基础上会出现许多细小的褶子，此即为所谓“分摊拉力”。</p>
<img data-src="image-20200730133455227.png" alt="image-20200730133455227" style="zoom:33%;">
</li>
</ul>
<h4 id="雷区"><a class="markdownIt-Anchor" href="#雷区"></a> 雷区</h4>
<ol>
<li>褶皱太少，状似铁皮（布的质感）</li>
<li>衣褶过多，如着破布（不美观）</li>
<li>衣褶位置不对</li>
<li>线条太实或太虚</li>
</ol>
<h4 id="服装的质感软与硬"><a class="markdownIt-Anchor" href="#服装的质感软与硬"></a> 服装的质感：软与硬</h4>
<ul>
<li>软的衣服（如水手服、T恤）：
<ul>
<li>褶皱相对偏多</li>
<li>褶皱规律性弱</li>
<li>褶皱线条柔软</li>
<li>布纹偏多</li>
</ul>
</li>
<li>硬的衣服（如西服、制服）：
<ul>
<li>褶皱相对较少</li>
<li>褶皱规律相对较强</li>
<li>褶皱线条偏硬</li>
<li>布纹偏少</li>
</ul>
</li>
<li>实际区分方法：线条</li>
</ul>
<h3 id="衣物绘制注意事项"><a class="markdownIt-Anchor" href="#衣物绘制注意事项"></a> 衣物绘制注意事项</h3>
<h4 id="厚度"><a class="markdownIt-Anchor" href="#厚度"></a> 厚度</h4>
<p>布是有厚度的，我们画布的时候要注意在垂下的边角处线与线的交汇处不要接死，留出一定的空隙以体现布料的厚度。</p>
<img data-src="image-20200730134510170.png" alt="image-20200730134510170" style="zoom:33%;">
<h4 id="虚实"><a class="markdownIt-Anchor" href="#虚实"></a> 虚实</h4>
<p>我们在画衣褶的时候要注意线的虚实变化。交代清楚线的虚实，衣纹会更有活力，更生动。</p>
<p>外粗里细，主要褶皱粗、次要衣纹细。</p>
<h4 id="大小对比"><a class="markdownIt-Anchor" href="#大小对比"></a> 大小对比</h4>
<p>我们画衣纹的时候也要注意有大小对比，不要把每一个纹路画的一样大，这样会显得呆板无趣。</p>
<img data-src="image-20200730135011004.png" alt="image-20200730135011004" style="zoom:33%;">
<h3 id="jk制服的画法"><a class="markdownIt-Anchor" href="#jk制服的画法"></a> JK制服的画法</h3>
<h4 id="分类-2"><a class="markdownIt-Anchor" href="#分类-2"></a> 分类</h4>
<p><strong>上衣</strong>：水手服、衬衫+（∅、针织衫、西服、马甲、背心）</p>
<p><strong>裙子</strong>：格子裙、净色裙、净色+条纹</p>
<p><strong>领饰</strong>：领绳、领带、领结、领巾</p>
<h4 id="变化"><a class="markdownIt-Anchor" href="#变化"></a> 变化</h4>
<p><strong>领口</strong>：圆领、尖领；长领口、短领口（向下延伸长度）；领子上带条纹、不带条纹</p>
<img data-src="image-20200811011515263.png" alt="image-20200811011515263" style="zoom:50%;">
<img data-src="image-20200811011529584.png" alt="image-20200811011529584" style="zoom: 33%;">
<p><strong>百褶裙堆叠方式</strong>：上下上下式、阶梯式</p>
<img data-src="image-20200811011403507.png" alt="image-20200811011403507" style="zoom: 33%;">
<h4 id="特点"><a class="markdownIt-Anchor" href="#特点"></a> 特点</h4>
<ol>
<li>水手服并不是收腰紧身的，而是使用了相对较硬的材质、在胸部以下更偏向线性延伸的。</li>
</ol>
<h4 id="示例"><a class="markdownIt-Anchor" href="#示例"></a> 示例</h4>
<img data-src="image-20200811013940137.png" alt="image-20200811013940137" style="zoom:33%;">
<h3 id="花边的画法"><a class="markdownIt-Anchor" href="#花边的画法"></a> 花边的画法</h3>
<img data-src="image-20200811112029242.png" alt="image-20200811112029242" style="zoom:33%;">
<h3 id="服装的设计"><a class="markdownIt-Anchor" href="#服装的设计"></a> 服装的设计</h3>
<ol>
<li>元素的组合——主元素、辅元素。如以和风为主，但辅以花边和宽松裙摆等Lolita的设计。</li>
<li>变形：打破传统，求异。如传统的和服袖子都很长，领结都在领子下面，而求异的设计就可以把和服的袖子缩短、领结直接绑在颈部。</li>
<li>切割：衣服的虚与实。这里的实指的是有布料覆盖的地方，而虚则是指切开露出、没有布料覆盖的位置。虚的位置往往可以出现在肩部、腰部、腿部、胳膊等。</li>
<li>对比：
<ol>
<li>体积的对比（大、小）</li>
<li>长度的对比（长、短）</li>
<li>娇小的角色穿宽松较大的服装（如埃罗芒阿老师、点兔、小埋）。宽大的衣服更显得角色本身的娇小。</li>
<li>性感的角色产布料较少的衣服，突出其身材</li>
</ol>
</li>
<li>剪影：整体上突出主元素</li>
</ol>
]]></content>
      <tags>
        <tag>art</tag>
        <tag>painting</tag>
        <tag>human-body</tag>
      </tags>
  </entry>
  <entry>
    <title>常用的模式识别中的图像特征介绍</title>
    <url>/2018/04/02/img-features/</url>
    <content><![CDATA[<h2 id="局部二值模式英文local-binary-patterns缩写lbp"><a class="markdownIt-Anchor" href="#局部二值模式英文local-binary-patterns缩写lbp"></a> <a href="https://blog.csdn.net/u013207865/article/details/49720509">局部二值模式（英文：Local binary patterns，缩写：LBP）</a></h2>
<p>在最简简化的情况下，局部二值模式特征向量可以通过如下方式计算：</p>
<ul>
<li>
<p>将检测窗口切分为区块（cells，例如，每个区块16x16像素）。</p>
</li>
<li>
<p>对区块中的每个像素，与它的八个邻域像素进行比较（左上、左中、左下、右上等）。可以按照顺时针或者逆时针的顺序进行比较。</p>
</li>
<li>
<p>对于中心像素大于某个邻域的，设置为1；否则，设置为0。这就获得了一个8位的二进制数（通常情况下会转换为十进制数字），作为该位置的特征。</p>
<span id="more"></span>
</li>
<li>
<p>对每一个区块计算直方图。</p>
</li>
<li>
<p>此时，可以选择将直方图归一化；</p>
</li>
<li>
<p>串联所有区块的直方图，这就得到了当前检测窗口的特征向量。</p>
</li>
<li>
<p>Python实现库函数：<a href="http://scikit-image.org/docs/stable/api/skimage.feature.html#local-binary-pattern">请点这里</a></p>
</li>
</ul>
<img data-src="/2018/04/02/img-features/20131025114220937.png" class title="局部二值模式">
<h2 id="方向梯度直方图英语histogram-of-oriented-gradient简称hog"><a class="markdownIt-Anchor" href="#方向梯度直方图英语histogram-of-oriented-gradient简称hog"></a> <a href="https://www.jianshu.com/p/395f0582c5f7">方向梯度直方图（英语：Histogram of oriented gradient，简称HOG）</a></h2>
<ul>
<li><strong>方向梯度直方图</strong>是应用在<a href="https://zh.wikipedia.org/wiki/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89">计算机视觉</a>和<a href="https://zh.wikipedia.org/wiki/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86">图像处理</a>领域，用于<a href="https://zh.wikipedia.org/w/index.php?title=%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B&amp;action=edit&amp;redlink=1">目标检测</a>的特征描述器。这项技术是用来计算局部图像梯度的方向信息的统计值。这种方法跟<a href="https://zh.wikipedia.org/w/index.php?title=%E8%BE%B9%E7%BC%98%E6%96%B9%E5%90%91%E7%9B%B4%E6%96%B9%E5%9B%BE&amp;action=edit&amp;redlink=1">边缘方向直方图</a>（edge orientation histograms）、<a href="https://zh.wikipedia.org/wiki/%E5%B0%BA%E5%BA%A6%E4%B8%8D%E5%8F%98%E7%89%B9%E5%BE%81%E5%8F%98%E6%8D%A2">尺度不变特征变换</a>（scale-invariant feature transform descriptors）以及<a href="https://zh.wikipedia.org/w/index.php?title=%E5%BD%A2%E7%8A%B6%E4%B8%8A%E4%B8%8B%E6%96%87%E6%96%B9%E6%B3%95&amp;action=edit&amp;redlink=1">形状上下文方法</a>（ shape contexts）有很多相似之处，但与它们的不同点是：HOG描述器是在一个网格密集的大小统一的细胞单元（dense grid of uniformly spaced cells）上计算，而且为了提高性能，还采用了重叠的局部对比度归一化（overlapping local contrast normalization）技术</li>
<li>HOG描述器最重要的思想是：在一副图像中，局部目标的表象和形状（appearance and shape）能够被梯度或边缘的方向密度分布很好地描述。具体的实现方法是：首先将图像分成小的连通区域，我们把它叫细胞单元。然后采集细胞单元中各像素点的梯度的或边缘的方向直方图。最后把这些直方图组合起来就可以构成特征描述器。为了提高性能，我们还可以把这些局部直方图在图像的更大的范围内（我们把它叫区间或block）进行对比度归一化（contrast-normalized），所采用的方法是：先计算各直方图在这个区间（block）中的密度，然后根据这个密度对区间中的各个细胞单元做归一化。通过这个归一化后，能对光照变化和阴影获得更好的效果。</li>
<li>与其他的特征描述方法相比，HOG描述器有很多优点。首先，由于HOG方法是在图像的局部细胞单元上操作，所以它对图像几何的（geometric）和光学的（photometric）形变都能保持很好的不变性，这两种形变只会出现在更大的空间领域上。其次，作者通过实验发现，在粗的空域抽样（coarse spatial sampling）、精细的方向抽样（fine orientation sampling）以及较强的局部光学归一化（strong local photometric normalization）等条件下，只要行人大体上能够保持直立的姿势，就容许行人有一些细微的肢体动作，这些细微的动作可以被忽略而不影响检测效果。综上所述，HOG方法是特别适合于做图像中的行人检测的。</li>
<li>Python实现库函数：<a href="http://scikit-image.org/docs/stable/api/skimage.feature.html#hog">请点这里</a></li>
</ul>
<img data-src="/2018/04/02/img-features/v2-890c6f08045598e83c90f2d52b946c17_hd.jpg" class title="梯度直方图">
<img data-src="/2018/04/02/img-features/v2-f356313f5806fdaaf59ec9196af353b7_hd.jpg" class title="8*8网格直方图">
<img data-src="/2018/04/02/img-features/v2-802e88923e7e26459250d31086e033ea_hd.jpg" class title="visualizing_histogram">
<h2 id="尺度不变特征转换scale-invariant-feature-transform-或-sift"><a class="markdownIt-Anchor" href="#尺度不变特征转换scale-invariant-feature-transform-或-sift"></a> <a href="https://blog.csdn.net/zddblog/article/details/7521424">尺度不变特征转换(Scale-invariant feature transform 或 SIFT)</a></h2>
<ul>
<li>
<p>尺度不变特征转换(Scale-invariant feature transform或SIFT)是一种电脑视觉的算法用来侦测与描述影像中的局部性特征，它在空间尺度中寻找极值点，并提取出其位置、尺度、旋转不变量，此算法由 David Lowe在1999年所发表，2004年完善总结。其应用范围包含物体辨识、机器人地图感知与导航、影像缝合、3D模型建立、手势辨识、影像追踪和动作比对。局部影像特征的描述与侦测可以帮助辨识物体，SIFT 特征是基于物体上的一些局部外观的兴趣点而与影像的大小和旋转无关。对于光线、噪声、些微视角改变的容忍度也相当高。基于这些特性，它们是高度显著而且相对容易撷取，在母数庞大的特征数据库中，很容易辨识物体而且鲜有误认。使用 SIFT特征描述对于部分物体遮蔽的侦测率也相当高，甚至只需要3个以上的SIFT物体特征就足以计算出位置与方位。在现今的电脑硬件速度下和小型的特征数据库条件下，辨识速度可接近即时运算。SIFT特征的信息量大，适合在海量数据库中快速准确匹配。</p>
</li>
<li>
<p>SIFT算法的特点有：</p>
<ol>
<li>
<p>SIFT特征是图像的局部特征，其对旋转、尺度缩放、亮度变化保持不变性，对视角变化、仿射变换、噪声也保持一定程度的稳定性；</p>
</li>
<li>
<p>独特性（Distinctiveness）好，信息量丰富，适用于在海量特征数据库中进行快速、准确的匹配；</p>
</li>
<li>
<p>多量性，即使少数的几个物体也可以产生大量的SIFT特征向量；</p>
</li>
<li>
<p>高速性，经优化的SIFT匹配算法甚至可以达到实时的要求；</p>
</li>
<li>
<p>可扩展性，可以很方便的与其他形式的特征向量进行联合。</p>
</li>
</ol>
</li>
<li>
<p>SIFT算法可以解决的问题：</p>
<p>目标的自身状态、场景所处的环境和成像器材的成像特性等因素影响图像配准/目标识别跟踪的性能。而SIFT算法在一定程度上可解决：</p>
<ol>
<li>
<p>目标的旋转、缩放、平移（RST）</p>
</li>
<li>
<p>图像仿射/投影变换（视点viewpoint）</p>
</li>
<li>
<p>光照影响（illumination）</p>
</li>
<li>
<p>目标遮挡（occlusion）</p>
</li>
<li>
<p>杂物场景（clutter）</p>
</li>
<li>
<p>噪声</p>
</li>
</ol>
</li>
<li>
<p>Lowe将SIFT算法分解为如下四步：</p>
<ol>
<li>
<p>尺度空间极值检测：搜索所有尺度上的图像位置。通过高斯微分函数来识别潜在的对于尺度和旋转不变的兴趣点。</p>
</li>
<li>
<p>关键点定位：在每个候选的位置上，通过一个拟合精细的模型来确定位置和尺度。关键点的选择依据于它们的稳定程度。</p>
</li>
<li>
<p>方向确定：基于图像局部的梯度方向，分配给每个关键点位置一个或多个方向。所有后面的对图像数据的操作都相对于关键点的方向、尺度和位置进行变换，从而提供对于这些变换的不变性。</p>
</li>
<li>
<p>关键点描述：在每个关键点周围的邻域内，在选定的尺度上测量图像局部的梯度。这些梯度被变换成一种表示，这种表示允许比较大的局部形状的变形和光照变化。</p>
</li>
</ol>
</li>
<li>
<p>Python实现库函数：<a href="http://scikit-image.org/docs/stable/api/skimage.feature.html#daisy">请点这里</a> （这个实现有近似成分）</p>
</li>
</ul>
<h2 id="以上内容的python实现-github-地址请点这里"><a class="markdownIt-Anchor" href="#以上内容的python实现-github-地址请点这里"></a> 以上内容的Python实现 Github 地址：<a href="https://github.com/miracleyou/cs231n_assignment_HUST/blob/master/cs231n_assignment1_HUST.ipynb">请点这里</a></h2>
]]></content>
      <tags>
        <tag>machine-learning</tag>
        <tag>CV</tag>
        <tag>image-processing</tag>
      </tags>
  </entry>
  <entry>
    <title>使用IPV6和远程桌面连接局域网中的主机</title>
    <url>/2019/09/18/ipv6-out/</url>
    <content><![CDATA[<p>前几天装配了一个性能和体验都十分不错的主机之后，考虑到后面可能大多数时间我可能还是会在实验室里工作，所以为了随时能够访问主机中的各种资料、程序以及游戏而不用随时插拔并背上沉重的硬盘等设备，使用远程桌面进行访问是非常有必要的。</p>
<p>整个过程持续了接近一天，最终做到了：**不用花一分钱（前提是你拥有一个可用的域名），不使用花生壳之类的服务，能在相互间链路支持IPV6的设备访问自己的主机。(这一假设能否成立由相互间物理距离以及身边ipv6普及情况而定)**下面是详细的步骤说明：</p>
<span id="more"></span>
<h2 id="查看主机与路由器的基本信息"><a class="markdownIt-Anchor" href="#查看主机与路由器的基本信息"></a> 查看主机与路由器的基本信息</h2>
<p>为了远程访问我们的主机，首先有必要搞清楚一些基本的信息，如使用<code>ipconfig</code>确定IPV4/IPV6地址，并判断其ip是属于局域网还是公网。局域网有三段地址，判断方式如下：</p>
<p>A类，第一段为10的都为私网地址，或10.0.0.1–10.255.255.254，其中10.0.0.0表示整个网段，10.0.0.255是广播地址。<br>
B类，以172.16–172.31开头的都是私网地址，或172.16.0.0.1–172.31.255.254，其中172.16.0.0表示整个网段，172.16.255.255是广播地址<br>
C类，以192.168开头的都是私网地址，或192.168.0.1–192.168.255.254，其中192.168.0.0表示整个网段，192.168.0.255是广播地址</p>
<p><img data-src="006y8mN6ly1g7lwr7qshmj30qo0dcjsm.jpg" alt></p>
<p>通常情况下，我们家中或实验室中的设备被分配的都是内网ip，注意这里的ip指的都是ipv4，之后再经由NAT(Net Adress Translation)被映射出外网。</p>
<p>查询路由器对应的公网ip由调查所知有两种易行方案：</p>
<ol>
<li>直接登录路由器的管理页面查看<br>
比如我使用的xfinity路由器，登录界面就是这样。而登录网址，往往是上图中的“默认网关”的ip地址，在我这里就是10.0.0.1</li>
</ol>
<p><img data-src="006y8mN6ly1g7lwr40md9j30xf0u0wh2.jpg" alt="路由器登录界面"><br>
<img data-src="006y8mN6ly1g7lwr2xyohj30u0133wi0.jpg" alt="路由器详细信息"></p>
<ol start="2">
<li>使用一些提供公网ip查询的<a href="https://ifconfig.me">网站</a>进行查询。由于内网中的设备都经过了NAT的转换，所以查出来的这个ip既是你对外暴露的ipv4地址，也是路由器的ipv4地址，但这种方式比起直接登录查看可能会差一些，适用于没有路由器权限时使用。<br>
<img data-src="006y8mN6ly1g7lwra8jl2j30u013gq70.jpg" alt></li>
</ol>
<h2 id="打开主机上的关于远程连接的设置"><a class="markdownIt-Anchor" href="#打开主机上的关于远程连接的设置"></a> 打开主机上的关于远程连接的设置</h2>
<p>具体操作如下图所示，打开控制面板中的远程设置，勾选相应选项即可。</p>
<p><img data-src="006y8mN6ly1g7lwr6gm1wj31hb0u0djp.jpg" alt></p>
<h2 id="局域网下验证ipv4连接与ipv6连接"><a class="markdownIt-Anchor" href="#局域网下验证ipv4连接与ipv6连接"></a> 局域网下验证ipv4连接与ipv6连接</h2>
<p>在主机以外的设备上尝试对主机进行连接，确认局域网下可以进行连接。这里推荐微软的<strong>Microsoft Remote Desktop</strong>软件。其支持Windows、Mac、iOS、Android等主流平台，使用十分简易方便。此处不展开。</p>
<h2 id="设置二级域名与解析"><a class="markdownIt-Anchor" href="#设置二级域名与解析"></a> 设置二级域名与解析</h2>
<h3 id="登录域名服务商"><a class="markdownIt-Anchor" href="#登录域名服务商"></a> 登录域名服务商</h3>
<p><img data-src="006y8mN6ly1g7lwr8uolrj31p10u0goq.jpg" alt></p>
<p>点击对应域名最右侧的“解析”按钮（在截图外面），进入域名解析设置。由于ipv4被设置了NAT，所以很难在不做内网穿透的情况下进行使用，尤其是在没有服务器的情况下，而租赁服务器的价格并不便宜，且链接速度将会同时受到穿透服务器的网速制约，所以并不推荐。</p>
<h3 id="添加二级域名解析记录"><a class="markdownIt-Anchor" href="#添加二级域名解析记录"></a> 添加二级域名解析记录</h3>
<p>综上所述，这里决定采用IPV6直接解析，这样做的好处是IPV6是不做NAT的，也即其和设备是唯一对应的，这是一个很方便的地方。于是，我们将在我们已经入手的域名上添加一个二级域名，即在一级域名前再加一个前缀，如<code>domainname.com</code>可以拥有无数个<code>xxx.domainname.com</code>，这个xxx可以自定义。</p>
<p>由于我们要做的是对ipv6的解析，所以这里添加一条<strong>AAAA</strong>记录。而这个记录是为了我的windows域名解析服务，所以这里我使用了“win”这个前缀（这个随意其实）。</p>
<p><img data-src="006y8mN6ly1g7lwr58axpj33k60mqq77.jpg" alt></p>
<p>这条记录对应的记录值即为刚才我们用ipconfig查出来的那个“临时ipv6地址”。保存退出。</p>
<h2 id="在电脑上部署ddns服务"><a class="markdownIt-Anchor" href="#在电脑上部署ddns服务"></a> 在电脑上部署DDNS服务</h2>
<p>我们现在已经拥有了一个与主机ipv6对应的域名，即我们现在已经可以使用域名访问我们的主机了（前提是前面在局域网内测试通过），我们在Microsoft Remote Desktop上新建一个连接，把刚才输入ip的地方这次输成刚才解析的域名，在我这即为“<a href="http://win.xxxxxxxx.xxx">win.xxxxxxxx.xxx</a>”。做一次连接测试，如果连接成功，那么恭喜你，你的ipv6地址已经很好的绑定到域名上了，我们可进行下一步——部署DDNS服务。</p>
<p>至于什么事DDNS，既然有现成的解释，我就不强行再加工了，下面附上<a href="https://zhuanlan.zhihu.com/p/46580280">知乎</a>上一段说明：</p>
<blockquote>
<p>DDNS的全称是动态域名服务，简单的说就是把一个IP地址映射到一个域名身上，一般大公司诸如百度这些IP都是固定的，而对个人用户来说，想有一个固定的家庭网络IP地址显然是一件不现实的事情，因为首先不说大部分人都是运营商的内网IP，即便少部分人申请到了公网IP，也都不是固定的，因为IPV4资源很紧张，不可能给每个人都分配公网IP，这个问题到IPV6可以解决，但是那也是以后的事情了，而且固定IP费用非常高昂，不是一般人可以承受的。但是我们在外网想要访问我们的家庭网络怎么办呢？这就需要DDNS了，DDNS将用户的动态IP地址映射到一个固定的域名解析服务上，用户每次连接网络的时候客户端程序就会通过信息传递把该主机的动态IP地址传送给位于服务商主机上的服务器程序，而服务器程序负责提供DNS服务并实现动态域名解析。这样我们只要在外部输入我们的域名就可以访问了，即便IP换了也是一样的。</p>
</blockquote>
<p>当然，原文是讲用ipv4做DDNS，并要涉及到花生壳和路由器设置，但很多情况下着并不是我们想要和想要承受的负担。那么如何在没有路由器权限的情况下做到动态的域名解析？</p>
<p>这里我使用了码云上一个<a href="https://gitee.com/XuChaoProject/AliyunDdnsCSharp">Windows的动态域名解析服务</a>，详情请自行点击链接研究，这里不做过多说明。简单的原理就是它在后台开了一个Windows服务，这个服务每隔x分钟便会将你电脑当前的ipv6地址解析到阿里云的云解析服务器上，最优秀的是它是默认开机启动的，从此妈妈再也不用担心我的域名没法实时解析！</p>
<p>当然，如果你是linux用户，其实你的选择更多，GitHub上有好几个动态解析代码可供使用，这里列出几个：</p>
<ol>
<li><a href="https://github.com/yyqian/aliyun-ddns">https://github.com/yyqian/aliyun-ddns</a></li>
<li><a href="https://github.com/AlanLang/aliyun-ddns-server">https://github.com/AlanLang/aliyun-ddns-server</a></li>
<li><a href="https://github.com/rfancn/aliyun-ddns-client">https://github.com/rfancn/aliyun-ddns-client</a> （这个是py脚本，不过只支持ipv4解析，姑且列上来）</li>
</ol>
<p>配置好后，理论上你就拥有了一个可以被外网访问到的主机了，恭喜你！</p>
]]></content>
      <tags>
        <tag>tech</tag>
        <tag>tool</tag>
        <tag>ipv6</tag>
        <tag>reverse-proxy</tag>
        <tag>windows</tag>
      </tags>
  </entry>
  <entry>
    <title>IoU, AP, mAP等对比</title>
    <url>/2020/07/14/iou-ap-map/</url>
    <content><![CDATA[<h1 id="iou-ap-map-map05-map05-095-average-map"><a class="markdownIt-Anchor" href="#iou-ap-map-map05-map05-095-average-map"></a> IoU, AP, mAP, mAP@0.5, mAP@[0.5: 0.95],  Average mAP</h1>
<h2 id="tldr"><a class="markdownIt-Anchor" href="#tldr"></a> TL;DR</h2>
<ol>
<li>IoU：两个框框重叠部分面积/两个框框合并后的总面积​</li>
<li>AP：绘制Recall-Precision图，经过平滑后曲线的下面全面积。这个图的绘制方法是：按照每个预测结果的Confidence从上往下排列，先只取一个画出图上左上角第一个点，然后是只取前两个，直到取完。</li>
<li>mAP：AP是针对某一个类的，而mAP是把各个类的AP做一个平均。</li>
<li>mAP@0.5：当IoU阈值为0.5时的mAP。</li>
<li>mAP@[0.5:0.95]：COCO要求IoU阈值在[0.5, 0.95]区间内每隔0.05取一次，这样就可以计算出10个类似于PASCAL的mAP，然后这10个还要再做平均。</li>
</ol>
<span id="more"></span>
<h2 id="查准率precision和查全率recall"><a class="markdownIt-Anchor" href="#查准率precision和查全率recall"></a> <strong>查准率（Precision）和查全率（recall）</strong></h2>
<p>查准率（Precision）是指在所有预测为正例中真正例的比率，也即预测的准确性。</p>
<p>查全率（Recall）是指在所有正例中被正确预测的比率，也即预测正确的覆盖率。</p>
<p>一个样本模型预测按正确与否分类如下：</p>
<p>真正例： <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>P</mi><mo>=</mo><mi>T</mi><mi>r</mi><mi>u</mi><mi>e</mi><mtext> </mtext><mi>P</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">TP=True\space Positive</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">u</span><span class="mord mathnormal">e</span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal">o</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">e</span></span></span></span></p>
<p>真反例： <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>N</mi><mo>=</mo><mi>T</mi><mi>r</mi><mi>u</mi><mi>e</mi><mtext> </mtext><mi>N</mi><mi>e</mi><mi>g</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">TN=True\space Negative</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">u</span><span class="mord mathnormal">e</span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">e</span></span></span></span></p>
<p>假正例：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mi>P</mi><mo>=</mo><mi>F</mi><mi>a</mi><mi>l</mi><mi>s</mi><mi>e</mi><mtext> </mtext><mi>P</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">FP=False\space Positive</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">s</span><span class="mord mathnormal">e</span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal">o</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">e</span></span></span></span></p>
<p>假反例：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mi>N</mi><mo>=</mo><mi>F</mi><mi>a</mi><mi>l</mi><mi>s</mi><mi>e</mi><mtext> </mtext><mi>N</mi><mi>e</mi><mi>g</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">FN=False\space Negative</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">s</span><span class="mord mathnormal">e</span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">e</span></span></span></span></p>
<p><strong>则，查准率和查全率计算公式：</strong></p>
<p><strong>查准率</strong>：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>=</mo><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>P</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">Precision=\frac{TP}{TP+FP}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">e</span><span class="mord mathnormal">c</span><span class="mord mathnormal">i</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.275662em;vertical-align:-0.403331em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.872331em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">F</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.403331em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p>
<p><strong>查全率</strong>：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo>=</mo><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">Recall=\frac{TP}{TP+FN}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal">e</span><span class="mord mathnormal">c</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.275662em;vertical-align:-0.403331em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.872331em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">F</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.403331em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p>
<h2 id="交并比iouintersection-over-union"><a class="markdownIt-Anchor" href="#交并比iouintersection-over-union"></a> <strong>交并比IoU(Intersection over union)</strong></h2>
<p>交并比IoU衡量的是两个区域的重叠程度，是两个区域重叠部分面积占二者总面积（重叠部分只计算一次）的比例。如下图，两个矩形框的IoU是交叉面积（中间图片红色部分）与合并面积（右图红色部分）面积之比。</p>
<p><img data-src="v2-11ed1bf4a882ee38f9ea1f73a2593472_1440w.jpg" alt="img">IoU计算重叠度</p>
<p>这里需要注意的是IoU=0.5，并不意味着每个框刚好有50%与另外一个框交叉部分，而是每个框大约有2/3被交叉。有点反直觉。</p>
<p>我当初看到IoU，非常疑惑为啥不按交叉面积占每个框的比例（IoA 也即Intersection over Area）取大值计算重叠度，更符合直觉。其实这种算法只反应小图片的被遮盖度，并不能反映互相之间的重叠度，一般情况下不可取。如下图，橙色部分较小，IoA很大，但对于蓝色部分，IoA就很小，只按橙色取IoA显然有失偏驳。</p>
<p><img data-src="v2-284022eaa7bbb8dd7b4f8488e0495fcd_1440w.jpg" alt="img">IoA计算重叠度</p>
<h2 id="单类别apaverage-precision的计算"><a class="markdownIt-Anchor" href="#单类别apaverage-precision的计算"></a> <strong>单类别AP(Average Precision)的计算</strong></h2>
<p>物体检测中的每一个预测结果包含两部分，预测框（bounding box）和置信概率（Pc）。bounding box通常以矩形预测框的左上角和右下角的坐标表示，即x_min, y_min, x_max, y_max，如下图。置信概率Pc有两层意思，一是所预测bounding box的类别，二是这个类别的置信概率，如下图中的P_dog=0.88，代表预测绿色框为dog，并且置信概率为88%。</p>
<p><img data-src="v2-8e1e070d1a59043a349eb1f921ea1e1c_1440w.jpg" alt="img"></p>
<p>那么，怎么才叫预测正确呢？显而易见的，必须满足两个条件：</p>
<ol>
<li>类别正确且置信度大于一定阀值（P_threshold）</li>
<li>预测框与真实框（ground truth）的IoU大于一定阀值（IoU_threshold）</li>
</ol>
<p>如下图，假如P_threshold=0.6，IoU_threshold=0.5，则绿色框预测正确，记为True Positive。</p>
<p><img data-src="v2-fa34f541cee564e83435562297e768ab_1440w.jpg" alt="img"></p>
<p>而在衡量模型性能时，IoU_threshold先取一个定值，然后综合考虑各种P_threshold取值时的性能，进而得到一个与P_threshold选定无关的模型性能衡量标准。</p>
<p><strong>AP是计算单类别的模型平均准确度。</strong></p>
<p>假如目标类别为Dog，有5张照片，共包含7只Dog，也即GT（Ground Truth）数量为7，经模型预测，得到了Dog的10个预测结果，选定IoU_threshold=0.5，然后按confidence从高到低排序，如下图。其中，BB表示Bounding Box序号，GT=1表示有GT与所预测的Bounding Box的IoU&gt;=IoU_threshold，Bounding Box序号相同代表所对应的GT是同一个。</p>
<table>
<thead>
<tr>
<th>Rank</th>
<th>BB</th>
<th>confidence</th>
<th>GT</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>BB1</td>
<td>0.9</td>
<td>1</td>
</tr>
<tr>
<td>2</td>
<td>BB2</td>
<td>0.8</td>
<td>1</td>
</tr>
<tr>
<td>3</td>
<td>BB1</td>
<td>0.8</td>
<td>1</td>
</tr>
<tr>
<td>4</td>
<td>BB3</td>
<td>0.5</td>
<td>0</td>
</tr>
<tr>
<td>5</td>
<td>BB4</td>
<td>0.4</td>
<td>0</td>
</tr>
<tr>
<td>6</td>
<td>BB5</td>
<td>0.4</td>
<td>1</td>
</tr>
<tr>
<td>7</td>
<td>BB6</td>
<td>0.3</td>
<td>0</td>
</tr>
<tr>
<td>8</td>
<td>BB7</td>
<td>0.2</td>
<td>0</td>
</tr>
<tr>
<td>9</td>
<td>BB8</td>
<td>0.1</td>
<td>1</td>
</tr>
<tr>
<td>10</td>
<td>BB9</td>
<td>0.1</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>因此，如果设置P_threshold=0，则有 TP=5 (BB1, BB2, BB5, BB8, BB9)，FP=5 (重复检测到的BB1也算FP)。除了表里检测到的5个GT以外，我们还有2个GT没被检测到，因此: FN = 2.</p>
<p>然后依次从上到下设定对应的rank为正反分界线，此rank之前（包含此rank）的预测为正，此rank之后的预测为反，然后计算对应的Precision和Recall：</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">rank=1  precision=1.00 and recall=0.14</span><br><span class="line">--------------------------------------</span><br><span class="line">rank=2  precision=1.00 and recall=0.29</span><br><span class="line">--------------------------------------</span><br><span class="line">rank=3  precision=0.66 and recall=0.29</span><br><span class="line">--------------------------------------</span><br><span class="line">rank=4  precision=0.50 and recall=0.29</span><br><span class="line">--------------------------------------</span><br><span class="line">rank=5  precision=0.40 and recall=0.29</span><br><span class="line">--------------------------------------</span><br><span class="line">rank=6  precision=0.50 and recall=0.43</span><br><span class="line">--------------------------------------</span><br><span class="line">rank=7  precision=0.43 and recall=0.43</span><br><span class="line">--------------------------------------</span><br><span class="line">rank=8  precision=0.38 and recall=0.43</span><br><span class="line">--------------------------------------</span><br><span class="line">rank=9  precision=0.44 and recall=0.57</span><br><span class="line">--------------------------------------</span><br><span class="line">rank=10 precision=0.50 and recall=0.71</span><br><span class="line">--------------------------------------</span><br></pre></td></tr></table></figure>
<p>比如rank=4时，TP=2 (BB1, BB2)，则</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">Precision=2/4=0.5，Recall=TP/GT=2/7=0.29</span><br></pre></td></tr></table></figure>
<p>可以看出，随着预测正反分割线的向下移动，Recall稳步变大，Precision整体减小，局部上下跳动，PR曲线如下图：</p>
<p><img data-src="v2-0a899369aeab8824dc3dd3e4fe572cd3_1440w.jpg" alt="img"></p>
<p>AP(Average Precision)的计算基本等同于计算PR曲线下的面积，但略有不同。需要先将PR曲线平滑化。</p>
<p>方法是，查全率r对应的查准率p，取查全率大于等于r时最大的查准率p。即，</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>t</mi><mi>e</mi><mi>x</mi><mo>=</mo><mi>p</mi><mo stretchy="false">(</mo><mi>r</mi><mo stretchy="false">)</mo><mo>=</mo><munder><mo><mi>max</mi><mo>⁡</mo></mo><mrow><mover accent="true"><mi>r</mi><mo>~</mo></mover><mo>≥</mo><mi>r</mi></mrow></munder><mrow><mi>p</mi><mo stretchy="false">(</mo><mover accent="true"><mi>r</mi><mo>~</mo></mover><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">tex=p(r)=\max_{\tilde{r}\geq r}{p(\tilde{r})}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.578681em;vertical-align:-0.828681em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.43055999999999983em;"><span style="top:-2.366498em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord accent mtight"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6678599999999999em;"><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span><span style="top:-3.0500000000000003em;"><span class="pstrut" style="height:2.7em;"></span><span class="accent-body" style="left:-0.19444em;"><span class="mord mtight">~</span></span></span></span></span></span></span><span class="mrel mtight">≥</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.828681em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6678599999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span><span style="top:-3.35em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;"><span class="mord">~</span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></span></p>
<p>平滑后的曲线如下图中的绿色曲线：</p>
<p><img data-src="v2-666e46a022e32981aeb07b85958803cc_1440w.jpg" alt="img"></p>
<p>对于AP(Average Precision)的计算有两种方法：</p>
<p><strong>1. VOC2010之前的方法</strong></p>
<p>AP =（平滑后PR曲线上，Recall分别等于0，0.1，0.2，… , 1.0等11处Precision的平均值）。</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>A</mi><mi>P</mi><mo>=</mo><mfrac><mn>1</mn><mn>11</mn></mfrac><munder><mo>∑</mo><mrow><mi>r</mi><mo>⊆</mo><mrow><mo fence="true">{</mo><mn>0</mn><mo separator="true">,</mo><mn>0.1</mn><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><mn>1.0</mn><mo fence="true">}</mo></mrow></mrow></munder><mrow><mi>p</mi><mrow><mo fence="true">(</mo><mi>r</mi><mo fence="true">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">AP=\frac{1}{11}\sum_{r\subseteq\left\{0,0.1,..,1.0\right\}}{p\left(r\right)}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.8374449999999998em;vertical-align:-1.516005em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">1</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em;"><span style="top:-1.808995em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mrel mtight">⊆</span><span class="minner mtight"><span class="mopen mtight delimcenter" style="top:0em;"><span class="mtight">{</span></span><span class="mord mtight">0</span><span class="mpunct mtight">,</span><span class="mord mtight">0</span><span class="mord mtight">.</span><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="mord mtight">.</span><span class="mord mtight">.</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span><span class="mord mtight">.</span><span class="mord mtight">0</span><span class="mclose mtight delimcenter" style="top:0em;"><span class="mtight">}</span></span></span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.516005em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span></span></span></span></p>
<p>这里则有：</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">AP = (1 + 1 + 1 + 0.5 + 0.5 + 0.5 + 0.5 + 0.5 + 0 + 0 + 0) / 11 = 0.5</span><br></pre></td></tr></table></figure>
<p><strong>2. VOC2010及以后的方法</strong></p>
<p>AP=平滑后PR曲线下包围的面积</p>
<p>这里则有：</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">AP = (0.14-0) * 1 + (0.29-0.14) * 1 + (0.43-0.29) * 0.5 + (0.57-0.43) * 0.5 + (0.71-0.57) * 0.5 + (1-0.71) * 0 = 0.5</span><br></pre></td></tr></table></figure>
<p>这里两种方案得出的AP值相同，但通常是不同的。</p>
<p>需要注意的是上述AP的计算并没有显式设定<code>P_threshold</code>，而是通过从上到下依次指定每一个rank为正反分界线来变相的反映<code>P_threshold</code>不同取值。</p>
<h2 id="map的计算"><a class="markdownIt-Anchor" href="#map的计算"></a> <strong>mAP的计算</strong></h2>
<p>上述计算的AP只是针对dog这个类别，物体检测通常有多个类别，模型性能肯定是多个类别准度的综合度量。</p>
<p><strong>1. VOC数据集中的mAP</strong></p>
<p>VOC数据集中的mAP计算的是<code>IoU_threshold=0.5</code>时各个类别AP的均值。</p>
<p><strong>2. COCO数据集中的mAP</strong></p>
<p>检测是否正确有两个超参数，<code>P_threshold</code>和<code>IoU_threshold</code>。AP是固定了<code>IoU_threshold</code>，再综合考虑各个<code>P_threshold</code>下的模型平均准确度。</p>
<p>VOC认为<code>IoU_threshold</code>固定一个单值0.5即可，COCO则认为固定了<code>IoU_threshold</code>的取值，无法衡量<code>IoU_threshold</code>对模型性能的影响。</p>
<p>比如，</p>
<p>A模型在<code>IoU_threshold=0.5</code>时，<code>mAP=0.4</code>。</p>
<p>B模型在<code>IoU_threshold=0.7</code>时，<code>mAP</code>同样为0.4。</p>
<p>依据VOC的标准，AB模型的性能一样，但显然B模型的框更准，性能更优。</p>
<p>COCO在VOC标准的基础上，取<code>IoU_threshold=0.5，0.55， 0.6，… , 0.95</code>时各个mAP的均值。</p>
<h2 id="reference"><a class="markdownIt-Anchor" href="#reference"></a> Reference</h2>
<ol>
<li><a href="https://arleyzhang.github.io/articles/c521a01c/">目标检测评价标准-AP mAP</a></li>
<li><a href="http://blog.sina.com.cn/s/blog_9db078090102whzw.html">多标签图像分类任务的评价方法-mAP</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/56961620">详解object detection中的mAP</a></li>
<li><a href="https://blog.csdn.net/luke_sanjayzzzhong/article/details/89851944">对于目标检测中mAP@0.5的理解</a></li>
<li><a href="https://datascience.stackexchange.com/questions/16797/what-does-the-notation-map-5-95-mean">What does the notation mAP@[.5:.95] mean?</a></li>
</ol>
]]></content>
      <tags>
        <tag>machine-learning</tag>
        <tag>deep-learning</tag>
      </tags>
  </entry>
  <entry>
    <title>日本の高等教育システムの紹介</title>
    <url>/2018/07/29/japanese-u/</url>
    <content><![CDATA[<h1 id="日本の高等教育システムの紹介"><a class="markdownIt-Anchor" href="#日本の高等教育システムの紹介"></a> 日本の高等教育システムの紹介</h1>
<h2 id="overall-introduction"><a class="markdownIt-Anchor" href="#overall-introduction"></a> Overall Introduction</h2>
<h3 id="大学"><a class="markdownIt-Anchor" href="#大学"></a> 大学</h3>
<p>日本的大学分为三种：国立大学、公立大学和私立大学。国立大学就是国家设立的学校，比如东京大学;公立大学为地方设置的大学，比如东京都立大学;私立大学是学校法人设立的学校，比如早稻田、庆应大学。不论国立、公立或是私立的学校，都需经国家教育主管部门的批准和监督。</p>
<span id="more"></span>
<p>在日本，无论国立、公立或私立大学都有少数一流大学，比如国立的东京大学、京都大学，私立的早稻田大学和庆应义塾大学等，都是世界闻名的优秀学府。总之，不能以国立或是私立的概念作为评价大学的标准。这二者的区别只是在于，国、公立大学的经费主要由国家财政拨款，其学费相对私立大学要便宜一些。</p>
<h3 id="大学院"><a class="markdownIt-Anchor" href="#大学院"></a> 大学院</h3>
<p>日本的<strong>大学院</strong>是读<strong>硕士和博士</strong>的地方。日本的<strong>硕士</strong>叫做<strong>修士</strong>，学制为<strong>两年</strong>。虽然日本也有研究生这个概念，但是与中国的“研究生”有所不同： <em>中国的“研究生”指的就是硕士，而日本的“<strong>研究生</strong>”是日本一种特殊的制度，是由于学生尚未达到读修士的水平，需花一年左右的时间跟导师补充相应的知识而设立的制度，大约相当于硕士或是博士的预科，是没有学位的。</em> 不可以与国内的研究生划等号。</p>
<p>日本的还有为数不少的短大及专门学校。短大的学制为2到3年，大约相当于我国的大专，主要是家政、人文、教育及社会方面的专业。专门学校也相当于我国的大专，不过，日本的专业学校是进行职业教育，并教授可实际应用的技术、知识和技能，专业以电 子、机械、化工为主，是培养高级技术工人的学校。</p>
<h3 id="语言学校与大学预科"><a class="markdownIt-Anchor" href="#语言学校与大学预科"></a> 语言学校与大学预科</h3>
<p>如果留学生希望直接申请大学、大学院或是专门学校，日语必须达到二级水平(如果想进一流大学则必须达到一级)是相当关键的。但是，能满足大学所有入学条件的学生毕竟是少数，因此，为了给留学生们提供一个过渡的环境，日本出现了语言学校和大学预科。留学生在就读语言学校和大学预科时，主要是培养自己的日语能力并补习一些文化课知识，为升入大学做准备。</p>
<h2 id="merit-of-going-to-japan-to-continue-your-study-as-a-syuushi"><a class="markdownIt-Anchor" href="#merit-of-going-to-japan-to-continue-your-study-as-a-syuushi"></a> Merit of Going to Japan to continue your study as a SyuuShi</h2>
<ol>
<li>国、公立大学在入国管理局和大使馆有很高的信誉，所以，申请手续比较简单，签证率百分之百</li>
<li>是留日项目中费用最低的，正式入学后<strong>学费全免或半免的比率很高</strong>，<strong>获得奖学金的机会很多</strong></li>
<li>国、公立大学一般都设有面向留学生的免费语言课程，省去读语言学校的时间和金钱</li>
<li>家属可以申请陪读</li>
<li>留学生公寓</li>
<li>享受国民健康保险</li>
<li>毕业后就业前景广阔</li>
</ol>
<h2 id="go-to-japan-to-study-cs"><a class="markdownIt-Anchor" href="#go-to-japan-to-study-cs"></a> Go to Japan to study CS</h2>
<p>首先这个问题的产生和日本国情有关，作为早已进入发达国家（共产主义）的日本，<em>各个行业发展的都非常平衡，每个行业的待遇也都差不多</em>。既然每个行业都差不多，日本IT行业好像听起来就比较累，并且又有着“3K党”的传说（きつい、厳しい、帰れない），自然在日本本土完全就没有成为热门专业。反观国内为什么计算机这么火？说白了还是<strong>待遇问题</strong>，在国内面向funding project和面向工资编程的导向下码农大军如排山倒海之势袭来，恰有一统全国之势，因为国内不选择计算机几乎没法找到有钱途的工作。就拿我自己来说吧，当时学校最火的专业分数要比计算机高20分左右，在不求最好但求最高的心态驱使下自然就选了分数最高的专业。而高中同班同学由于比自己低20分，被从当时“最热的专业”调剂到计算机，刚开始同学还愤愤不平。毅种循环，毕业找工作的时候到了，同学年薪20w，我由于要出国只是想了解一下就业形势，结果拿到收入最高的公司offer收入没到同学2分之1…就我个人来说是不是看中了高薪才转cs的呢？这也没什么好掩饰的，没错我就是想赚钱，当然本身也感兴趣（并不是主要原因）</p>
<p>另一方面门槛低未尝不是好事呢，在我看来这恰恰给广大由于种种原因编程并不是特别强的留学生，或者是想转行在国内又无法马上找到IT工作的人提供了机会，如果计算机在日本火起来我们还能这么容易找到工作么？对于那些编程实力很强的人想来日本，请移步六本木谷歌高盛，苹果也打算2017年3月在日本建设研发中心，不少美国企业家也都有日本情节，比如乔帮主的偶像就是盛田昭夫，对于那些很优秀的人日本也不至于埋没人才。</p>
<p>很多人拿日本和美国cs比，我觉得这是不太公平的。首先如果真的很有学术天分，打算做一辈子学术，并且自身硬件极好，注意是一定是极好，美国名校PhD的确是最好的选择。但我想大多数人可能和我一样，本科并没有石破天惊的顶会论文，没有逆天的GPA，也没有拿到手软的国际大奖，有的只是工薪家庭自费两年会给家里带来沉重经济负担的心理压力。在这样的状态下，能够正常生活都是一个问题，还有多大的心思专心学术呢？而日本的国立大学学费可以说低到了一定境界，比日本人还便宜一半，几乎等于白送，而在美国学费是要比本土高很多的。另外湾区的生活成本要比东京高很多，虽然工资高但真按照生活质量没法说一定比东京好，日本的空气质量和生活舒适度一句话说是一个来了就不想走的地方。</p>
<p>接下来是大家比较关心的问题，既然日本互联网环境这么不好，那对于将来的发展岂不是很可怕，什么都学不到怎么办？其实公司里还是有不少人挺厉害的，我刚刚也说过在日本选择做码农的都是真爱，和国内面向工资不一样，所以里面的人工作热情都很高。刚进去的几年肯定会有比你厉害不少的前辈，并且你遇到不会的细节里面的人会跟你一点点详细解答。当然编程最主要的还是靠自己，参观飞机场学不会开飞机，和陈立杰坐在一起也不会提高你的编程水平，自己多练是提高编程能力的唯一途径。</p>
<p>待遇方面，工作于日本互联网可以在国内一半劳动时间，（国内996，日本964）具有国内码农一半（甚至更低）编程水平的前提下找到不低于甚至超过国内互联网公司的工作，并且不用扮演自动吸霾机的角色。</p>
<p>抛开名校情结和大神光环不说，对于留学生能具体感受到的切实利益，</p>
<h3 id="日本计算机方向留学相对于北美的优势究竟在哪里呢"><a class="markdownIt-Anchor" href="#日本计算机方向留学相对于北美的优势究竟在哪里呢"></a> 日本计算机方向留学相对于北美的优势究竟在哪里呢？</h3>
<ol>
<li>
<p>以极低的费用获得改变人生的机会，就拿我自己来说，单是美国两年天价的硕士学费就足以把家里直接拖垮。而日本国立大学的学费仅有1w5，和国内差不多，并且日本的生活费和北京没什么差别，完全不用担心经济上有任何的负担。</p>
</li>
<li>
<p>之前也提到过，能够以很小的竞争以不强的编程能力轻松找到日企互联网公司极低工作强度的工作，400万的评价年薪虽说并不比国内高很多，但注意这是在国内一半劳动强度情况下的收入。国内互联网公司普遍996甚至更夸张，而日本通常是964，为什么说964呢，因为日本假期实在太多，动不动就连休，休日，平均起来大约一周工作四天，并且互联网公司普遍不加班，那些说日企压力大的人可以醒醒了。而如果剩下的时间不想浪费怎么办？自己给自己加班，下班了多练练编程吧，想一下怎样提高代码运行效率，怎样写出更优雅简洁的代码，怎样突破自己的极限。</p>
</li>
<li>
<p>能够以硕士期间的研究状态判断自己是不是适合做学术这一条路线。拿我自己来说东大入学之前我认为将来一定是以学术路线发展的，并且肯定会读博。修士入学之后，每天基本上除了申请就是做科研了，还记得第一年修士寒假，大年三十的晚上写程序写到了半夜一点多，修士第一年连一部日剧都没追完，但越往后越深切的感受到读博士和当初想象的能够按照自己的兴趣解决问题并不一样。首先为什么要读博士？读博最理想的出路就是博士后回国找教职了，但大部分人都充当了分母的角色。就拿回国任教来说，现在都会要求发多少顶会论文，所以说现在的形势是读博士＝＝发论文，如果没法快速的发论文，教授不同意不说，就连毕业都是个问题。这样就造成了很多人为了发论文而发论文，大部分论文也极偏理论性，学到的大都是屠龙之技，往往用Matlab和Python导一下库验证一下就算完了，很少有人静下心来用C++自己先实现一遍原理，虽说不要重复发明轮子，但我认为重复制造轮子还是必须的，在正式进行科研之前首先要保证能够有足够强的工程能力实现任何论文里的代码。并且读的论文越多，越感受到大部分论文都是没有困难创造困难也要上，因此现在我可以清楚地知道自己不适合学术界闭门造车这条路，但工程能力还是要有的，所以毕业之前的研究重心就转移到了代码上。相比较而言，美国授课硕士结束想读博士的话还要重头再来五年，而日本只需要三年，衔接上也更自然。</p>
</li>
<li>
<p>申请门槛较低，相对于国内挤破头申请美国CS而言，日本似乎冷门许多。首先日本计算机原则上不需要任何语言成绩就可以申请（个别教授会要求），而美国是必须要有托福和GRE，另外日本对于GPA的要求不像美国那么高，注意不是说日本不看GPA，相反非常看，只是说不要求太高，但还是要保证中上等水平。另外门槛低是不是意味着随便谁都可以申请到呢？显然不是，就拿我三年来100多人的申请经验来说，教授的要求简直实现了新的飞跃，尤其是2017年入学的这一届。很多开始不看成绩单的教授慢慢看起了成绩单，很多刚开始接收二本学生的教授开始挑起了985，很多开始985见人就要的教授开始挑起了Top5，很多原本不要求语言的教授突然提出要求N1，很多不看计划书的教授开始要求了计划书，很多自身水平一般的教授要求计划书提出新算法解决当今学术难题，很多不面试的教授开始要求了面试，很多收过人的教授突然不再接收留学生，不一而足。申请是一场博弈，遭受挫折之后，我也会马上调整战略，与人斗其乐无穷。</p>
</li>
<li>
<p>生活舒适度极高，这体现在干净到不真实的空气，极高的国民素质和各行各业绝佳的服务体验，教授对学生研究课题以及个人的尊重，好到夸张的治安，美味的日料和二次元的天堂…</p>
</li>
</ol>
]]></content>
      <tags>
        <tag>university</tag>
        <tag>Japan</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch中常用图像变换</title>
    <url>/2018/04/13/img-pre-process/</url>
    <content><![CDATA[<h1 id="pytorch-torchvision-transform"><a class="markdownIt-Anchor" href="#pytorch-torchvision-transform"></a> pytorch torchvision transform</h1>
<ol>
<li><a href="https://ptorch.com/docs/1/transforms#transforms-on-pil-image">对PIL.Image进行变换</a></li>
<li><a href="https://ptorch.com/docs/1/transforms#transforms-on-torch-tensor">对Tensor进行变换</a></li>
<li><a href="https://ptorch.com/docs/1/transforms#conversion-transforms">Conversion Transforms</a></li>
<li><a href="https://ptorch.com/docs/1/transforms#generic-transforms">通用变换</a></li>
</ol>
<span id="more"></span>
<hr>
<p>变换是常用的图像变换。它们可以用<code>Compose</code>连接在一起。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">torchvision</span>.transforms.Compose(transforms)</span><br></pre></td></tr></table></figure>
<p>将多个transform组合起来使用。</p>
<p>transforms： 由transform构成的列表. 例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">transforms.Compose([</span><br><span class="line">     transforms.CenterCrop(<span class="number">10</span>),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<h4 id="对pilimage进行变换"><a class="markdownIt-Anchor" href="#对pilimage进行变换"></a> 对PIL.Image进行变换</h4>
<hr>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">torchvision</span>.transforms.Scale(size, interpolation=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>按照规定的尺寸重新调节<code>PIL.Image</code>。</p>
<p><strong>参数说明</strong>：</p>
<ol>
<li>size (sequence or int) - 期望输出尺寸。如果size是一个像(w, h)的序列，输出大小将按照w,h匹配到。如果大小是int，则图像将匹配到这个数字。例如，如果原图的<code>height&gt;width</code>,那么改变大小后的图片大小是<code>(size*height/width, size)</code>。</li>
<li>interpolation (int, optional) -需要添加值。默认的是<code>PIL.Image.BILINEAR</code></li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">torchvision</span>.transforms.CenterCrop(size)</span><br></pre></td></tr></table></figure>
<p>将给定的PIL.Image进行中心切割，得到给定的size，size可以是tuple，(target_height, target_width)。size也可以是一个Integer，在这种情况下，切出来的图片的形状是正方形。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">torchvision</span>.transforms.RandomCrop(size, padding=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>切割中心点的位置随机选取。size可以是tuple也可以是Integer。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">torchvision</span>.transforms.RandomHorizontalFlip</span><br></pre></td></tr></table></figure>
<p>随机水平翻转给定的PIL.Image,概率为0.5。即：一半的概率翻转，一半的概率不翻转。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">torchvision</span>.transforms.RandomSizedCrop(size, interpolation=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>先将给定的PIL.Image随机切，然后再resize成给定的size大小。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">torchvision</span>.transforms.Pad(padding, fill=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>将给定的PIL.Image的所有边用给定的pad value填充。 padding：要填充多少像素 fill：用什么值填充</p>
<h4 id="对tensor进行变换"><a class="markdownIt-Anchor" href="#对tensor进行变换"></a> 对Tensor进行变换</h4>
<hr>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">torchvision</span>.transforms.Normalize(mean, std)</span><br></pre></td></tr></table></figure>
<p>给定均值：(R,G,B) 方差：（R，G，B），将会把Tensor正则化。即：Normalized_image=(image-mean)/std。</p>
<p><strong>参数说明：</strong></p>
<ol>
<li>mean (sequence) – 序列R, G, B的均值。</li>
<li>std (sequence) – 序列 R, G, B 的平均标准偏差.</li>
</ol>
<p><strong>call(tensor)</strong> 参数: tensor (Tensor) – 规范化的大小（c，h，w）的张量图像. 返回结果: 规范化的图片. 返回样式: Tensor张量</p>
<h4 id="对conversion进行变换"><a class="markdownIt-Anchor" href="#对conversion进行变换"></a> 对Conversion进行变换</h4>
<hr>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">torchvision</span>.transforms.ToTensor</span><br></pre></td></tr></table></figure>
<p>把一个取值范围是[0,255]的PIL.Image或者shape为(H,W,C)的numpy.ndarray，转换成形状为[C,H,W]，取值范围是[0,1.0]的torch.FloadTensor</p>
<p><strong>call(pic)</strong></p>
<ol>
<li>参数: pic (PIL.Image or numpy.ndarray) – 图片转换为张量.</li>
<li>返回结果: 转换后的图像。</li>
<li>返回样式: Tensor张量</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">torchvision</span>.transforms.ToPILImage</span><br></pre></td></tr></table></figure>
<p>将shape为(C,H,W)的Tensor或shape为(H,W,C)的numpy.ndarray转换成PIL.Image，值不变。</p>
<p><strong>call(pic)</strong></p>
<ol>
<li>参数: pic (Tensor or numpy.ndarray) – 图像转换为pil.image。</li>
<li>返回结果: 图像转换为PIL.Image.</li>
<li>返回样式: PIL.Image</li>
</ol>
<h4 id="通用变换"><a class="markdownIt-Anchor" href="#通用变换"></a> 通用变换</h4>
<hr>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">torchvision</span>.transforms.Lambda(lambd)</span><br></pre></td></tr></table></figure>
<p>使用lambd作为转换器。</p>
<p>参数说明: lambd (function) – Lambda/function 用于转换.</p>
]]></content>
      <tags>
        <tag>machine-learning</tag>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>KD-Tree的理解</title>
    <url>/2018/04/01/kd-tree/</url>
    <content><![CDATA[<h2 id="由下图可以大致看出kd-tree的构造方式"><a class="markdownIt-Anchor" href="#由下图可以大致看出kd-tree的构造方式"></a> 由下图可以大致看出KD-Tree的构造方式：</h2>
<img data-src="/2018/04/01/kd-tree/kd-tree.png" class title="KD-Tree 理解图">
<p>首先问题是隶属于分类问题的。每个sample有若干个属性（axis），如（3，4）就是一个有两个属性的sample。我们按axis=0，1，2，…的方式分别寻找每个维度（属性）的中位数并分别划分开来，就得到了一个树状结构，这样预测一个新的数据点的时候就可以很方便的按照树状结构将其归位到某个分区里去，而不用花费大量的计算资源去计算距离了。</p>
]]></content>
      <tags>
        <tag>machine-learning</tag>
      </tags>
  </entry>
  <entry>
    <title>主要神经网络layer的合理排布顺序</title>
    <url>/2018/08/21/layer-order/</url>
    <content><![CDATA[<h3 id="开篇名义先把普遍的神经网络层的排布顺序展示出来"><a class="markdownIt-Anchor" href="#开篇名义先把普遍的神经网络层的排布顺序展示出来"></a> 开篇名义，先把普遍的神经网络层的排布顺序展示出来：</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Enter: Convlution -&gt; Batch Normalization -&gt; Relu -&gt; Max Pool</span><br><span class="line">Middle: Convlution -&gt; Batch Normalization -&gt; Relu</span><br><span class="line">Middle Complicated: -&gt; CONV/FC -&gt; BatchNorm -&gt; ReLu(or other activation) -&gt; Dropout -&gt; CONV/FC -&gt;</span><br><span class="line">Tail: Max Pool -&gt; View -&gt; (Dropout) -&gt; Fc</span><br></pre></td></tr></table></figure>
<span id="more"></span>
<h3 id="关于-max-pool-和-relu-的相对位置"><a class="markdownIt-Anchor" href="#关于-max-pool-和-relu-的相对位置"></a> 关于 Max Pool 和 Relu 的相对位置</h3>
<blockquote>
<p>If you consider the final result, both orders [conv -&gt; relu -&gt; max pooling] and [conv -&gt; max pooling -&gt; relu] will have the same outputs. But if you compare the running time of 2 ways there will be a difference.</p>
<p>To simplify the problem, just ignore layer convolution layer because it is the same in both cases.</p>
<p>Relu layer don’t change the size of the input. Let assume we use max pooling 2x2, so the size of input will be reduce by 2 in height and width when apply max poling layer ( [w, h, d] -&gt; max_pooling_2x2 -&gt; [w/2, h/2, d]).</p>
<p><strong>In case 1</strong> we using relu -&gt; max pooling the size of data will be:</p>
<p><strong>image[w, h, d] -&gt; [[relu]]</strong> -&gt;<em>image[w, h, d]-&gt;[[max pooling]]</em> -&gt; image[w/2, h/2, d]</p>
<p><strong>In case 2</strong> we using max pooling -&gt; relu the size of data will be:</p>
<p><em>image[w, h, d] -&gt;[[max pooling]]</em> -&gt; <strong>image[w/2, h/2, d]-&gt; [[relu]]</strong> -&gt; image[w/2, h/2, d]</p>
<p><strong>image[w, h, d] -&gt; [[relu]]</strong> vs <strong>image[w/2, h/2, d]-&gt; [[relu]] :</strong> case 2 save 4 time computational cost than case 1 in layer [[relu]] by using max pooling before relu.</p>
<p>In conclusion, you can save a lot of running time if you put max pooling before the non-linear layers like relu or sigmoid.</p>
</blockquote>
<h3 id="关于-max-pool-和-dropout-的相对位置"><a class="markdownIt-Anchor" href="#关于-max-pool-和-dropout-的相对位置"></a> 关于 Max Pool 和 Dropout 的相对位置</h3>
<blockquote>
<p><strong>Edit:</strong> As @Toke Faurby correctly pointed out, the default implementation in tensorflow actually uses an element-wise dropout. What I described earlier applies to a specific variant of dropout in CNNs, called <a href="https://arxiv.org/pdf/1411.4280.pdf">spatial dropout</a>:</p>
<p>In a CNN, each neuron produces one feature map. Since <s>dropout</s> <strong>spatial dropout</strong> works per-neuron, dropping a neuron means that the corresponding feature map is dropped - e.g. each position has the same value (usually 0). So each feature map is either fully dropped or not dropped at all.</p>
<p>Pooling usually operates separately on each feature map, so it should not make any difference if you apply dropout before or after pooling. At least this is the case for pooling operations like maxpooling or averaging.</p>
<p><strong>Edit:</strong> However, if you actually use <strong>element-wise</strong> dropout (which seems to be set as default for tensorflow), it actually makes a difference if you apply dropout before or after pooling. However, there is not necessarily a <em>wrong</em> way of doing it. Consider the average pooling operation: if you apply dropout before pooling, you effectively scale the resulting neuron activations by <code>1.0 - dropout_probability</code>, but most neurons will be non-zero (in general). If you apply dropout after average pooling, you generally end up with a fraction of <code>(1.0 - dropout_probability)</code> non-zero “unscaled” neuron activations and a fraction of <code>dropout_probability</code> zero neurons. Both seems viable to me, neither is outright wrong.</p>
</blockquote>
<h3 id="关于-bn-和-dropout-的相对位置"><a class="markdownIt-Anchor" href="#关于-bn-和-dropout-的相对位置"></a> 关于 BN 和 Dropout 的相对位置</h3>
<blockquote>
<p>In the <a href="https://arxiv.org/pdf/1502.03167.pdf">Ioffe and Szegedy 2015</a>, the authors state that “we would like to ensure that for any parameter values, the network always produces activations with the desired distribution”. So the Batch Normalization Layer is actually inserted right after a Conv Layer/Fully Connected Layer, but before feeding into ReLu (or any other kinds of) activation. See <a href="https://www.youtube.com/watch?v=jhUZ800C650&amp;index=5&amp;list=PLLvH2FwAQhnpj1WEB-jHmPuUeQ8mX-XXG">this video</a> at around time 53 min for more details.</p>
<p>As far as dropout goes, I believe dropout is applied after activation layer. In the <a href="https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf">dropout paper</a> figure 3b, the dropout factor/probability matrix r(l) for hidden layer l is applied to it on y(l), where y(l) is the result after applying activation function f.</p>
<p>So in summary, the order of using batch normalization and dropout is:</p>
<p>-&gt; CONV/FC -&gt; BatchNorm -&gt; ReLu(or other activation) -&gt; Dropout -&gt; CONV/FC -&gt;</p>
</blockquote>
]]></content>
      <tags>
        <tag>machine-learning</tag>
        <tag>neural-network</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux下百度网盘命令行客户端</title>
    <url>/2018/08/28/linux-baidu-netdisk/</url>
    <content><![CDATA[<h1 id="问题"><a class="markdownIt-Anchor" href="#问题"></a> 问题</h1>
<p>往Linux上上传超大文件（如数据集）或从服务器上下载训练好的模型时，用传统的scp或zssh都较慢，如果有中间跳板机，更是只能使用zssh。</p>
<h1 id="解决方案"><a class="markdownIt-Anchor" href="#解决方案"></a> 解决方案</h1>
<p><strong>使用Linux下的百度网盘客户端进行中介。</strong></p>
<p><strong>发布页面：<a href="https://github.com/iikira/BaiduPCS-Go/releases">BaiduPCS-Go</a></strong></p>
<span id="more"></span>
<h2 id="优点如下"><a class="markdownIt-Anchor" href="#优点如下"></a> 优点如下：</h2>
<ol>
<li>速度快，如果你恰好有百度网盘的会员且服务器端网速可以，甚至可以轻松跑到10M/s以上。</li>
<li>支持秒传。如果这个文件曾经被上传过一次百度云，你再次上传时一秒结束战斗。</li>
<li>多平台支持, 支持 Windows, macOS, linux, 移动设备等.</li>
<li>百度帐号多用户支持;</li>
<li>支持搜索文件。太好用了有木有。</li>
<li>通配符匹配网盘路径和 Tab 自动补齐命令和路径, <a href="https://baike.baidu.com/item/%E9%80%9A%E9%85%8D%E7%AC%A6">通配符_百度百科</a>;</li>
<li><a href="https://github.com/iikira/BaiduPCS-Go#%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%E7%9B%AE%E5%BD%95">下载</a>网盘内文件, 支持多个文件或目录下载, 支持断点续传和单文件并行下载;</li>
<li><a href="https://github.com/iikira/BaiduPCS-Go#%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6%E7%9B%AE%E5%BD%95">上传</a>本地文件, 支持上传大文件(&gt;2GB), 支持多个文件或目录上传;</li>
<li><a href="https://github.com/iikira/BaiduPCS-Go#%E7%A6%BB%E7%BA%BF%E4%B8%8B%E8%BD%BD">离线下载</a>, 支持http/https/ftp/电驴/磁力链协议.</li>
</ol>
<p>个人感觉进去了之后就像一个小的独立操作系统，支持其设定的各种命令，而且大多数和linux原生命令重合，如<code>cd</code>，<code>ls</code>，<code>search</code>等。</p>
<h2 id="使用方法"><a class="markdownIt-Anchor" href="#使用方法"></a> 使用方法</h2>
<ol>
<li>
<p>从**<a href="https://github.com/iikira/BaiduPCS-Go/releases">BaiduPCS-Go</a>**这个发布页面用wget等命令下载符合你机器cpu架构的版本。</p>
</li>
<li>
<p>解压压缩包，进入解压后目录，运行<code>./BaiduPCS-Go</code></p>
</li>
<li>
<p><code>ls</code>查看主目录，<code>cd</code>切换到你想下载的位置。</p>
</li>
<li>
<p>上传：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">BaiduPCS-Go upload &lt;本地文件/目录的路径1&gt; &lt;文件/目录2&gt; &lt;文件/目录3&gt; ... &lt;目标目录&gt;</span><br><span class="line">BaiduPCS-Go u &lt;本地文件/目录的路径1&gt; &lt;文件/目录2&gt; &lt;文件/目录3&gt; ... &lt;目标目录&gt;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>下载：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">BaiduPCS-Go download &lt;网盘文件或目录的路径1&gt; &lt;文件或目录2&gt; &lt;文件或目录3&gt; ...</span><br><span class="line">BaiduPCS-Go d &lt;网盘文件或目录的路径1&gt; &lt;文件或目录2&gt; &lt;文件或目录3&gt; ...</span><br></pre></td></tr></table></figure>
</li>
</ol>
]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux系统GPU服务器选择调研</title>
    <url>/2018/08/19/linux-gpu-server-choice/</url>
    <content><![CDATA[<h2 id="主要方向"><a class="markdownIt-Anchor" href="#主要方向"></a> 主要方向</h2>
<ol>
<li>
<p>自行组装一台GPU Linux机器。网上许多教程都是教人如何DIY的。这种方案的优点是不但便宜不少，而且还可以从中学习到很多相关知识，如果您有这个需求，并且也有时间、想学习相关内容，或是对价格比较敏感，DIY是一个相对较好的选择。但是缺点也是存在的。首先是售后服务问题，一旦机器出了故障，维修可能会相对比较麻烦，尤其是在您自身也对此不是很专业的情况下。另外是自行DIY可能会产生搭配不合理的问题，比如选用了散热性能不足的器材、最大功率不足的电源等，这些都会为您未来的使用带来隐患。</p>
<span id="more"></span>
</li>
<li>
<p>在各大购物网站上购买组装完成的“深度学习机器”。这种机器的缺点是贵，优点是真心方便而且相对来说会更有保障。尤其是在比较负责的平台上购买的机器可以得到贴心的售后服务，而且机子的各个部分都经过专业人士的挑选，质量相对有保障，不会轻易发生电源线起火、散热不足导致GPU故障等问题（相对的）。另外值得一提的是，现在市面上卖的“深度学习机器”往往还预装好了Linux系统和诸如TensorFlow、Pytorch等主流框架、Anaconda以及CUDA等驱动。如果您所在的团队中没有对机器配置十分了解的成员，并不愿意花费这个时间成本去学习相关知识，这种现成的专用机其实是一个很好的选择。</p>
</li>
</ol>
<h2 id="参考来源"><a class="markdownIt-Anchor" href="#参考来源"></a> 参考来源</h2>
<p>这篇博客中我不会自行详细分析如何组装，而是一篇调研，所以会附上我参考过的各个信息源，并在文末贴出英文PPT。</p>
<ul>
<li><a href="http://nicholasyuan.com/deeplearning/2016/10/07/buy-computer.html">深度学习攒机小记 by nicholas</a></li>
<li><a href="http://www.52nlp.cn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%BB%E6%9C%BA%E6%94%92%E6%9C%BA%E5%B0%8F%E8%AE%B0">深度学习主机攒机小记</a></li>
<li><a href="http://www.52nlp.cn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%BB%E6%9C%BA%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE-ubuntu16-04-geforce-gtx1080-tensorflow">深度学习主机环境配置: Ubuntu16.04+GeForce GTX 1080+TensorFlow</a></li>
<li><a href="https://www.zhihu.com/question/33996159/answer/157949879">如何配置一台适用于深度学习的工作站</a></li>
<li><a href="https://docs.google.com/spreadsheets/d/111PwO4C4Clh16nUaAKACx46scQKaEntd6QGua8_pyIw/edit#gid=968981801">Deep Learning GPUs 详细对比表格</a></li>
<li><a href="http://mli.github.io/gpu/2016/01/17/build-gpu-clusters/">GPU集群折腾手记——2015</a></li>
<li><a href="https://oldpan.me/archives/machine-deeplearning-station-list">给你一份配置清单:机器学习、深度学习电脑显卡配置指南</a></li>
<li><a href="https://www.cnblogs.com/xuliangxing/p/7543977.html">深度学习（TensorFlow）环境搭建：（一）硬件选购和主机组装</a></li>
<li><a href="http://www.52nlp.cn/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%90%AD%E5%BB%BA%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AEubuntu-1080ti-cuda-cudnn">从零开始搭建深度学习服务器: 基础环境配置（Ubuntu + GTX 1080 TI + CUDA + cuDNN）</a></li>
</ul>
<h2 id="阶段性结论"><a class="markdownIt-Anchor" href="#阶段性结论"></a> 阶段性结论</h2>
<p>通过参考以上各博文，以及在一些实际购物网站的调查，大致可以得出以下的结论：对于一个小型团队，或是团队中做深度学习的成员较少时，当前购买双路GTX 1080Ti，搭配Intel Core i7 7800X/7900X 是一个理想的选择。如果不想花费太多时间，或是想马上部署并展开应用的团队，在京东/淘宝（国内）亚马逊（美国）等处购买整机也是一个不错的选择。</p>
<h2 id="ppt细节"><a class="markdownIt-Anchor" href="#ppt细节"></a> PPT细节</h2>
<p>![Linux GPU Server Choice.001](…/…/…/…/…/Desktop/Linux GPU Server Choice/Linux GPU Server Choice.001.jpeg)</p>
<p><img data-src="006tNbRwgy1fufzby2xj4j30k00f0tbx.jpg" alt="Linux GPU Server Choice.012"></p>
<p><img data-src="006tNbRwgy1fufzbuhx6uj30k00f0taa.jpg" alt="Linux GPU Server Choice.006"></p>
<p><img data-src="006tNbRwgy1fufzc03y46j30k00f077r.jpg" alt="Linux GPU Server Choice.011"></p>
<p><img data-src="006tNbRwgy1fufzbvekw6j30k00f0taa.jpg" alt="Linux GPU Server Choice.013"></p>
<p>![Linux GPU Server Choice.005](…/…/…/…/…/Desktop/Linux GPU Server Choice/Linux GPU Server Choice.005.jpeg)</p>
<p><img data-src="006tNbRwgy1fufzbu3ew2j30k00f0q5e.jpg" alt="Linux GPU Server Choice.004"></p>
<p><img data-src="006tNbRwgy1fufzc1q3hvj30k00f0mzq.jpg" alt="Linux GPU Server Choice.010"></p>
<p><img data-src="006tNbRwgy1fufzg8grkgj30k00f0wp8.jpg" alt="Linux GPU Server Choice.008"></p>
<p><img data-src="006tNbRwgy1fufzc3eq2qj30k00f0gqn.jpg" alt="Linux GPU Server Choice.001"></p>
<p><img data-src="006tNbRwgy1fufzc2rh4uj30k00f0goe.jpg" alt="Linux GPU Server Choice.009"></p>
<p><img data-src="006tNbRwgy1fufzc15854j30k00f0tex.jpg" alt="Linux GPU Server Choice.007"></p>
<p><img data-src="006tNbRwgy1fufzbyzq43j30k00f078j.jpg" alt="Linux GPU Server Choice.003"></p>
<p><img data-src="006tNbRwgy1fufzbwuz9zj30k00f0dn9.jpg" alt="Linux GPU Server Choice.002"></p>
<p>![Linux GPU Server Choice.014](…/…/…/…/…/Desktop/Linux GPU Server Choice/Linux GPU Server Choice.014.jpeg)</p>
]]></content>
      <tags>
        <tag>linux</tag>
        <tag>GPU</tag>
        <tag>server</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 查看服务器开放的端口号</title>
    <url>/2018/08/27/linux-open-port/</url>
    <content><![CDATA[<h1 id="问题"><a class="markdownIt-Anchor" href="#问题"></a> 问题</h1>
<p>如何确定一台Linux主机上有哪些端口正在使用。</p>
<h1 id="解决方案"><a class="markdownIt-Anchor" href="#解决方案"></a> 解决方案</h1>
<ol>
<li>安装<strong>nmap工具检测开放端口</strong>：<code>apt-get install nmap</code></li>
<li>查看本机活跃端口：<code>nmap 127.0.0.1</code></li>
</ol>
]]></content>
      <tags>
        <tag>linux</tag>
        <tag>server</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux(Ubuntu)装机与配置笔记</title>
    <url>/2022/04/11/linux-setup/</url>
    <content><![CDATA[<h2 id="硬盘相关">硬盘相关</h2>
<ol type="1">
<li><p><strong>df命令</strong> <code>df</code>：检查linux服务器的文件系统的磁盘空间占用情况。<strong>它只会显示已经挂载的磁盘信息！</strong></p>
<p><code>df -h</code>, 即<code>--human-readble</code>：以1024的倍数的方式显示大小。(e.g., 1023M)</p>
<p><code>df -T</code>：查看所有磁盘的文件系统类型(type)</p>
<span id="more"></span></li>
<li><p><strong><code>fdisk</code>命令</strong></p>
<p><code>fdisk</code>：强大的磁盘监视和操作工具。</p>
<p><code>fdisk -l</code>会显示<strong>所有的</strong>磁盘和分区！不论有没有挂载，都会被列出来。</p></li>
<li><p><strong>mount命令</strong></p>
<p><code>mount</code>：挂载一个文件系统</p>
<p><code>mount -t ntfs &lt;source&gt; &lt;target&gt;</code>：以ntfs文件系统的形式从源目录挂载到目标目录。t表示types类型</p>
<p><code>mount -a</code>：挂载 fstab 中的所有文件系统。a表示all</p></li>
<li><p><strong>blkid命令</strong></p>
<p><code>sudo blkid</code>：获取各个分区的UUID和分区类型TYPE</p></li>
<li><p>物理磁盘与磁盘分区：一个物理磁盘在<code>fdisk -l</code>中的显示往往类似于<code>/dev/sda</code>，<code>/dev/sdb</code>，<code>/dev/nvme0n1</code>。一般情况下是不带数字的，sda sdb是最常见的命名。而分区命名则是如：<code>/dev/sda1</code>，<code>/dev/sdb2</code>之类在物理磁盘的后面带上数字表示分区编号。</p>
<p>但有些如双系统中，可能会出现最后一个例子中展示的命名，这种磁盘的分区则是以<code>p[x]</code>结尾，如<code>/dev/nvme0n1p1</code>，<code>/dev/nvme0n1p9</code>。</p></li>
<li><p>Linux开机后不会自动挂载Windows文件格式NTFS的磁盘。</p></li>
<li><p><code>sudo chmod -R 777 &lt;Folder_Name&gt;</code> 可以取消一个文件夹的全部访问权限。</p></li>
<li><p><code>chmod</code>命令对ext3/4文件系统，即Linux格式的文件系统才有效，对其他文件系统，如vfat(Fat32)，NTFS都是无效的。</p></li>
<li><p>/etc/fstab` 文件是掌管硬盘自动挂载配置的文件，包含自动挂载分区过程的必要信息。每一条记录格式如下：</p>
<p><code>[Device] [Mount Point] [File System Type] [Options] [Dump] [Pass]</code></p>
<p>如：</p>
<p><code>UUID=B45A01D55A019570 /data ntfs defaults 0 2</code></p>
<p>其中：</p>
<p><code>[Options]</code> ：<code>defaults</code>表示用默认的<code>rw, suid, dev, exec, auto, nouser, async</code>等选项（不同内核和文件系统不同）进行挂载，这些选项的含义：<code>rw</code> 可读写；<code>suid</code> 执行程序时遵守<code>uuid</code>；<code>dev</code> 解释字符或禁止特殊设备；<code>exec</code> 允许执行二进制文件；<code>auto</code> 可以<code>-a</code>方式加载；<code>nouser</code> 禁止普通用户挂载此文件系统；<code>async</code> 所有I/O异步完成。</p>
<p><code>[Dump]</code> ：是否开启分区备份，0表示关闭</p>
<p><code>[Pass]</code>：系统启动时检查分区错误的顺序，root为1，其他为2，0为不检查。</p></li>
<li><p>在<code>fstab</code>文件中添加记录前一定要先尝试用mount命令手动挂载。</p></li>
</ol>
<h3 id="参考">参考</h3>
<ol type="1">
<li><a href="https://blog.csdn.net/qxqxqzzz/article/details/89790688">Ubuntu18.04 开机自动挂载其他硬盘</a></li>
<li><a href="https://blog.csdn.net/ybdesire/article/details/79145180">Linux查看与挂载新磁盘</a></li>
</ol>
<h2 id="cuda的安装">CUDA的安装</h2>
<ol type="1">
<li><p>这里是官方<a href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/#environment-setup">指南</a>，注意使用左侧的导航链接，以免翻看中看漏信息。下载链接在<a href="https://developer.nvidia.com/cuda-downloads">这里</a>。</p></li>
<li><p>检查自己的GPU是否是CUDA-capable，在终端中输入<code>lspci | grep -I NVIDIA</code> ，会显示自己的NVIDIA GPU版本信息，去CUDA的官网查看自己的GPU版本是否在CUDA的支持列表中。</p></li>
<li><p>检查自己的Linux版本是否支持 CUDA（Ubuntu 稳定支持版没问题）。</p></li>
<li><p>检查其他问题。这里就不详述了，正常情况下一般OK，这里主要要检查是否安装了<code>gcc</code>，是否安装了<code>kernel header</code>和 <code>package development</code>。如果害怕出现问题可以参考<a href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#pre-installation-actions">官网</a>执行这几步检测。</p></li>
<li><p>于<a href="https://developer.nvidia.com/cuda-downloads">CUDA官网</a>下载与系统对应的CUDA版本。最后一个选项选择<code>runfile</code>，因为其所需步骤最少，也因此最不容易出问题。所有选项完成后，你会看到如下两行命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget http://developer.download.nvidia.com/compute/cuda/10.2/Prod/local_installers/cuda_10.2.89_440.33.01_linux.run</span><br><span class="line">sudo sh cuda_10.2.89_440.33.01_linux.run</span><br></pre></td></tr></table></figure>
<p>先不要执行第二条<code>sudo</code>开头的指令，只使用<code>wget</code>下载。</p></li>
<li><p>如果之前有安装过其他版本的CUDA并希望将其卸载，使用<code>sudo nvidia-uninstall</code>卸载。如果该命令不在系统路径中，则使用<code>sudo /usr/bin/nvidia-uninstall</code>（位置可能变化）卸载。如果还是没有，或是之前的驱动已经损坏，则：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt-get remove --purge nvidia*</span><br><span class="line">sudo <span class="built_in">chmod</span> +x NVIDIA-Linux-x86_64-410.93.run</span><br><span class="line">sudo ./NVIDIA-Linux-x86_64-410.93.run --uninstall</span><br></pre></td></tr></table></figure></li>
<li><p>屏蔽<code>nouveau</code>驱动。</p></li>
</ol>
<h3 id="nouveau是什么">Nouveau是什么</h3>
<blockquote>
<h4 id="nouveau-accelerated-open-source-driver-for-nvidia-cards">Nouveau: Accelerated Open Source driver for nVidia cards</h4>
<p>The <strong>nouveau</strong> project aims to build high-quality, free/libre software drivers for <a href="https://nouveau.freedesktop.org/wiki/CodeNames/">nVidia cards</a>. “Nouveau” [<em>nuvo</em>] is the French word for “new”. Nouveau is composed of a Linux kernel KMS driver (nouveau), Gallium3D drivers in Mesa, and the Xorg DDX (xf86-video-nouveau). The kernel components have also been ported to <a href="https://nouveau.freedesktop.org/wiki/NetBSD/">NetBSD</a>.</p>
</blockquote>
<p>简单说，nouveau是Linux系统默认的给NVIDIA卡预装的一个图形加速驱动，而这个驱动会与CUDA产生部分冲突，所以在安装CUDA之前需要将其禁用，否则会出现卡在开机登录界面无法进入图形界面（仍然可以ssh访问），黑屏，鼠标键盘输入被禁用等问题中的一个或多个（亲身经历）。</p>
<p>继续安装教程：</p>
<ol start="6" type="1">
<li><p>刚才说到要屏蔽<code>nouveau</code>，那么怎么知道你有没有装它呢？ 使用<code>lsmod | grep nouveau</code>命令，如果没有输出，就可以判定你没有运行<code>nouveau</code>，可以直接进入下一步，否则：</p>
<ol type="1">
<li><p>Create a file at <code>/etc/modprobe.d/blacklist-nouveau.conf</code> with the following contents:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">blacklist nouveau</span><br><span class="line">options nouveau modeset=0</span><br></pre></td></tr></table></figure></li>
<li><p>Regenerate the kernel initramfs:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo update-initramfs -u</span><br></pre></td></tr></table></figure></li>
<li><p>Restart.</p></li>
<li><p>Run <code>lsmod | grep nouveau</code> again. If there is no output, then you succeed.</p></li>
</ol></li>
<li><p>此后建议进入一个非图形界面安装，这里可以在重启后使用<code>ssh</code>接入，也可以在重启后按<code>alt+ctrl+f1</code>，进入<strong>text mode</strong>，登录账户。</p></li>
<li><p>输入 <code>sudo service lightdm stop</code> 关闭图形化界面。</p></li>
<li><p>执行刚才官网中给出的第二条命令：<code>sudo sh cuda_10.2.89_440.33.01_linux.run</code>。注意这里的版本会不断有变化。注意这里有一个点，即你是否要同时安装OpenGL，如果你是双显，且主显是非NVIDIA的GPU需要选择no，否则yes。同理，如果准备选no，也可以一开始就加上参数<code>--no-opengl-files</code>。 另外，如果不能直接执行，使用<code>sudo chmod a+x cuda_xx.xx.xx_linux.run</code>为其赋权。</p></li>
<li><p>安装成功后，会提示你将cuda的几个路径添加到系统路径中，这里重复一下，</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> PATH=/usr/local/cuda-10.2/bin:/usr/local/cuda-10.2/NsightCompute-2019.1<span class="variable">$&#123;PATH:+:<span class="variable">$&#123;PATH&#125;</span>&#125;</span></span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=/usr/local/cuda-10.2/lib64\</span><br><span class="line">                         <span class="variable">$&#123;LD_LIBRARY_PATH:+:<span class="variable">$&#123;LD_LIBRARY_PATH&#125;</span>&#125;</span></span><br></pre></td></tr></table></figure></li>
<li><p>使用<code>nvcc -V</code>检测是否安装成功。当然也可以同时测试<code>nvidia-smi</code>。这里可能会报错并提示需要apt安装一个包，按提示来。</p></li>
<li><p>此时可能要再安装一个nvidia driver，具体适配版本可以在<a href="https://www.nvidia.com/download/index.aspx">这里</a>找到。</p></li>
<li><p>reboot，此时你可能会发现GUI的登录界面消失了，你面对的只有一个空白的壁纸/纯色。不要慌张，只要切换一下display manager就好了。如果你默认的是<code>gbm3</code> display manager，那最简单的方法就是直接安装<code>lightdm</code>并切换过去就好了。</p>
<p>首先按<code>CTRL+ALT+F5</code>进入纯命令行模式，然后输入：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt install lightdm</span><br><span class="line">sudo dpkg-reconfigure lightdm</span><br></pre></td></tr></table></figure>
<p>如果提示服务没起来，用<code>sudo systemctl start lightdm</code>。</p></li>
<li><p>完成。</p></li>
</ol>
<h2 id="nvidia-driver-的安装与使用">NVIDIA Driver 的安装与使用</h2>
<p>这里需要澄清一个问题，即NVIDIA Driver，NVIDIA utils (390), CUDA 之间的关系。NVIDIA Driver是需要单独安装的，它与Nouveau是并列关系。系统默认的<strong>显卡驱动</strong>是后者。utils 是服务于Driver的，比如<code>nvidia-smi</code>, <code>nvidia-settings</code>等就是utils的组件。而CUDA是建构在Driver之上的一个服务于深度学习程序的<strong>指令转换器</strong>，所以要现有前两者，CUDA才能正常运行。</p>
<p>安装Driver有两种方法，一种是在GUI中的<strong>Software &amp; Updates</strong>中选择Additional Drivers中的第一行<strong>Proprietary, tested</strong>的那个NVIDIA Driver选项，然后Apply Changes即可。</p>
<figure>
<img data-src="ubuntu-18.04-nvidia-drivers-430.png" alt="ubuntu 18.04 nvidia-drivers 430"><figcaption aria-hidden="true">ubuntu 18.04 nvidia-drivers 430</figcaption>
</figure>
<p>也可以在命令行中用<code>sudo ubuntu-drivers autoinstall</code> 选项来进行安装。这里就不展开了，<a href="https://www.linuxbabe.com/ubuntu/install-nvidia-driver-ubuntu-18-04">这篇文章</a>讲的非常详细。</p>
<h3 id="error-shooting">Error Shooting</h3>
<ul>
<li>如果系统分辨率突然被固定为了一个很小的数值，且无法调整，请尝试<code>nvcc --version</code>和<code>nvidia-smi</code>，往往是由于CUDA相关的两个路径没有很好的添加到正确的位置。如果想保险，直接在<code>~/.bashrc</code>或<code>~/.zshrc</code>中添加那两行<code>export</code>命令，然后重启。</li>
<li>如果你电脑物理连接了两个显示器，而你登录后发现桌面是空的，也没有Dock，什么都没有，有可能是他们在另一个显示器上，即使你没打开那个显示器。</li>
</ul>
<h3 id="参考-1">参考</h3>
<ol type="1">
<li><a href="https://developer.nvidia.com/cuda-downloads">NVIDIA CUDA下载官网</a></li>
<li><a href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html">NVIDIA 官方安装指南（英文）</a></li>
<li><a href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#pre-installation-actions">NVIDIA 官方安装指南中前置检查部分</a></li>
<li><a href="https://www.pugetsystems.com/labs/hpc/How-To-Install-CUDA-10-together-with-9-2-on-Ubuntu-18-04-with-support-for-NVIDIA-20XX-Turing-GPUs-1236/">How To Install CUDA 10 (together with 9.2) on Ubuntu 18.04 with support for NVIDIA 20XX Turing GPUs</a></li>
<li><a href="https://blog.csdn.net/lipi37/article/details/90407099">Ubuntu 安装 cuda 时卡在登录界面（login loop)的解决方案之一</a></li>
<li><a href="https://blog.csdn.net/wkk15903468980/article/details/56489704">ubuntu安装cuda循环登录</a></li>
<li><a href="https://blog.csdn.net/qq_33200967/article/details/80689543">Ubuntu安装和卸载CUDA和CUDNN</a></li>
<li><a href="https://blog.csdn.net/wf19930209/article/details/81879514">Linux安装CUDA的正确姿势</a></li>
</ol>
<h2 id="cuda-与-cudnn-的联系">CUDA 与 CUDNN 的联系</h2>
<ol type="1">
<li>要先装CUDA再装CUDNN。</li>
<li>前者是平台，后者是基于平台的深度学习加速器。加速可以应用于几乎全部深度学习平台。还是要安的。</li>
<li>一般深度学习使用安装runtime版本即可。</li>
<li><a href="https://developer.nvidia.com/rdp/cudnn-download">CUDNN官方下载</a>，<a href="https://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html">CUDNN官方安装步骤</a></li>
</ol>
<h2 id="修复ubuntu中检测到系统程序错误的问题">修复Ubuntu中“检测到系统程序错误”的问题</h2>
<h3 id="问题描述">问题描述</h3>
<p>每次开机时都会有“<strong>Ubuntu xx.xx 在启动时检测到系统程序错误</strong> ”弹窗出现。即使点击报告下次还会继续出现。</p>
<h3 id="问题来源">问题来源</h3>
<p>之前的某个时刻某个程序崩溃了，而Ubuntu想让你决定要不要把这个问题报告给开发者，这样他们就能够修复这个问题。</p>
<h3 id="解决办法">解决办法</h3>
<ol type="1">
<li><code>sudo rm /var/crash/*</code> ：删除这些错误报告。但是如果又有一个程序崩溃了，你就会再次看到“检测到系统程序错误”的错误。你可以再次删除这些报告文件，或者选择禁用Apport来彻底地摆脱这个错误弹窗。如果你这样做，系统中任何程序崩溃时，系统都不会再通知你。但这未必一件坏事，除非你愿意填写错误报告。如果你不想填写错误报告，那么这些错误通知存不存在都不会有什么区别。</li>
<li><code>sudo vim /etc/default/apport</code> 永久屏蔽这些报错。</li>
</ol>
<h3 id="参考-2">参考</h3>
<ol type="1">
<li><a href="https://blog.csdn.net/hywerr/article/details/72582082">如何修复ubuntu中检测到系统程序错误的问题</a></li>
<li><a href="https://itsfoss.com/how-to-fix-system-program-problem-detected-ubuntu/">How To Fix System Program Problem Detected In Ubuntu</a></li>
</ol>
<h2 id="安装python3.6版本的anaconda">安装Python3.6版本的Anaconda</h2>
<p>由于之前使用的一些开源库和软件对3.7的支持性尚还有问题，而Anaconda默认Python版本为3.6， 所以有必要把Anaconda降级为3.6版本。</p>
<p>安装方法：</p>
<ol type="1">
<li><p>到Anaconda官网下载并安装最新3.7版本。</p></li>
<li><p>世界线开始分歧，你可以选择保留3.7版本的Anaconda，并创建一个虚拟环境，或是直接替换Python版本。</p>
<ol type="1">
<li><p>对前者， 若只要一个python环境不要packages，</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda create --name ana36 python=3.6</span><br><span class="line"><span class="built_in">source</span> activate ana36</span><br></pre></td></tr></table></figure>
<p>反之，如果要安装一个新的Anaconda，包含默认的所有packages，</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda create -n ana36 anaconda python=3.6</span><br><span class="line"><span class="built_in">source</span> activate ana36</span><br></pre></td></tr></table></figure></li>
<li><p>对后者，</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda install python=3.6</span><br></pre></td></tr></table></figure></li>
</ol></li>
</ol>
<h2 id="添加vim拷贝至系统剪贴板快捷键支持">添加Vim拷贝至系统剪贴板快捷键支持</h2>
<p>(from: <a href="http://vim.wikia.com/wiki/Mac_OS_X_clipboard_sharing">link</a>)</p>
<p>Having trouble copying selected text from Vim (not MacVim)? Since using <code>"+y</code> or '"*y' in Vim on a Mac doesn't actually copy the selected text to the system clipboard, you might find it beneficial to do the following:</p>
<ol type="1">
<li>Open your <code>~/.vimrc</code> file</li>
<li>add <code>vmap '' :w !pbcopy</code></li>
<li>Save it and <code>source</code> the file</li>
</ol>
<p>现在，你就可以在 visual mode， 即在Esc命令模式后按下v键后的选择模式中，选好需要拷贝区域后，连击两次<code>'</code> ，即使用 <code>''</code>来拷贝所选区域。</p>
<h2 id="在maclinux上使用ssh挂载远程网络硬盘">在Mac/Linux上使用ssh挂载远程网络硬盘</h2>
<p>TL;DR：</p>
<ol type="1">
<li>安装sshfs: <code>sudo apt-get install sshfs</code></li>
<li>直接在<code>~/.zshrc</code>中添加以下行：（当然，需要更改文件夹名称，以及挂载后的命名）</li>
</ol>
<h3 id="连接本地linux-server">连接本地Linux Server</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">connect_misaka</span></span> () &#123;</span><br><span class="line">    <span class="keyword">if</span> [ ! -d <span class="string">&quot;/Volumes/misaka-home&quot;</span> ]</span><br><span class="line">    <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">mkdir</span> /Volumes/misaka-home</span><br><span class="line">        sshfs -o allow_other,default_permissions,IdentityFile=~/.ssh/id_rsa,reconnect,ServerAliveInterval=15,ServerAliveCountMax=3 misaka:/home/miracle /Volumes/misaka-home/ -ovolname=mk-home</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">if</span> [ ! -d <span class="string">&quot;/Volumes/misaka-storage&quot;</span> ]</span><br><span class="line">    <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">mkdir</span> /Volumes/misaka-storage</span><br><span class="line">        sshfs -o allow_other,default_permissions,IdentityFile=~/.ssh/id_rsa,reconnect,ServerAliveInterval=15,ServerAliveCountMax=3 misaka:/data /Volumes/misaka-storage/ -ovolname=mk-2T</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="连接gypsum">连接Gypsum</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">connect_gypsum</span></span> () &#123;</span><br><span class="line">    <span class="keyword">if</span> [ ! -d <span class="string">&quot;/Volumes/gypsum/&quot;</span> ]</span><br><span class="line">    <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">mkdir</span> /Volumes/gypsum</span><br><span class="line">        sshfs -o allow_other,default_permissions,IdentityFile=~/.ssh/id_rsa,reconnect,ServerAliveInterval=15,ServerAliveCountMax=3 gypsum:/home/zhongyangzha /Volumes/gypsum/ -ovolname=gp-home</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">if</span> [ ! -d <span class="string">&quot;/Volumes/gypsum-scratch/&quot;</span> ]</span><br><span class="line">    <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">mkdir</span> /Volumes/gypsum-scratch/</span><br><span class="line">        sshfs -o allow_other,default_permissions,IdentityFile=~/.ssh/id_rsa,reconnect,ServerAliveInterval=15,ServerAliveCountMax=3 gypsum:/mnt/nfs/scratch1/zhongyangzha/ /Volumes/gypsum-scratch/ -ovolname=gp-scratch</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">if</span> [ ! -d <span class="string">&quot;/Volumes/gypsum-work/&quot;</span> ]</span><br><span class="line">    <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">mkdir</span> /Volumes/gypsum-work</span><br><span class="line">        sshfs -o allow_other,default_permissions,IdentityFile=~/.ssh/id_rsa,reconnect,ServerAliveInterval=15,ServerAliveCountMax=3 gypsum:/mnt/nfs/work1/trahman/zhongyangzha /Volumes/gypsum-work/ -ovolname=gp-work</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="参数解释">参数解释</h3>
<ol type="1">
<li><code>ovolname</code>：挂载上网络硬盘之后硬盘的命名</li>
<li><code>IdentityFile</code>：如果已经设置了免密登录，用这个参数指明ssh私钥位置即可，不需要输入密码。</li>
<li><code>&lt;source&gt; &lt;target&gt;</code>：网络硬盘源位置&lt;username@ip.address:/the/source/path&gt; 与本机目标挂载位置</li>
<li><code>reconnect,ServerAliveInterval=15,ServerAliveCountMax=3</code>：多次断线重连，可以再断开网络连接、服务器重启等问题发生后再次自动连接。</li>
</ol>
<h2 id="硬盘相关-1">硬盘相关</h2>
<h3 id="硬盘信息查看三幻神">硬盘信息查看三幻神</h3>
<ol type="1">
<li><code>sudo fdisk -l</code>: 最为详细全面的硬盘信息，既包含了已挂载的盘，也包含了未挂载的盘。其含有磁盘在<code>/dev</code>中的位置，size（非常详细，既有易于阅读的单位MB/GB等，也有精确到字节和扇区的信息），硬盘型号，disklabel型号（GPT DOS）等。</li>
<li><code>df -h</code>: 含有所有当前已挂载的磁盘的信息，包括<code>/dev</code>位置，总空间，已用空间和可用空间，利用率，以及挂载点位置。</li>
<li><code>sudo blkid</code>: 全部（已挂载+未挂载）的硬盘信息，包括<code>/dev</code>位置，文件系统类型（ntfs，ext4，fat32等），Label（就是Windows上写的卷名），UUID，以及Partition UUID。</li>
</ol>
<h3 id="为什么有的硬盘开机就自动挂载了而另一些则没有">为什么有的硬盘开机就自动挂载了，而另一些则没有</h3>
<ol type="1">
<li>在我遇到的情况里，什么都不用做就会自动挂载的是外置的USB盘符，它们其实是开机之后被一个个load起来的。而装在主机里面的那些硬盘，则需要额外进行设置以便能开机自动挂载。</li>
<li>设置方法：<code>sudo vim /etc/fstab</code>进行编辑即可。每个想要挂在的盘各自写一行，每行包括设备UUID，挂载点，文件系统，以及后面不怎么用改的三个参数（用 <code>default 0 0</code>填充即可）。这些信息的查看方法在上个小节有提。</li>
</ol>
]]></content>
      <tags>
        <tag>python</tag>
        <tag>machine-learning</tag>
        <tag>deep-learning</tag>
        <tag>linux</tag>
        <tag>ssh</tag>
        <tag>net-disk</tag>
        <tag>cuda</tag>
      </tags>
  </entry>
  <entry>
    <title>今日PPT汇报感想</title>
    <url>/2018/03/09/liu-criticize/</url>
    <content><![CDATA[<p>今天中午做了招新宣讲会的PPT展示试讲工作。试讲了两次都被刘玉老师严厉的批评了，之后钟老师特地陪我走回了寝室，路上的一番话给了我很多的启示。十分感谢钟老师的平易近人的谈心，确实让我认识到了不少之前没有注意或是注意了却没有着手去改正的问题，在大学阶段还能遇到这样真的关心自己的导师实在是太幸福了。刘老师确实对我很严厉，不过每次被骂仔细想想都能让我认真反思一些深处的问题，从而能让其得以及时的解决，的确让我很敬佩。这几天经历的一些事情给我的感受：</p>
<span id="more"></span>
<ul>
<li>不要试图去为一些改变不了的事情解释。因为即使说了也改变不了什么，反而会使得交谈双方都不愉快</li>
<li>自己认为的“友好的”解释往往可能是对方眼中的辩解，尤其不要经常性的解释，即使有想要纠正的点，留到最后一起讲会给人更加礼貌的直观感受</li>
<li>倾向于解释可以看做是急于得到别人承认的表现，其实真正做了事情之后，反而是沉默点更能引起别人尊重，事情永远是摆在那里的</li>
<li>和平级或是下级的人讲话时可以较为及时的提出异议，但面对上级、长辈的时候更多的听会让人觉得你更尊重别人</li>
<li>刘老师说的问题往往是客观存在的，耐心的听取更有经验的人的意见会使你更加快速的进步</li>
<li>我性格方面过于喜欢表现和说话，而在做的事情同样多的时候，过多的表现往往会使得别人降低对你的看法</li>
<li>多观察别人的做法，多观察同样的事情更有经验的人怎么处理，说的太多解释往往会让自己错失良机</li>
<li>不要怕犯错，一开始做总会有这样那样的问题的，不过你要学会从中学到一些什么，作为自己的经验</li>
</ul>
<p>以上。希望后面真的可以用时间的染缸来让自己染上这些优雅的颜色。</p>
]]></content>
      <tags>
        <tag>essay</tag>
      </tags>
  </entry>
  <entry>
    <title>避免脏活，完美使用Markdown在知乎编辑内容</title>
    <url>/2020/04/26/markdown-4-zhihu/</url>
    <content><![CDATA[<p>知乎上的本文链接：<a href="https://zhuanlan.zhihu.com/p/97455277">Link</a></p>
<p>首先吐槽一下知乎的编辑器。虽然个人博客上的不少内容都曾有想过搬到知乎一份，但是知乎的编辑器真的是令人绝望式的难用。尽管现在可以使用文件导入功能导入md文件和Word文档，且能支持一些简单的Markdown语法，但每种途径都有着无法避免的缺点，从结果上来说则是只能被迫接受或是不完美的格式亦或是大量手动且重复的图片上传。</p>
<p>口说无凭，这里放一下几种方法的对比图来详述一下问题所在：</p>
<span id="more"></span>
<h3 id="typora中原文件"><a class="markdownIt-Anchor" href="#typora中原文件"></a> Typora中原文件</h3>
<img data-src="./image-20191214174243537.png" alt="image-20191214174243537" style="zoom:50%;">
<p>这份测试文件虽然短，但是基本包含了常见几种要素：标题、正文、图片、表格、代码、公式。下面让我们看看知乎支持的几种上传方式的效果：</p>
<h3 id="1-直接复制typora中的内容到知乎编辑器"><a class="markdownIt-Anchor" href="#1-直接复制typora中的内容到知乎编辑器"></a> 1. 直接复制Typora中的内容到知乎编辑器</h3>
<img data-src="./image-20191214174118623.png" alt="image-20191214174118623" style="zoom:50%;">
<p>可以看到，标题和正文区分开了，不过所有的标题都变成了一级标题。另外本地的图片无法导入，只剩下一个展占位符。表格全乱，公式直接消失了。但代码的高亮仍是C++，正确。</p>
<h3 id="2-直接导入markdown文件"><a class="markdownIt-Anchor" href="#2-直接导入markdown文件"></a> 2. 直接导入Markdown文件</h3>
<p>你可以在编辑器的这个位置导入文件：</p>
<img data-src="./image-20191214174529632.png" alt="image-20191214174529632" style="zoom:33%;">
<img data-src="./image-20191214174506716.png" alt="image-20191214174506716" style="zoom:33%;">
<p>导入刚才我们看到的测试文件原档的效果是这样的：</p>
<img data-src="./image-20191214174704023.png" alt="image-20191214174704023" style="zoom:50%;">
<p>同前，标题和正文区分开了，不过所有的标题都变成了一级标题。另外本地的图片无法导入，只剩下一个占位符。表格全乱，公式没有消失，但也并没有被渲染。代码的高亮仍是C++，正确。</p>
<h3 id="3-先使用typora导出为word再用知乎编辑器导入word"><a class="markdownIt-Anchor" href="#3-先使用typora导出为word再用知乎编辑器导入word"></a> 3. 先使用Typora导出为Word，再用知乎编辑器导入Word</h3>
<p>上面的两种最直观的方法的一大问题就是图片导入不进去。而对于一些长篇的科技文章，图片既多又重要，手动一个个添加容易错而且浪费科研人员的时间和热情。当然我知道导入Markdown时并没有顺带把图片本身导入进去，但我仍觉得这是知乎团队应该做的工作，而且是相当基本的工作。好吧，既然现在不可行，那么导出成Word再导入该不会有这个问题了吧，我们来看看：</p>
<img data-src="./image-20191214175626414.png" alt="image-20191214175626414" style="zoom:50%;">
<p>好家伙，图片导入进去了，表格直接炸飞天了，而且更可气的是代码的高亮没了，格式也出现了问题。其他的嘛，不看不得了，一看发现公式似乎直接没了，中间还莫名其妙多了一堆空行。当然，标题等级的问题还是没解决。</p>
<p>那是Typora导出Word导出的不好吗？我打开了导出的Word文件：</p>
<img data-src="./image-20191214180048117.png" alt="image-20191214180048117" style="zoom:50%;">
<p>公式存在，高亮正确，标题等级正确，表格正确，没有奇怪的空行。虽然和Markdown渲染的结果相比也并不好看说实话，但至少它是对的，而知乎编辑器错的五花八门。</p>
<h2 id="那么如何拯救自己的双手和灵魂呢"><a class="markdownIt-Anchor" href="#那么如何拯救自己的双手和灵魂呢"></a> 那么，如何拯救自己的双手和灵魂呢？</h2>
<h3 id="首先调整好你的markdown编辑器"><a class="markdownIt-Anchor" href="#首先调整好你的markdown编辑器"></a> 首先调整好你的Markdown编辑器</h3>
<p>为什么要首先调整好编辑器呢？这里我说的调整主要指的是对图片管理方式的调整。如果您使用Typora，建议在偏好设置页面将相关参数调整至和下图完全一致，以防后面出现问题。</p>
<p>这里做的工作主要是将所有来源的图片都自动保存至同名文件夹下，以相对路径储存。使用其他Markdown编辑器的小伙伴也可以对照调整。这么做的目的主要是为了方便后面对图片的批量上传与转换。</p>
<img data-src="./image-20191214221536561.png" alt="image-20191214221536561" style="zoom:50%;">
<p>相信很多同学看到这里就会发出疑问，为什么不适用iPic之类的图床软件直接上传至图床呢？既方便又舒适。我的答案是，因为我吃过亏。我的内容之前一直独发于我的个人博客，然而今年中旬，突然之间整个网站所有的图片都挂掉了，只显示一个占位符和无法访问的提示，之后我发现之前使用的新浪图床加入了防盗链，所以就GG了。当然后面我也用Python再一次解决了这个问题，对解决方法感兴趣的图形可以移步这里，然而这一次的教训让我理解了这些图床<strong>并不可控</strong>。它们随时可以剥夺掉你博客中的全部图片，而你是无力至极的。</p>
<p>在那之后，我就选择了本地储存+Github备份的模式，这样既可以永久有安心的本地档，也有方便使用的Github链接，可以说是既方便又安全。</p>
<h3 id="之后解决图片上传问题"><a class="markdownIt-Anchor" href="#之后解决图片上传问题"></a> 之后解决图片上传问题</h3>
<p>最方便的解决办法即为利用好GitHub的资源了。建立一个Public的GitHub仓库，这里我命名作**<a href="https://github.com/miracleyoo/Markdown4Zhihu">Markdown4Zhihu</a>**，注意一定要为Public，否则知乎无法访问这些图片。</p>
<img data-src="./image-20191214221339326.png" alt="image-20191214221339326" style="zoom:50%;">
<p>当然，如果你觉得麻烦，也可以直接folk我建好的仓库，一会儿我们要提到的“一键Markdown知乎适配脚本”也会在这个仓库里。你只需要将你的文件和相应的图片文件夹放到这个<code>Data</code>子目录下，即可调用脚本一键转换，并将涉及到的图片自动推到你相应的GitHub仓库中。</p>
<img data-src="./image-20191214213407292.png" alt="image-20191214213407292" style="zoom:50%;">
<p>这是我们使用脚本一键转换后的结果。它很好的解决的图片上传的问题，同时也保证了代码段的高亮，同时，所有的行内公式和多行公式都得到了转换。转换后的公式在知乎上传文件之后，是可交互的，即你可以在上传之后在知乎编辑器中修改你的公式，而不必重新再来一遍。</p>
<p>至于表格，这个真木得办法，因为知乎压根不支持表格你说这咋整嘛。但是也不是没有可替代方案。如果表格不是很多，你可以直接对其进行截图，删去原代码后粘贴截图。之后它就会按照图片模式被兼容上去。如果你不想截图也可，做了相应操作后会得到上图的结果，对于少量表格来看也是OK的。你可以在<a href="https://zhuanlan.zhihu.com/p/97432671">这里</a>看到上传到知乎后的效果。</p>
<h3 id="最后是具体使用流程"><a class="markdownIt-Anchor" href="#最后是具体使用流程"></a> 最后是具体使用流程</h3>
<p>这里我们假设您的文件名为<code>一个测试文档.md</code>，并将其和同名图片文件夹放到<code>Data</code>目录下（如果新建文件时就直接在Data里面建会更加方便），接着打开terminal(Linux/MacOS)或Git Bash(Windows)(或其他任何支持Git命令的终端)，<code>cd</code>进入该项目的根目录，即<code>Markdown4Zhihu</code>目录，输入以下命令：</p>
<p><code>python zhihu-publisher.py --input=&quot;./Data/一个测试文档.md&quot;</code></p>
<p>OK，all set. 在<code>Data</code>目录下，你可以看到一个<code>一个测试文档_for_zhihu.md</code>的文件，将它上传至知乎编辑器即可。</p>
<p>PS: 脚本使用Python3，Python2可能会有潜在问题。</p>
<h2 id="最后的话"><a class="markdownIt-Anchor" href="#最后的话"></a> 最后的话</h2>
<p>知乎的开发者的逻辑其实我真的比较迷，我们大学学生团队的自建论坛都可以原生完美支持Markdown和公式，然而知乎却一直说这个功能必要性不足强调开发难度。同样令人难受的是知乎的搜索，多少年过去了非热门话题还是一如既往的难用，搜索还是借助Google 的 “问题+知乎”。不知道这是什么原因，不过还是希望知乎团队先把这些非常基础的东西做好再大谈用户体验。</p>
<p>这次的解决方案需要对GitHub和命令行有基础的了解，不过考虑到会来读这篇文章的人应该程序员居多，问题应该不是很大。脚本还比较新，如果有bug欢迎提出。最后再放一下GitHub链接，如果它有帮到你，希望能随手留下一个star，谢谢！<strong><a href="https://github.com/miracleyoo/Markdown4Zhihu">Markdown4Zhihu</a></strong></p>
]]></content>
      <tags>
        <tag>tool</tag>
        <tag>markdown</tag>
        <tag>math</tag>
      </tags>
  </entry>
  <entry>
    <title>MATLAB 中与函数、方程相关内容</title>
    <url>/2020/01/10/matlab-func/</url>
    <content><![CDATA[<h2 id="符号变量-syms"><a class="markdownIt-Anchor" href="#符号变量-syms"></a> 符号变量 syms</h2>
<p>在MATLAB中创建或定义一个函数需要用到符号变量。一般情况下，想要绘制函数图像时，往往使用<code>x=[a:0.01:b]</code>的方式先创建一个x的离散定义域，然后再用<code>y=func(x)</code>的方式定义函数本身，最后使用plot(x,y)的方式绘制图像。</p>
<p>然而，当涉及到函数极值、求导、方程求解、连续图像绘制等问题时，这种方法就不够用了。</p>
<span id="more"></span>
<p>想要创建一个<strong>符号函数</strong>，我们首先要创建一个或多个<strong>符号变量</strong>，用以表示符号函数本身。其定义方式即为<code>syms x x1 x2</code>。其中<code>x,x1,x2</code> 都是符号变量，一个符号函数可以由多个符号变量组成。</p>
<p>符号变量可以有定义域，这里或称<strong>限制条件</strong>。</p>
<p>限制条件可以在定义时就加上，但往往是较为简单的条件，如<em>positive</em>, <em>real</em>, <em>integer</em> 等。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="comment">% Create symbolic variables x and y, and assume that they are integers.</span></span><br><span class="line">syms x y integer</span><br><span class="line"></span><br><span class="line"><span class="comment">% Create another variable z, and assume that it has a positive rational value.</span></span><br><span class="line">syms z positive rational</span><br><span class="line"></span><br><span class="line"><span class="comment">% Check assumptions on each variable. For example, check assumptions set on the variable x.</span></span><br><span class="line">assumptions(x)</span><br><span class="line"></span><br><span class="line"><span class="comment">% Clear assumptions on x, y, and z.</span></span><br><span class="line">assume([x y z],<span class="string">&#x27;clear&#x27;</span>)</span><br><span class="line">assumptions</span><br><span class="line"></span><br><span class="line"><span class="comment">% Create a 1-by-3 symbolic array a and assume that the array elements have real values.</span></span><br><span class="line">syms a [<span class="number">1</span> <span class="number">3</span>] <span class="built_in">real</span></span><br><span class="line">assumptions</span><br></pre></td></tr></table></figure>
<p>其次，我们也可以使用更加精确的方法进行限定，即使用<code>assume</code>命令。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">syms x</span><br><span class="line">assume(<span class="number">0</span>&lt;x&lt;<span class="number">4</span>)</span><br></pre></td></tr></table></figure>
<h2 id="定义函数"><a class="markdownIt-Anchor" href="#定义函数"></a> 定义函数</h2>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="comment">% 方法1 使用这种方法不用特意定义自变量</span></span><br><span class="line">y = @(t) <span class="built_in">cos</span>(<span class="number">3</span>*t);</span><br><span class="line"></span><br><span class="line"><span class="comment">% 方法2 先定义自变量为符号变量再定义函数本身</span></span><br><span class="line">syms x</span><br><span class="line">fun = <span class="number">0.5</span>*x*(<span class="built_in">exp</span>(<span class="number">-2</span>*x)+<span class="built_in">exp</span>(<span class="number">-1.5</span>*x)+<span class="built_in">exp</span>(-x))</span><br></pre></td></tr></table></figure>
<h2 id="快速绘制函数图像"><a class="markdownIt-Anchor" href="#快速绘制函数图像"></a> 快速绘制函数图像</h2>
<p>MATLAB中的函数<code>fplot</code>可以迅速绘制一个符号函数的函数图像，并可以对其显示的x范围进行设定。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">fplot(fun)</span><br><span class="line">fplot(fun,x,[<span class="number">1</span>,<span class="number">2</span>])</span><br></pre></td></tr></table></figure>
<p>默认情况下，其绘制区间为<code>[-5, 5]</code>，但如果符号变量本身有定义域限制，则会优先其定义域，优先级最高的是在绘制函数中指定的绘制区间。</p>
<p>当然，<code>fplot</code>函数还可以绘制多条曲线、分段函数以及参数函数等，详见<a href="https://ww2.mathworks.cn/help/matlab/ref/fplot.html">帮助文档</a>，这里给出几个简单常用例子。</p>
<p>指定绘图区间并绘制分段函数<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>e</mi><mi>x</mi></msup><mtext> −</mtext><mn>3</mn><mo>&lt;</mo><mi>x</mi><mo>&lt;</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">e^x\space −3&lt;x&lt;0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.747722em;vertical-align:-0.08333em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span></span></span></span></span><span class="mspace"> </span><span class="mord">−</span><span class="mord">3</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span></p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>o</mi><mi>s</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mtext> </mtext><mn>0</mn><mo>&lt;</mo><mi>x</mi><mo>&lt;</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">cos(x)\space 0&lt;x&lt;3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">o</span><span class="mord mathnormal">s</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace"> </span><span class="mord">0</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span></span></span></span></p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">使用 <span class="built_in">hold</span> on 绘制多个线条。使用 fplot 的第二个输入参数指定绘图区间。使用 <span class="string">&#x27;b&#x27;</span> 将绘制的线条颜色指定为蓝色。在相同坐标区中绘制多个线条时，坐标轴范围会调整以容纳所有数据。</span><br><span class="line">fplot(@(x) <span class="built_in">exp</span>(x),[<span class="number">-3</span> <span class="number">0</span>],<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line"><span class="built_in">hold</span> on</span><br><span class="line">fplot(@(x) <span class="built_in">cos</span>(x),[<span class="number">0</span> <span class="number">3</span>],<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line"><span class="built_in">hold</span> off</span><br><span class="line">grid on</span><br></pre></td></tr></table></figure>
<img data-src="./specifyplottingintervalandplotpiecewisefunctionsexample_01_zh_CN.png" alt="img" style="zoom:50%;">
<p>当然，使用<code>fplot</code>方法绘制的图像也是可以进行样式自定义的：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">fplot(@(x) <span class="built_in">sin</span>(x+<span class="built_in">pi</span>/<span class="number">5</span>),<span class="string">&#x27;Linewidth&#x27;</span>,<span class="number">2</span>);</span><br><span class="line"><span class="built_in">hold</span> on</span><br><span class="line">fplot(@(x) <span class="built_in">sin</span>(x-<span class="built_in">pi</span>/<span class="number">5</span>),<span class="string">&#x27;--or&#x27;</span>);</span><br><span class="line">fplot(@(x) <span class="built_in">sin</span>(x),<span class="string">&#x27;-.*c&#x27;</span>)</span><br><span class="line"><span class="built_in">hold</span> off</span><br></pre></td></tr></table></figure>
<img data-src="./specifylinepropertiesanddisplaymarkersexample_01_zh_CN.png" alt="img" style="zoom:50%;">
<h2 id="解方程"><a class="markdownIt-Anchor" href="#解方程"></a> 解方程</h2>
<p>MATLAB中有两种常用解方程的函数：<code>solve</code>和<code>vpasolve</code>。前者会返回一个符号解，它的做法就像人类手工推理一样，计算出所有的符号解。而后者则会计算方程的数值解，且只会返回其找到的第一个数值解。</p>
<p>当我们想要使用<code>vpasolve</code>算出某个x范围中的所有解时候，我们有两种方法：</p>
<h3 id="1-画出方程对应的函数图像并传给vpasolve一个猜测起点"><a class="markdownIt-Anchor" href="#1-画出方程对应的函数图像并传给vpasolve一个猜测起点"></a> 1. 画出方程对应的函数图像，并传给<code>vpasolve</code>一个猜测起点</h3>
<p>如给定方程<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>200</mn><mo>∗</mo><mi>s</mi><mi>i</mi><mi>n</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><msup><mi>x</mi><mn>3</mn></msup><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">200*sin(x) = x^3 - 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord">0</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.897438em;vertical-align:-0.08333em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>, 我们先画出它的图像进行观察：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">syms x</span><br><span class="line">eqnLeft = <span class="number">200</span>*<span class="built_in">sin</span>(x);</span><br><span class="line">eqnRight = x^<span class="number">3</span> - <span class="number">1</span>;</span><br><span class="line">fplot([eqnLeft eqnRight])</span><br><span class="line">title([texlabel(eqnLeft) <span class="string">&#x27; = &#x27;</span> texlabel(eqnRight)])</span><br></pre></td></tr></table></figure>
<img data-src="./FindMultipleSolutionsBySpecifyingInitialGuessesExample_01.png" alt="img" style="zoom:50%;">
<p>观察后发现，这个方程有三个解，分别在-3, 0, 4的附近，于是我们可以用以下语句找到其所有的三个解</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">S1 = vpasolve(eqnLeft == eqnRight, x);</span><br><span class="line">S2 = vpasolve(eqnLeft == eqnRight, x, <span class="number">-3</span>);</span><br><span class="line">S3 = vpasolve(eqnLeft == eqnRight, x, <span class="number">4</span>);</span><br></pre></td></tr></table></figure>
<h3 id="2-使vpasolve拥有一个随机起点并进行循环"><a class="markdownIt-Anchor" href="#2-使vpasolve拥有一个随机起点并进行循环"></a> 2. 使<code>vpasolve</code>拥有一个随机起点，并进行循环</h3>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> n = <span class="number">1</span>:<span class="number">3</span></span><br><span class="line">    S = vpasolve(f,x,[<span class="number">0</span>,<span class="number">2</span>],<span class="string">&#x27;Random&#x27;</span>,<span class="built_in">true</span>)</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="3-仅针对多项式函数"><a class="markdownIt-Anchor" href="#3-仅针对多项式函数"></a> 3. 仅针对多项式函数</h3>
<p>如果你的函数是一个标准的多相似函数，那么你可以使用<code>roots</code>函数一次性得到所有的解。详情请参阅<a href="https://www.mathworks.com/help/matlab/ref/roots.html">帮助文档</a>。</p>
<h2 id="寻找函数极大极小值"><a class="markdownIt-Anchor" href="#寻找函数极大极小值"></a> 寻找函数极大极小值</h2>
<p>在MATLAB中似乎没有直接一键求出函数的最值的办法，但我们却可以用<code>fminsearch</code>求出某个点附近的极值。</p>
<p>与前面提到的解方程类似，由于该函数并不会直接的把全局最值给你，所以最好先把函数图像画出来，然后观察需要求的极值在那个点附近，然后使用<code>fminsearch</code>函数把相关点的横坐标解出，如果需要最值的值，再把这个横坐标带回去求值。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">syms x</span><br><span class="line">y=<span class="built_in">real</span>((<span class="number">1</span>-<span class="built_in">exp</span>(<span class="number">8</span>*<span class="built_in">i</span>*<span class="built_in">pi</span>*<span class="built_in">cos</span>(x)))/(<span class="number">1</span>-<span class="built_in">exp</span>(<span class="built_in">i</span>*<span class="built_in">pi</span>*<span class="built_in">cos</span>(x))));</span><br><span class="line">fplot(y,[<span class="number">0</span>,<span class="number">3</span>]);</span><br><span class="line">fminsearch(matlabFunction(-y),<span class="number">1.5</span>);</span><br><span class="line"><span class="comment">% ans = 1.5708</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<img data-src="./image-20200216152601687.png" alt="image-20200216152601687" style="zoom:35%;">
<p>请注意，这里在search的时候我将y改为了-y，因为我要找的是极大值而非极小值。</p>
<p>接着，我们将函数y变为<code>matlabFunction</code>型变量，在根据刚才输出的值求出极值大小：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">q=matlabFunction(y)</span><br><span class="line">q(<span class="number">1.5708</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>于是，我们就找到了函数在该点附近的极值。</p>
<p>你甚至可以看到MATLAB的优化路径：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">options = optimset(<span class="string">&#x27;PlotFcns&#x27;</span>,@optimplotfval);</span><br><span class="line">fun = @(x)<span class="number">100</span>*(x(<span class="number">2</span>) - x(<span class="number">1</span>)^<span class="number">2</span>)^<span class="number">2</span> + (<span class="number">1</span> - x(<span class="number">1</span>))^<span class="number">2</span>;</span><br><span class="line">x0 = [<span class="number">-1.2</span>,<span class="number">1</span>];</span><br><span class="line">x = fminsearch(fun,x0,options)</span><br></pre></td></tr></table></figure>
<img data-src="./image-20200216153158018.png" alt="image-20200216153158018" style="zoom:33%;">
<h2 id="对函数求导"><a class="markdownIt-Anchor" href="#对函数求导"></a> 对函数求导</h2>
<p>定义好一个符号函数后，直接使用<code>diff</code>命令即可对函数进行符号求导。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">syms x</span><br><span class="line">fun=<span class="number">0.5</span>*x*(<span class="built_in">exp</span>(<span class="number">-2</span>*x)+<span class="built_in">exp</span>(<span class="number">-1.5</span>*x)+<span class="built_in">exp</span>(-x))</span><br><span class="line">diff(fun) <span class="comment">% or diff(fun, x)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>需要注意的一点是，<code>diff</code>函数不但对符号函数有效，其对数列也是有效的：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">X = [<span class="number">1</span> <span class="number">1</span> <span class="number">2</span> <span class="number">3</span> <span class="number">5</span> <span class="number">8</span> <span class="number">13</span> <span class="number">21</span>];</span><br><span class="line">Y = diff(X)</span><br><span class="line"><span class="comment">% Y = 1×7</span></span><br><span class="line"><span class="comment">%     0     1     1     2     3     5     8</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>matlab</tag>
      </tags>
  </entry>
  <entry>
    <title>MATLAB中列出文件夹下内容并提取含Pattern文件名存储</title>
    <url>/2018/08/27/matlab-list-folder-and-save/</url>
    <content><![CDATA[<h1 id="问题"><a class="markdownIt-Anchor" href="#问题"></a> 问题</h1>
<p>MATLAB中如何将一个文件夹下所有文件列出并储存到一个字符串数组中，最后提取含有特定Pattern的文件名。</p>
<h1 id="解决方案"><a class="markdownIt-Anchor" href="#解决方案"></a> 解决方案</h1>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">filenames = dir;</span><br><span class="line">filenames = &#123;filenames.name&#125;;</span><br><span class="line">filenames = string(filenames);</span><br><span class="line">STTF = startsWith(filenames,<span class="string">&#x27;.&#x27;</span>);</span><br><span class="line">filenames = filenames(~STTF);</span><br><span class="line">MTF = contains(filenames,<span class="string">&#x27;.mat&#x27;</span>);</span><br><span class="line">filenames = filenames(MTF);</span><br><span class="line">filenum = <span class="built_in">length</span>(filenames);</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>matlab</tag>
      </tags>
  </entry>
  <entry>
    <title>Matlab与Python联合编程</title>
    <url>/2018/08/18/matlab2python/</url>
    <content><![CDATA[<p>先交代一下背景：一个机器学习代码的检验需要用到lab之前写好的仿真代码，现在需要将这两份代码结合在一起工作，并且把机器学习完成的任务部分的matlab代码用Python代码代替。</p>
<p>最开始想出来的可能方法大致的有如下三个：</p>
<span id="more"></span>
<h2 id="可能方案"><a class="markdownIt-Anchor" href="#可能方案"></a> 可能方案</h2>
<ol>
<li>
<p>将3500行MATLAB代码直接翻译成Python代码。</p>
<ul>
<li>优点：最直观，适配性最强，GitHub有相关转换脚本</li>
</ul>
<ul>
<li>缺点：耗时大，暗bug难以调试</li>
</ul>
</li>
<li>
<p>将Matlab代码拆分成几个大函数，封装好后用Python运行这些文件</p>
<ul>
<li>优点：大大降低工作量，而且能够保证封装的文件运行得到正确的结果</li>
</ul>
<ul>
<li>缺点：调用泊松方程部分知识一个小调用，整个Main文件大体还要改，list等的传参也很成问题</li>
</ul>
</li>
<li>
<p>将机器学习部分做成Linux服务器端，在Matlab端只调用接口</p>
<ul>
<li>优点：快速，可复用</li>
</ul>
<ul>
<li>缺点：同样的问题时学习成本较高。有做不出来的可能，耗时较长</li>
</ul>
</li>
</ol>
<h2 id="相关资源"><a class="markdownIt-Anchor" href="#相关资源"></a> 相关资源</h2>
<ul>
<li>Matlab代码到Python的编译器：<a href="https://github.com/victorlei/smop">Small Matlab to Python compiler</a></li>
<li>我尝试转换后的结果（经过手动Debug）：<a href="https://github.com/miracleyoo/Diode-Electron-Hole-Particles-Simulation">Diode-Electron-Hole-Particles-Simulation</a></li>
<li>Matlab官方给定Python中调用MATLAB API：<a href="https://ww2.mathworks.cn/help/matlab/matlab-engine-for-python.html">用于 Python 的 MATLAB API</a></li>
<li>上述API安装方法：<a href="https://ww2.mathworks.cn/help/matlab/matlab_external/install-the-matlab-engine-for-python.html">安装用于 Python 的 MATLAB 引擎 API</a></li>
<li>通过Python调用用户自定义脚本的方法：<a href="https://ww2.mathworks.cn/help/matlab/matlab_external/call-user-script-and-function-from-python.html">通过 Python 调用用户脚本和函数</a></li>
<li>Python 类型、容器到 MATLAB 的映射：<a href="https://ww2.mathworks.cn/help/matlab/matlab_external/pass-data-to-matlab-from-python.html">从 Python 将数据传递到 MATLAB</a></li>
<li>Python与Matlab混合编程实例博客：<a href="http://zhaoxuhui.top/blog/2017/12/14/Python%E4%B8%8EMatlab%E6%B7%B7%E5%90%88%E7%BC%96%E7%A8%8B.html">Python与Matlab混合编程</a></li>
<li>将所有工作区变量保存到 MAT 文件：<a href="https://ww2.mathworks.cn/help/matlab/ref/save.html#btox10b-2_1">将所有工作区变量保存到 MAT 文件</a></li>
</ul>
<h2 id="实验过程"><a class="markdownIt-Anchor" href="#实验过程"></a> 实验过程</h2>
<p>起初我尝试了第一种方法，借助GitHub上开源的MATLAB转Python的东风，只用了几个小时便完成了大致的转换，本来信心满满准备着手测试时，却意外的发现尽管大部分语法都得到了正确的转换，但是还是有许许多多细节问题需要一步步调整。整个调试持续了整整三天，当最终可以运行是却再次发现了两个问题：</p>
<ol>
<li>运行速度相较于MATLAB原生程序慢了太多。MATLAB上只要0.4秒的程序转成了Python竟然需要上千秒。经过仔细的分析，原因主要有两个：一是MATLAB本身就对矩阵运算进行的大量的优化，而Python想要实现相似功能只能借助第三方库函数。二是自动转换脚本为了保证数组下标等的正确性引入了一个新的类matlab array。每个数组都会被初始化为一个实例，而这本身就是很耗时间的。三是其中涉及了很多类型转换，而数组有很大很多，不少数组都有多达数万个元素，拷贝式的转换会消耗掉巨量的时间。</li>
<li>结果不正确。有部分函数和方法MATLAB和Python的解读不同。这种问题大部分是可以被发现的，但是实际上debug的难度随着代码长度和复杂度而急剧上升，尤其是原来的代码本身就较为dirty，而不是结构化的运算时。另外还有部分不仔细分析调试断点根本无法发现的隐藏式的bug，这些都使得这个庞然大物似的代码极难调试。</li>
</ol>
<p>之后，我试着只手动重写main程序，其他的模块全部封装化，但结果依旧不理想。由于程序不断地在MATLAB和Python解释环境中切换，这必然涉及到大量的传参，而MATLAB和Python之间的传参甚至比普通的类型转换更加耗时，往往一个循环要消耗数百秒。Python中一个MATLAB的函数调用传参转换花的时间和本身花去的时间之比根据参数数量和大小甚至可以达到了1:200以上。这无疑是一个令人震惊的比例。但是如果希望通过不断调用MATLAB函数并将长达400行左右的main函数通过Python执行，大量的传参就是无法避免的。</p>
<p>于是，经过充分的思考后，我果断放弃了之前五天的成果，选择了下一种方法：只在Python中控制主循环以及几个关键而小的变量，把之前的main长长的代码拆成了数个代码块，打包成一个个可供Python调用的函数，并把函数文件间的沟通“大任”从Python主程序转移到了中间mat文件。每个MATLAB脚本执行之前都会Load之前存下的中间变量并在结尾储存当前所有的中间变量。通过这种方法，Python中每个循环的执行速度也由直接传参的数百秒降低到了可以接受的0.5秒。之后便是把自己的机器学习代码写了一个简单而迅速的接口，替换掉了原有的泊松方程求解部分。预计下种可以出来正式的拟合曲线。</p>
<h2 id="简单结论"><a class="markdownIt-Anchor" href="#简单结论"></a> 简单结论</h2>
<ul>
<li>Smop自动转换会把数组、矩阵解释为一种自定义类matlab array，来回转换效率很低。</li>
<li>如果工程项目真的很小，并且希望考虑执行效率，建议手动转换Python</li>
<li>如果工程项目中等（1~3个.m文件），并对效率没有太高要求，可以使用GitHub的smop自动转换后<strong>手动Debug</strong>。</li>
<li>如果工程可以拆分为数个函数，并且运行的机器上已经装有MATLAB或是可以并愿意画上十几个G安装MATLAB，可以考虑使用MATLAB官方提供的Python调用MATLAB函数的接口。</li>
<li>如果采用Python调用MATLAB函数的解决方案，建议只把Python中必须用到的变量传递给Python主程序，其他部分则考虑采用储存和加载工作区全部变量的方式操作。注意这两种变量不要混着用，即既在储存文件时储存，又传回Python，这样很容易引起混乱。</li>
</ul>
]]></content>
      <tags>
        <tag>python</tag>
        <tag>matlab</tag>
      </tags>
  </entry>
  <entry>
    <title>MATLAB的数组元胞结构解析</title>
    <url>/2018/08/27/matlab-list-matrix/</url>
    <content><![CDATA[<h1 id="问题"><a class="markdownIt-Anchor" href="#问题"></a> 问题</h1>
<p>MATLAB的数组、元胞、字符串数组分别有什么特点？其与Python等语言的数组有什么较大区别？存储和转换时有什么需要注意？</p>
<h1 id="解答"><a class="markdownIt-Anchor" href="#解答"></a> 解答</h1>
<ol>
<li>
<p>MATLAB的元胞其实和Python中的数组更加相近，二者都可以储存混合大小和类型的变量，如果在元胞中储存数组，它们没必要维度相同。而MATLAB的数组必须保证每一维度的元素数目相同。</p>
</li>
<li>
<p>MATLAB数组各个维度的存储顺序和Python正好相反。一个在Python中shape为[2,3,4,5]的数组到了MATLAB中会变成[5,4,3,2]。这种数据的储存方法是和<a href="https://zh.wikipedia.org/zh-hans/Fortran">Fortran</a>相似的，採用列優先（Column first）。Python中的几个数组通过[A, B]的方式合并时会在最左边（第一维）增加一个“2”（因为这里合并的是两个数组），而MATLAB的cat方法合并两个数组则会在最右边（最后一维）增加一个“2”。</p>
</li>
<li>
<p>如果是普通数组拿来存储字符串，则必须要保证每个字符串长度相同。但是MATLAB提供了字符串数组这种数据格式。</p>
<span id="more"></span>
<h2 id="创建对象"><a class="markdownIt-Anchor" href="#创建对象"></a> 创建对象</h2>
<p>您可以通过用双引号括起一段文本来创建字符串。从 R2017a 开始引入双引号。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">str = &quot;Hello, world&quot; </span><br><span class="line"></span><br><span class="line">str = &quot;Hello, world&quot; </span><br></pre></td></tr></table></figure>
<p>创建字符串数组的一种方法是使用方括号将字符串串联成数组，就像将数字串联成数值数组一样。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">str = [&quot;Mercury&quot;,&quot;Gemini&quot;,&quot;Apollo&quot;; &quot;Skylab&quot;,&quot;Skylab B&quot;,&quot;ISS&quot;] </span><br><span class="line"></span><br><span class="line">str = 2x3 string array &quot;Mercury&quot; &quot;Gemini&quot; &quot;Apollo&quot; &quot;Skylab&quot; &quot;Skylab B&quot; &quot;ISS&quot; </span><br></pre></td></tr></table></figure>
<p>也可以按如下所述，使用 <code>string</code> 函数将不同数据类型的变量转换成字符串数组。</p>
<h3 id="语法"><a class="markdownIt-Anchor" href="#语法"></a> 语法</h3>
<p><code>str = string(A)</code></p>
<p><code>str = string(D)</code></p>
<p><code>str = string(D,fmt)</code></p>
<p><code>str = string(D,fmt,locale)</code></p>
</li>
<li>
<p>将元胞转换成普通List：</p>
<h2 id="cell2mat"><a class="markdownIt-Anchor" href="#cell2mat"></a> cell2mat</h2>
<p>将元胞数组转换为基础数据类型的普通数组</p>
<h2 id="语法-2"><a class="markdownIt-Anchor" href="#语法-2"></a> 语法</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">A = cell2mat(C)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>将元胞数组转为字符串数组：</p>
<p>直接<code>string(C)</code></p>
</li>
<li>
<p>储存的时候，当待储存的变量小于2G时可以使用scipy读取，而大于2G时会储存为<a href="https://stackoverflow.com/questions/17316880/reading-v-7-3-mat-file-in-python">v 7.3 mat file in python</a>，这时如果想用Python读取.mat数据，传统的scipy则不再支持，这时需要使用h5py模块读取。但是请注意：scipy在读取的时候回自动把MATLAB数据格式转化成Python格式的顺序，即可以维持原来的顺序不变，而用h5py模块时则会将MATLAB的数组顺序完全颠倒过来。此时，需要使用<code>np.transpose</code>函数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ! v 7.3 .mat file</span></span><br><span class="line"><span class="keyword">import</span> scipy.io</span><br><span class="line">mat = scipy.io.loadmat(<span class="string">&#x27;test.mat&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># v 7.3 .mat file</span></span><br><span class="line"><span class="keyword">import</span> h5py</span><br><span class="line"><span class="keyword">with</span> h5py.File(<span class="string">&#x27;test.mat&#x27;</span>, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.keys()</span><br><span class="line">    </span><br><span class="line"><span class="comment"># transpose</span></span><br><span class="line">X = np.transpose(X, (<span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>))</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>当然，也可以在MATLAB中存储大数据时先提前把顺序倒好：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">X = <span class="built_in">permute</span>(X, [<span class="number">4</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>]);</span><br></pre></td></tr></table></figure></li>
</ol>
]]></content>
      <tags>
        <tag>matlab</tag>
      </tags>
  </entry>
  <entry>
    <title>MATLAB实用Tricks</title>
    <url>/2018/09/15/matlab-tricks/</url>
    <content><![CDATA[<h1 id="permute"><a class="markdownIt-Anchor" href="#permute"></a> permute</h1>
<p>重新排列 N 维数组的维度</p>
<h2 id="语法"><a class="markdownIt-Anchor" href="#语法"></a> 语法</h2>
<p><code>B = permute(A,order)</code></p>
<h2 id="说明"><a class="markdownIt-Anchor" href="#说明"></a> 说明</h2>
<p><code>B = permute(A,order)</code> 重新排列 <code>A</code> 的维度使其按向量 <code>order</code> 所指定的顺序排列。<code>B</code> 含有与 <code>A</code> 相同的值，但访问任意特定元素所需的下标的顺序已按 <code>order</code> 所指定的顺序重新排列。<code>order</code> 的所有元素都必须是唯一的正整数实数值。</p>
<span id="more"></span>
<h2 id="示例"><a class="markdownIt-Anchor" href="#示例"></a> 示例</h2>
<p>全部折叠</p>
<h3 id="置换数组维度"><a class="markdownIt-Anchor" href="#置换数组维度"></a> 置换数组维度</h3>
<p>创建一个 3×4×5 数组，并置换它，以便将第一个和第三个维度交换。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">A = <span class="built_in">rand</span>(<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>);</span><br><span class="line">B = <span class="built_in">permute</span>(A,[<span class="number">3</span> <span class="number">2</span> <span class="number">1</span>]);</span><br><span class="line"><span class="built_in">size</span>(B)</span><br><span class="line"><span class="built_in">ans</span> = </span><br><span class="line"></span><br><span class="line">     <span class="number">5</span>     <span class="number">4</span>     <span class="number">3</span></span><br></pre></td></tr></table></figure>
<h2 id="通过-python-调用用户脚本和函数"><a class="markdownIt-Anchor" href="#通过-python-调用用户脚本和函数"></a> 通过 Python 调用用户脚本和函数</h2>
<p>此示例显示如何通过 Python® 来调用 MATLAB® 脚本，以计算三角形的面积。</p>
<p>在您的当前文件夹中名为 <code>triarea.m</code> 的文件中创建一个 MATLAB 脚本。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">b = <span class="number">5</span>;</span><br><span class="line">h = <span class="number">3</span>;</span><br><span class="line">a = <span class="number">0.5</span>*(b.* h)</span><br></pre></td></tr></table></figure>
<p>保存该文件后，启动 Python 并调用该脚本。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">import matlab.engine</span><br><span class="line">eng = matlab.engine.start_matlab()</span><br><span class="line">eng.triarea(nargout=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">a =</span><br><span class="line"></span><br><span class="line">    <span class="number">7.5000</span></span><br></pre></td></tr></table></figure>
<p>指定 <code>nargout=0</code>。尽管脚本会打印输出，但它不会向 Python 返回任何输出参数。</p>
<p>将脚本转换为函数并通过引擎调用该函数。要编辑文件，请打开 MATLAB 编辑器。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">eng.edit(<span class="string">&#x27;triarea&#x27;</span>,nargout=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>删除三个语句。然后添加一条函数声明并保存文件。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">a</span> = <span class="title">triarea</span><span class="params">(b,h)</span></span></span><br><span class="line">a = <span class="number">0.5</span>*(b.* h);</span><br></pre></td></tr></table></figure>
<p>通过引擎调用新的 <code>triarea</code> 函数。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">ret = eng.triarea(<span class="number">1.0</span>,<span class="number">5.0</span>)</span><br><span class="line">print(ret)</span><br><span class="line"><span class="number">2.5</span></span><br></pre></td></tr></table></figure>
<p><code>triarea</code> 函数仅返回一个输出参数，因此无需指定 <code>nargout</code>。</p>
<h1 id="调用其他文件夹中的方法"><a class="markdownIt-Anchor" href="#调用其他文件夹中的方法"></a> 调用其他文件夹中的方法</h1>
<p>有时我们希望把matlab的函数文件单独放到一个文件夹，或是其他涉及将.m文件分散放置的情况，这时候要添加路径。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">addpath Datasets</span><br><span class="line">addpath /Users/miracle/Desktop/MST Project/project code/auto-scan-point</span><br></pre></td></tr></table></figure>
<p>这样就可以调用添加的路径下的m文件了。</p>
<h1 id="列出某文件夹内容的方法"><a class="markdownIt-Anchor" href="#列出某文件夹内容的方法"></a> 列出某文件夹内容的方法</h1>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">dir</span><br><span class="line">dir name</span><br><span class="line">listing = dir(name)</span><br></pre></td></tr></table></figure>
<h1 id="查找与指定名称匹配的文件"><a class="markdownIt-Anchor" href="#查找与指定名称匹配的文件"></a> 查找与指定名称匹配的文件</h1>
<p>列出包含词语 <code>my</code> 且扩展名为 <code>.m</code> 的所有文件。</p>
<p>创建文件夹 <code>myfolder</code>，其包含文件 <code>myfile1.m</code>、<code>myfile2.m</code> 和 <code>myfile3.txt</code>。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">mkdir myfolder </span><br><span class="line">movefile myfile1.m myfolder</span><br><span class="line">movefile myfile2.m myfolder</span><br><span class="line">movefile myfile3.txt myfolder </span><br></pre></td></tr></table></figure>
<p>列出 <code>myfolder</code> 中符合条件的文件。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">cd myfolder </span><br><span class="line">dir *my*.m </span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; myfile1.m myfile2.m </span><br></pre></td></tr></table></figure>
<h1 id="在子文件夹中查找文件"><a class="markdownIt-Anchor" href="#在子文件夹中查找文件"></a> 在子文件夹中查找文件</h1>
<p>列出当前文件夹中和当前文件夹的所有子文件夹中的所有文件。</p>
<p>创建文件夹 <code>myfolder1</code>，其中包含以下文件和文件夹：</p>
<pre><code>文件结构
myfile1.m 
myfolder2 
	myfile2.m 
	myfolder3.m 
		myfile3.m

mkdir myfolder1 mkdir myfolder1/myfolder2 mkdir myfolder1/myfolder2/myfolder3 movefile myfile1.m myfolder1 movefile myfile2.m myfolder1/myfolder2 movefile myfile3.m myfolder1/myfolder2/myfolder3 
</code></pre>
<p>列出 <code>myfolder1</code> 中和 <code>myfolder1</code> 的子文件夹中扩展名为 <code>.m</code> 的所有文件。</p>
<pre><code>cd myfolder1 dir **/*.m 

Files Found in Current Folder: myfile1.m Files Found in: myfolder2 myfile2.m Files Found in: myfolder2/myfolder3 myfile3.m 
</code></pre>
]]></content>
      <tags>
        <tag>matlab</tag>
      </tags>
  </entry>
  <entry>
    <title>2018年于密苏里科技大学暑研感想</title>
    <url>/2018/10/12/mst-feel/</url>
    <content><![CDATA[<h1 id="2018年于密苏里科技大学暑研感想"><a class="markdownIt-Anchor" href="#2018年于密苏里科技大学暑研感想"></a> 2018年于密苏里科技大学暑研感想</h1>
<p>脚下坚实的土地是球形的，但徒步向前的旅人一步步走着笔直的路；指缝中划过的时间是不断流逝的，但驻足于此的行者却认为同样的时光将无限地流转。休假、旅行、访学，从某处离去，又终将归来，同样的处所、相同的人、不变的关切和思念，却又有了些不同的记忆、熟识了另一批友人、拥有了新的想法和兴趣以及微调过的思想。行走于一条莫比乌斯环，漫步一周，归来，虽情景依旧，却再也无法当初。</p>
<span id="more"></span>
<p>旅行给了人什么？如果被问及这个问题，我想无疑答案将会是一个新的自我吧。异国他乡新的文化碰撞、来自不同学校、不同地域、不同国家的人各异的性格和处事方式、崭新关系的建立、以及在此之上产生的体验和记忆，无疑都会给人渲染上一层新的颜色。</p>
<p>也许是托当代科技的福，在离开生活了三个月之久的小城罗拉前夜依然理所当然的认为这样的生活还会一如既往的持续下去，正如过去的三个月那样。在实验室工作、学习、写代码、做演讲；与mentor讨论问题，交流经验、分享知识；在讲台下不断修改一份份Slides；在讲台上展示最新的成果与体悟；在同学和教授家开party，跳舞、唱歌、吃自制的火锅；在周末驱车圣路易闲逛，感受博物馆诉说的历史；在罗拉的各个餐厅驻足，留下小费和欢笑；和陆鸿宇一起谈动漫、讲日语；和大家挤在一起、注视着草丛中时隐时现的敌人；飞去洛杉矶做会议的志愿者、体会美丽的海滩和有趣有料的环球影城；在center健身、游泳、挥洒汗水；在篮球和足球场上狂奔、为精彩的一刹而击掌欢呼。在罗拉和煦的阳光下，我们曾一起奋斗、一同欢笑，留下的是代码和成果，带走的是知识与美好。</p>
<p>仍清晰地记得初来这座小城时，同行的四个人无一人能下厨做饭，当时我们采购了大量的泡面和速冻食品，连续在罗拉的各个饭店留下足迹，而实验室对面的麦当劳更成了我们的后厨，每当没有学长学姐带去吃饭的时候就只能光顾那里，而最极端的时候甚至可以一日三入金拱门。也是自然而然的，不到一个月，胖了将近十斤。但我们也没有坐以待毙，从即将毕业的学长学姐那里“继承”了锅碗瓢盆、菜刀砧板，又从沃尔玛和圣路易的中超凑齐了各种调味料和食材，之后的时光里则拜“下厨房”APP为师，开启了我们四人的手制料理生活。我们Miner Inn的每个人都掌握了几样拿手菜，平衡了膳食后，我的体重也渐渐回到了最初的水平。</p>
<p>“只有尝试迈出第一步才能摆脱偏见，遇见更好的自己。”在这里的经历告诉了我这一点。之前我一直不太乐意去健身房，潜意识中觉得这是很荒谬而无聊的事情，并且目标对象是减肥的人和肌肉男。但是在周围学长和同学的带动下一步踏进健身房后，我开始意识到也许之前的想法才是真正荒谬的。对肌肉的精准锻炼、对运动强度的把控、形式多样的健身器材都使得健身成为了一项舒适而开心的事情，而来这里运动的也并非只有肥胖症患者和肌肉男。游泳也是这样，尽管只是学会了一些皮毛，但是也敢于下水游了。一直以来我都感觉很怕水，尝试了几次后最终还是放弃了，但在学长们的悉心指导下，我发现其实并不是真的不能游泳，而是内心深处始终对于呛水有着巨大的恐惧，所以无法将埋头水中，更无法游起来了。同理还有MATLAB，之前一直十分不习惯这种语言，但是真当做起来项目时，我竟开始觉得这门语言也有其方便和合理之处。当然做饭、用英语做演讲等也都是这样，一旦克服了最初的恐惧，后面便会渐渐变得得心应手，并开始领会其中乐趣。</p>
<p>戏剧之所以令人回味，也许在于其落幕后观客依旧能在脑海中一遍遍回放其中的一幕幕场景，细细抚摩台上演员眉宇间流动的气，品味其颦笑中藏匿的神。而照片亦是如此。</p>
<p><img data-src="006tNbRwly1fwqarifr05j30rs15o4gf.jpg" alt="IMG_3762"></p>
<p>下了飞机便是美国。我们的第一餐选择了最原汁原味的麦当劳。四人谈笑风生，本无趣味的快速食品倒也在耳边萦绕的英语这味佐料下生出些别具一格的风味来。之后再次转机，离开西雅图，抵达圣路易，并在学长们深夜体贴的接机车的音乐声中来到了中部小城罗拉。看房间，小，紧凑，但毕竟首次住单人房，倒也有滋有味，甚是舒服。出门便是密苏里科技大学的校区，宽敞，阳光充沛，绿色的草坪在太阳下映衬着红墙，美。</p>
<p><img data-src="006tNbRwgy1fwqar7f0qij30rs15owu2.jpg" alt="IMG_3772"></p>
<p>第一次出行发生在我们落地的那周周末。一众学长驱车带着我们实习生来到了省城圣路易，参观了博物馆、逛了百货大楼、还愉快的享用了一次西餐和一次标准的四川菜。不同菜系各有其长，不在牛排上期待蒜香，不在火锅里寻觅甜酱才是愉快生活的保障。</p>
<p><img data-src="006tNbRwly1fwqard9lb3j30rs15odvq.jpg" alt="IMG_3768"></p>
<p>做饭，是一种必然的选择。第一个月的泡面和巅峰时一日三食的麦当劳成功让我随身多携带了五公斤的的卡路里，然而是自己的手作料理和运动重新把它们燃烧了。从最初被浙江同学敬畏的鸡蛋土豆丝到什锦米饭，一直到后来的拿手小菜炒生菜、酸辣土豆丝和番茄鸡蛋等，一步步，进入了我们的菜谱中。</p>
<p><img data-src="006tNbRwgy1fwdttttsv7j30rs15ob29.jpg" alt="IMG_3765"></p>
<p>不久，我们迎来了期盼已久的洛杉矶之旅。这次来洛杉矶长滩是为了做一个行业会议的志愿者，在这里我遇到了一批日本教授和工业界会社员，交谈甚欢的同时也收获了一些名片和一个Cisco的实习机会，不错。当然工作之余的娱乐活动和会议主办方提供的兼具社交性的出游活动体验也是十分惬意的。</p>
<p><img data-src="006tNbRwly1fwqara7ezsj315o0rsng4.jpg" alt="IMG_3766"></p>
<p>在没有排班的一天里，我和两名同学一同来到了洛杉矶的环球影城，这里无疑是我到访过的最棒的游园设施了。逼真的3D效果、沉浸式的环境、精彩的现场表演、华美的灯光秀以及刺激的项目体验都给我们带来了无穷的乐趣，尤其是哈利波特小镇，各种细节都完美还原原作，体验项目中的3D制作更是让人仿佛穿越来到了那个魔法世界，挥舞着手中的魔杖…</p>
<p><img data-src="006tNbRwgy1fwdulezgp9j315o15okjm.jpg" alt="IMG_3764"></p>
<p>从洛杉矶回来后的生活也是相当多彩的。足球比赛、烧烤、Road Kill烤肋排等都是生活中不错的调味料，更不用说实验室里可爱的妹子们了。</p>
<p><img data-src="006tNbRwgy1fwduocfxu6j30rs15ohdt.jpg" alt="IMG_3767"></p>
<p>去一次射击店体验真实吃鸡操作，是来美国前一个重要的小目标。现实中的射击体验店也确实没让我失望。教练从手枪教起，然后我渐渐上手了猎枪、5.56口径红点瞄准步枪、7.62口径子弹的AKM等的基操，一句话：酷毙了！尽管已经是绝地海岛和热情雨林中久经沙场的老枪手了，但摸到真正的步枪，上膛，瞄准，扣动扳机，等待并顶住那一声巨响的这一系列仪式似的步骤还是让人内心激动不已——硝烟特有的浪漫。</p>
<p><img data-src="006tNbRwly1fwqarlq8grj315o15okhe.jpg" alt="IMG_3769"></p>
<p><img data-src="006tNbRwgy1fwduydoyckj315o15ohdu.jpg" alt="IMG_3770"></p>
<p><img data-src="006tNbRwgy1fwduyktro8j30rs15ox6p.jpg" alt="IMG_3771"></p>
<p>州立博物馆、大学万国庆典、机车博物馆参观，这些都是后来发生的事情了。其间一个项目做完了，并在岭神的指导下完成了paper的outline和初稿；接手了另一个有趣的任务并借此拉到了谷歌的项目；完成了Linux课设和数字图像处理课设这两个历史遗留任务；开始入门了深度强化学习并写出了第一个基于该技术的项目，编码完成后“惊喜”的发现新出的一篇韩国论文和我们完美撞车了；长胖了并又瘦了，还学会了在水里扑腾。日子就像这么一条铁轨，在日复一日的咣当、咣当的声响中不断向前，蓦然回首，竟已然到了站台。</p>
<p>张中洋</p>
<p>2018.10.12</p>
]]></content>
      <tags>
        <tag>essay</tag>
        <tag>EMC</tag>
        <tag>abroad</tag>
      </tags>
  </entry>
  <entry>
    <title>Matplotlib and its Legend</title>
    <url>/2020/03/12/matplotlib-legend/</url>
    <content><![CDATA[<p><strong>This blog comes from an answer from <a href="https://stackoverflow.com/questions/4700614/how-to-put-the-legend-out-of-the-plot">How to put the legend out of the plot</a>. Reprint it here for note. Original author keeps all the right.</strong></p>
<h2 id="placing-the-legend-bbox_to_anchor"><a class="markdownIt-Anchor" href="#placing-the-legend-bbox_to_anchor"></a> Placing the legend (<code>bbox_to_anchor</code>)</h2>
<p>A legend is positioned inside the bounding box of the axes using the <code>loc</code> argument to <a href="http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.legend"><code>plt.legend</code></a>.<br>
E.g. <code>loc=&quot;upper right&quot;</code> places the legend in the upper right corner of the bounding box, which by default extents from <code>(0,0)</code> to <code>(1,1)</code> in axes coordinates (or in bounding box notation <code>(x0,y0, width, height)=(0,0,1,1)</code>).</p>
<span id="more"></span>
<p>To place the legend outside of the axes bounding box, one may specify a tuple <code>(x0,y0)</code> of axes coordinates of the lower left corner of the legend.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.legend(loc=(<span class="number">1.04</span>,<span class="number">0</span>))</span><br></pre></td></tr></table></figure>
<p>However, a more versatile approach would be to manually specify the bounding box into which the legend should be placed, using the <strong><code>bbox_to_anchor</code></strong> argument. One can restrict oneself to supply only the <code>(x0,y0)</code> part of the bbox. This creates a zero span box, out of which the legend will expand in the direction given by the <code>loc</code> argument. E.g.</p>
<p><strong>plt.legend(bbox_to_anchor=(1.04,1), loc=“upper left”)</strong></p>
<p>places the legend outside the axes, such that the upper left corner of the legend is at position <code>(1.04,1)</code> in axes coordinates.</p>
<p>Further examples are given below, where additionally the interplay between different arguments like <code>mode</code> and <code>ncols</code> are shown.</p>
<p><a href="https://i.stack.imgur.com/OIMyM.png"><img data-src="OIMyM.png" alt="enter image description here"></a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">l1 = plt.legend(bbox_to_anchor=(<span class="number">1.04</span>,<span class="number">1</span>), borderaxespad=<span class="number">0</span>)</span><br><span class="line">l2 = plt.legend(bbox_to_anchor=(<span class="number">1.04</span>,<span class="number">0</span>), loc=<span class="string">&quot;lower left&quot;</span>, borderaxespad=<span class="number">0</span>)</span><br><span class="line">l3 = plt.legend(bbox_to_anchor=(<span class="number">1.04</span>,<span class="number">0.5</span>), loc=<span class="string">&quot;center left&quot;</span>, borderaxespad=<span class="number">0</span>)</span><br><span class="line">l4 = plt.legend(bbox_to_anchor=(<span class="number">0</span>,<span class="number">1.02</span>,<span class="number">1</span>,<span class="number">0.2</span>), loc=<span class="string">&quot;lower left&quot;</span>,</span><br><span class="line">                mode=<span class="string">&quot;expand&quot;</span>, borderaxespad=<span class="number">0</span>, ncol=<span class="number">3</span>)</span><br><span class="line">l5 = plt.legend(bbox_to_anchor=(<span class="number">1</span>,<span class="number">0</span>), loc=<span class="string">&quot;lower right&quot;</span>, </span><br><span class="line">                bbox_transform=fig.transFigure, ncol=<span class="number">3</span>)</span><br><span class="line">l6 = plt.legend(bbox_to_anchor=(<span class="number">0.4</span>,<span class="number">0.8</span>), loc=<span class="string">&quot;upper right&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>Details about how to interpret the 4-tuple argument to <code>bbox_to_anchor</code>, as in <code>l4</code>, can be found in <a href="https://stackoverflow.com/questions/39803385/what-does-a-4-element-tuple-argument-for-bbox-to-anchor-mean-in-matplotlib">this question</a>. The <code>mode=&quot;expand&quot;</code> expands the legend horizontally inside the bounding box given by the 4-tuple. For a vertically expanded legend, see <a href="https://stackoverflow.com/questions/46710546/matplotlib-expand-legend-vertically">this question</a>.</p>
<p>Sometimes it may be useful to specify the bounding box in figure coordinates instead of axes coordinates. This is shown in the example <code>l5</code> from above, where the <code>bbox_transform</code> argument is used to put the legend in the lower left corner of the figure.</p>
<h3 id="postprocessing"><a class="markdownIt-Anchor" href="#postprocessing"></a> Postprocessing</h3>
<p>Having placed the legend outside the axes often leads to the undesired situation that it is completely or partially outside the figure canvas.</p>
<p>Solutions to this problem are:</p>
<ul>
<li>
<p><strong>Adjust the subplot parameters</strong><br>
One can adjust the subplot parameters such, that the axes take less space inside the figure (and thereby leave more space to the legend) by using <a href="http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.subplots_adjust"><code>plt.subplots_adjust</code></a>. E.g.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.subplots_adjust(right=<span class="number">0.7</span>)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>leaves 30% space on the right-hand side of the figure, where one could place the legend.</p>
<ul>
<li>
<p><strong>Tight layout</strong><br>
Using <a href="http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.tight_layout"><code>plt.tight_layout</code></a> Allows to automatically adjust the subplot parameters such that the elements in the figure sit tight against the figure edges. Unfortunately, the legend is not taken into account in this automatism, but we can supply a rectangle box that the whole subplots area (including labels) will fit into.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.tight_layout(rect=[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0.75</span>,<span class="number">1</span>])</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><strong>Saving the figure with <code>bbox_inches = &quot;tight&quot;</code></strong><br>
The argument <code>bbox_inches = &quot;tight&quot;</code> to <a href="http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.savefig"><code>plt.savefig</code></a> can be used to save the figure such that all artist on the canvas (including the legend) are fit into the saved area. If needed, the figure size is automatically adjusted.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.savefig(<span class="string">&quot;output.png&quot;</span>, bbox_inches=<span class="string">&quot;tight&quot;</span>)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><strong>automatically adjusting the subplot params</strong><br>
A way to automatically adjust the subplot position such that the legend fits inside the canvas <strong>without changing the figure size</strong> can be found in this answer: <a href="https://stackoverflow.com/a/43001737/4124317">Creating figure with exact size and no padding (and legend outside the axes)</a></p>
</li>
</ul>
<p>Comparison between the cases discussed above:</p>
<p><a href="https://i.stack.imgur.com/zqKjY.png"><img data-src="zqKjY.png" alt="enter image description here"></a></p>
<h2 id="alternatives-a-figure-legend"><a class="markdownIt-Anchor" href="#alternatives-a-figure-legend"></a> Alternatives <strong>A figure legend</strong></h2>
<p>One may use a legend to the figure instead of the axes, <a href="https://matplotlib.org/api/_as_gen/matplotlib.figure.Figure.html#matplotlib.figure.Figure.legend"><code>matplotlib.figure.Figure.legend</code></a>. This has become especially useful for matplotlib version &gt;=2.1, where no special arguments are needed</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">fig.legend(loc=7) </span><br></pre></td></tr></table></figure>
<p>to create a legend for all artists in the different axes of the figure. The legend is placed using the <code>loc</code> argument, similar to how it is placed inside an axes, but in reference to the whole figure - hence it will be outside the axes somewhat automatically. What remains is to adjust the subplots such that there is no overlap between the legend and the axes. Here the point <em>“Adjust the subplot parameters”</em> from above will be helpful. An example:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">x = np.linspace(<span class="number">0</span>,<span class="number">2</span>*np.pi)</span><br><span class="line">colors=[<span class="string">&quot;#7aa0c4&quot;</span>,<span class="string">&quot;#ca82e1&quot;</span> ,<span class="string">&quot;#8bcd50&quot;</span>,<span class="string">&quot;#e18882&quot;</span>]</span><br><span class="line">fig, axes = plt.subplots(ncols=<span class="number">2</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">    axes[i//<span class="number">2</span>].plot(x,np.sin(x+i), color=colors[i],label=<span class="string">&quot;y=sin(x+&#123;&#125;)&quot;</span>.<span class="built_in">format</span>(i))</span><br><span class="line"></span><br><span class="line">fig.legend(loc=<span class="number">7</span>)</span><br><span class="line">fig.tight_layout()</span><br><span class="line">fig.subplots_adjust(right=<span class="number">0.75</span>)   </span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><a href="https://i.stack.imgur.com/v1AU6.png"><img data-src="v1AU6.png" alt="enter image description here"></a></p>
<p><strong>Legend inside dedicated subplot axes</strong><br>
An alternative to using <code>bbox_to_anchor</code> would be to place the legend in its dedicated subplot axes (<code>lax</code>). Since the legend subplot should be smaller than the plot, we may use <code>gridspec_kw=&#123;&quot;width_ratios&quot;:[4,1]&#125;</code> at axes creation. We can hide the axes <code>lax.axis(&quot;off&quot;)</code> but still put a legend in. The legend handles and labels need to obtained from the real plot via <code>h,l = ax.get_legend_handles_labels()</code>, and can then be supplied to the legend in the <code>lax</code> subplot, <code>lax.legend(h,l)</code>. A complete example is below.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.rcParams[<span class="string">&quot;figure.figsize&quot;</span>] = <span class="number">6</span>,<span class="number">2</span></span><br><span class="line"></span><br><span class="line">fig, (ax,lax) = plt.subplots(ncols=<span class="number">2</span>, gridspec_kw=&#123;<span class="string">&quot;width_ratios&quot;</span>:[<span class="number">4</span>,<span class="number">1</span>]&#125;)</span><br><span class="line">ax.plot(x,y, label=<span class="string">&quot;y=sin(x)&quot;</span>)</span><br><span class="line">....</span><br><span class="line"></span><br><span class="line">h,l = ax.get_legend_handles_labels()</span><br><span class="line">lax.legend(h,l, borderaxespad=<span class="number">0</span>)</span><br><span class="line">lax.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>This produces a plot, which is visually pretty similar to the plot from above:</p>
<p><a href="https://i.stack.imgur.com/4RrYb.png"><img data-src="4RrYb.png" alt="enter image description here"></a></p>
<p>We could also use the first axes to place the legend, but use the <code>bbox_transform</code> of the legend axes,</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ax.legend(bbox_to_anchor=(<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>), bbox_transform=lax.transAxes)</span><br><span class="line">lax.axis(<span class="string">&quot;off&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>In this approach, we do not need to obtain the legend handles externally, but we need to specify the <code>bbox_to_anchor</code> argument.</p>
<h3 id="further-reading-and-notes"><a class="markdownIt-Anchor" href="#further-reading-and-notes"></a> Further reading and notes:</h3>
<ul>
<li>Consider the matplotlib <a href="http://matplotlib.org/users/legend_guide.html">legend guide</a> with some examples of other stuff you want to do with legends.</li>
<li>Some example code for placing legends for pie charts may directly be found in answer to this question: <a href="https://stackoverflow.com/questions/43272206/python-legend-overlaps-with-the-pie-chart">Python - Legend overlaps with the pie chart</a></li>
<li>The <code>loc</code> argument can take numbers instead of strings, which make calls shorter, however, they are not very intuitively mapped to each other. Here is the mapping for reference:</li>
</ul>
<p><a href="https://i.stack.imgur.com/jxecX.png"><img data-src="jxecX.png" alt="enter image description here"></a></p>
]]></content>
      <tags>
        <tag>python</tag>
        <tag>matplotlib</tag>
      </tags>
  </entry>
  <entry>
    <title>Multi-Armed Bandit： epsilon-greedy</title>
    <url>/2018/11/29/multi-armed-bandit/</url>
    <content><![CDATA[<p><strong>本文主要内容转载自：<a href="https://zhuanlan.zhihu.com/p/32410420">Multi-Armed Bandit: Thompson Sampling</a>，经过部分整合修改</strong></p>
<h2 id="背景"><a class="markdownIt-Anchor" href="#背景"></a> <strong>背景</strong></h2>
<p>假设我们开了一家叫Surprise Me的饭馆，客人来了不用点餐，由算法来决定改做哪道菜，整个过程如下：</p>
<p>步骤 1: 客人 user = 1…T 依次到达餐馆</p>
<p>步骤 2: 给客人推荐一道菜，客人接受则留下吃饭(reward=1)，拒绝则离开(reward=0)</p>
<span id="more"></span>
<p>步骤 3: 记录选择接受的客人总数 total_reward += reward</p>
<p>整个过程的伪代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, T): <span class="comment"># T个客人依次进入餐馆</span></span><br><span class="line">    <span class="comment"># 从N道菜中推荐一个，reward = 1 表示客人接受，reward = 0 表示客人拒绝并离开</span></span><br><span class="line">    item, reward = pick_one(t, N) </span><br><span class="line">    total_reward += reward <span class="comment"># 一共有多少客人接受了推荐</span></span><br></pre></td></tr></table></figure>
<h2 id="假设"><a class="markdownIt-Anchor" href="#假设"></a> <strong>假设</strong></h2>
<p>为了由浅入深地解决这个问题，我们先做两个假设：</p>
<ol>
<li>同一道菜，有时候会做的好吃一些 (概率＝p)，有时候会难吃一些 (概率 = 1-p)，但我们并不知道概率p是多少，只能通过多次观测进行统计。</li>
<li>菜做的好吃时 (概率=p)，客人一定会留下(reward=1)；菜不好吃时(概率 = 1- p)，客人一定会离开 (reward=0)。暂时先不考虑个人口味的差异 (<a href="https://zhuanlan.zhihu.com/p/32382432">后续会在Contextual Bandit中考虑</a>)</li>
<li>菜好吃不好吃只有客人才说的算，饭馆是事先不知道的（<a href="https://zhuanlan.zhihu.com/p/32410420">先验知识会在Bayesian Bandit中考虑</a>）</li>
</ol>
<h2 id="解决思路"><a class="markdownIt-Anchor" href="#解决思路"></a> 解决思路</h2>
<p>**探索阶段 (Exploration)：通过多次观测推断出一道菜做的好吃的概率 － **如果一道菜已经推荐了k遍（获取了k次反馈），我们就可以算出菜做的好吃的概率：</p>
<p><img data-src="equation?tex=%5Ctilde%7Bp%7D+%3D+%5Cfrac%7B%5Csum%7Breward_i%7D%7D%7Bk%7D" alt="tilde{p} = frac{sum{reward_i}}{k}"></p>
<p>如果推荐的次数足够多，k足够大，那么 <img data-src="https://www.zhihu.com/equation?tex=%5Ctilde%7Bp%7D" alt="tilde{p}"> 会趋近于真实的菜做的好吃的概率 <img data-src="equation?tex=%7Bp%7D" alt="{p}"> 。</p>
<p>**利用阶段 (Exploitation)：已知所有的菜做的好吃的概率，该如何推荐？－ **如果每道菜都推荐了多遍，我们就可以计算出N道菜做的好吃的概率 { <img data-src="https://www.zhihu.com/equation?tex=%5Ctilde%7Bp%7D_%7B1%7D%2C+%5Ctilde%7Bp%7D_%7B2%7D%2C+...%2C+%5Ctilde%7Bp%7D_%7BN%7D" alt="tilde{p}{1}, tilde{p}{2}, ..., tilde{p}{N}">}，那么我们就可以推荐 <img data-src="equation?tex=%5Ctilde%7Bp%7D" alt="tilde{p}"> 最大的那道菜。</p>
<h2 id="核心问题什么时候探索exploration什么时候利用-exploitation"><a class="markdownIt-Anchor" href="#核心问题什么时候探索exploration什么时候利用-exploitation"></a> 核心问题：什么时候探索(Exploration)，什么时候利用 (Exploitation)?</h2>
<p>探索 (Exploration) v.s. 利用(Exploitation)，这是一个经久不衰的问题：</p>
<ul>
<li>Exploration的代价是要不停的拿用户去试菜，影响客户的体验，但有助于更加准确的估计每道菜好吃的概率</li>
<li>Exploitation会基于目前的估计拿出“最好的”菜来服务客户，但目前的估计可能是不准的（因为试吃的人还不够多）</li>
</ul>
<p>解决方法 <img data-src="equation?tex=%5Cepsilon+%EF%BC%8D+greedy" alt="epsilon － greedy"> ：每当客人到来时:</p>
<ul>
<li>以 <img data-src="https://www.zhihu.com/equation?tex=%5Cepsilon" alt="epsilon"> 的概率选择探索 (Exploration) ，从N道菜中随机选择(概率为<img data-src="https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cepsilon%7D%7BN%7D" alt="frac{epsilon}{N}"> )一个让客人试吃，根据客人的反馈更新菜的做的好吃的概率 { <img data-src="equation?tex=%5Ctilde%7Bp%7D_%7B1%7D%2C+%5Ctilde%7Bp%7D_%7B2%7D%2C+...%2C+%5Ctilde%7Bp%7D_%7BN%7D" alt="tilde{p}{1}, tilde{p}{2}, ..., tilde{p}{N}">}</li>
<li>以 <img data-src="https://www.zhihu.com/equation?tex=1-%5Cepsilon" alt="1-epsilon"> 的概率选择利用 (Exploitation)，从N道菜{ <img data-src="equation?tex=%5Ctilde%7Bp%7D_%7B1%7D%2C+%5Ctilde%7Bp%7D_%7B2%7D%2C+...%2C+%5Ctilde%7Bp%7D_%7BN%7D" alt="tilde{p}{1}, tilde{p}{2}, ..., tilde{p}{N}">}中选择好吃的概率最高的菜推荐给用户</li>
</ul>
<p>那么 <img data-src="equation?tex=%5Cepsilon+%EF%BC%8D+greedy" alt="epsilon － greedy"> 的缺点是什么呢：</p>
<ul>
<li><strong>在试吃次数相同的情况下，好吃和难吃的菜得到试吃的概率是一样的</strong>：有一道菜持续能得到好吃的反馈，而另一道菜持续得到难吃的反馈，但在 <img data-src="https://www.zhihu.com/equation?tex=%5Cepsilon+%EF%BC%8D+greedy+" alt="epsilon － greedy "> 中，探索两道菜的概率是一样的（均为<img data-src="equation?tex=%5Cfrac%7B%5Cepsilon%7D%7BN%7D" alt="frac{epsilon}{N}">）。</li>
<li><strong>在估计的成功概率相同的情况下，试吃次数多的和试吃次数少的菜得到再试吃的概率是一样的</strong>：假设有两道菜，第一道菜50人当中30个人说好，第二道菜5个人当中3个人说好，虽然两道菜的成功概率都是60%(30/50 = 3/50)，但显然反馈的人越多，概率估计的越准。再探索时，应该把重心放在试吃次数少的菜上。</li>
</ul>
<p>最后附上 <img data-src="equation?tex=%5Cepsilon+%EF%BC%8D+greedy" alt="epsilon － greedy"> 的完整代码：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">T = 100000 # T个客人</span><br><span class="line">N = 10 # N道菜</span><br><span class="line"></span><br><span class="line">true_rewards = np.random.uniform(low=0, high=1, size=N) # N道菜好吃的概率</span><br><span class="line">estimated_rewards = np.zeros(N)</span><br><span class="line">number_of_trials = np.zeros(N)</span><br><span class="line">total_reward = 0 </span><br><span class="line"></span><br><span class="line">def alpha_greedy(N, alpha=0.1):</span><br><span class="line">    item = 0</span><br><span class="line">    if np.random.random() &lt; alpha:</span><br><span class="line">        item = np.random.randint(low=0, high=N)</span><br><span class="line">    else:</span><br><span class="line">        item = np.argmax(estimated_rewards)</span><br><span class="line">    reward = np.random.binomial(n=1, p=true_rewards[item])</span><br><span class="line">    return item, reward</span><br><span class="line"></span><br><span class="line">for t in range(1, T): # T个客人依次进入餐馆</span><br><span class="line">   # 从N道菜中推荐一个，reward = 1 表示客人接受，reward = 0 表示客人拒绝并离开</span><br><span class="line">   item, reward = alpha_greedy(N)</span><br><span class="line">   total_reward += reward # 一共有多少客人接受了推荐</span><br><span class="line"></span><br><span class="line">   # 更新菜的平均成功概率</span><br><span class="line">   number_of_trials[item] += 1</span><br><span class="line">   estimated_rewards[item] = ((number_of_trials[item] - 1) * estimated_rewards[item] + reward) / number_of_trials[item]</span><br><span class="line"></span><br><span class="line">print(&quot;total_reward=&quot; + str(total_reward))</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>machine-learning</tag>
      </tags>
  </entry>
  <entry>
    <title>我家的特色年味</title>
    <url>/2018/03/07/my-hometown/</url>
    <content><![CDATA[<p>想必有很多人曾在书中剧内数度玩味三国时那股股混沌中夹杂着些许血特有咸腥的风，憧憬过那位位暴戾中透露着几分霸气的王。静听远古的编钟在时空中的回响，壮士的怒号在河川中的激荡，仿佛正是这些或雅致或激昂的点点律动谱出了眼帘中映出的那些直栏横槛、雕栏画柱、壮美河山。但是并非所有人都知道，那位在碣石旁静观沧海、以伏枥老骥自比的那位老人曹操安置其玉玺之处乃名为许都，或曰：许昌。</p>
<span id="more"></span>
<p>今年回到许昌后，令我感触最深的便是建筑风格上的大幅转变。原本破旧的小平房摇身一变化为了开阔敞亮的广场、毫无特色的小楼被艺术家们琢磨玩味，施以细工，竟也散发出一股古色古香。最令人拍手叫绝的是其亦真亦假的设计，将真正的古建筑和经过装饰的新建筑有机的融合在了一起，令人浮想联翩。春节至，演绎来。曹操上朝大队的表演，和着编钟古筝中荡漾出的旋律，给往来其间的游者以一种独特而奇妙的体验，环视四周，又有皮影戏、铁匠铺与镖局等来增添春节之喜庆气氛。</p>
<p>会亲朋，见好友，赏灯笼，泛游船，逛庙会，乐游园。没了鞭炮的喧嚣，少了龙狮的聒噪，拭去世俗的尘埃，漫步历史之河畔，此之谓许昌之春节也。</p>
<p><img data-src="ancient_city.jpg" alt></p>
]]></content>
      <tags>
        <tag>essay</tag>
        <tag>prose</tag>
      </tags>
  </entry>
  <entry>
    <title>namedtuple</title>
    <url>/2018/08/19/namedtuple/</url>
    <content><![CDATA[<h1 id="python-namedtuple使用详解"><a class="markdownIt-Anchor" href="#python-namedtuple使用详解"></a> Python namedtuple使用详解</h1>
<p>本文转载至：<a href="https://blog.csdn.net/kongxx/article/details/51553362">链接</a></p>
<p>namedtuple是继承自tuple的子类。namedtuple创建一个和tuple类似的对象，而且对象拥有可访问的属性。</p>
<p>下面看个例子：</p>
<span id="more"></span>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> namedtuple</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个namedtuple类型User，并包含name，sex和age属性。</span></span><br><span class="line">User = namedtuple(<span class="string">&#x27;User&#x27;</span>, [<span class="string">&#x27;name&#x27;</span>, <span class="string">&#x27;sex&#x27;</span>, <span class="string">&#x27;age&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个User对象</span></span><br><span class="line">user = User(name=<span class="string">&#x27;kongxx&#x27;</span>, sex=<span class="string">&#x27;male&#x27;</span>, age=<span class="number">21</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 也可以通过一个list来创建一个User对象，这里注意需要使用&quot;_make&quot;方法</span></span><br><span class="line">user = User._make([<span class="string">&#x27;kongxx&#x27;</span>, <span class="string">&#x27;male&#x27;</span>, <span class="number">21</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> user</span><br><span class="line"><span class="comment"># User(name=&#x27;user1&#x27;, sex=&#x27;male&#x27;, age=21)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取用户的属性</span></span><br><span class="line"><span class="built_in">print</span> user.name</span><br><span class="line"><span class="built_in">print</span> user.sex</span><br><span class="line"><span class="built_in">print</span> user.age</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改对象属性，注意要使用&quot;_replace&quot;方法</span></span><br><span class="line">user = user._replace(age=<span class="number">22</span>)</span><br><span class="line"><span class="built_in">print</span> user</span><br><span class="line"><span class="comment"># User(name=&#x27;user1&#x27;, sex=&#x27;male&#x27;, age=21)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将User对象转换成字典，注意要使用&quot;_asdict&quot;</span></span><br><span class="line"><span class="built_in">print</span> user._asdict()</span><br><span class="line"><span class="comment"># OrderedDict([(&#x27;name&#x27;, &#x27;kongxx&#x27;), (&#x27;sex&#x27;, &#x27;male&#x27;), (&#x27;age&#x27;, 22)])</span></span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>点石成金，挥刀琢玉——“双创老太”刘玉那些事儿</title>
    <url>/2019/08/21/liuyu-introduction/</url>
    <content><![CDATA[<p>高调、爱折腾、不走寻常路、犀利、“毒舌”、超级大忙人，她是被贴满标签的华中大教授——刘玉老师。而其中最响亮，最广为人知的标签，一定非“双创老太”莫属。今天，让我们走近这神秘的刘玉教授，说一说，她的那些事儿。</p>
<span id="more"></span>
<iframe src="//player.bilibili.com/player.html?aid=64840863&cid=112556496&page=1" width="740" height="500" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>
<h2 id="span-stylefont-size-20pxcolor-whitebackground-color-redfont-weight-bold她是谁span"><a class="markdownIt-Anchor" href="#span-stylefont-size-20pxcolor-whitebackground-color-redfont-weight-bold她是谁span"></a> <span style="font-size: 20px;color: white;background-color: red;font-weight: bold;">她是谁？</span></h2>
<ul>
<li>湖北省创业红娘众创空间        负责人</li>
<li>武汉创业红娘公益服务中心     理事长</li>
<li>华中科技大学    电信学院      教   授</li>
<li>华中科技大学    Dian团队      创始人</li>
</ul>
<hr>
<h2 id="span-stylefont-size20pxcolorwhitebackground-color-redfont-weightbold她都做过什么span"><a class="markdownIt-Anchor" href="#span-stylefont-size20pxcolorwhitebackground-color-redfont-weightbold她都做过什么span"></a> <span style="font-size:20px;color:white;background-color: red;font-weight:bold;">她都做过什么？</span></h2>
<p>###<span style="font-size:16px;color:red;font-weight:bold;">扶弟子创新</span></p>
<p>曾指导本科生获全国挑战杯特等奖，Dian团队育人模式获国家教学成果二等奖，教育部大学生创新性实验计划的“源头”之一，央视小崔说事栏目曾以“点亮未来”专题报道，曾应邀到全国高校、中学、企事业等逾百家单位作创新创业报告，引起强烈反响。曾获评“全国师德先进个人”和湖北省“五一劳动奖章”、湖北省教育系统“三育人”奖、 宝钢优秀教师特等奖的提名奖、两次获华中科技大学教学质量优秀一等奖。</p>
<p>在她严格要求和精心培养下，Dian团队出站队员600多人在社会上总体表现优异，近7年涌现出50余家创业公司，其中贝贝网和贝店已成为独角兽，释码大华、ping++、悦然心动等创业公司业绩斐然，4人荣登福布斯中国30位“30岁以下创业者”榜单。</p>
<h3 id="span-stylefont-size16pxcolorredfont-weightbold帮他人创业span"><a class="markdownIt-Anchor" href="#span-stylefont-size16pxcolorredfont-weightbold帮他人创业span"></a> <span style="font-size:16px;color:red;font-weight:bold;">帮他人创业</span></h3>
<p>2015年3月，刘玉创办“创业红娘工作室”，义务为优秀创业项目与投资机构牵线搭桥，创业项目的甄选范围从华中科技大学在校生拓宽至全社会，不分地域、不分年龄、不分学校、不分学历。至今，经刘玉老师推荐的创业项目已超过500个，融资成交率超13%，促成投资总额2.57亿元。</p>
<hr>
<h2 id="span-stylefont-size20pxcolorwhitebackground-color-redfont-weightbold她的那些事儿span"><a class="markdownIt-Anchor" href="#span-stylefont-size20pxcolorwhitebackground-color-redfont-weightbold她的那些事儿span"></a> <span style="font-size:20px;color:white;background-color: red;font-weight:bold;">她的那些事儿</span></h2>
<ul>
<li>
<p><a href="http://szbold.cjn.cn/cjrb/html/2015-12/25/content_5498033.htm"><span style="color:red;font-size:18px;">刘玉:创客点睛手——《长江日报》</span></a></p>
</li>
<li>
<p><a href="https://www.chsi.com.cn/jyzx/200711/20071108/1493323.html"><span style="color:red;font-size:18px;">创新潜能在实践中尽情释放</span></a></p>
</li>
<li>
<p><a href="http://hb.people.com.cn/n2/2016/0115/c337099-27552249.html"><span style="color:red;font-size:18px;">人民网专访“创业红娘”刘玉：如何做到人靠谱、事落实、有情怀</span></a></p>
</li>
<li>
<p><a href="http://zqb.cyol.com/html/2016-01/19/nw.D110000zgqnb_20160119_2-10.htm"><span style="color:red;font-size:18px;">刘玉：被“强推转身”的创业红娘——《中国青年报》</span></a></p>
</li>
<li>
<p><a href="http://cjrb.cjn.cn/html/2018-04/04/content_67430.htm"><span style="color:red;font-size:18px;">全国布撒“姻缘线”的“创业红娘” ——武汉首个创业服务公益机构实录——《长江日报》</span></a></p>
</li>
<li>
<p><a href="http://news.cnhubei.com/xw//sh/201604/t3592740.shtml"><span style="color:red;font-size:18px;">武汉女教授入选“中国好人” 免费孵出50多家公司——荆楚网</span></a></p>
</li>
<li>
<p><a href="http://hb.people.com.cn/n2/2017/0526/c337099-30246043.html"><span style="color:red;font-size:18px;">华科Dian团队15年走出10余家“过亿”企业——人民网</span></a></p>
</li>
<li>
<p><a href="http://cppcc.people.com.cn/GB/35377/11493611.html"><span style="color:red;font-size:18px;">崔永元“说事”设“圈套” 女教授均“化险为夷”——中国政协新闻网</span> </a></p>
</li>
<li>
<p><a href="http://www.cnki.com.cn/Article/CJFDTotal-DYXS201409005.htm"><span style="color:red;font-size:18px;">“点”下种子——访谈华中科技大学“点团队”创始人刘玉教授——《大学生》</span></a></p>
</li>
<li>
<p><a href="http://news.cjn.cn/sywh/201705/t3010007.htm"><span style="color:red;font-size:18px;">华科创客点睛手刘玉讲述：张小龙在武汉首提微信产品观——荆楚网</span></a></p>
</li>
<li>
<p><a href="http://hustxb.cuepa.cn/show_more.php?tkey=&amp;bkey=&amp;doc_id=235846"><span style="color:red;font-size:18px;">刘延东寄语Dian团队———在实践中释放创新潜能</span></a></p>
</li>
<li>
<p><a href="http://zqb.cyol.com/html/2014-06/26/nw.D110000zgqnb_20140626_3-07.htm"><span style="color:red;font-size:18px;">华中科大教授刘玉：人才标准固化扼杀大学生创新热情——《中国青年报》</span></a></p>
</li>
<li>
<p><a href="http://xhpfmapi.zhongguowangshi.com/vh512/share/1876388?channel=weixin"><span style="color:red;font-size:18px;">双创老太和一个校园创新社团的15年——《新华网》</span></a></p>
</li>
</ul>
]]></content>
      <tags>
        <tag>Introduction</tag>
        <tag>Liuyu</tag>
      </tags>
  </entry>
  <entry>
    <title>Nohup 命令总结</title>
    <url>/2018/05/06/nohup/</url>
    <content><![CDATA[<p><strong>用途</strong>：不挂断地运行命令。</p>
<p><strong>语法</strong>：<code>nohup Command [ Arg … </code>][ &amp; ]</p>
<p><strong>描述</strong>：nohup 命令运行由 Command 参数和任何相关的 Arg 参数指定的命令，忽略所有挂断（SIGHUP）信号。在注销后使用 nohup 命令运行后台中的程序。要运行后台中的 nohup 命令，添加 &amp; （ 表示”and”的符号）到命令的尾部。</p>
<p><strong>输出被重定向</strong>到myout.file文件：<code>nohup command &gt; myout.file 2&gt;&amp;1 &amp;</code></p>
<p>两个常用的<strong>ftp工具</strong>：ncftpget和ncftpput，可以实现后台的ftp上传和下载，这样就可以利用这些命令在后台上传和下载文件了。</p>
<span id="more"></span>
<p>如何杀死nohup进程：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">this is how I try to find the process ID:</span><br><span class="line">ps -ef |grep <span class="built_in">nohup</span> </span><br><span class="line">this is the <span class="built_in">command</span> to <span class="built_in">kill</span></span><br><span class="line"><span class="built_in">kill</span> -9 1787 787</span><br></pre></td></tr></table></figure>
<p>查看最新输出文件内容：<code>tail my.log</code></p>
<p>动态追踪最新输出内容：<code>tail -f my.log</code></p>
]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch 自动生成网络结构图</title>
    <url>/2018/08/11/net-visualization/</url>
    <content><![CDATA[<h1 id="pytorch-自动生成网络结构图"><a class="markdownIt-Anchor" href="#pytorch-自动生成网络结构图"></a> Pytorch 自动生成网络结构图</h1>
<p>Pytorch没有TensorFlow类似的原生支持，尽管也可以用TensorBoardX进行可视化，但是其生成的网络图不适合直接展示。所以，有没有合适的自动化方案？</p>
<p>首先，可以利用一个开源库，<a href="https://github.com/szagoruyko/functional-zoo">functional-zoo</a></p>
<span id="more"></span>
<h2 id="所需准备"><a class="markdownIt-Anchor" href="#所需准备"></a> 所需准备：</h2>
<ol>
<li><code>brew/apt-get/yum install graphviz</code></li>
<li><code>conda install python-graphviz</code></li>
<li><code>pip install torchviz</code></li>
</ol>
<p>以我自己的网络为例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">from</span> graphviz <span class="keyword">import</span> Digraph</span><br><span class="line"><span class="keyword">from</span> torchviz <span class="keyword">import</span> make_dot</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> models <span class="keyword">import</span> miracle_lineconv_net</span><br><span class="line"><span class="keyword">from</span> config <span class="keyword">import</span> Config</span><br><span class="line">opt = Config()</span><br><span class="line"></span><br><span class="line">x = Variable(torch.randn(<span class="number">128</span>,<span class="number">2</span>,<span class="number">41</span>,<span class="number">9</span>))<span class="comment">#change 12 to the channel number of network input</span></span><br><span class="line">model = miracle_lineconv_net.MiracleLineConvNet(opt)</span><br><span class="line">y = model(x)</span><br><span class="line">g = make_dot(y)</span><br><span class="line">g.view()</span><br></pre></td></tr></table></figure>
<ul>
<li>如果依然有安装问题，继续下载 <code>pip install git+https://github.com/szagoruyko/pytorchviz</code></li>
</ul>
<h2 id="官方效果如下图"><a class="markdownIt-Anchor" href="#官方效果如下图"></a> 官方效果如下图：</h2>
<p><img data-src="0069RVTdly1fu5opw86r4j30nq0ou416.jpg" alt="image-20180811001334071"></p>
]]></content>
      <tags>
        <tag>machine-learning</tag>
        <tag>pytorch</tag>
        <tag>visualization</tag>
      </tags>
  </entry>
  <entry>
    <title>使用Numpy广播将不同形状的矩阵或数组加减乘除</title>
    <url>/2018/04/02/numpy-broadcasting/</url>
    <content><![CDATA[<h2 id="首先先强调一点很容易混淆的点"><a class="markdownIt-Anchor" href="#首先先强调一点很容易混淆的点"></a> 首先先强调一点很容易混淆的点：</h2>
<blockquote>
<ul>
<li>一个shape为(4,)的np.array其实是一行！！一行4列！！而不是4行每行1个元素！！</li>
<li>上面说的这个👆array假设叫x，那么想把x加到一个shape为(9,4)的matrix上是可以直接加的，如果想要把x加到一个shape为(4,9)的matrix上要先转置！而且不能直接转置，因为一个array的转置的形状是不会变的。。正确做法是：先把x变成一个数组，之后再对这个数组转置，这时候x的形状就已经变成了(4,1)，成了真正的4行每行1列，也就可以把它加到shape为(4,9)的matrix上去喽~</li>
</ul>
</blockquote>
<p>在我们所以Numpy的过程中，常常会有大量的矩阵数组需要运算，但是不同类型的Numpy怎样进行加减乘除呢？这就要用到我们Numpy的广播。</p>
<span id="more"></span>
<h2 id="快速入门numpy广播"><a class="markdownIt-Anchor" href="#快速入门numpy广播"></a> 快速入门Numpy广播</h2>
<p>Numpy的广播既是在2个不同的矩阵运算过程中，Numpy将较小的数组拉伸成较大数组的形状(shape)，然后<strong>Numpy加减乘除不同矩阵的加减乘除运算</strong>，好的没我们来看一下一个例子：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a = np.array([3.0, 4.0, 5.0, 6.0])</span><br><span class="line">b = np.array([3.0, 4.0])</span><br><span class="line">print a * b</span><br></pre></td></tr></table></figure>
<p>将会出现这样的错误<code>ValueError: operands could not be broadcast together with shapes (3,)， (2,)</code>, 在这里，我们只需要将a转换成一个2维数组，即可进行广播，如：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a = np.array([3.0, 4.0, 5.0, 6.0])</span><br><span class="line">b = np.array([3.0, 4.0])</span><br><span class="line">a.shape = (2,2)</span><br><span class="line">print a * b</span><br><span class="line"># 输出：[[ 3.  4.] [ 5.  6.]] [[  9.  16.] [ 15.  24.]]</span><br><span class="line"></span><br><span class="line"># 例外一个例子</span><br><span class="line">x = np.arange(4)</span><br><span class="line">z = np.ones((3,4))</span><br><span class="line"></span><br><span class="line">print x + z</span><br></pre></td></tr></table></figure>
<p>好的到这里其实主要我们已经将完了所有的内容，如果你想要了解更多，可以查看下面的内容，其实都是一些描述性的，我觉得不是那么有必要看</p>
<h2 id="什么是numpy广播"><a class="markdownIt-Anchor" href="#什么是numpy广播"></a> 什么是Numpy广播</h2>
<p>广播术语描述了在算术运算过程中numpy如何处理具有不同形状的数组。受到某些约束，较小的数组是跨越较大阵列的“广播”，以便它们具有兼容的形状。广播提供了一种向量化数组操作的方法，以便循环发生在C而不是Python中。它不会造成不必要的数据副本，通常会导致高效的算法实现。然而，广播是一个坏主意，因为它导致低效的内存使用减慢了计算的情况。</p>
<p>NumPy操作通常是在逐个元素的基础上完成的。在最简单的情况下，两个阵列必须具有完全相同的形状，如下例所示：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a = np.array([3.0, 4.0, 5.0])</span><br><span class="line">b = np.array([3.0, 3.0, 3.0])</span><br><span class="line">print a * b</span><br><span class="line"># 输出：[  9.  12.  15.]</span><br></pre></td></tr></table></figure>
<p>当数组的形状满足某些限制时，NumPy的广播规则放宽了这个约束。当操作中组合数组和标量值时，会发生最简单的广播示例：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a = np.array([3.0, 4.0, 5.0])</span><br><span class="line">b = 3.0</span><br><span class="line">print a * b</span><br><span class="line"># 输出：[  9.  12.  15.]</span><br></pre></td></tr></table></figure>
<p>上面2个例子的结果相同，在计算期间，我们可以看作b被拉伸成与a相同的形状，新元素 b只是原始标量的副本。拉伸类比只是概念性的。NumPy足够聪明才能使用原始的标量值，而无需实际复制，因此广播操作尽可能地作为记忆和计算效率。</p>
<p>第二个示例中的代码比第一个示例中的代码更有效，因为广播在乘法期间移动较少的内存（b是标量而不是数组）。</p>
<h2 id="一般广播规则"><a class="markdownIt-Anchor" href="#一般广播规则"></a> 一般广播规则</h2>
<p>在两个数组上运行时，NumPy将元素的形状进行比较。它从尾随的维度开始，并向前推进。两个尺寸兼容</p>
<ul>
<li>他们是平等的</li>
<li>其中一个是1</li>
</ul>
<p>如果不满足这些条件， 则抛出异常，表示阵列具有不兼容的形状。结果数组的大小是输入数组的每个维度的最大大小。<code>ValueError: frames are not aligned</code> 接下来我们看一下一些具体的例子：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; x = np.arange(4)</span><br><span class="line">&gt;&gt;&gt; xx = x.reshape(4,1)</span><br><span class="line">&gt;&gt;&gt; y = np.ones(5)</span><br><span class="line">&gt;&gt;&gt; z = np.ones((3,4))</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; x.shape</span><br><span class="line">(4,)</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; y.shape</span><br><span class="line">(5,)</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; x + y</span><br><span class="line">&lt;type &#x27;exceptions.ValueError&#x27;&gt;: shape mismatch: objects cannot be broadcast to a single shape</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; xx.shape</span><br><span class="line">(4, 1)</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; y.shape</span><br><span class="line">(5,)</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; (xx + y).shape</span><br><span class="line">(4, 5)</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; xx + y</span><br><span class="line">array([[ 1.,  1.,  1.,  1.,  1.],</span><br><span class="line">       [ 2.,  2.,  2.,  2.,  2.],</span><br><span class="line">       [ 3.,  3.,  3.,  3.,  3.],</span><br><span class="line">       [ 4.,  4.,  4.,  4.,  4.]])</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; x.shape</span><br><span class="line">(4,)</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; z.shape</span><br><span class="line">(3, 4)</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; (x + z).shape</span><br><span class="line">(3, 4)</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; x + z</span><br><span class="line">array([[ 1.,  2.,  3.,  4.],</span><br><span class="line">       [ 1.,  2.,  3.,  4.],</span><br><span class="line">       [ 1.,  2.,  3.,  4.]])</span><br></pre></td></tr></table></figure>
<p>广播提供了一种方便的方式来拍摄两个阵列的外部产品（或任何其他外部操作）。以下示例显示了两个1-d数组的外部加法运算：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; a = np.array([0.0, 10.0, 20.0, 30.0])</span><br><span class="line">&gt;&gt;&gt; b = np.array([1.0, 2.0, 3.0])</span><br><span class="line">&gt;&gt;&gt; a[:, np.newaxis] + b</span><br><span class="line">array([[  1.,   2.,   3.],</span><br><span class="line">       [ 11.,  12.,  13.],</span><br><span class="line">       [ 21.,  22.,  23.],</span><br><span class="line">       [ 31.,  32.,  33.]])</span><br></pre></td></tr></table></figure>
<p>这里，<code>newaxis</code>索引操作符插入一个新轴<code>a</code>，使其成为一个二维<code>4x1</code>数组。将<code>4x1</code>阵列与<code>b</code>形状组合<code>(3,)</code>，产生一个<code>4x3</code>数组。</p>
<p>原文出处： <a href="https://ptorch.com/news/38.html">使用Numpy广播将不同形状的矩阵或数组加减乘除 - pytorch中文网</a></p>
]]></content>
      <tags>
        <tag>python</tag>
        <tag>machine-learning</tag>
        <tag>numpy</tag>
      </tags>
  </entry>
  <entry>
    <title>Numpy高维数组连续切片</title>
    <url>/2018/08/11/numpy-high-dim-slicing/</url>
    <content><![CDATA[<h1 id="numpy高维数组连续切片"><a class="markdownIt-Anchor" href="#numpy高维数组连续切片"></a> Numpy高维数组连续切片</h1>
<p>先回顾一下基础：</p>
<h2 id="创建数组一般5种方式创建数组"><a class="markdownIt-Anchor" href="#创建数组一般5种方式创建数组"></a> 创建数组：一般5种方式创建数组</h2>
<h3 id="1-从其他python结构转变如列表元祖"><a class="markdownIt-Anchor" href="#1-从其他python结构转变如列表元祖"></a> 1. 从其他python结构转变，如列表，元祖</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = np.array([<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">0</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = np.array([<span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = np.array([[<span class="number">1</span>,<span class="number">2.0</span>],[<span class="number">0</span>,<span class="number">0</span>],(<span class="number">1</span>+<span class="number">1j</span>,<span class="number">3.</span>)]) <span class="comment"># note mix of tuple and lists,and types</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = np.array([[ <span class="number">1.</span>+<span class="number">0.j</span>, <span class="number">2.</span>+<span class="number">0.j</span>], [ <span class="number">0.</span>+<span class="number">0.j</span>, <span class="number">0.</span>+<span class="number">0.j</span>], [ <span class="number">1.</span>+<span class="number">1.j</span>, <span class="number">3.</span>+<span class="number">0.j</span>]])<span class="number">1234</span></span><br></pre></td></tr></table></figure>
<span id="more"></span>
<h3 id="2-numpy内置的方式创建如arangeoneszeros"><a class="markdownIt-Anchor" href="#2-numpy内置的方式创建如arangeoneszeros"></a> 2. numpy内置的方式创建，如arange，ones，zeros，</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.arange(<span class="number">10</span>)</span><br><span class="line">array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.arange(<span class="number">2</span>, <span class="number">10</span>, dtype=np.<span class="built_in">float</span>)</span><br><span class="line">array([ <span class="number">2.</span>, <span class="number">3.</span>, <span class="number">4.</span>, <span class="number">5.</span>, <span class="number">6.</span>, <span class="number">7.</span>, <span class="number">8.</span>, <span class="number">9.</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.arange(<span class="number">2</span>, <span class="number">3</span>, <span class="number">0.1</span>)</span><br><span class="line">array([ <span class="number">2.</span> , <span class="number">2.1</span>, <span class="number">2.2</span>, <span class="number">2.3</span>, <span class="number">2.4</span>, <span class="number">2.5</span>, <span class="number">2.6</span>, <span class="number">2.7</span>, <span class="number">2.8</span>, <span class="number">2.9</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.linspace(<span class="number">1.</span>, <span class="number">4.</span>, <span class="number">6</span>)</span><br><span class="line">array([ <span class="number">1.</span> , <span class="number">1.6</span>, <span class="number">2.2</span>, <span class="number">2.8</span>, <span class="number">3.4</span>, <span class="number">4.</span> ])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.indices((<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line">array([[[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>]], [[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]]])<span class="number">12345678910</span></span><br></pre></td></tr></table></figure>
<p>3.从磁盘的标准格式或定制格式<br>
4.从使用了字符串或缓存的原始数据创建数组<br>
这里用到了genfromtxt()函数，而且还要导入StringIO，内容好像蛮多的，得单独整理<br>
5.使用专门库的函数创建，如random</p>
<h2 id="数组的索引"><a class="markdownIt-Anchor" href="#数组的索引"></a> 数组的索引</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = np.arange(<span class="number">10</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.shape = (<span class="number">2</span>,<span class="number">5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.reshape(<span class="number">2</span>,<span class="number">5</span>)<span class="comment">#和上句一样的效果，但是上句改变了x的形状，此句x依然是原先的一维数组，</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = np.arange(<span class="number">10</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="number">2</span>:<span class="number">5</span>]</span><br><span class="line">array([<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[:-<span class="number">7</span>]</span><br><span class="line">array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="number">1</span>:<span class="number">7</span>:<span class="number">2</span>]<span class="comment">#这里注意，python的list是不具有间隔切片</span></span><br><span class="line">array([<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = np.arange(<span class="number">35</span>).reshape(<span class="number">5</span>,<span class="number">7</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y[<span class="number">1</span>:<span class="number">5</span>:<span class="number">2</span>,::<span class="number">3</span>]<span class="comment">#别弄错成了y[1:5:2][::3]</span></span><br><span class="line">array([[ <span class="number">7</span>, <span class="number">10</span>, <span class="number">13</span>],</span><br><span class="line">       [<span class="number">21</span>, <span class="number">24</span>, <span class="number">27</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = np.arange(<span class="number">10</span>,<span class="number">1</span>,-<span class="number">1</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">array([<span class="number">10</span>, <span class="number">9</span>, <span class="number">8</span>, <span class="number">7</span>, <span class="number">6</span>, <span class="number">5</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[np.array([<span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">8</span>])]<span class="comment">#以3,3,1,8索引位的数创建数组</span></span><br><span class="line">array([<span class="number">7</span>, <span class="number">7</span>, <span class="number">9</span>, <span class="number">2</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[np.array([<span class="number">3</span>,<span class="number">3</span>,-<span class="number">3</span>,<span class="number">8</span>])]</span><br><span class="line">array([<span class="number">7</span>, <span class="number">7</span>, <span class="number">4</span>, <span class="number">2</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[np.array([<span class="number">3</span>, <span class="number">3</span>, <span class="number">20</span>, <span class="number">8</span>])]</span><br><span class="line">&lt;<span class="built_in">type</span> ’exceptions.IndexError’&gt;: index <span class="number">20</span> out of bounds <span class="number">0</span>&lt;=index&lt;<span class="number">9</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[np.array([[<span class="number">1</span>,<span class="number">1</span>],[<span class="number">2</span>,<span class="number">3</span>]])]</span><br><span class="line">array([[<span class="number">9</span>, <span class="number">9</span>],</span><br><span class="line">       [<span class="number">8</span>, <span class="number">7</span>]])</span><br></pre></td></tr></table></figure>
<p>下面是正题：</p>
<h2 id="多维数组的索引"><a class="markdownIt-Anchor" href="#多维数组的索引"></a> 多维数组的索引</h2>
<p>先拿出来自己的例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># scatGaAs[3, :, 2]</span></span><br><span class="line">scatGaAs[np.ix_([<span class="number">3</span>], np.arange(<span class="number">1</span>, Ek_pts+<span class="number">1</span>), [<span class="number">1</span>])]</span><br></pre></td></tr></table></figure>
<p>乱七八糟的，还是画图吧</p>
<p><img data-src="0069RVTdly1fu5rpz0moij30yu196tfn.jpg" alt="image-20180811015729519"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>y[np.array([<span class="number">0</span>,<span class="number">2</span>,<span class="number">4</span>]), np.array([<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>])]<span class="comment">#这里的y就是上面创建的5*7的二维数组，这里可以理解成x坐标0,2,4，y坐标0,1,2的三个数</span></span><br><span class="line">array([ <span class="number">0</span>, <span class="number">15</span>, <span class="number">30</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y[np.array([<span class="number">0</span>,<span class="number">2</span>,<span class="number">4</span>]), np.array([<span class="number">0</span>,<span class="number">1</span>])]</span><br><span class="line">&lt;<span class="built_in">type</span> ’exceptions.ValueError’&gt;: shape mismatch: objects cannot be broadcast to a single shape</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y[np.array([<span class="number">0</span>,<span class="number">2</span>,<span class="number">4</span>]),<span class="number">0</span>:<span class="number">1</span>]</span><br><span class="line">array([[ <span class="number">0</span>],</span><br><span class="line">       [<span class="number">14</span>],</span><br><span class="line">       [<span class="number">28</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y[np.array([<span class="number">0</span>,<span class="number">2</span>,<span class="number">4</span>]), <span class="number">1</span>]</span><br><span class="line">array([ <span class="number">1</span>, <span class="number">15</span>, <span class="number">29</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y[np.array([<span class="number">0</span>,<span class="number">2</span>,<span class="number">4</span>])]<span class="comment">#取0行，2行，4行</span></span><br><span class="line">array([[ <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>],</span><br><span class="line">[<span class="number">14</span>, <span class="number">15</span>, <span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>, <span class="number">19</span>, <span class="number">20</span>],</span><br><span class="line">[<span class="number">28</span>, <span class="number">29</span>, <span class="number">30</span>, <span class="number">31</span>, <span class="number">32</span>, <span class="number">33</span>, <span class="number">34</span>]])<span class="number">1234567891011121314</span></span><br></pre></td></tr></table></figure>
<p>布尔类型的索引</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = y&gt;<span class="number">20</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y[b]</span><br><span class="line">array([<span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>, <span class="number">24</span>, <span class="number">25</span>, <span class="number">26</span>, <span class="number">27</span>, <span class="number">28</span>, <span class="number">29</span>, <span class="number">30</span>, <span class="number">31</span>, <span class="number">32</span>, <span class="number">33</span>, <span class="number">34</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b[:,<span class="number">5</span>] <span class="comment"># use a 1-D boolean whose first dim agrees with the first dim of y</span></span><br><span class="line">array([<span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">True</span>, <span class="literal">True</span>], dtype=<span class="built_in">bool</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y[b[:,<span class="number">5</span>]]</span><br><span class="line">array([[<span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>, <span class="number">24</span>, <span class="number">25</span>, <span class="number">26</span>, <span class="number">27</span>],</span><br><span class="line">[<span class="number">28</span>, <span class="number">29</span>, <span class="number">30</span>, <span class="number">31</span>, <span class="number">32</span>, <span class="number">33</span>, <span class="number">34</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = np.arange(<span class="number">30</span>).reshape(<span class="number">2</span>,<span class="number">3</span>,<span class="number">5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">array([[[ <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">[ <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>],</span><br><span class="line">[<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>]],</span><br><span class="line">[[<span class="number">15</span>, <span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>, <span class="number">19</span>],</span><br><span class="line">[<span class="number">20</span>, <span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>, <span class="number">24</span>],</span><br><span class="line">[<span class="number">25</span>, <span class="number">26</span>, <span class="number">27</span>, <span class="number">28</span>, <span class="number">29</span>]]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = np.array([[<span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">False</span>], [<span class="literal">False</span>, <span class="literal">True</span>, <span class="literal">True</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[b]</span><br><span class="line">array([[ <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">[ <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>],</span><br><span class="line">[<span class="number">20</span>, <span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>, <span class="number">24</span>],</span><br><span class="line">[<span class="number">25</span>, <span class="number">26</span>, <span class="number">27</span>, <span class="number">28</span>, <span class="number">29</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y[b[:,<span class="number">5</span>],<span class="number">1</span>:<span class="number">3</span>]</span><br><span class="line">array([[<span class="number">22</span>, <span class="number">23</span>],</span><br><span class="line">[<span class="number">29</span>, <span class="number">30</span>]])<span class="number">12345678910111213141516171819202122232425</span></span><br></pre></td></tr></table></figure>
<p>再拿出来官方文档：</p>
<h2 id="basic-slicing-and-indexing"><a class="markdownIt-Anchor" href="#basic-slicing-and-indexing"></a> Basic Slicing and Indexing</h2>
<p>Basic slicing extends Python’s basic concept of slicing to N dimensions. Basic slicing occurs when <em>obj</em> is a <a href="https://docs.python.org/dev/library/functions.html#slice"><code>slice</code></a> object (constructed by <code>start:stop:step</code> notation inside of brackets), an integer, or a tuple of slice objects and integers. <code>Ellipsis</code> and <a href="https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.indexing.html#numpy.newaxis"><code>newaxis</code></a> objects can be interspersed with these as well. In order to remain backward compatible with a common usage in Numeric, basic slicing is also initiated if the selection object is any non-ndarray sequence (such as a <a href="https://docs.python.org/dev/library/stdtypes.html#list"><code>list</code></a>) containing <a href="https://docs.python.org/dev/library/functions.html#slice"><code>slice</code></a> objects, the <code>Ellipsis</code> object, or the <a href="https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.indexing.html#numpy.newaxis"><code>newaxis</code></a> object, but not for integer arrays or other embedded sequences.</p>
<p>All arrays generated by basic slicing are always <a href="https://docs.scipy.org/doc/numpy-1.13.0/glossary.html#term-view">views</a> of the original array.</p>
<p>The standard rules of sequence slicing apply to basic slicing on a per-dimension basis (including using a step index). Some useful concepts to remember include:</p>
<ul>
<li>
<p>The basic slice syntax is <code>i:j:k</code> where <em>i</em> is the starting index, <em>j</em> is the stopping index, and <em>k</em> is the step. This selects the <em>m</em> elements (in the corresponding dimension) with index values <em>i</em>, <em>i + k</em>, …, <em>i + (m - 1) k</em> where  and <em>q</em> and <em>r</em> are the quotient and remainder obtained by dividing <em>j - i</em> by <em>k</em>: <em>j - i = q k + r</em>, so that <em>i + (m - 1) k &lt; j</em>.</p>
<p>Example</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = np.array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="number">1</span>:<span class="number">7</span>:<span class="number">2</span>]</span><br><span class="line">array([<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>])</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Negative <em>i</em> and <em>j</em> are interpreted as <em>n + i</em> and <em>n + j</em> where <em>n</em> is the number of elements in the corresponding dimension. Negative <em>k</em> makes stepping go towards smaller indices.</p>
<p>Example</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[-<span class="number">2</span>:<span class="number">10</span>]</span><br><span class="line">array([<span class="number">8</span>, <span class="number">9</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[-<span class="number">3</span>:<span class="number">3</span>:-<span class="number">1</span>]</span><br><span class="line">array([<span class="number">7</span>, <span class="number">6</span>, <span class="number">5</span>, <span class="number">4</span>])</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Assume <em>n</em> is the number of elements in the dimension being sliced. Then, if <em>i</em> is not given it defaults to 0 for <em>k &gt; 0</em> and <em>n - 1</em> for <em>k &lt; 0</em> . If <em>j</em> is not given it defaults to <em>n</em> for <em>k &gt; 0</em> and <em>-n-1</em> for <em>k &lt; 0</em> . If <em>k</em> is not given it defaults to 1. Note that <code>::</code> is the same as <code>:</code> and means select all indices along this axis.</p>
<p>Example</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="number">5</span>:]</span><br><span class="line">array([<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>If the number of objects in the selection tuple is less than <em>N</em> , then <code>:</code> is assumed for any subsequent dimensions.</p>
<p>Example</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = np.array([[[<span class="number">1</span>],[<span class="number">2</span>],[<span class="number">3</span>]], [[<span class="number">4</span>],[<span class="number">5</span>],[<span class="number">6</span>]]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.shape</span><br><span class="line">(<span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="number">1</span>:<span class="number">2</span>]</span><br><span class="line">array([[[<span class="number">4</span>],</span><br><span class="line">        [<span class="number">5</span>],</span><br><span class="line">        [<span class="number">6</span>]]])</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><code>Ellipsis</code> expand to the number of <code>:</code> objects needed to make a selection tuple of the same length as <code>x.ndim</code>. There may only be a single ellipsis present.</p>
<p>Example</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[...,<span class="number">0</span>]</span><br><span class="line">array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Each <a href="https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.indexing.html#numpy.newaxis"><code>newaxis</code></a> object in the selection tuple serves to expand the dimensions of the resulting selection by one unit-length dimension. The added dimension is the position of the <a href="https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.indexing.html#numpy.newaxis"><code>newaxis</code></a> object in the selection tuple.</p>
<p>Example</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[:,np.newaxis,:,:].shape</span><br><span class="line">(<span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>An integer, <em>i</em>, returns the same values as <code>i:i+1</code> <strong>except</strong> the dimensionality of the returned object is reduced by 1. In particular, a selection tuple with the <em>p</em>-th element an integer (and all other entries <code>:</code>) returns the corresponding sub-array with dimension <em>N - 1</em>. If <em>N = 1</em> then the returned object is an array scalar. These objects are explained in <a href="https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.scalars.html#arrays-scalars">Scalars</a>.</p>
</li>
<li>
<p>If the selection tuple has all entries <code>:</code> except the <em>p</em>-th entry which is a slice object <code>i:j:k</code>, then the returned array has dimension <em>N</em> formed by concatenating the sub-arrays returned by integer indexing of elements <em>i</em>, <em>i+k</em>, …, <em>i + (m - 1) k &lt; j</em>,</p>
</li>
<li>
<p>Basic slicing with more than one non-<code>:</code> entry in the slicing tuple, acts like repeated application of slicing using a single non-<code>:</code> entry, where the non-<code>:</code> entries are successively taken (with all other non-<code>:</code> entries replaced by <code>:</code>). Thus, <code>x[ind1,...,ind2,:]</code> acts like <code>x[ind1][...,ind2,:]</code> under basic slicing.</p>
<p>Warning</p>
<p>The above is <strong>not</strong> true for advanced indexing.</p>
</li>
<li>
<p>You may use slicing to set values in the array, but (unlike lists) you can never grow the array. The size of the value to be set in<code>x[obj] = value</code> must be (broadcastable) to the same shape as <code>x[obj]</code>.</p>
</li>
</ul>
<p>Note</p>
<p>Remember that a slicing tuple can always be constructed as <em>obj</em> and used in the <code>x[obj]</code> notation. Slice objects can be used in the construction in place of the <code>[start:stop:step]</code> notation. For example, <code>x[1:10:5,::-1]</code> can also be implemented as <code>obj = (slice(1,10,5), slice(None,None,-1)); x[obj]</code> . This can be useful for constructing generic code that works on arrays of arbitrary dimension.</p>
<ul>
<li>
<p><code>numpy.``newaxis</code></p>
<p>The <a href="https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.indexing.html#numpy.newaxis"><code>newaxis</code></a> object can be used in all slicing operations to create an axis of length one. <a href="https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.indexing.html#numpy.newaxis"><code>newaxis</code></a> is an alias for ‘None’, and ‘None’ can be used in place of this with the same result.</p>
</li>
</ul>
<h2 id="advanced-indexing"><a class="markdownIt-Anchor" href="#advanced-indexing"></a> Advanced Indexing</h2>
<p>Advanced indexing is triggered when the selection object, <em>obj</em>, is a non-tuple sequence object, an <a href="https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.ndarray.html#numpy.ndarray"><code>ndarray</code></a> (of data type integer or bool), or a tuple with at least one sequence object or ndarray (of data type integer or bool). There are two types of advanced indexing: integer and Boolean.</p>
<p>Advanced indexing always returns a <em>copy</em> of the data (contrast with basic slicing that returns a <a href="https://docs.scipy.org/doc/numpy-1.13.0/glossary.html#term-view">view</a>).</p>
<p>Warning</p>
<p>The definition of advanced indexing means that <code>x[(1,2,3),]</code> is fundamentally different than <code>x[(1,2,3)]</code>. The latter is equivalent to <code>x[1,2,3]</code> which will trigger basic selection while the former will trigger advanced indexing. Be sure to understand why this occurs.</p>
<p>Also recognize that <code>x[[1,2,3]]</code> will trigger advanced indexing, whereas <code>x[[1,2,slice(None)]]</code> will trigger basic slicing.</p>
<h3 id="integer-array-indexing"><a class="markdownIt-Anchor" href="#integer-array-indexing"></a> Integer array indexing</h3>
<p>Integer array indexing allows selection of arbitrary items in the array based on their <em>N</em>-dimensional index. Each integer array represents a number of indexes into that dimension.</p>
<h4 id="purely-integer-array-indexing"><a class="markdownIt-Anchor" href="#purely-integer-array-indexing"></a> Purely integer array indexing</h4>
<p>When the index consists of as many integer arrays as the array being indexed has dimensions, the indexing is straight forward, but different from slicing.</p>
<p>Advanced indexes always are <a href="https://docs.scipy.org/doc/numpy-1.13.0/reference/ufuncs.html#ufuncs-broadcasting">broadcast</a> and iterated as <em>one</em>:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result[i_1, ..., i_M] == x[ind_1[i_1, ..., i_M], ind_2[i_1, ..., i_M],</span><br><span class="line">                           ..., ind_N[i_1, ..., i_M]]</span><br></pre></td></tr></table></figure>
<p>Note that the result shape is identical to the (broadcast) indexing array shapes <code>ind_1, ..., ind_N</code>.</p>
<p>Example</p>
<p>From each row, a specific element should be selected. The row index is just <code>[0, 1, 2]</code> and the column index specifies the element to choose for the corresponding row, here <code>[0, 1, 0]</code>. Using both together the task can be solved using advanced indexing:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]]</span><br><span class="line">array([<span class="number">1</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br></pre></td></tr></table></figure>
<p>To achieve a behaviour similar to the basic slicing above, broadcasting can be used. The function <a href="https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.ix_.html#numpy.ix_"><code>ix_</code></a> can help with this broadcasting. This is best understood with an example.</p>
<p>Example</p>
<p>From a 4x3 array the corner elements should be selected using advanced indexing. Thus all elements for which the column is one of <code>[0, 2]</code>and the row is one of <code>[0, 3]</code> need to be selected. To use advanced indexing one needs to select all elements <em>explicitly</em>. Using the method explained previously one could write:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = array([[ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>],</span><br><span class="line"><span class="meta">... </span>           [ <span class="number">3</span>,  <span class="number">4</span>,  <span class="number">5</span>],</span><br><span class="line"><span class="meta">... </span>           [ <span class="number">6</span>,  <span class="number">7</span>,  <span class="number">8</span>],</span><br><span class="line"><span class="meta">... </span>           [ <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rows = np.array([[<span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line"><span class="meta">... </span>                 [<span class="number">3</span>, <span class="number">3</span>]], dtype=np.intp)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>columns = np.array([[<span class="number">0</span>, <span class="number">2</span>],</span><br><span class="line"><span class="meta">... </span>                    [<span class="number">0</span>, <span class="number">2</span>]], dtype=np.intp)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[rows, columns]</span><br><span class="line">array([[ <span class="number">0</span>,  <span class="number">2</span>],</span><br><span class="line">       [ <span class="number">9</span>, <span class="number">11</span>]])</span><br></pre></td></tr></table></figure>
<p>However, since the indexing arrays above just repeat themselves, broadcasting can be used (compare operations such as<code>rows[:, np.newaxis] + columns</code>) to simplify this:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>rows = np.array([<span class="number">0</span>, <span class="number">3</span>], dtype=np.intp)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>columns = np.array([<span class="number">0</span>, <span class="number">2</span>], dtype=np.intp)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rows[:, np.newaxis]</span><br><span class="line">array([[<span class="number">0</span>],</span><br><span class="line">       [<span class="number">3</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[rows[:, np.newaxis], columns]</span><br><span class="line">array([[ <span class="number">0</span>,  <span class="number">2</span>],</span><br><span class="line">       [ <span class="number">9</span>, <span class="number">11</span>]])</span><br></pre></td></tr></table></figure>
<p>This broadcasting can also be achieved using the function <a href="https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.ix_.html#numpy.ix_"><code>ix_</code></a>:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[np.ix_(rows, columns)]</span><br><span class="line">array([[ <span class="number">0</span>,  <span class="number">2</span>],</span><br><span class="line">       [ <span class="number">9</span>, <span class="number">11</span>]])</span><br></pre></td></tr></table></figure>
<p>Note that without the <code>np.ix_</code> call, only the diagonal elements would be selected, as was used in the previous example. This difference is the most important thing to remember about indexing with multiple advanced indexes.</p>
<h4 id="combining-advanced-and-basic-indexing"><a class="markdownIt-Anchor" href="#combining-advanced-and-basic-indexing"></a> Combining advanced and basic indexing</h4>
<p>When there is at least one slice (<code>:</code>), ellipsis (<code>...</code>) or <code>np.newaxis</code> in the index (or the array has more dimensions than there are advanced indexes), then the behaviour can be more complicated. It is like concatenating the indexing result for each advanced index element</p>
<p>In the simplest case, there is only a <em>single</em> advanced index. A single advanced index can for example replace a slice and the result array will be the same, however, it is a copy and may have a different memory layout. A slice is preferable when it is possible.</p>
<p>Example</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="number">1</span>:<span class="number">2</span>, <span class="number">1</span>:<span class="number">3</span>]</span><br><span class="line">array([[<span class="number">4</span>, <span class="number">5</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="number">1</span>:<span class="number">2</span>, [<span class="number">1</span>, <span class="number">2</span>]]</span><br><span class="line">array([[<span class="number">4</span>, <span class="number">5</span>]])</span><br></pre></td></tr></table></figure>
<p>The easiest way to understand the situation may be to think in terms of the result shape. There are two parts to the indexing operation, the subspace defined by the basic indexing (excluding integers) and the subspace from the advanced indexing part. Two cases of index combination need to be distinguished:</p>
<ul>
<li>The advanced indexes are separated by a slice, ellipsis or newaxis. For example <code>x[arr1, :, arr2]</code>.</li>
<li>The advanced indexes are all next to each other. For example <code>x[..., arr1, arr2, :]</code> but <em>not</em> <code>x[arr1, :, 1]</code> since <code>1</code> is an advanced index in this regard.</li>
</ul>
<p>In the first case, the dimensions resulting from the advanced indexing operation come first in the result array, and the subspace dimensions after that. In the second case, the dimensions from the advanced indexing operations are inserted into the result array at the same spot as they were in the initial array (the latter logic is what makes simple advanced indexing behave just like slicing).</p>
<p>Example</p>
<p>Suppose <code>x.shape</code> is (10,20,30) and <code>ind</code> is a (2,3,4)-shaped indexing <code>intp</code> array, then <code>result = x[...,ind,:]</code> has shape (10,2,3,4,30) because the (20,)-shaped subspace has been replaced with a (2,3,4)-shaped broadcasted indexing subspace. If we let <em>i, j, k</em> loop over the (2,3,4)-shaped subspace then <code>result[...,i,j,k,:] = x[...,ind[i,j,k],:]</code>. This example produces the same result as <a href="https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.ndarray.take.html#numpy.ndarray.take"><code>x.take(ind, axis=-2)</code></a>.</p>
<p>Example</p>
<p>Let <code>x.shape</code> be (10,20,30,40,50) and suppose <code>ind_1</code> and <code>ind_2</code> can be broadcast to the shape (2,3,4). Then <code>x[:,ind_1,ind_2]</code> has shape (10,2,3,4,40,50) because the (20,30)-shaped subspace from X has been replaced with the (2,3,4) subspace from the indices. However,<code>x[:,ind_1,:,ind_2]</code> has shape (2,3,4,10,30,50) because there is no unambiguous place to drop in the indexing subspace, thus it is tacked-on to the beginning. It is always possible to use <a href="https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.ndarray.transpose.html#numpy.ndarray.transpose"><code>.transpose()</code></a> to move the subspace anywhere desired. Note that this example cannot be replicated using <a href="https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.take.html#numpy.take"><code>take</code></a>.</p>
]]></content>
      <tags>
        <tag>python</tag>
        <tag>numpy</tag>
      </tags>
  </entry>
  <entry>
    <title>Numpy矩阵拼接数据集</title>
    <url>/2018/08/18/numpy-concatenate/</url>
    <content><![CDATA[<p>机器学习中，有时候需要自己生成含有n个channel、size相同的输入数据。这个时候就需要进行numpy的拼接操作了。</p>
<h3 id="先看示例代码"><a class="markdownIt-Anchor" href="#先看示例代码"></a> 先看示例代码：</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">gen_input</span>(<span class="params">Vn, Vp, nx1, ny1, net_charge</span>):</span><br><span class="line">    net_charge = np.array(net_charge)[np.newaxis, :]</span><br><span class="line">    border_cond = np.zeros((<span class="number">1</span>, <span class="built_in">int</span>(ny1), <span class="built_in">int</span>(nx1)))</span><br><span class="line">    border_cond[<span class="number">0</span>, :, <span class="number">0</span>] = Vn</span><br><span class="line">    border_cond[<span class="number">0</span>, :, -<span class="number">1</span>] = Vp</span><br><span class="line">    model_input = np.concatenate((net_charge, border_cond), axis=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> model_input[np.newaxis, :]</span><br></pre></td></tr></table></figure>
<p>上面的net_charge和border_cond即为需要进行拼接操作的两个matrix，分别使用了[np.newaxis,:]和初始化的时候就多生成一维的方法，最后使用np.concatenate进行拼接。</p>
<span id="more"></span>
<h3 id="数组拼接方法一"><a class="markdownIt-Anchor" href="#数组拼接方法一"></a> 数组拼接方法一</h3>
<p>思路：首先将数组转成列表，然后利用列表的拼接函数append()、extend()等进行拼接处理，最后将列表转成数组。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a_list.extend(b_list)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a_list</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">10</span>, <span class="number">12</span>, <span class="number">15</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a=np.array(a_list)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">array([ <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">5</span>, <span class="number">10</span>, <span class="number">12</span>, <span class="number">15</span>])</span><br></pre></td></tr></table></figure>
<p>该方法只适用于简单的一维数组拼接，由于转换过程很耗时间，对于大量数据的拼接一般不建议使用。</p>
<h3 id="数组拼接方法二"><a class="markdownIt-Anchor" href="#数组拼接方法二"></a> 数组拼接方法二</h3>
<p>思路：numpy提供了numpy.append(arr, values, axis=None)函数。对于参数规定，要么一个数组和一个数值；要么两个数组，不能三个及以上数组直接append拼接。append函数返回的始终是一个一维数组。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a=np.arange(<span class="number">5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.append(a,<span class="number">10</span>)</span><br><span class="line">array([ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>,  <span class="number">4</span>, <span class="number">10</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b=np.array([<span class="number">11</span>,<span class="number">22</span>,<span class="number">33</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b</span><br><span class="line">array([<span class="number">11</span>, <span class="number">22</span>, <span class="number">33</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.append(a,b)</span><br><span class="line">array([ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>,  <span class="number">4</span>, <span class="number">11</span>, <span class="number">22</span>, <span class="number">33</span>]) </span><br></pre></td></tr></table></figure>
<p>numpy的数组没有动态改变大小的功能，numpy.append()函数每次都会重新分配整个数组，并把原来的数组复制到新数组中。</p>
<h3 id="数组拼接方法三"><a class="markdownIt-Anchor" href="#数组拼接方法三"></a> 数组拼接方法三</h3>
<p>思路：numpy提供了numpy.concatenate((a1,a2,…), axis=0)函数。能够一次完成多个数组的拼接。其中a1,a2,…是数组类型的参数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a=np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b=np.array([<span class="number">11</span>,<span class="number">22</span>,<span class="number">33</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c=np.array([<span class="number">44</span>,<span class="number">55</span>,<span class="number">66</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.concatenate((a,b,c),axis=<span class="number">0</span>)  <span class="comment"># 默认情况下，axis=0可以不写</span></span><br><span class="line">array([ <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>, <span class="number">11</span>, <span class="number">22</span>, <span class="number">33</span>, <span class="number">44</span>, <span class="number">55</span>, <span class="number">66</span>]) <span class="comment">#对于一维数组拼接，axis的值不影响最后的结果</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.concatenate((a,b),axis=<span class="number">1</span>)  <span class="comment">#axis=1表示对应行的数组进行拼接</span></span><br><span class="line">array([[ <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>, <span class="number">11</span>, <span class="number">21</span>, <span class="number">31</span>],</span><br><span class="line">       [ <span class="number">4</span>,  <span class="number">5</span>,  <span class="number">6</span>,  <span class="number">7</span>,  <span class="number">8</span>,  <span class="number">9</span>]])</span><br></pre></td></tr></table></figure>
<h3 id="拼接方法时间比较"><a class="markdownIt-Anchor" href="#拼接方法时间比较"></a> 拼接方法时间比较</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> time <span class="keyword">import</span> clock <span class="keyword">as</span> now</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a=np.arange(<span class="number">9999</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b=np.arange(<span class="number">9999</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>time1=now()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c=np.append(a,b)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>time2=now()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span> time2-time1</span><br><span class="line"><span class="number">28.2316728446</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a=np.arange(<span class="number">9999</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b=np.arange(<span class="number">9999</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>time1=now()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c=np.concatenate((a,b),axis=<span class="number">0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>time2=now()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span> time2-time1</span><br><span class="line"><span class="number">20.3934997107</span></span><br></pre></td></tr></table></figure>
<p>可知，concatenate()效率更高，适合大规模的数据拼接</p>
<h3 id="numpy添加新的维度newaxis"><a class="markdownIt-Anchor" href="#numpy添加新的维度newaxis"></a> numpy添加新的维度：newaxis</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.random.randint(<span class="number">1</span>, <span class="number">8</span>, size=<span class="number">5</span>)</span><br><span class="line">x</span><br><span class="line">Out[<span class="number">48</span>]: array([<span class="number">4</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">5</span>])</span><br><span class="line">x1 = x[np.newaxis, :]</span><br><span class="line">x1</span><br><span class="line">Out[<span class="number">50</span>]: array([[<span class="number">4</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">5</span>]])</span><br><span class="line">x2 = x[:, np.newaxis]</span><br><span class="line">x2</span><br><span class="line">Out[<span class="number">52</span>]: </span><br><span class="line">array([[<span class="number">4</span>],</span><br><span class="line">       [<span class="number">6</span>],</span><br><span class="line">       [<span class="number">6</span>],</span><br><span class="line">       [<span class="number">6</span>],</span><br><span class="line">       [<span class="number">5</span>]])</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>python</tag>
        <tag>numpy</tag>
      </tags>
  </entry>
  <entry>
    <title>目标检测学习笔记</title>
    <url>/2019/02/16/obj-det/</url>
    <content><![CDATA[<h2 id="pre-knowledge"><a class="markdownIt-Anchor" href="#pre-knowledge"></a> Pre Knowledge</h2>
<h3 id="anchors"><a class="markdownIt-Anchor" href="#anchors"></a> Anchors</h3>
<p>提到RPN网络，就不能不说anchors。所谓anchors，实际上就是一组作用在滑动窗口上的不同大小、不同形状的检测框。实际上，论文通过anchors引入了检测中常用到的多尺度方法。</p>
<p><img data-src="006y8mN6ly1g7lwlolk5gj30qy0gumyd.jpg" alt></p>
<span id="more"></span>
<p>那么这9个anchors是做什么的呢？借用Faster RCNN论文中的原图，遍历Conv layers计算获得的feature maps，为每一个点都配备这9种anchors作为初始的检测框。这样做获得检测框很不准确，不用担心，后面还有2次bounding box regression可以修正检测框位置。</p>
<p><img data-src="006y8mN6ly1g7lwlpxr9gj30qy0gumyd.jpg" alt></p>
<p>解释一下上面这张图的数字。</p>
<ol>
<li>在原文中使用的是ZF model中，其Conv Layers中最后的conv5层num_output=256，对应生成256张特征图，所以相当于feature map每个点都是256-dimensions</li>
<li>在conv5之后，做了rpn_conv/3x3卷积且num_output=256，相当于每个点又融合了周围3x3的空间信息（猜测这样做也许更鲁棒？反正我没测试），同时256-d不变（如图4和图7中的红框）</li>
<li>假设在conv5 feature map中每个点上有k个anchor（默认k=9），而每个anhcor要分foreground和background，所以每个点由256d feature转化为cls=2k scores；而每个anchor都有[x, y, w, h]对应4个偏移量，所以reg=4k coordinates</li>
<li>补充一点，全部anchors拿去训练太多了，训练程序会在合适的anchors中<strong>随机</strong>选取128个postive anchors+128个negative anchors进行训练。</li>
</ol>
<p><strong>其实RPN最终就是在原图尺度上，设置了密密麻麻的候选Anchor。然后用cnn去判断哪些Anchor是里面有目标的foreground anchor，哪些是没目标的backgroud。所以，仅仅是个二分类而已！</strong></p>
<p>那么Anchor一共有多少个？原图800x600，VGG下采样16倍，feature map每个点设置9个Anchor，所以共有17100个。</p>
<h3 id="region-proposal-networksrpn"><a class="markdownIt-Anchor" href="#region-proposal-networksrpn"></a> Region Proposal Networks(RPN)</h3>
<blockquote>
<p>A Region Proposal Network (RPN) takes an image (of any size) as input and outputs a set of rectangular object proposals, each with an objectness score.</p>
</blockquote>
<p><img data-src="006y8mN6ly1g7lwm49qjrj311609y0tp.jpg" alt="Network Structure"></p>
<p><img data-src="006tNbRwgy1fxvxstswxlj30qy0guq3j.jpg" alt="Paper Image"></p>
<ul>
<li><strong>Input:</strong> 一个任意形状的图像</li>
<li><strong>Output:</strong> 一系列框住了可能目标物体的矩形，每个矩形同时配一个置信分数</li>
<li>这个首部的3x3的小卷积核是一切的开始。这个卷积核会把3x3x(256 or 512, deepth or channel, depends on the feature extracting network, we take 256 here)的数据卷积成一个1x1x256的低维list，供后续卷积使用。</li>
<li>3x3小卷积核后面跟着两个更小的1x1的卷积核。这两个1x1的小卷积核的功能是维度变换，作用分别是做分类任务和bounding box位置的回归，这两者的维度分别为(2k和4k)。之所以分类有2k是由于这里把前景和背景的概率分别进行了预测，而每个上一步卷积出来的低维list都会对应有k个anchor。Bounding box回归每个anchor需要四个值的原因是其实这里的回归进行的是一个线性变换（x、y方向的scale与平移），刚好需要四个参数。具体如下：<br>
<img data-src="006tNbRwgy1fxvykq0qalj31fu0bumyi.jpg" alt></li>
<li>Loss问题：RPN实质上是一个同时具有分类与回归两种功能的Multi-Task任务，所以其Loss也是由两部分组成的：<br>
<img data-src="006tNbRwgy1fxvyqnx4pvj30yu046mx6.jpg" alt></li>
</ul>
<h4 id="faq"><a class="markdownIt-Anchor" href="#faq"></a> FAQ</h4>
<p><strong>Q1:</strong> 这里的1x1卷积核不是只对一个256元素的array做了一个维度变换吗，和anchor怎么扯上关系的？<br>
<strong>A1:</strong> 其实anchor的分类（前背景）与位置回归是作为这些输出的label出现的，即这个1x1的卷积核确实只是一个单纯的维度变换，作用其实和全连接层是一致的，只是训练时候输出的值的label是用Anchor的前背景以及位置映射来标注的。<br>
<strong>Q2:</strong> 为什么前背景分类需要用两个值进行标注，一个不是已经足够了吗？<br>
<strong>A2:</strong> 因为标注的并不是直接的IoU(Intersection-over-Union)， 而是两个binary的数字，Pos:0/1 Neg:0/1；此外还要考虑的是除了Pos和Neg两类，还有既不Pos也不Neg的无用类别，这种类别的Pos和Neg都是0。详见：<br>
<img data-src="006tNbRwgy1fxvyo307inj31fu0ae75s.jpg" alt></p>
<h3 id="feature-pyramid-network-fpn"><a class="markdownIt-Anchor" href="#feature-pyramid-network-fpn"></a> Feature Pyramid Network (<strong>FPN</strong>)</h3>
<p><strong>理解：通过捕获特征提取中各个池化层间的特征图，加上压缩后又通过插值得到同样size的特征图的方法得到可供后续处理的多种尺寸的特征图，从而使得网络可以提取到同一张图片上各种尺度的目标</strong></p>
<p>多尺度检测在目标检测中变得越来越重要，对小目标的检测尤其如此。现在主流的目标检测方法很多都用到了多尺度的方法，包括最新的yolo v3。Feature Pyramid Network (<strong>FPN</strong>)则是一种精心设计的多尺度检测方法，下面就开始简要介绍FPN。</p>
<p>FPN结构中包括自下而上，自上而下和横向连接三个部分，如下图所示。这种结构可以将各个层级的特征进行融合，使其同时具有强语义信息和强空间信息，在特征学习中算是一把利器了。</p>
<p><img data-src="006y8mN6ly1g7lwlrh5lej30so0p0jtd.jpg" alt></p>
<p>FPN实际上是一种通用架构，可以结合各种骨架网络使用，比如VGG，ResNet等。Mask RCNN文章中使用了ResNNet-FPN网络结构。如下图：</p>
<p><img data-src="006y8mN6ly1g7lwlwq9k2j31060p8wgx.jpg" alt></p>
<p>ResNet-FPN包括3个部分，自下而上连接，自上而下连接和横向连接。下面分别介绍。</p>
<p><strong>自下而上</strong></p>
<p>从下到上路径。可以明显看出，其实就是简单的特征提取过程，和传统的没有区别。具体就是将ResNet作为骨架网络，根据feature map的大小分为5个stage。stage2，stage3，stage4和stage5各自最后一层输出conv2，conv3，conv4和conv5分别定义为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mn>2</mn></msub><mo separator="true">,</mo><msub><mi>C</mi><mn>3</mn></msub><mo separator="true">,</mo><msub><mi>C</mi><mn>4</mn></msub><mo separator="true">,</mo><msub><mi>C</mi><mn>5</mn></msub></mrow><annotation encoding="application/x-tex">C_2,C_3,C_4,C_5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, 他们相对于原始图片的stride是{4,8,16,32}。需要注意的是，考虑到内存原因，stage1的conv1并没有使用。</p>
<p><strong>自上而下和横向连接</strong></p>
<p>自上而下是从最高层开始进行上采样，这里的上采样直接使用的是最近邻上采样，而不是使用反卷积操作，一方面简单，另外一方面可以减少训练参数。横向连接则是将上采样的结果和自底向上生成的相同大小的feature map进行融合。具体就是对 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mn>2</mn></msub><mo separator="true">,</mo><msub><mi>C</mi><mn>3</mn></msub><mo separator="true">,</mo><msub><mi>C</mi><mn>4</mn></msub><mo separator="true">,</mo><msub><mi>C</mi><mn>5</mn></msub></mrow><annotation encoding="application/x-tex">C_2,C_3,C_4,C_5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 中的每一层经过一个conv 1x1操作（1x1卷积用于降低通道数），无激活函数操作，输出通道全部设置为相同的256通道，然后和上采样的feature map进行加和操作。在融合之后还会再采用3*3的卷积核对已经融合的特征进行处理，目的是消除上采样的混叠效应（aliasing effect）。</p>
<p>实际上，<strong>上图少绘制了一个分支</strong>：M5经过步长为2的max pooling下采样得到 P6，作者指出使用P6是想得到更大的anchor尺度512×512。但P6是只用在 RPN中用来得到region proposal的，并不会作为后续Fast RCNN的输入。</p>
<p>总结一下，ResNet-FPN作为RPN输入的feature map是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mi>P</mi><mn>2</mn><mo separator="true">,</mo><mi>P</mi><mn>3</mn><mo separator="true">,</mo><mi>P</mi><mn>4</mn><mo separator="true">,</mo><mi>P</mi><mn>5</mn><mo separator="true">,</mo><mi>P</mi><mn>6</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[P2,P3,P4,P5,P6]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord">3</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord">4</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord">5</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord">6</span><span class="mclose">]</span></span></span></span> ，而作为后续Fast RCNN的输入则是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mi>P</mi><mn>2</mn><mo separator="true">,</mo><mi>P</mi><mn>3</mn><mo separator="true">,</mo><mi>P</mi><mn>4</mn><mo separator="true">,</mo><mi>P</mi><mn>5</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[P2,P3,P4,P5]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord">3</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord">4</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord">5</span><span class="mclose">]</span></span></span></span>。</p>
<h3 id="线性插值"><a class="markdownIt-Anchor" href="#线性插值"></a> 线性插值</h3>
<p><strong>理解：对于一个新的点，对其角线上的两个点进行操作，以它们和新点之间夹的点的距离为权重，进行平均操作</strong></p>
<p>已知数据 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>0</mn></msub><mo separator="true">,</mo><msub><mi>y</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">x_0, y_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>与 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>y</mi><mn>1</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(x_1, y_1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> ，要计算 $[x_0, x_1] $区间内某一位置 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">x</span></span></span></span> 在直线上的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span>值，如下图所示。</p>
<p><img data-src="006tNbRwgy1fxwc6411fkj30iu0iy3zd.jpg" alt></p>
<p>计算方法很简单，通过斜率相等就可以构建y和x之间的关系，如下：<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi>y</mi><mo>−</mo><msub><mi>y</mi><mn>0</mn></msub></mrow><mrow><mi>x</mi><mo>−</mo><msub><mi>x</mi><mn>0</mn></msub></mrow></mfrac><mo>=</mo><mfrac><mrow><mi>y</mi><mo>−</mo><msub><mi>y</mi><mn>1</mn></msub></mrow><mrow><mi>x</mi><mo>−</mo><msub><mi>x</mi><mn>1</mn></msub></mrow></mfrac><mo>=</mo><mo>=</mo><mo>=</mo><mo>=</mo><mo>&gt;</mo><mi>y</mi><mo>=</mo><mfrac><mrow><mi>x</mi><mo>−</mo><msub><mi>x</mi><mn>0</mn></msub></mrow><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>−</mo><msub><mi>x</mi><mn>0</mn></msub></mrow></mfrac><msub><mi>y</mi><mn>1</mn></msub><mo>+</mo><mfrac><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>−</mo><mi>x</mi></mrow><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>−</mo><msub><mi>x</mi><mn>0</mn></msub></mrow></mfrac><msub><mi>y</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\frac{y - y_0}{x - x_0} = \frac{y - y_1}{x - x_1} ====&gt; y=\frac{x-x_0}{x_1-x_0}y_1+\frac{x_1-x}{x_1-x_0}y_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2995389999999998em;vertical-align:-0.44509999999999994em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.854439em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.446108em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.44509999999999994em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2995389999999998em;vertical-align:-0.44509999999999994em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.854439em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.446108em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.44509999999999994em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span></span><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">=</span></span><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">=</span></span><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">=</span></span><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.263531em;vertical-align:-0.44509999999999994em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8184309999999999em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.4101em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.44509999999999994em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.263531em;vertical-align:-0.44509999999999994em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8184309999999999em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.4101em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.44509999999999994em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><br>
仔细看就是用 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">x</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">x_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> ， <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">x_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的距离作为一个权重（除以 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>−</mo><msub><mi>x</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">x-x_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是归一化的作用），用于 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">y_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">y_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的加权。这个思想很重要，因为知道了这个思想，理解双线性插值就非常简单了。</p>
<h3 id="双线性插值"><a class="markdownIt-Anchor" href="#双线性插值"></a> 双线性插值</h3>
<p><strong>理解：双线性插值本质上就是在两个方向上（先对四个角上的点同一y的两个点分别做线性插值，再在y轴上对这两个新产生的点做线性插值）做线性插值。</strong></p>
<p><img data-src="006tNbRwgy1fxwc6udoxpj310a0j4jsh.jpg" alt></p>
<p>如图，假设我们想得到P点的插值，我们可以先在x方向上，对 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mn>11</mn></msub></mrow><annotation encoding="application/x-tex">Q_{11}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mn>21</mn></msub></mrow><annotation encoding="application/x-tex">Q_{21}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>之间做线性插值得到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>R</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">R_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>， <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>R</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">R_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 同理可得。然后在y方向上对 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>R</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">R_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>R</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">R_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 进行线性插值就可以得到最终的P。其实知道这个就已经理解了双线性插值的意思了，如果用公式表达则如下（注意<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span></span>前面的系数看成权重就很好理解了)。</p>
<p>首先在 <em>x</em> 方向进行线性插值，得到<br>
<img data-src="006y8mN6ly1g7lwm8qgkjj30ze0aawfs.jpg" alt><br>
然后在 <em>y</em> 方向进行线性插值，得到<br>
<img data-src="006y8mN6ly1g7lwlsmq4lj30zo03ot8t.jpg" alt></p>
<p>这样就得到所要的结果 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(x,y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span><br>
<img data-src="006y8mN6ly1g7lwmaa8g6j310a0j4gmh.jpg" alt></p>
<h3 id="roi-pooling"><a class="markdownIt-Anchor" href="#roi-pooling"></a> ROI pooling</h3>
<p><strong>理解：把一个任意形状(AxB)的区域压缩成相同特征图(MxN)的方法：把这个区域等分成MxN份，在每个区域上做Max Pooling</strong></p>
<p>通过一个例子来形象理解。假设现在我们有一个8x8大小的feature map，我们要在这个feature map上得到ROI，并且进行ROI pooling到2x2大小的输出。</p>
<p><img data-src="006y8mN6ly1g7lwm388gcj30zo0nc0vq.jpg" alt></p>
<p>假设ROI的bounding box为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>y</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator="true">,</mo><msub><mi>y</mi><mn>2</mn></msub><mo stretchy="false">]</mo><mo>=</mo><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>3</mn><mo separator="true">,</mo><mn>7</mn><mo separator="true">,</mo><mn>8</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[x_1,y_1,x_2,y_2]=[0,3,7,8]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">3</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">7</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">8</span><span class="mclose">]</span></span></span></span> 。如图：</p>
<p><img data-src="006y8mN6ly1g7lwm753psj30zm0i275n.jpg" alt></p>
<p>将它划分为2x2的网格，因为ROI的长宽除以2是不能整除的，所以会出现每个格子大小不一样的情况。</p>
<p><img data-src="006y8mN6ly1g7lwmapai7j30zq05mjrx.jpg" alt></p>
<p>进行max pooling的最终2x2的输出为：</p>
<p><img data-src="006y8mN6ly1g7lwlyc815j30ba0bamxg.jpg" alt></p>
<p>最后以一张动图形象概括之：</p>
<p><img data-src="006y8mN6ly1g7lwlud1s1g30go0ciacs.gif" alt></p>
<h3 id="roi-align"><a class="markdownIt-Anchor" href="#roi-align"></a> ROI Align</h3>
<p><strong>理解：在之前的ROI Pooling的基础上取消了其做的两种近似，而用前面提到的双线性插值法得到更加精确的结果</strong></p>
<p>在Faster RCNN中，有两次整数化的过程：</p>
<ol>
<li>region proposal的xywh通常是小数，但是为了方便操作会把它整数化。</li>
<li>将整数化后的边界区域平均分割成 k x k 个单元，对每一个单元的边界进行整数化。</li>
</ol>
<p>两次整数化的过程如下图所示：</p>
<p><img data-src="006y8mN6ly1g7lwm8au03j30ze0aawfs.jpg" alt></p>
<p>事实上，经过上述两次整数化，此时的候选框已经和最开始回归出来的位置有一定的偏差，这个偏差会影响检测或者分割的准确度。在论文里，作者把它总结为“不匹配问题”（misalignment）。</p>
<p>为了解决这个问题，ROI Align方法取消整数化操作，保留了小数，使用以上介绍的双线性插值的方法获得坐标为浮点数的像素点上的图像数值。但在实际操作中，ROI Align并不是简单地补充出候选区域边界上的坐标点，然后进行池化，而是重新进行设计。</p>
<p>下面通过一个例子来讲解ROI Align操作。如下图所示，虚线部分表示feature map，实线表示ROI，这里将ROI切分成2x2的单元格。如果采样点数是4，那我们首先将每个单元格子均分成四个小方格（如红色线所示），每个小方格中心就是采样点。这些采样点的坐标通常是浮点数，所以需要对采样点像素进行双线性插值（如四个箭头所示），就可以得到该像素点的值了。然后对每个单元格内的四个采样点进行maxpooling，就可以得到最终的ROIAlign的结果。</p>
<p><img data-src="006y8mN6ly1g7lwm0fc6rj30v00u0jtq.jpg" alt></p>
<p>需要说明的是，在相关实验中，作者发现将采样点设为4会获得最佳性能，甚至直接设为1在性能上也相差无几。事实上，ROI Align 在遍历取样点的数量上没有ROIPooling那么多，但却可以获得更好的性能，这主要归功于解决了misalignment的问题。</p>
<h2 id="faster-rcnn"><a class="markdownIt-Anchor" href="#faster-rcnn"></a> Faster RCNN</h2>
<p><img data-src="006y8mN6ly1g7lwlv96qnj30n60ngdh6.jpg" alt="原论文中Faster RCNN基本结构"></p>
<p><img data-src="006y8mN6ly1g7lwlzge8ej31160iotaq.jpg" alt="详细网络结构"></p>
<p><img data-src="006y8mN6ly1g7lwlxmfscj30zo0a0q47.jpg" alt="Faster RCNN 网络分模块解析"></p>
<p><img data-src="006y8mN6ly1g7lwm9l7pij310a0j4gmh.jpg" alt="训练时网络图"></p>
<h2 id="mask-rcnn"><a class="markdownIt-Anchor" href="#mask-rcnn"></a> Mask RCNN</h2>
<p><img data-src="006y8mN6ly1g7lwm28dkaj30yy0bcta2.jpg" alt="Mask RCNN 网络分模块解析"></p>
<h3 id="与faster-rcnn关系"><a class="markdownIt-Anchor" href="#与faster-rcnn关系"></a> 与Faster RCNN关系</h3>
<p>简单来说，Mask RCNN的头部网络和Faster RCNN完全相同，不同的地方只有最后的预测部分，从之前的<strong>分类+bounding box回归</strong>改为了<strong>分类+bounding box回归+Mask预测</strong><br>
Mask RCNN的构建很简单，只是在ROI pooling（实际上用到的是ROIAlign，后面会讲到）之后添加卷积层，进行mask预测的任务。</p>
<h3 id="损失"><a class="markdownIt-Anchor" href="#损失"></a> 损失</h3>
<p>Mask RCNN定义多任务损失：<br>
<img data-src="006y8mN6ly1g7lwm6f7dcj30zm0i275n.jpg" alt></p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi>c</mi><mi>l</mi><mi>s</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_{cls}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi>b</mi><mi>o</mi><mi>x</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_{box}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">b</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>与faster rcnn的定义没有区别。需要具体说明的是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi>m</mi><mi>a</mi><mi>s</mi><mi>k</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_{mask}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> ，假设一共有K个类别，则mask分割分支的输出维度是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mo>∗</mo><mi>m</mi><mo>∗</mo><mi>m</mi></mrow><annotation encoding="application/x-tex">K*m*m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.46528em;vertical-align:0em;"></span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">m</span></span></span></span> , 对于 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo>∗</mo><mi>m</mi></mrow><annotation encoding="application/x-tex">m*m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.46528em;vertical-align:0em;"></span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">m</span></span></span></span>中的每个点，都会输出K个二值Mask（每个类别使用sigmoid输出）。需要注意的是，计算loss的时候，并不是每个类别的sigmoid输出都计算二值交叉熵损失，而是该像素属于哪个类，哪个类的sigmoid输出才要计算损失(如图红色方形所示)。并且在测试的时候，我们是通过分类分支预测的类别来选择相应的mask预测。这样，mask预测和分类预测就彻底解耦了。</p>
<p>这与FCN方法是不同，FCN是对每个像素进行多类别softmax分类，然后计算交叉熵损失，很明显，这种做法是会造成类间竞争的，而每个类别使用sigmoid输出并计算二值损失，可以避免类间竞争。实验表明，通过这种方法，可以较好地提升性能。</p>
<h2 id="论文"><a class="markdownIt-Anchor" href="#论文"></a> 论文</h2>
<ul>
<li>RCNN: <a href="http://fcv2011.ulsan.ac.kr/files/announcement/513/r-cnn-cvpr.pdf">here</a></li>
<li>Fast RCNN: <a href="https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Girshick_Fast_R-CNN_ICCV_2015_paper.html">here</a></li>
<li>Faster RCNN: <a href="http://papers.nips.cc/paper/5638-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks">here</a></li>
<li>Mask RCNN: <a href="https://ieeexplore.ieee.org/abstract/document/8237584/">here</a></li>
</ul>
<h2 id="代码"><a class="markdownIt-Anchor" href="#代码"></a> 代码</h2>
<ul>
<li>Fast RCNN: <a href="https://github.com/rbgirshick/fast-rcnn">here</a></li>
<li>Faster RCNN: <a href="https://github.com/jwyang/faster-rcnn.pytorch">here</a></li>
<li>Mask RCNN:  <a href="https://github.com/roytseng-tw/Detectron.pytorch">here</a></li>
</ul>
<h2 id="参考"><a class="markdownIt-Anchor" href="#参考"></a> 参考</h2>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/31983610">【CV-instance segmentation】Mask R-CNN阅读笔记</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/31426458">一文读懂Faster RCNN</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/37998710">令人拍案称奇的Mask RCNN</a></li>
</ul>
]]></content>
      <tags>
        <tag>machine-learning</tag>
        <tag>deep-learning</tag>
        <tag>object-detection</tag>
      </tags>
  </entry>
  <entry>
    <title>Off-Policy &amp; On-Policy</title>
    <url>/2019/01/22/off-on-policy/</url>
    <content><![CDATA[<p>On-Policy 与 Off-Policy的本质区别在于：更新Q值时所使用的方法是沿用既定的策略（on-policy）还是使用新策略（off-policy）。</p>
<p><img data-src="006tKfTcgy1g0f8y7lartj30ib0kf768.jpg" alt></p>
<span id="more"></span>
<p><img data-src="006tKfTcgy1g0f8yhlj6cj30ja0cv75a.jpg" alt></p>
<p>Sarsa更新Q值的时候对下一步的估计采用的是Q本身的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><mo stretchy="false">(</mo><mi>S</mi><mtext>’</mtext><mo separator="true">,</mo><mi>A</mi><mtext>’</mtext><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Q(S’,A’)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">Q</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord">’</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">A</span><span class="mord">’</span><span class="mclose">)</span></span></span></span>，而Q-Learning更新的时候对下一步的估计部分则采用的是直接取采取动作a后环境中各个a’对应的Q的最大值，即其在选择Action的时候使用的是e-greedy算法，而更新Q值的时候则采用了直接取最大值的greedy算法。</p>
<h2 id="反映到结果上"><a class="markdownIt-Anchor" href="#反映到结果上"></a> 反映到结果上</h2>
<p><strong>On-policy</strong>：必须本人在场, 并且一定是本人边玩边学习。<br>
<strong>Off-policy</strong>：可以选择自己玩, 也可以选择看着别人玩, 通过看别人玩来学习别人的行为准则。</p>
]]></content>
      <tags>
        <tag>machine-learning</tag>
        <tag>deep-learning</tag>
        <tag>reinforcement-learning</tag>
      </tags>
  </entry>
  <entry>
    <title>OKR初认识</title>
    <url>/2018/03/22/okr/</url>
    <content><![CDATA[<h1 id="okr-初认识"><a class="markdownIt-Anchor" href="#okr-初认识"></a> OKR 初认识</h1>
<ul>
<li>O是Objective，KR是Key Results。每个项目组的O是其当前的主要目标，比如把准确率提升至80%；KR是关键目标，比如要继续调研多少种模型。</li>
<li>KR记住一定要加上时间节点进去</li>
<li>O一般不超过4个，每个O下面对应的KR最多也不超过4个</li>
<li>年度目标，季度目标，每周目标，每日目标</li>
<li>最好70%完成度的目标比较合适，可以使得任务的完成度充分拉伸</li>
<li>关键是要有一个具体的数据并且要起到激励作用，而不要使用副词“大幅度”，“尽量”等</li>
</ul>
]]></content>
      <tags>
        <tag>management</tag>
        <tag>okr</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Server One-Key Setup</title>
    <url>/2019/09/20/one-key-linux/</url>
    <content><![CDATA[<p>推荐一下新写的Linux系统一键装机脚本(๑´∀｀๑)一行命令获得常用命令行软件、zsh、方便好用的诸多zsh插件（如自动补全、一键解压、目录快速跳转、命令行语法高亮等。详见readme和source code）以及一个配置好的spacevim。当前只支持ubuntu。后面将会支持centos。</p>
<p>你将在任何一个新的Linux系统上一键得到一个稳定可靠的使用体验！当然，脚本高度可定制，以上所有内容都可以简单地增减。有问题或需求欢迎提issue～（注意⚠️在已经使用并配置过的电脑上运行可能会出现zshrc配置重复问题）</p>
<p><a href="https://github.com/miracleyoo/initialize-server-script">GitHub链接</a></p>
<span id="more"></span>
<p><strong>下面是英文的使用说明：</strong></p>
<h2 id="overview"><a class="markdownIt-Anchor" href="#overview"></a> Overview</h2>
<p>This project aims to conveniently setup and deploy a Linux environment which is easy to use and help install many useful packages. It mainly have the ability to deploy zsh with a set of handy plugins, and a spacevim, which is my favorite vim distro. You will not encounter messy installation problems and the script is tested on ubuntu and WSL ubuntu.</p>
<p>Currently, it only support Ubuntu system, but the support of centos is also on the way, maybe also the MacOS version.</p>
<p>It is highly customizable and elegantly wrote, you can folk and customize your own version based on it!</p>
<h2 id="usage"><a class="markdownIt-Anchor" href="#usage"></a> Usage</h2>
<h3 id="method-1"><a class="markdownIt-Anchor" href="#method-1"></a> Method 1</h3>
<ol>
<li>Make sure you already have curl installed by “sudo apt-get install curl”.</li>
<li>Use command <code>curl -fsSL https://raw.githubusercontent.com/miracleyoo/initialize-server-script/master/one-key-linux-setup.sh -o minit.sh &amp;&amp; sudo bash minit.sh</code></li>
<li>You are all set! Here is an awesome new linux!</li>
</ol>
<h3 id="method-2"><a class="markdownIt-Anchor" href="#method-2"></a> Method 2</h3>
<ol>
<li>Make sure you already have curl installed by “sudo apt-get install git”.</li>
<li>Clone this repo using <code>git clone https://github.com/miracleyoo/initialize-server-script</code></li>
<li>Switch into this folder and run <code>./one-key-linux-setup.sh</code></li>
<li>You are all set!</li>
</ol>
<h2 id="content"><a class="markdownIt-Anchor" href="#content"></a> Content</h2>
<ol>
<li><code>apt-get install packags</code> like git, curl, tmux, vim, and python supports.</li>
<li>A <code>zsh</code> which has plenty of handy plugins like <code>oh-my-zsh</code>, <code>git</code>, <code>zsh-autosuggestions</code>, <code>zsh-syntax-highlighting</code>, <code>zsh-completions</code> , <code>extract</code>, <code>z</code>, <code>cp</code>. They are managed with <code>antigen</code>, which made it easy and decent to mange your zsh plugins. You can get even more plugins <a href="https://github.com/robbyrussell/oh-my-zsh/wiki/Plugins-Overview">here</a>.</li>
<li>A <code>.zshrc</code> file which contains some basic but useful functions. You can change it to your own favorite commands and alias.</li>
<li>A <a href="https://github.com/SpaceVim/SpaceVim">spacevim</a>, which is a quite good version of vim. It initially installed several famous plugins, with a nice interface. You will find it a really vim distro as you use it. Certainly, you can change to your own version, while I’ve tested several distro and they all have some kinds of inconvenience, like the line number, extra space, wrong background color and so on.</li>
<li>More on the way!</li>
</ol>
]]></content>
      <tags>
        <tag>tool</tag>
        <tag>linux</tag>
        <tag>server</tag>
      </tags>
  </entry>
  <entry>
    <title>Pandas Resample</title>
    <url>/2020/03/24/pandas-resample/</url>
    <content><![CDATA[<p>Pandas原生支持<code>resample</code>功能，前提是目标DataFrame需要有一个index的column。假设我们现在在对一个取样率为30Hz的DataFrame做操作，并想将它变resample为16Hz。</p>
<p>首先我们要建立一个<code>timestamp</code>的列，这个名字随意，然后它是以秒为单位的该帧的时间，如3.25，14.33。然后我们将其转换为datatime格式，单位为s。</p>
<span id="more"></span>
<p>之后便是直接resample，resample中的<code>rule</code>，即第一个参数，指明了resample后两帧之间的时间间隔，即周期。如果我们是16Hz，那这个周期为62.5ms。</p>
<p><code>resample</code>方法的格式是：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">DataFrame.resample(rule, how=<span class="literal">None</span>, axis=<span class="number">0</span>, fill_method=<span class="literal">None</span>, closed=<span class="literal">None</span>, label=<span class="literal">None</span>, convention=<span class="string">&#x27;start&#x27;</span>,kind=<span class="literal">None</span>, loffset=<span class="literal">None</span>, limit=<span class="literal">None</span>, base=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<h2 id="示例代码"><a class="markdownIt-Anchor" href="#示例代码"></a> 示例代码</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.index=pd.to_datetime(df[<span class="string">&#x27;timestamp&#x27;</span>],unit=<span class="string">&#x27;s&#x27;</span>)</span><br><span class="line">df=df.resample(<span class="string">&#x27;62.5L&#x27;</span>).mean()</span><br><span class="line">df=df.reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">del</span> df[<span class="string">&#x27;timestamp&#x27;</span>]</span><br></pre></td></tr></table></figure>
<h2 id="pandas时间缩写"><a class="markdownIt-Anchor" href="#pandas时间缩写"></a> Pandas时间缩写</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">B         business day frequency</span><br><span class="line">C         custom business day frequency (experimental)</span><br><span class="line">D         calendar day frequency</span><br><span class="line">W         weekly frequency</span><br><span class="line">M         month end frequency</span><br><span class="line">SM        semi-month end frequency (15th and end of month)</span><br><span class="line">BM        business month end frequency</span><br><span class="line">CBM       custom business month end frequency</span><br><span class="line">MS        month start frequency</span><br><span class="line">SMS       semi-month start frequency (1st and 15th)</span><br><span class="line">BMS       business month start frequency</span><br><span class="line">CBMS      custom business month start frequency</span><br><span class="line">Q         quarter end frequency</span><br><span class="line">BQ        business quarter endfrequency</span><br><span class="line">QS        quarter start frequency</span><br><span class="line">BQS       business quarter start frequency</span><br><span class="line">A         year end frequency</span><br><span class="line">BA, BY    business year end frequency</span><br><span class="line">AS, YS    year start frequency</span><br><span class="line">BAS, BYS  business year start frequency</span><br><span class="line">BH        business hour frequency</span><br><span class="line">H         hourly frequency</span><br><span class="line">T, min    minutely frequency</span><br><span class="line">S         secondly frequency</span><br><span class="line">L, ms     milliseconds</span><br><span class="line">U, us     microseconds</span><br><span class="line">N         nanoseconds</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>python</tag>
        <tag>machine-learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Paper：&quot;Solving Poisson&#39;s Equation using Deep Learning in Particle Simulation of PN Junction&quot;</title>
    <url>/2018/10/27/paper-dl-poisson/</url>
    <content><![CDATA[<p>最近在Dr.Fan和Ling Zhang学长的帮助下总结了暑研期间在密苏里科技大学EMC Lab所做的部分工作，完成了第一篇paper: *“Solving Poisson’s Equation using Deep Learning in Particle Simulation of PN Junction”*的编写和修改工作，并投稿于2019 International Symposium on Electromagnetic Compatibility (by IEEE)会议。</p>
<p>目前已经将预印本传至Arxiv: <a href="https://arxiv.org/abs/1810.10192">Link</a>，有兴趣的话可以看下<sub>内容可能还有诸多纰漏，如有发现欢迎邮件联系</sub></p>
<p>再次感谢paper完成过程中给予了大力帮助的各位。</p>
<p><a href="1540623051128-acaa562b-65c3-4980-952d-d30c765f51b8-image.png"><img data-src="https://bbs.dian.org.cn/assets/uploads/files/1540623051128-acaa562b-65c3-4980-952d-d30c765f51b8-image-resized.png" alt="0_1540623045920_acaa562b-65c3-4980-952d-d30c765f51b8-image.png"></a></p>
]]></content>
      <tags>
        <tag>machine-learning</tag>
        <tag>deep-learning</tag>
        <tag>paper</tag>
        <tag>EMC</tag>
      </tags>
  </entry>
  <entry>
    <title>Paper Reading： &quot;W!NCE： Unobtrusive Sensing of Upper Facial Action Units with EOG-based Eyewear&quot;</title>
    <url>/2019/10/20/paper-rev-wnce/</url>
    <content><![CDATA[<h2 id="one-line-summary"><a class="markdownIt-Anchor" href="#one-line-summary"></a> One Line Summary</h2>
<p>W!NCW developes a two-stage processing pipeline which can do continuously and unobtrusively sensing of upper facial action units with high fidelity. Because it doesn’t use camera so it also eliminate the privacy concerns.</p>
<span id="more"></span>
<h2 id="terms"><a class="markdownIt-Anchor" href="#terms"></a> Terms</h2>
<ol>
<li>Electrooculography(EOG, 眼球电图检查): A technique for measuring the corneo-retinal standing potential that exists between the front and the back of the human eye. The resulting signal is called the electrooculogram. Primary applications are in ophthalmological diagnosis and in recording eye movements.</li>
<li>Motion artifacts removal pipeline: Mainly used to remove noise across multiple EOF channels and many different head movement patterns. It is based on neural network.</li>
<li></li>
</ol>
<h2 id="points"><a class="markdownIt-Anchor" href="#points"></a> Points</h2>
<ol>
<li>There are already standard Facial Action Coding System(FACS) along with camera based methods which can be applied to check facial expressions, but their positioning is awkward and they may bring in privacy problems.</li>
<li>The hardware is not a lab-product, rather, it is based on commercially available comfortable daily eyeware device J!NS MEME.</li>
<li>EOG metrics is useful for recognizing different types of activities such as reading and writing. since each activity has its own unique eye movement pattern.</li>
<li>The EOG sensors are placed on the nose and the IMU sensor is embedded in the temples of the eyeglass.</li>
<li>W!NCE takes the body motion into consideration, while existing work work in motion artifact removal from physiological signals couldn’t do so.</li>
<li>The lower face action is harder to be detected because the signal are generated  in distant muscles, so it will be damped when reaches the sensor.</li>
<li>J!NS MEME employs stainless steel eletrodes which belong to the stiff material dry eletrodes. It has a lower price and a good electrical performance and lower possiblility of skin irritation compared to gel-based ones.</li>
<li>Some actions of heads will cast a similar influence on EOG sensors(like nod and lower eyebrows), while the IMU signals will be quite different, which can help confirm the real action.</li>
<li>We have to consider the signal variation across individuals, since the face shape, the shape of nose-bridge, the fit of the glasses behind the ear, the variation in the way individuals use upper facial muscles influence the signals captured greatly.</li>
<li>Personalizing with transfer learning is utilized to address the problem above. The device will take some labled data from user when they use it for the first time, and only re-train the last layer(full-connection layer).</li>
<li>The CNN model will not always be in the working state. In fact, the model process will only be triggered when substantial EOG activities are detected after the motion artifact removal stage. Also, the motion artifact removal model will only run when significant variation is observed in the raw EOG signal.</li>
</ol>
<h2 id="question"><a class="markdownIt-Anchor" href="#question"></a> Question</h2>
<ol>
<li>What if user sweet on there nose? Will it affect the accuracy of EOG sensor?</li>
<li>This eye-glass based design will be easy to accommodate for those who always wearing a glass, but to the others who don’t have the habit, it might be difficult.</li>
<li>For the CNN and motion artifact removal trigger, for the emotions or movement which only generate minor signal, like the lower face action, will it be detected?</li>
<li>How to know whether the prediction is right or not? User may express multiple emotion and movement at the same time. Same question when dataset is collected.</li>
<li>Why people will need, or need to buy this product? Will a normal person have the requisition to know their facial action and emotion all day? If so, what can the data collected derive?</li>
</ol>
<h2 id="images"><a class="markdownIt-Anchor" href="#images"></a> Images</h2>
<p><img data-src="image-20191020171322278.png" alt="image-20191020171322278"></p>
<p><img data-src="image-20191020172902493.png" alt="image-20191020172902493"></p>
<p><img data-src="image-20191020190355816.png" alt="image-20191020190355816"></p>
<p><img data-src="image-20191020173940080.png" alt="image-20191020173940080"></p>
<p><img data-src="image-20191020183735447.png" alt="image-20191020183735447"></p>
]]></content>
      <tags>
        <tag>machine-learning</tag>
        <tag>deep-learning</tag>
        <tag>paper</tag>
        <tag>HCI</tag>
        <tag>mobile-health</tag>
      </tags>
  </entry>
  <entry>
    <title>Paper Reading ： &quot;NOSE： A Novel Odor Sensing Engine for Ambient Monitoring of the Frying Cooking Method in Kitchen Environments&quot;</title>
    <url>/2019/10/24/paper-rev-nose/</url>
    <content><![CDATA[<h1 id="one-line-summary"><a class="markdownIt-Anchor" href="#one-line-summary"></a> One Line Summary</h1>
<p>NOSE: A device which utilize order sensing component and machine learning to detect which kind of cooking method and which kind of foods, oils are used when you are cooking. It can be used to periodically reports to users about their cooking habits.</p>
<span id="more"></span>
<h1 id="terms"><a class="markdownIt-Anchor" href="#terms"></a> Terms</h1>
<ol>
<li>MOS Gas Sensor: A sensor which is sensitive to specific target analytes and attempts to replicate the human olfactory system by detecting various types of odors.</li>
</ol>
<h1 id="points"><a class="markdownIt-Anchor" href="#points"></a> Points</h1>
<ol>
<li>In the real-world environment, we cannot get the data with a start and end well defined. Here the author exploited a two-level classification approach.</li>
</ol>
<p><img data-src="image-20191024193802569.png" alt="image-20191024193802569"></p>
<h1 id="images"><a class="markdownIt-Anchor" href="#images"></a> Images</h1>
<p><img data-src="image-20191021152129125.png" alt="image-20191021152129125"></p>
<p><img data-src="image-20191021154348447.png" alt="image-20191021154348447"></p>
<h1 id="questions"><a class="markdownIt-Anchor" href="#questions"></a> Questions</h1>
<ol>
<li>We can use multiple dimensional information to detect what is going on. For example, if we add sound detect devices or infrared sensor and use their signals to do analysis at the same time, the accuracy may get dramatically improved. If camera can also be applied, even more detailed information can be obtained.</li>
<li>Regarding the privacy issue, perhaps we can consider using a embedded auto-clip algorithm which make it possible to only output a limited region which only contains the main region of the Target-of-Interest.</li>
</ol>
<p><img data-src="image-20191024193841882.png" alt="image-20191024193841882"></p>
<ol start="3">
<li>We can even combine different sensor and use one as the trigger of another. For example, camera will only work when the odor sensor feels that there is someone cooking or when infrared sensor feels that someone is approaching or the microphone hears the noise of cooking.</li>
</ol>
]]></content>
      <tags>
        <tag>machine-learning</tag>
        <tag>paper</tag>
        <tag>HCI</tag>
        <tag>mobile-health</tag>
      </tags>
  </entry>
  <entry>
    <title>Paper Reading： &quot;wPerf： Generic Off-CPU Analysis to Identify Bottleneck Waiting Events&quot;</title>
    <url>/2019/10/19/paper-rev-wperf/</url>
    <content><![CDATA[<h2 id="one-line-summary"><a class="markdownIt-Anchor" href="#one-line-summary"></a> One Line Summary</h2>
<p>Some waiting events can cast impact to multiple threads. A method which can computes not only the local impact of a waiting event, but also whether such impact can indirectly reach other threads is developed.</p>
<span id="more"></span>
<h2 id="important-terms"><a class="markdownIt-Anchor" href="#important-terms"></a> Important terms</h2>
<ol>
<li>On-CPU analysis: Used to identify bottlenecks created by execution.</li>
<li>Off-CPU analysis: Used to identify bottlenecks created by waiting.</li>
<li>False wakeup: A phenomenon that a thread is woken up but finds its condi- tion to continue is not satisfied, so it has to sleep again.</li>
<li>Knot(in the wait-for graph): A section which never wait for the outside threads. Because optimizing outside events will not influence the status inside(and will not improve overall thoughput), so each knot must contain a bottlenect. In a graph, a knot is a nonempty set K of vertices such that the reachable set of each vertex in K is exactly set K; a sink is a vertex with no edges directed from it.</li>
<li>Cascaded redistribution: If thread A waits for thread B from t1 to t2, wPerf checks what B is doing during t1 to t2 and if B is waiting for an- other thread, wPerf will re-distribute the corresponding weight and perform the check recursively.</li>
</ol>
<h2 id="points"><a class="markdownIt-Anchor" href="#points"></a> Points</h2>
<ol>
<li>wPerf act on events(Get the impact of events on all threads).</li>
<li>On-CPU analysis already has some tools good enough, while Off-CPU analysis is still inaccurate.</li>
<li>Wait-for graph: Each thread is a vertex and a directed edge from A to B means the time thread A waits for B.</li>
<li>Events with a small local impact usually have a small global im- pact, but events with a large local impact may not have a large global impact.</li>
<li>Things to be recorded: scheduling events, IRQ(interrupt request) events, information for I/O devices, information for busy waiting, call stacks.</li>
<li>wPerf can start and stop recording at any time.</li>
<li>wPerf treat I/O device as a pseudo I/O thread.</li>
<li>In order to minimize the overhead, recorder buffers events and flushs the buffers to trace file in the background. Also, the recorder creates a buffer and a trace file for each core to avoid contention.</li>
</ol>
<p><img data-src="image-20191019213731331.png" alt="image-20191019213731331"></p>
<h2 id="graphs"><a class="markdownIt-Anchor" href="#graphs"></a> Graphs</h2>
<p><img data-src="image-20191019184627121.png" alt="image-20191019184627121"></p>
<p><img data-src="image-20191019193352798.png" alt="image-20191019193352798"></p>
<h2 id="pros"><a class="markdownIt-Anchor" href="#pros"></a> Pros</h2>
<ol>
<li>It innovatively utilizes the “wait-for” graph method to investigate the wating relationship between threads, which make it easy to locate the bottleneck.</li>
<li>wPerf takes all these I/O operation, busy waiting, false wakeup into consideration, which make it more accuarte and competible to various cases.</li>
<li>Introduced “cascaded redistribution” which can help us find the origin bottleneck rather than simply take the waiting thread as the reason of latency.</li>
</ol>
<h2 id="cons"><a class="markdownIt-Anchor" href="#cons"></a> Cons</h2>
<ol>
<li>It can not be applied to distributed system currently.</li>
<li>It mainly foucuses on Off-CPU analysis, it may consider the combination of both On-CPU and Off-CPU analysis.</li>
<li>It brings in overheads in its recording process, especially when there are many waiting events.</li>
</ol>
<p><strong>Zhongyang Zhang</strong></p>
]]></content>
      <tags>
        <tag>paper</tag>
        <tag>system</tag>
        <tag>computer-architecture</tag>
      </tags>
  </entry>
  <entry>
    <title>Mac、Windows、iPad三端完美论文管理、阅读与编辑系统配置</title>
    <url>/2020/04/26/paper-zotero-dropbox/</url>
    <content><![CDATA[<p>管理好自己手中的论文，不让他们被吞噬与“Download”文件夹的茫茫文件海洋中已非易事，而能在需要时迅速定位，能在Windows的Desktop与便携的MacBook上无缝对接论文库则需要相对精细化的管理。然而，很多时候并不适合展开自己的笔记本电脑来“郑重”地阅读一篇论文，在一些相对零碎的时间里随手抽出包中的iPad，读读前面顺手存下的论文，则可大大增加自己的学术幸福感。</p>
<span id="more"></span>
<h2 id="需求分析"><a class="markdownIt-Anchor" href="#需求分析"></a> 需求分析</h2>
<p>上面这几点也正是我对论文管理系统的要求。注意这里提到的是“系统”，而并是一个单一的软件。这里提炼一下日常对论文管理及阅读的需求，您可以看看和自己的需求是否吻合：</p>
<ol>
<li>以分层目录的形式将论文进行归档，并且有时需要让同一篇论文同时存放于多个目录中。</li>
<li>支持多及目录（多&gt;2）。</li>
<li>支持从网页上便捷地储存论文以及文档。</li>
<li>支持拖入PDF自动寻找论文信息。</li>
<li>需要对论文的PDF原件进行存储，最好能够自动下载缺失的PDF。</li>
<li>需要在Mac和Windows端都能访问论文目录，且对PDF文件的修改能够同步。</li>
<li>PDF的存储最好和数据库系统分离，以便搜索、单独更改或访问。</li>
<li>需要对论文进行可自定义格式的自动重命名。</li>
<li>界面不能太丑。</li>
<li>支持高度自定义或有充足的功能，最好可以使用第三方插件。</li>
<li>支持各种引文格式。</li>
<li>支持Latex和Word的便捷引用，Word最好有插件。</li>
<li>拥有较大的云存储空间，至少足以存储所有的PDF文档。</li>
<li>可以从iPad上访问并且可以同步、上传对论文的更改。</li>
<li>三个平台PDF阅读器配置最好统一，以免高亮、插入文本等格式不一。</li>
</ol>
<p>归纳出的这几点便是我对论文管理系统的所有需求了。之后便是对各种论文管理软件的试用和组合。这里直奔主题，给出我现在的全套系统配置及选择的原因。</p>
<h2 id="系统配置"><a class="markdownIt-Anchor" href="#系统配置"></a> 系统配置</h2>
<ul>
<li>Mac与Windows端主论文管理软件：<a href="https://www.zotero.org/">Zotero</a></li>
<li>主要插件：<a href="http://zotfile.com/">zotfile</a>，<a href="https://github.com/retorquere/zotero-better-bibtex">zotero-better-bibtex</a></li>
<li>Mac、Windows与iPad统一PDF同步软件：Dropbox</li>
<li>Mac、Windows与iPad统一PDF阅读器：Adobe Acrobat</li>
</ul>
<h2 id="选用原因"><a class="markdownIt-Anchor" href="#选用原因"></a> 选用原因</h2>
<h3 id="zotero"><a class="markdownIt-Anchor" href="#zotero"></a> Zotero</h3>
<p>各大平台上以及Zotero官网对其讲解都很多也很充分了，如果你能够并且愿意花上一些时间来进行自定义配置，它将是一个可以满足几乎所有对论文管理需求的终极软件。我这里只指出一些我认为非常不错的特性。</p>
<ol>
<li>跨平台。Mac，Windows和Linux都有支持。</li>
<li>浏览器论文抓取插件很好用。既可直接抓取PDF文章之后解析出论文，也可在如Google Scholar等页面直接批量抓取添加论文索引，并再自动下载相应的PDF。甚至在一些作业性质的小论文中有时需要直接引用某个网页或某个文档，它也可以直接生成条目。</li>
<li>支持多级目录。这个多理论上似乎可以无限多下去，非常自由。</li>
<li>有很好用的Word插件，使用体验丝滑流畅。</li>
<li>拥有在线的庞大引用格式库，基本可以找到所有需要的引文格式。</li>
<li>可以加载很多第三方插件，如支持自定义格式重命名的zotfile，针对输出引用进行优化的better-bibtex等。</li>
<li>可以将条目的PDF文件储存目录单列出来，存到一个自定义的地方，比如Dropbox文件夹内部。</li>
</ol>
<h3 id="dropbox"><a class="markdownIt-Anchor" href="#dropbox"></a> Dropbox</h3>
<ol>
<li>因为现在在美国读书，Dropbox的服务相对来说是快速且稳定的。</li>
<li>Dropbox的同步功能做的非常好，这也是其在此领域深耕多年的结果。</li>
<li>最重要一点，Dropbox在iPad上和Adobe Acrobat有着原生的集成。在Dropbox中使用Acrobat打开并编辑文件，其修改是可以直接同步到Dropbox云端的。这一点对于移动端浏览和编辑论文起到了至关重要的作用。</li>
<li>免费版虽然只有2G初始空间，但是可以通过邀请好友注册达到最大的18G。虽然不是特别大，但是对于存储论文已经绰绰有余了。（另这个邀请注册送空间可以直接去淘宝搜索，可以画很少的钱得到很多注册服务，直达18G。）</li>
</ol>
<h3 id="adobe-acrobat"><a class="markdownIt-Anchor" href="#adobe-acrobat"></a> Adobe Acrobat</h3>
<ol>
<li>多平台支持。Mac，Windows，Linux，iOS，Android都有着很好的支持。</li>
<li>专业，支持各种编辑方式。常见的高亮、下划线、添加文本、画方框、做批注等自然都是支持的。</li>
<li>很多高校都和Adobe公司有着协议，使用学生邮箱可以直接免费使用全套功能。</li>
<li>同前面所述，其和Dropbox的关联性支持是整套系统成功的关键。</li>
</ol>
<h3 id="对比原因"><a class="markdownIt-Anchor" href="#对比原因"></a> 对比原因</h3>
<ol>
<li>之前有在用Mendeley，但是对比Zotero，尤其是对比Zotero和其第三方插件的丰富功能后，前者明显力不从心。另外Windows版本其界面没有针对高分辨率进行适配，并且使用了默认的宋体，显示英文丑陋不堪，且无法更改。在论坛上看到有许多坛友几年前就提出了这些问题，然而显然开发者并没有做出相应。对比Zotero，其论坛环境、活跃程度以及问题解决速度都会更好。</li>
<li>Endnote是收费软件，我并没有深入使用，这里不多置评，但各位可以容易查到Endnote和Zotero的区别。</li>
<li>iPad上也考虑过使用PDF Reader – Document Expert作为浏览和编辑软件，但是从Dropbox打开的文件编辑后是以副本的形式存在了本地，并没有被同步，这是无法接受的。</li>
</ol>
<h2 id="配置细节"><a class="markdownIt-Anchor" href="#配置细节"></a> 配置细节</h2>
<h3 id="zotero设置部分"><a class="markdownIt-Anchor" href="#zotero设置部分"></a> Zotero设置部分</h3>
<ol>
<li>在所有需要同步的电脑上登录Zotero的账号，如没有，请注册。</li>
<li>打开设置，更改<code>Files and Folders</code> 中的<code>Base Directory</code>选项为你的同步盘地址，如Dropbox，OneDrive，坚果云等。请不要动下面的<code>Data Directory Location</code>，这个是Zotero的总体数据库的地址，不建议放到云文件夹下，因为只要有两个端同时使用Zotero这个同步就崩掉了。</li>
</ol>
<p><img data-src="image-20191110225913571.png" alt="image-20191110225913571"></p>
<ol start="3">
<li>安装<a href="http://zotfile.com/">zotfile</a>。更改有关文件的设置。</li>
</ol>
<p>从Tools栏进入ZotFile Preference</p>
<p><img data-src="image-20191110230601630.png" alt="image-20191110230601630"></p>
<p>更改PDF文件存储位置。这里是把文件储存到云盘的关键步骤。上面那个更改文件存储地址的作用是指定未来加入的PDF文件的存储地址，而这里是把已经在库的文件移动到这个地址。两个地址相同。</p>
<p><img data-src="image-20191110230944192.png" alt="image-20191110230944192"></p>
<p>更改重命名相关的设置。这里的%y就是论文发表年份，%j是期刊名，%t是论文标题。而中间的下划线则只是单纯的会在重命名后的文件名中的两个元素之间加一个下滑线罢了，这里可以替换做任意。</p>
<p><img data-src="image-20191110230654373.png" alt="image-20191110230654373"></p>
<p>在你的所有需要同步的电脑上做完上述步骤后，如果你之前没有Zotero或它是全新的没有条目，那你的设定已经结束。如果库中已有很多论文，想要直接移动到Dropbox相应目录下，那么请执行下一步：</p>
<ol start="4">
<li>移动与重命名已有文件</li>
</ol>
<p><img data-src="image-20191110231928468.png" alt="image-20191110231928468"></p>
<p>点击 My Library，全选所有条目，右键选择<code>Manage Attachments</code>-&gt;<code>Rename Attachments</code>开始移动和重命名。</p>
<p><img data-src="image-20191110232045736.png" alt="image-20191110232045736"></p>
<p><img data-src="image-20191110232150562.png" alt="image-20191110232150562"></p>
<h3 id="ipad设置部分"><a class="markdownIt-Anchor" href="#ipad设置部分"></a> iPad设置部分</h3>
<ol>
<li>下载Dropbox和Acrobat。</li>
<li>打开Dropbox，进入你的论文同步文件夹，任选一篇点击打开</li>
<li>右下角找到一个光标键，点击，会提示用Adobe Acrobat Reader打开。</li>
<li>All set.</li>
</ol>
<p><img data-src="IMG_2601.jpg" alt="IMG_2601"></p>
]]></content>
      <tags>
        <tag>paper</tag>
        <tag>tool</tag>
      </tags>
  </entry>
  <entry>
    <title>PS混合模式原理与示例</title>
    <url>/2020/05/24/ps-blend/</url>
    <content><![CDATA[<h2 id="模式官方介绍"><a class="markdownIt-Anchor" href="#模式官方介绍"></a> 模式官方介绍</h2>
<p><strong>正片叠底</strong></p>
<p>查看<strong>每个通道</strong>中的颜色信息，并将基色与混合色进行正片叠底。结果色总是较暗的颜色。任何颜色与黑色正片叠底产生黑色。任何颜色与白色正片叠底保持不变。当您用黑色或白色以外的颜色绘画时，绘画工具绘制的连续描边产生逐渐变暗的颜色。这与使用多个标记笔在图像上绘图的效果相似。</p>
<img data-src="image-20200519225738854.png" alt="image-20200519225738854" style="zoom:33%;">
<p>如图，重点是<strong>分通道</strong>，所有的模式混合都是基于通道的。即红色的底色，往上加蓝色和绿色结果都是黑色。因为RGB通道相互间的暗色都是黑色。当然，它们与黑色叠加也是黑色的。</p>
<span id="more"></span>
<p><strong>滤色</strong></p>
<p>查看每个通道的颜色信息，并将混合色的互补色与基色进行正片叠底。结果色总是较亮的颜色。用黑色过滤时颜色保持不变。用白色过滤将产生白色。此效果类似于多个摄影幻灯片在彼此之上投影。</p>
<p><strong>正常</strong></p>
<p>编辑或绘制每个像素，使其成为结果色。这是默认模式。（在处理位图图像或索引颜色图像时，“正常”模式也称为<em>阈值</em>。）</p>
<p><strong>溶解</strong></p>
<p>编辑或绘制每个像素，使其成为结果色。但是，根据任何像素位置的不透明度，结果色由基色或混合色的像素随机替换。</p>
<p><strong>背后</strong></p>
<p>仅在图层的透明部分编辑或绘画。此模式仅在取消选择了“锁定透明区域”的图层中使用，类似于在透明纸的透明区域背面绘画。</p>
<p><strong>清除</strong></p>
<p>编辑或绘制每个像素，使其透明。此模式可用于形状工具（当选定填充区域 <img data-src="P_VectorShapeFilled_Md_N.png" alt="img"> 时）、油漆桶工具 <img data-src="P_Fill_Lg_N.png" alt="img">、画笔工具 <img data-src="P_Brush_Lg_N.png" alt="img">、铅笔工具 <img data-src="P_Draw_Lg_N.png" alt="img">、“填充”命令和“描边”命令。您必须位于取消选择了“锁定透明区域”的图层中才能使用此模式。</p>
<p><strong>变暗</strong></p>
<p>查看每个通道中的颜色信息，并选择基色或混合色中较暗的颜色作为结果色。将替换比混合色亮的像素，而比混合色暗的像素保持不变。</p>
<p><strong>颜色加深</strong></p>
<p>查看每个通道中的颜色信息，并通过增加二者之间的对比度使基色变暗以反映出混合色。与白色混合后不产生变化。</p>
<p><strong>线性加深</strong></p>
<p>查看每个通道中的颜色信息，并通过减小亮度使基色变暗以反映混合色。与白色混合后不产生变化。</p>
<p><strong>变亮</strong></p>
<p>查看每个通道中的颜色信息，并选择基色或混合色中较亮的颜色作为结果色。比混合色暗的像素被替换，比混合色亮的像素保持不变。</p>
<p><strong>颜色减淡</strong></p>
<p>查看每个通道中的颜色信息，并通过减小二者之间的对比度使基色变亮以反映出混合色。与黑色混合则不发生变化。</p>
<p><strong>线性减淡（添加）</strong></p>
<p>查看每个通道中的颜色信息，并通过增加亮度使基色变亮以反映混合色。与黑色混合则不发生变化。</p>
<p><strong>叠加</strong></p>
<p>对颜色进行正片叠底或过滤，具体取决于基色。图案或颜色在现有像素上叠加，同时保留基色的明暗对比。不替换基色，但基色与混合色相混以反映原色的亮度或暗度。</p>
<p><strong>柔光</strong></p>
<p>使颜色变暗或变亮，具体取决于混合色。此效果与发散的聚光灯照在图像上相似。如果混合色（光源）比 50% 灰色亮，则图像变亮，就像被减淡了一样。如果混合色（光源）比 50% 灰色暗，则图像变暗，就像被加深了一样。使用纯黑色或纯白色上色，可以产生明显变暗或变亮的区域，但不能生成纯黑色或纯白色。</p>
<p><strong>强光</strong></p>
<p>对颜色进行正片叠底或过滤，具体取决于混合色。此效果与耀眼的聚光灯照在图像上相似。如果混合色（光源）比 50% 灰色亮，则图像变亮，就像过滤后的效果。这对于向图像添加高光非常有用。如果混合色（光源）比 50% 灰色暗，则图像变暗，就像正片叠底后的效果。这对于向图像添加阴影非常有用。用纯黑色或纯白色上色会产生纯黑色或纯白色。</p>
<p><strong>亮光</strong></p>
<p>通过增加或减小对比度来加深或减淡颜色，具体取决于混合色。如果混合色（光源）比 50% 灰色亮，则通过减小对比度使图像变亮。如果混合色比 50% 灰色暗，则通过增加对比度使图像变暗。</p>
<p><strong>线性光</strong></p>
<p>通过减小或增加亮度来加深或减淡颜色，具体取决于混合色。如果混合色（光源）比 50% 灰色亮，则通过增加亮度使图像变亮。如果混合色比 50% 灰色暗，则通过减小亮度使图像变暗。</p>
<p><strong>点光</strong></p>
<p>根据混合色替换颜色。如果混合色（光源）比 50% 灰色亮，则替换比混合色暗的像素，而不改变比混合色亮的像素。如果混合色比 50% 灰色暗，则替换比混合色亮的像素，而比混合色暗的像素保持不变。这对于向图像添加特殊效果非常有用。</p>
<p><strong>实色混合</strong></p>
<p>将混合颜色的红色、绿色和蓝色通道值添加到基色的 RGB 值。如果通道的结果总和大于或等于 255，则值为 255；如果小于 255，则值为 0。因此，所有混合像素的红色、绿色和蓝色通道值要么是 0，要么是 255。此模式会将所有像素更改为主要的加色（红色、绿色或蓝色）、白色或黑色。</p>
<p><strong>差值</strong></p>
<p>查看每个通道中的颜色信息，并从基色中减去混合色，或从混合色中减去基色，具体取决于哪一个颜色的亮度值更大。与白色混合将反转基色值；与黑色混合则不产生变化。</p>
<p><strong>排除</strong></p>
<p>创建一种与“差值”模式相似但对比度更低的效果。与白色混合将反转基色值。与黑色混合则不发生变化。</p>
<p><strong>减去</strong></p>
<p>查看每个通道中的颜色信息，并从基色中减去混合色。在 8 位和 16 位图像中，任何生成的负片值都会剪切为零。</p>
<p><strong>划分</strong></p>
<p>查看每个通道中的颜色信息，并从基色中划分混合色。</p>
<p><strong>色相</strong></p>
<p>用基色的明亮度和饱和度以及混合色的色相创建结果色。</p>
<p><strong>饱和度</strong></p>
<p>用基色的明亮度和色相以及混合色的饱和度创建结果色。在无 (0) 饱和度（灰度）区域上用此模式绘画不会产生任何变化。</p>
<p><strong>颜色</strong></p>
<p>用基色的明亮度以及混合色的色相和饱和度创建结果色。这样可以保留图像中的灰阶，并且对于给单色图像上色和给彩色图像着色都会非常有用。</p>
<p><strong>明度</strong></p>
<p>用基色的色相和饱和度以及混合色的明亮度创建结果色。此模式创建与“颜色”模式相反的效果。</p>
<p><strong>浅色</strong></p>
<p>比较混合色和基色的所有通道值的总和并显示值较大的颜色。“浅色”不会生成第三种颜色（可以通过“变亮”混合获得），因为它将从基色和混合色中选取最大的通道值来创建结果色。</p>
<p><strong>深色</strong></p>
<p>比较混合色和基色的所有通道值的总和并显示值较小的颜色。“深色”不会生成第三种颜色（可以通过“变暗”混合获得），因为它将从基色和混合色中选取最小的通道值来创建结果色。</p>
<h2 id="公式"><a class="markdownIt-Anchor" href="#公式"></a> 公式</h2>
<p><img data-src="365c8ef854384f00b13c69e81eb2d41b.jpg" alt="img"></p>
<p>注释：</p>
<p>1.混合模式的数学计算公式，另外还介绍了不透明度。</p>
<p>2.这些公式仅适用于RGB图像，对于Lab颜色图像而言，这些公式将不再适用。</p>
<p>3.在公式中——</p>
<p>A 代表下面图层的颜色值，也称为基色；</p>
<p>B 代表上面图层的颜色值，也成为混合色；</p>
<p>C 代表混合图层的颜色值，也称为结果色；</p>
<p>D 表示该层的透明度。</p>
<h2 id="详细举例推理"><a class="markdownIt-Anchor" href="#详细举例推理"></a> 详细举例推理</h2>
<p>我们先建立两个图层：</p>
<p>当前选中层（Active Layer）为<strong>A层</strong>，或称“<strong>混合色</strong> blend color”</p>
<p>下层（Background Layer）为<strong>B层</strong>，或称“<strong>基色</strong> base color”，两者混合得到“<strong>结果色</strong> Result color”</p>
<p><img data-src="v2-49a088eef8b2851abc6bb5809dff666c_720w.png" alt="img"></p>
<h2 id="混合模式的基本原理"><a class="markdownIt-Anchor" href="#混合模式的基本原理"></a> <strong>混合模式的基本原理</strong></h2>
<p>取A层任意一个像素a [R1, G1, B1]，与B层对应位置的像素b [R2, G2, B2] 进行数学运算，得到c [R3, G3, B3]</p>
<ul>
<li>R1 某种运算 R2 = R3</li>
<li>G1 某种运算 G2 = G3</li>
<li>B1 某种运算 B2 = B3</li>
</ul>
<p>A、B两层<strong>所有像素</strong>都独立进行同样的运算，即得到混合后的结果C，即新的A层（注意虽然A层缩略图没有变，但直方图已经变了），而B保持不变</p>
<p>举一个简单例子，PS默认的图层混合模式是“正常”，在不透明度为100%时，</p>
<ul>
<li>R1 正常 R2 = R1</li>
<li>G1 正常 G2 = G1</li>
<li>B1 正常 B2 = B1</li>
</ul>
<p>也就是说，“正常”模式下，A层在B层之上，看到的只有A层，看不到B层</p>
<h2 id="混合模式的分类"><a class="markdownIt-Anchor" href="#混合模式的分类"></a> <strong>混合模式的分类</strong></h2>
<p>一般系：正常、溶解</p>
<p>变暗系：变暗、深色、正片叠底、颜色加深、线性加深</p>
<p>变亮系：变亮、浅色、滤色、颜色减淡、线性减淡</p>
<p>对比系：叠加、强光、柔光、亮光、线性光、点光、实色混合</p>
<ul>
<li>
<ul>
<li>该组特点是让亮的更亮，暗的更暗，每一个“对比系”的混合模式都可看作“变暗系”和“变亮系”的结合，如“叠加”是对较暗的像素进行“正片叠底”，对较亮的像素进行“滤色”</li>
</ul>
</li>
</ul>
<p>负片系：差值、排除</p>
<p>相消系：减去、划分</p>
<p>HSL系：色相、饱和度、颜色、明度</p>
<h2 id="混合模式彼此之间的联系"><a class="markdownIt-Anchor" href="#混合模式彼此之间的联系"></a> <strong>混合模式彼此之间的联系</strong></h2>
<ol>
<li>
<p>对于大多数混合模式，图层“不透明度”和“填充度”对混合效果影响是一样的，也就是说，60%的不透明度，与60%的填充度，得到的效果一样；但以下8种混合模式是例外</p>
<ul>
<li>颜色加深、颜色减淡</li>
<li>线性加深、线性减淡</li>
<li>亮光、线性光、实色混合</li>
<li>差值</li>
</ul>
</li>
<li>
<p>以下5组混合模式是相反对应关系（从后面的公式就可以看出）</p>
<ul>
<li>变暗 - 变亮</li>
<li>深色 - 浅色</li>
<li>正片叠底 - 滤色</li>
<li>颜色加深 - 颜色减淡</li>
<li>线性加深 - 线性减淡</li>
</ul>
</li>
<li>
<p>具有“互逆”关系的混合模式有两组，举例，A层在上，对A“叠加”；B层在上，对B“强光”：两种情况得到的效果是一样的</p>
<ul>
<li>叠加 <img data-src="equation.svg" alt="[公式]"> 强光</li>
<li>颜色 <img data-src="equation" alt="[公式]"> 明度</li>
</ul>
</li>
</ol>
<h2 id="每一种混合模式的运算方法"><a class="markdownIt-Anchor" href="#每一种混合模式的运算方法"></a> <strong>每一种混合模式的运算方法</strong></h2>
<p>当通道位深度为8位时，R、G、B三通道数值范围在0到255，我们除以255，得到0~1范围内的数值</p>
<p>我们用下图所示的两个100像素的图层做实验</p>
<p>A层有一个颜色， [R, G, B]值分别是 [102, 153, 204]，即[0.4, 0.6, 0.8]</p>
<p>B层有两个颜色，[0, 51, 102] 和 [255, 204, 153]，即 [0, 0.2, 0.4] 和 [1, 0.8, 0.6]</p>
<p><img data-src="v2-49a088eef8b2851abc6bb5809dff666c_720w.png" alt="img"></p>
<p>选中A层，调节混合模式</p>
<h2 id="i-正常系"><a class="markdownIt-Anchor" href="#i-正常系"></a> I 正常系</h2>
<blockquote>
<p><strong>正常 Normal</strong></p>
</blockquote>
<p>设不透明度为n</p>
<p><em><em><em>c = n*</em>*</em>*a + (1-n)*</em>***b***</p>
<p>当不透明度为100%</p>
<p><em><strong>c = a</strong></em></p>
<blockquote>
<p><strong>溶解 Dissolve</strong></p>
</blockquote>
<p>对每个像素而言，其结果色是基色或混合色的随机值，取决于其“不透明度”：“不透明度”高时，更多像素取自当前层；低时，更多像素取自背景层</p>
<h2 id="ii-变暗和变亮系"><a class="markdownIt-Anchor" href="#ii-变暗和变亮系"></a> II 变暗和变亮系</h2>
<blockquote>
<p><strong>变暗 Darken</strong></p>
</blockquote>
<p><em><strong>c = min(a,b)</strong> 逐通道进行运算</em></p>
<p>B: 颜色1 [0, 0.2, 0.4] 颜色2 [1, 0.8, 0.6]</p>
<p><img data-src="v2-9d6d881e09d25ea68d31b4aeb0a42584_720w.png" alt="img"></p>
<p>A: [0.4, 0.6, 0.8]</p>
<p><img data-src="v2-a97a64c70b7213f2179afa2c4969eb7e_720w.png" alt="img"></p>
<p>C: 颜色1 [0, 0.2, 0.4] 颜色2 [0.4, 0.6, 0.6]</p>
<p><img data-src="v2-6cd964357c823d7704b86e4aa486b02b_720w.png" alt="img"></p>
<p>得到变暗的效果</p>
<blockquote>
<p><strong>变亮</strong> <strong>Lighten</strong></p>
</blockquote>
<p>*<strong>c = max(a,b)*</strong> <em>逐通道进行运算</em></p>
<p>B: 颜色1 [0, 0.2, 0.4] 颜色2 [1, 0.8, 0.6]</p>
<p><img data-src="v2-9d6d881e09d25ea68d31b4aeb0a42584_720w.png" alt="img"></p>
<p>A: [0.4, 0.6, 0.8]</p>
<p><img data-src="v2-a97a64c70b7213f2179afa2c4969eb7e_720w.png" alt="img"></p>
<p>C: 颜色1 [0.4, 0.6, 0.8] 颜色2 [1, 0.8, 0.8]</p>
<p><img data-src="v2-c520d5c07364cbed9ce6b58faf3475c7_720w.png" alt="img"></p>
<p>得到变亮的效果</p>
<blockquote>
<p><strong>深色 Darker Color</strong></p>
</blockquote>
<p><em><strong>c = min(a, b)</strong> 三通道整体进行运算，不会产生新的颜色</em></p>
<p>B: 颜色1 [0, 0.2, 0.4] 颜色2 [1, 0.8, 0.6]</p>
<p><img data-src="v2-9d6d881e09d25ea68d31b4aeb0a42584_720w.png" alt="img"></p>
<p>A: [0.4, 0.6, 0.8]</p>
<p><img data-src="v2-a97a64c70b7213f2179afa2c4969eb7e_720w.png" alt="img"></p>
<p>C: 颜色1 [0, 0.2, 0.4] 颜色2 [0.4, 0.6, 0.8]</p>
<p><img data-src="v2-c520d5c07364cbed9ce6b58faf3475c7_720w.png" alt="img"></p>
<p>该混合模式不会产生新的颜色，注意与“变暗”的区别</p>
<blockquote>
<p><strong>浅色 Lighter Color</strong></p>
</blockquote>
<p><em><strong>c = max(a, b)</strong></em> <em>三通道整体进行运算</em>*，不会产生新的颜色*</p>
<p>B: 颜色1 [0, 0.2, 0.4] 颜色2 [1, 0.8, 0.6]</p>
<p><img data-src="v2-9d6d881e09d25ea68d31b4aeb0a42584_720w.png" alt="img"></p>
<p>A: [0.4, 0.6, 0.8]</p>
<p><img data-src="v2-a97a64c70b7213f2179afa2c4969eb7e_720w.png" alt="img"></p>
<p>C: 颜色1 [0.4, 0.6, 0.8] 颜色2 [1, 0.8, 0.6]</p>
<p><img data-src="v2-0734309c8a2c9ef18543c4a3e89b765a_720w.png" alt="img"></p>
<p>该混合模式不会产生新的颜色，注意与“变亮”的区别</p>
<blockquote>
<p><strong>正片叠底 Multiply</strong></p>
</blockquote>
<p><em><strong>c = a*b</strong> 逐通道进行运算</em></p>
<p>B: 颜色1 [0, 0.2, 0.4] 颜色2 [1, 0.8, 0.6]</p>
<p><img data-src="v2-9d6d881e09d25ea68d31b4aeb0a42584_720w.png" alt="img"></p>
<p>A: [0.4, 0.6, 0.8]</p>
<p><img data-src="v2-a97a64c70b7213f2179afa2c4969eb7e_720w.png" alt="img"></p>
<p>C: 颜色1 [0, 0.12, 0.32] 颜色2 [0.4, 0.48, 0.48]</p>
<p><img data-src="v2-ef14152ab9c1ed17b69901e2b2f8fcaa_720w.png" alt="img"></p>
<p>常用的加深模式，用于产生阴影、去除白色和其他浅色。如同将所有的图层都叠在一起，上方一束光投下来到屏幕上；“颜色加深”和“线性加深”比“正片叠底”效果更为强烈</p>
<p>任何颜色和黑色混合结果都是黑的，任何颜色跟白色混合结果都是原来的颜色</p>
<p>“正片叠底”即所谓“减色”或“CMYK”模式，现实中相当于用染料、水彩笔绘画效果，如图所示</p>
<p><img data-src="v2-8f278da13cf831f924d4638abaf8f4b3_720w.png" alt="img"></p>
<blockquote>
<p><strong>滤色 Screen</strong></p>
</blockquote>
<p>***c = 1 − (1−a)*(1−b)***<em>逐通道进行运算</em></p>
<p>B: 颜色1 [0, 0.2, 0.4] 颜色2 [1, 0.8, 0.6]</p>
<p><img data-src="v2-9d6d881e09d25ea68d31b4aeb0a42584_720w.png" alt="img"></p>
<p>A: [0.4, 0.6, 0.8]</p>
<p><img data-src="v2-a97a64c70b7213f2179afa2c4969eb7e_720w.png" alt="img"></p>
<p>C: 颜色1 [0.4, 0.68, 0.88] 颜色2 [1, 0.92, 0.92]</p>
<p><img data-src="v2-3aa136ef959a58faeb862b5b51bdeae3_720w.png" alt="img"></p>
<p>常用的减淡方法，产生发光效果。如同将所有图层分开摆放，各有一束光通过各图层，汇聚在一块屏幕上</p>
<p>基色或混合色为白色时，结果会是白色；任何颜色和黑色混合，结果仍原来的颜色</p>
<p>“滤色”即所谓“加色”模式，现实中相当于发光体发光的叠加效果，如图所示</p>
<p><img data-src="v2-9e577680c0ad20d6d63b1864bfe391ec_720w.png" alt="img"></p>
<blockquote>
<p><strong>颜色加深 Color Burn</strong></p>
</blockquote>
<p><em><strong>c = 1 − (1−b)/a</strong></em> <em>逐通道进行运算</em></p>
<p>B: 颜色1 [0, 0.2, 0.4] 颜色2 [1, 0.8, 0.6]</p>
<p><img data-src="v2-9d6d881e09d25ea68d31b4aeb0a42584_720w.png" alt="img"></p>
<p>A: [0.4, 0.6, 0.8]</p>
<p><img data-src="v2-a97a64c70b7213f2179afa2c4969eb7e_720w.png" alt="img"></p>
<p>C: 颜色1 [0, 0, 0.25] 颜色2 [1, 0.67, 0.5]</p>
<p><img data-src="v2-a9617aa81abdba4047fea16108777627_720w.png" alt="img"></p>
<p>得到的效果比“正片叠底”更深，中调更高饱和，高光减弱</p>
<p>任何颜色跟白色（B=1）混合结果都是白色</p>
<blockquote>
<p><strong>颜色减淡 Color Dodge</strong></p>
</blockquote>
<p>***c = b / (1−a)***<em>逐通道进行运算</em></p>
<p>B: 颜色1 [0, 0.2, 0.4] 颜色2 [1, 0.8, 0.6]</p>
<p><img data-src="v2-9d6d881e09d25ea68d31b4aeb0a42584_720w.png" alt="img"></p>
<p>A: [0.4, 0.6, 0.8]</p>
<p><img data-src="v2-a97a64c70b7213f2179afa2c4969eb7e_720w.png" alt="img"></p>
<p>C: 颜色1 [0, 0.5, 1] 颜色2 [1, 1, 1]</p>
<p><img data-src="v2-3ef666006d4285e56f9c3545cda3c15d_720w.png" alt="img"></p>
<p>得到的效果比“滤色”更亮，色彩对比更加强烈，中调更高饱和，高光增强</p>
<p>任何颜色跟黑色（B=0）混合结果都是黑色</p>
<blockquote>
<p><strong>线性加深 Linear Burn</strong></p>
</blockquote>
<p><em><strong>c = a + b − 1</strong></em> <em>逐通道进行运算</em></p>
<p>B: 颜色1 [0, 0.2, 0.4] 颜色2 [1, 0.8, 0.6]</p>
<p><img data-src="v2-9d6d881e09d25ea68d31b4aeb0a42584_720w.png" alt="img"></p>
<p>A: [0.4, 0.6, 0.8]</p>
<p><img data-src="v2-a97a64c70b7213f2179afa2c4969eb7e_720w.png" alt="img"></p>
<p>C: 颜色1 [0, 0, 0.2] 颜色2 [0.4, 0.4, 0.4]</p>
<p><img data-src="v2-14a6ce57b48355c20df849b97d1e20f7_720w.png" alt="img"></p>
<p>得到的效果比“颜色加深”更深，比颜色加深饱和度低</p>
<p>任何颜色跟白色（B=1）混合结果都是原来的颜色</p>
<blockquote>
<p><strong>线性减淡 Linear Dodge</strong></p>
</blockquote>
<p><em><strong>c = a+b</strong></em> <em>逐通道进行运算</em></p>
<p>B: 颜色1 [0, 0.2, 0.4] 颜色2 [1, 0.8, 0.6]</p>
<p><img data-src="v2-9d6d881e09d25ea68d31b4aeb0a42584_720w.png" alt="img"></p>
<p>A: [0.4, 0.6, 0.8]</p>
<p><img data-src="v2-a97a64c70b7213f2179afa2c4969eb7e_720w.png" alt="img"></p>
<p>C: 颜色1 [0.4, 0.8, 1] 颜色2 [1, 1, 1]</p>
<p><img data-src="v2-1f74cf80b6e5cd9087bc3b6c944a904d_720w.png" alt="img"></p>
<p>得到的效果比“颜色减淡”更亮，但对比稍弱</p>
<p>任何颜色跟黑色（B=0）混合结果都是原来的颜色</p>
<h2 id="iii-对比系"><a class="markdownIt-Anchor" href="#iii-对比系"></a> III 对比系</h2>
<p>该组特点是让亮的更亮，暗的更暗，每一个“对比系”的混合模式都可看作“变暗系”和“变亮系”的结合，如“叠加”是对较暗的像素进行“正片叠底”，对较亮的像素进行“滤色”</p>
<blockquote>
<p><strong>叠加</strong> <strong>Overlay</strong></p>
</blockquote>
<p><em>逐通道进行运算</em></p>
<p>*<strong>若 b &lt;= 0.5: c = 2ab*</strong></p>
<p>*<strong>若 b &gt; 0.5: c = 1 - 2(1-a)(1-b)*</strong></p>
<p>B: 颜色1 [0, 0.2, 0.4] 颜色2 [1, 0.8, 0.6]</p>
<p><img data-src="v2-9d6d881e09d25ea68d31b4aeb0a42584_720w.png" alt="img"></p>
<p>A: [0.4, 0.6, 0.8]</p>
<p><img data-src="v2-a97a64c70b7213f2179afa2c4969eb7e_720w.png" alt="img"></p>
<p>C: 颜色1 [0, 0.24, 0.64] 颜色2[1, 0.84, 0.84]</p>
<p><img data-src="v2-24fbd55f5e94ed2b164d839d9d8ee8ab_720w.png" alt="img"></p>
<p>类似于 “正片叠底”+“滤色”的结合，但效果更柔和</p>
<p>A层在上，对A“叠加”；B层在上，对B“强光”：两种情况得到的效果是一样的</p>
<blockquote>
<p><strong>强光</strong> <strong>Hard Light</strong></p>
</blockquote>
<p><em>逐通道进行运算</em></p>
<p>*<strong>若 a &lt;= 0.5: c = 2ab*</strong></p>
<p>*<strong>若 a &gt; 0.5: c = 1 - 2(1-a)(1-b)*</strong></p>
<p>B: 颜色1 [0, 0.2, 0.4] 颜色2 [1, 0.8, 0.6]</p>
<p><img data-src="v2-9d6d881e09d25ea68d31b4aeb0a42584_720w.png" alt="img"></p>
<p>A: [0.4, 0.6, 0.8]</p>
<p><img data-src="v2-a97a64c70b7213f2179afa2c4969eb7e_720w.png" alt="img"></p>
<p>C: 颜色1 [0, 0.36, 0.76] 颜色2 [0.8, 0.84, 0.84]</p>
<p><img data-src="v2-f0b8f5ffd678a80c6712583b6598db8e_720w.png" alt="img"></p>
<p>类似于 “正片叠底”+“滤色”的结合，但效果更柔和</p>
<p>A层在上，对A“叠加”；B层在上，对B“强光”：两种情况得到的效果是一样的</p>
<blockquote>
<p><strong>柔光</strong> <strong>Soft Light</strong></p>
</blockquote>
<p><em>逐通道进行运算</em></p>
<p>*<strong>若 a &lt;= 0.5, c = 2ab + <img data-src="equation" alt="[公式]">(1-2a)*</strong></p>
<p>*<strong>若 a &gt; 0.5, c = 2b(1-a) + <img data-src="equation.svg" alt="[公式]">(2a-1)*</strong></p>
<p>B: 颜色1 [0, 0.2, 0.4] 颜色2 [1, 0.8, 0.6]</p>
<p><img data-src="v2-9d6d881e09d25ea68d31b4aeb0a42584_720w.png" alt="img"></p>
<p>A: [0.4, 0.6, 0.8]</p>
<p><img data-src="v2-a97a64c70b7213f2179afa2c4969eb7e_720w.png" alt="img"></p>
<p>C: 颜色1 [0, 0.25, 0.54] 颜色2 [1, 0.82, 0.71]</p>
<p><img data-src="v2-78b198e1c2fe8f6c060753318fb849ee_720w.png" alt="img"></p>
<p>效果类似于“叠加”，但效果更柔和，有透明的光线和阴影</p>
<p>类似于 “浅色”+“深色”的结合</p>
<blockquote>
<p><strong>亮光</strong> <strong>Vivid Light</strong></p>
</blockquote>
<p><em>逐通道进行运算，近似公式</em></p>
<p>*<strong>若 a &lt;= 0.5, c = 1 + (b-1)/2a*</strong></p>
<p>*<strong>若 a &gt; 0.5, c = b / 2(1-a)*</strong></p>
<p>B: 颜色1 [0, 0.2, 0.4] 颜色2 [1, 0.8, 0.6]</p>
<p><img data-src="v2-9d6d881e09d25ea68d31b4aeb0a42584_720w.png" alt="img"></p>
<p>A: [0.4, 0.6, 0.8]</p>
<p><img data-src="v2-a97a64c70b7213f2179afa2c4969eb7e_720w.png" alt="img"></p>
<p>C: 颜色1 [0, 0.25, 1] 颜色2 [1, 0.996, 1]</p>
<p><img data-src="v2-177f7f9a060ef7ccf2938c6ef9120350_720w.png" alt="img"></p>
<p>类似于“实色混合”，但效果通常更加剧烈</p>
<p>类似于 “颜色减淡”+“颜色加深”的结合</p>
<blockquote>
<p><strong>线性光</strong> <strong>Linear Light</strong></p>
</blockquote>
<p>*<strong>c = b + 2a -1*</strong> <em>逐通道进行运算，近似公式</em></p>
<p>B: 颜色1 [0, 0.2, 0.4] 颜色2 [1, 0.8, 0.6]</p>
<p><img data-src="v2-9d6d881e09d25ea68d31b4aeb0a42584_720w.png" alt="img"></p>
<p>A: [0.4, 0.6, 0.8]</p>
<p><img data-src="v2-a97a64c70b7213f2179afa2c4969eb7e_720w.png" alt="img"></p>
<p>C: 颜色1 [0, 0.4, 0.996] 颜色2 [0.8, 0.996, 1]</p>
<p><img data-src="v2-3e6f6616a8249f8e78a8553edc728d63_720w.png" alt="img"></p>
<p>类似于“亮光”，但效果通常更加剧烈</p>
<p>类似于 “线性加深”+“线性减淡”的结果</p>
<blockquote>
<p><strong>点光</strong> <strong>Pin Light</strong></p>
</blockquote>
<p><em>逐通道进行运算</em></p>
<p>*<strong>若 a &gt; 0.5, c = max ( 2(a-0.5) , b )*</strong></p>
<p>*<strong>若 a &lt;= 0.5, c = min ( 2a , b )*</strong></p>
<p>B: 颜色1 [0, 0.2, 0.4] 颜色2 [1, 0.8, 0.6]</p>
<p><img data-src="v2-9d6d881e09d25ea68d31b4aeb0a42584_720w.png" alt="img"></p>
<p>A: [0.4, 0.6, 0.8]</p>
<p><img data-src="v2-a97a64c70b7213f2179afa2c4969eb7e_720w.png" alt="img"></p>
<p>C: 颜色1 [0, 0.2, 0.6] 颜色2 [0.796, 0.8, 0.6]</p>
<p><img data-src="v2-fa86d21780209cf5b58e727fd33ef18f_720w.png" alt="img"></p>
<p>该混合模式较为强烈，容易形成色块色斑和噪点</p>
<p>类似于 “变亮”+“变暗”的结合</p>
<blockquote>
<p><strong>实色混合</strong> <strong>Hard Mix</strong></p>
</blockquote>
<p>*<strong>若 a+b &gt;= 1, c = 1; 否则 c=0*</strong> <em>逐通道进行运算</em></p>
<p>B: 颜色1 [0, 0.2, 0.4] 颜色2 [1, 0.8, 0.6]</p>
<p><img data-src="v2-9d6d881e09d25ea68d31b4aeb0a42584_720w.png" alt="img"></p>
<p>A: [0.4, 0.6, 0.8]</p>
<p><img data-src="v2-a97a64c70b7213f2179afa2c4969eb7e_720w.png" alt="img"></p>
<p>C: 颜色1 [0, 0, 1] 颜色2 [1, 1, 1]</p>
<p><img data-src="v2-ec227746d961f540cc8f70547614bffa_720w.png" alt="img"></p>
<p>结果只有8个颜色：R、G、B、C、M、Y 、K、White</p>
<p>如果“填充度”不为100，结果色会多于8</p>
<h2 id="iv-负片系"><a class="markdownIt-Anchor" href="#iv-负片系"></a> IV 负片系</h2>
<blockquote>
<p><strong>差值 Difference</strong></p>
</blockquote>
<p><em><strong>c = |b - a|</strong> 逐通道进行运算</em></p>
<p>B: 颜色1 [0, 0.2, 0.4] 颜色2 [1, 0.8, 0.6]</p>
<p><img data-src="v2-9d6d881e09d25ea68d31b4aeb0a42584_720w.png" alt="img"></p>
<p>A: [0.4, 0.6, 0.8]</p>
<p><img data-src="v2-a97a64c70b7213f2179afa2c4969eb7e_720w.png" alt="img"></p>
<p>C: 颜色1 [0.4, 0.4, 0.4] 颜色2 [0.6, 0.2, 0.2]</p>
<p><img data-src="v2-abd81b87e3014ae47f3deaea3958a5a1_720w.png" alt="img"></p>
<p>会有一定负片效果</p>
<blockquote>
<p><strong>排除 Exclusion</strong></p>
</blockquote>
<p><em><strong>c = a + b - 2ab</strong></em> <em>逐通道进行运算</em></p>
<p>B: 颜色1 [0, 0.2, 0.4] 颜色2 [1, 0.8, 0.6]</p>
<p><img data-src="v2-9d6d881e09d25ea68d31b4aeb0a42584_720w.png" alt="img"></p>
<p>A: [0.4, 0.6, 0.8]</p>
<p><img data-src="v2-a97a64c70b7213f2179afa2c4969eb7e_720w.png" alt="img"></p>
<p>C: 颜色1 [0.4, 0.56, 0.56] 颜色2 [0.6, 0.44, 0.44]</p>
<p><img data-src="v2-097f5e2b9c9646d69f6a07ce66783459_720w.png" alt="img"></p>
<p>会有一定负片效果</p>
<h2 id="v-相消系"><a class="markdownIt-Anchor" href="#v-相消系"></a> V 相消系</h2>
<blockquote>
<p><strong>减去Subtract</strong></p>
</blockquote>
<p><em><strong>c = b−a</strong></em><em>逐通道进行运算</em></p>
<p>B: 颜色1 [0, 0.2, 0.4] 颜色2 [1, 0.8, 0.6]</p>
<p><img data-src="v2-9d6d881e09d25ea68d31b4aeb0a42584_720w.png" alt="img"></p>
<p>A: [0.4, 0.6, 0.8]</p>
<p><img data-src="v2-a97a64c70b7213f2179afa2c4969eb7e_720w.png" alt="img"></p>
<p>C: 颜色1 [0, 0, 0] 颜色2 [0.6, 0.2, 0]</p>
<p><img data-src="v2-897968ab0abc87cf22279786051c46ab_720w.png" alt="img"></p>
<p>变深效果</p>
<p>常结合“应用图像”，用于高低频法调色</p>
<blockquote>
<p><strong>划分Divide</strong></p>
</blockquote>
<p>*<strong>c = b/a*</strong> <em>逐通道进行运算</em></p>
<p>B: 颜色1 [0, 0.2, 0.4] 颜色2 [1, 0.8, 0.6]</p>
<p><img data-src="v2-9d6d881e09d25ea68d31b4aeb0a42584_720w.png" alt="img"></p>
<p>A: [0.4, 0.6, 0.8]</p>
<p><img data-src="v2-a97a64c70b7213f2179afa2c4969eb7e_720w.png" alt="img"></p>
<p>C: 颜色1 [0, 0.33, 0.5] 颜色2 [1, 1, 0.75]</p>
<p><img data-src="v2-fc94414ecd4e5b95cb0ea5912858589c_720w.png" alt="img"></p>
<p>变亮效果</p>
<h2 id="汇总在一张a4纸上"><a class="markdownIt-Anchor" href="#汇总在一张a4纸上"></a> 汇总在一张A4纸上</h2>
<p><img data-src="v2-9777e7ee9933926f8cd3a50d905a592f_r.jpg" alt="preview"></p>
<h2 id="参考文献"><a class="markdownIt-Anchor" href="#参考文献"></a> 参考文献</h2>
<ul>
<li>Adobe中文官网</li>
<li><a href="https://zhuanlan.zhihu.com/p/94081709">Photoshop图层混合模式详解</a></li>
<li>另外一篇知乎文章，由于写的时候忘了，现在实在找不到了。。要是引用部分原作者来了请找我claim。</li>
</ul>
]]></content>
      <tags>
        <tag>art</tag>
        <tag>painting</tag>
        <tag>ps</tag>
      </tags>
  </entry>
  <entry>
    <title>PS笔刷探究</title>
    <url>/2020/05/20/ps-brush/</url>
    <content><![CDATA[<h2 id="选项研究"><a class="markdownIt-Anchor" href="#选项研究"></a> 选项研究</h2>
<p>由于多次搜索和研究画笔设置和笔刷的制作方法，但均感觉网上所讲一知半解居多，这次特意找时间全部整理了一遍。难理解的、可能并不常用的放在前面着重讲，容易理解的、常用的则放在后面。</p>
<h3 id="杂色noise"><a class="markdownIt-Anchor" href="#杂色noise"></a> 杂色(Noise)</h3>
<p>为个别画笔笔尖增加额外的随机性。当应用于柔画笔笔尖（包含灰度值的画笔笔尖）时，此选项最有效。</p>
<span id="more"></span>
<h3 id="湿边wet-edges"><a class="markdownIt-Anchor" href="#湿边wet-edges"></a> 湿边(Wet Edges)</h3>
<p>沿画笔描边的边缘增大油彩量，从而创建水彩效果。</p>
<h3 id="喷枪建立airbrushbuild-up"><a class="markdownIt-Anchor" href="#喷枪建立airbrushbuild-up"></a> 喷枪/建立(Airbrush/Build-up)</h3>
<p>将渐变色调应用于图像，同时模拟传统的喷枪技术。“画笔”面板中的“喷枪”选项与选项栏中的“喷枪”选项相对应。喷枪的本质特点是：当你的笔/鼠标在一个点按住停留的时候，颜色会不断加深，影响区域也越来越大。如果没有勾选喷枪/建立选项，按多久都是一样的颜色深度。从某种意义上讲，喷枪效果在“笔压”之外加入了一个“停留时间”维度。</p>
<h3 id="平滑smoothing"><a class="markdownIt-Anchor" href="#平滑smoothing"></a> 平滑(Smoothing)</h3>
<p>在画笔描边中生成更平滑的曲线。当使用光笔进行快速绘画时，此选项最有效；但是它在描边渲染中可能会导致轻微的滞后。</p>
<h3 id="保护纹理protect-texture"><a class="markdownIt-Anchor" href="#保护纹理protect-texture"></a> 保护纹理(Protect Texture)</h3>
<p>将相同图案和缩放比例应用于具有纹理的所有画笔预设。选择此选项后，在使用多个纹理画笔笔尖绘画时，可以模拟出一致的画布纹理。</p>
<h3 id="画笔笔势选项"><a class="markdownIt-Anchor" href="#画笔笔势选项"></a> 画笔笔势选项</h3>
<p>画笔笔势选项可让您获得类似光笔的效果，并可让您控制画笔的角度和位置。</p>
<p>这里说的光笔是指一种在板绘时可以感知笔的倾斜角度、旋转的笔。<strong>画笔笔势</strong>选项固定且剥夺了板绘笔旋转、倾斜、压力的能力，直接设定为了定值。</p>
<p><strong>倾斜 X</strong></p>
<p>确定画笔从左向右倾斜的角度。</p>
<p><strong>倾斜 Y</strong></p>
<p>确定画笔从前向后倾斜的角度。</p>
<p><strong>旋转</strong></p>
<p>确定硬毛刷的旋转角度。</p>
<p><strong>压力</strong></p>
<p>确定应用于画布上画笔的压力。</p>
<p>启用“覆盖”选项以维护静态画笔笔势。</p>
<h2 id="画笔散布"><a class="markdownIt-Anchor" href="#画笔散布"></a> 画笔散布</h2>
<p>“画笔散布”可确定描边中笔迹的数目和位置。</p>
<p>简单的说，开启了该选项后，画的时候笔迹并不会严格遵循你笔的下笔位置，而是会在x和y轴上有一个或多或少的偏移。</p>
<p><img data-src="pa_14.png" alt="Photoshop 画笔散布"></p>
<p>无散布的画笔描边（左图）和有散布的画笔描边（右图）</p>
<p><strong>散布和控制</strong></p>
<p>指定画笔笔迹在描边中的分布方式。当选择“两轴”时，画笔笔迹按径向分布。当取消选择“两轴”时，画笔笔迹垂直于描边路径分布。</p>
<p>要指定散布的最大百分比，请输入一个值。若要指定希望如何控制画笔笔迹的散布变化，请从“控制”弹出式菜单中选取一个选项：</p>
<p><strong>关</strong></p>
<p>指定不控制画笔笔迹的散布变化。</p>
<p><strong>渐隐</strong></p>
<p>按指定数量的步长将画笔笔迹的散布从最大散布渐隐到无散布。</p>
<p><strong>钢笔压力、钢笔斜度、光笔轮、旋转</strong></p>
<p>依据钢笔压力、钢笔斜度、钢笔拇指轮位置或钢笔的旋转来改变画笔笔迹的散布。</p>
<p><strong>计数</strong></p>
<p>指定在每个间距间隔应用的画笔笔迹数量。</p>
<h3 id="颜色动态画笔选项"><a class="markdownIt-Anchor" href="#颜色动态画笔选项"></a> 颜色动态画笔选项</h3>
<p>颜色动态决定描边路线中油彩颜色的变化方式。</p>
<p><img data-src="pa_18.png" alt="Photoshop 有颜色动态和无颜色动态的画笔描边"></p>
<p>无颜色动态的画笔描边（左图）和有颜色动态的画笔描边（右图）</p>
<p>它也可以用来制作如下的图像：</p>
<img data-src="image-20200519182011143.png" alt="image-20200519182011143" style="zoom:33%;">
<p><strong>每笔尖应用</strong></p>
<p>指定为描边中每个不同的笔尖图章更改颜色。</p>
<p>如果取消选中，则在每个描边开始时即进行动态更改。您便可以更改不同描边的颜色，而不是对每个描边内部更改颜色。</p>
<p><strong>前景/背景抖动和控制</strong></p>
<p>指定前景色和背景色之间的油彩变化方式。</p>
<p>要指定油彩颜色可以改变的百分比，请键入数字或使用滑块来输入值。若要指定希望如何控制画笔笔迹的颜色变化，请从“控制”弹出式菜单中选取一个选项：</p>
<p><strong>关</strong></p>
<p>指定不控制画笔笔迹的颜色变化。</p>
<p><strong>渐隐</strong></p>
<p>按指定数量的步长在前景色和背景色之间改变油彩颜色。</p>
<p><strong>钢笔压力、钢笔斜度、光笔轮、旋转</strong></p>
<p>依据钢笔压力、钢笔斜度、钢笔拇指轮位置或钢笔的旋转来改变前景色和背景色之间的油彩颜色。</p>
<p><strong>色相抖动</strong></p>
<p>指定描边中油彩色相可以改变的百分比。键入数字，或者使用滑块来输入值。较低的值在改变色相的同时保持接近前景色的色相. 较高的值增大色相间的差异。</p>
<p><strong>饱和度抖动</strong></p>
<p>指定描边中油彩饱和度可以改变的百分比。键入数字，或者使用滑块来输入值。较低的值在改变饱和度的同时保持接近前景色的饱和度。较高的值增大饱和度级别之间的差异。</p>
<p><strong>亮度抖动</strong></p>
<p>指定描边中油彩亮度可以改变的百分比。键入数字，或者使用滑块来输入值。较低的值在改变亮度的同时保持接近前景色的亮度。较高的值增大亮度级别之间的差异。</p>
<p><strong>纯度</strong></p>
<p>增大或减小颜色的饱和度。键入一个数字，或者使用滑块输入一个介于 -100 和 100 之间的百分比。如果该值为 -100，则颜色将完全去色；如果该值为 100，则颜色将完全饱和。</p>
<h2 id="双重画笔"><a class="markdownIt-Anchor" href="#双重画笔"></a> 双重画笔</h2>
<p>双重画笔组合两个笔尖来创建画笔笔迹。将在<strong>主画笔的画笔描边内</strong>应用第二个画笔纹理；仅绘制<strong>两个画笔描边的交叉区域</strong>。在“画笔”面板的“画笔笔尖形状”部分中设置主要笔尖的选项。从“画笔”面板的“双重画笔”部分选择另一个画笔笔尖，然后设置以下任意选项。</p>
<p><img data-src="pa_16.png" alt="Photoshop 主、辅助、双重画笔描边"></p>
<p><strong>A.</strong> 主画笔笔尖描边（尖角 55）。 <strong>B.</strong> 辅助画笔笔尖描边（草）。 <strong>C.</strong> 双重画笔描边（使用两者）。</p>
<p><strong>模式</strong></p>
<p>选择从主要笔尖和双重笔尖组合画笔笔迹时要使用的混合模式。（请参阅<a href="https://helpx.adobe.com/cn/photoshop/using/blending-modes.html">混合模式</a>。）</p>
<p><strong>直径</strong></p>
<p>控制双笔尖的大小。以像素为单位输入值，或者单击“使用取样大小”来使用画笔笔尖的原始直径。(只有当画笔笔尖形状是通过采集图像中的像素样本创建的时，“使用取样大小”选项才可用。)</p>
<p><strong>间距</strong></p>
<p>控制描边中双笔尖画笔笔迹之间的距离。若要更改间距，请键入数字，或使用滑块输入笔尖直径的百分比。</p>
<p><strong>散布</strong></p>
<p>指定描边中双笔尖画笔笔迹的分布方式。当选中“两轴”时，双笔尖画笔笔迹按径向分布。当取消选择“两轴”时，双笔尖画笔笔迹垂直于描边路径分布。若要指定散布的最大百分比，请键入数字或使用滑块来输入值。</p>
<p><strong>计数</strong></p>
<p>指定在每个间距间隔应用的双笔尖画笔笔迹的数量。键入数字，或者使用滑块来输入值。</p>
<h2 id="纹理画笔选项"><a class="markdownIt-Anchor" href="#纹理画笔选项"></a> 纹理画笔选项</h2>
<p>纹理画笔利用<strong>图案使描边</strong>看起来像是在带纹理的画布上绘制的一样。</p>
<p><img data-src="pa_15.png" alt="Photoshop 有纹理和无纹理的画笔描边"></p>
<p>无纹理的画笔描边（左图）和有纹理的画笔描边（右图）</p>
<p>单击图案样本，然后从弹出式面板中选择图案。设置下面的一个或多个选项：</p>
<p><strong>反相</strong></p>
<p>基于图案中的色调反转纹理中的亮点和暗点。当选择“反相”时，图案中的最亮区域是纹理中的暗点，因此接收最少的油彩；图案中的最暗区域是纹理中的亮点，因此接收最多的油彩。当取消选择“反相”时，图案中的最亮区域接收最多的油彩；图案中的最暗区域接收最少的油彩。</p>
<p><strong>比例</strong></p>
<p>指定图案的缩放比例。键入数字，或者使用滑块来输入图案大小的百分比值。</p>
<p><strong>为每个笔尖设置纹理</strong></p>
<p>将选定的纹理单独应用于画笔描边中的每个画笔笔迹，而不是作为整体应用于画笔描边（画笔描边由拖动画笔时连续应用的许多画笔笔迹构成）。必须选择此选项，才能使用“深度”变化选项。</p>
<p><strong>模式</strong></p>
<p>指定用于组合画笔和图案的混合模式。（请参阅<a href="https://helpx.adobe.com/cn/photoshop/using/blending-modes.html">混合模式</a>。）</p>
<p><strong>深度</strong></p>
<p>指定油彩渗入纹理中的深度。键入数字，或者使用滑块来输入值。如果是 100%，则纹理中的暗点不接收任何油彩。如果是 0%，则纹理中的所有点都接收相同数量的油彩，从而隐藏图案。</p>
<p><strong>最小深度</strong></p>
<p>指定将“深度控制”设置为“渐隐”、“钢笔压力”、“钢笔斜度”或“光笔轮”并且选中“为每个笔尖设置纹理”时油彩可渗入的最小深度。</p>
<p><strong>深度抖动和控制</strong></p>
<p>指定当选中“为每个笔尖设置纹理”时深度的改变方式。若要指定抖动的最大百分比，请输入一个值。若要指定希望如何控制画笔笔迹的深度变化，请从“控制”弹出式菜单中选取一个选项：</p>
<p><strong>关</strong></p>
<p>指定不控制画笔笔迹的深度变化。</p>
<p><strong>渐隐</strong></p>
<p>按指定数量的步长从“深度抖动”百分比渐隐到“最小深度”百分比。</p>
<p><strong>钢笔压力、钢笔斜度、光笔轮、旋转</strong></p>
<p>依据钢笔压力、钢笔斜度、钢笔拇指轮位置或钢笔旋转角度来改变深度。</p>
<h4 id="几个示例"><a class="markdownIt-Anchor" href="#几个示例"></a> 几个示例：</h4>
<p><strong>减去</strong>模式：</p>
<img data-src="image-20200519185949006.png" alt="image-20200519185949006" style="zoom:50%;">
<p><strong>正片叠底</strong>模式：</p>
<img data-src="image-20200519185914171.png" alt="image-20200519185914171" style="zoom:50%;">
<p><strong>颜色减淡</strong>模式：</p>
<img data-src="image-20200519190128765.png" alt="image-20200519190128765" style="zoom:40%;">
<p><strong>高度</strong>模式：</p>
<img data-src="image-20200519190234030.png" alt="image-20200519190234030" style="zoom:33%;">
<h3 id="画笔形状动态"><a class="markdownIt-Anchor" href="#画笔形状动态"></a> 画笔形状动态</h3>
<p>形状动态决定描边中画笔笔迹的变化。</p>
<p><img data-src="pa_13.png" alt="Photoshop 有形状动态和无形状动态的画笔描边"></p>
<p>无形状动态（左图）和有形状动态（右图）的画笔描边</p>
<p><strong>大小抖动和控制</strong></p>
<p>指定描边中画笔笔迹大小的改变方式。有关更多信息，请参阅<a href="https://helpx.adobe.com/cn/photoshop/using/creating-modifying-brushes.html">创建和修改画笔</a>。</p>
<p>若要指定抖动的最大百分比，请通过键入数字或使用滑块来输入值。若要指定希望如何控制画笔笔迹的大小变化，请从“控制”弹出式菜单中选取一个选项：</p>
<p><strong>关</strong></p>
<p>指定不控制画笔笔迹的大小变化。</p>
<p><strong>渐隐</strong></p>
<p>按指定数量的步长在初始直径和最小直径之间渐隐画笔笔迹的大小。每个步长等于画笔笔尖的一个笔迹。值的范围可以从 1 到 9999。例如，输入步长数 10 会产生 10 个增量的渐隐。</p>
<p><strong>钢笔压力、钢笔斜度或光笔轮</strong></p>
<p>可依据钢笔压力、钢笔斜度或钢笔拇指轮位置以在初始直径和最小直径之间改变画笔笔迹大小。</p>
<p><strong>最小直径</strong></p>
<p>指定当启用“大小抖动”或“大小控制”时画笔笔迹可以缩放的最小百分比。可通过键入数字或使用滑块来输入画笔笔尖直径的百分比值。</p>
<p><strong>倾斜缩放比例</strong></p>
<p>指定当“大小抖动”设置为“钢笔斜度”时，在旋转前应用于画笔高度的比例因子。键入数字，或者使用滑块输入画笔直径的百分比值。</p>
<p><strong>角度抖动和控制</strong></p>
<p>指定描边中画笔笔迹角度的改变方式。该选项启用时，每次你重新下笔，都会随机改变一个画笔角度，随机程度由你设置的值来决定。若要指定抖动的最大百分比，请输入一个 360 度的百分比值。若要指定希望如何控制画笔笔迹的角度变化，请从“控制”弹出式菜单中选取一个选项：</p>
<p><strong>关</strong></p>
<p>指定不控制画笔笔迹的角度变化。</p>
<p><strong>渐隐</strong></p>
<p>按指定数量的步长在 0 和 360 度之间渐隐画笔笔迹角度。</p>
<p><strong>钢笔压力、钢笔斜度、光笔轮、旋转</strong></p>
<p>依据钢笔压力、钢笔斜度、钢笔拇指轮位置或钢笔的旋转在 0 到 360 度之间改变画笔笔迹的角度。</p>
<p><strong>初始方向</strong></p>
<p>使画笔笔迹的角度基于画笔描边的初始方向。</p>
<p><strong>方向</strong></p>
<p>使画笔笔迹的角度基于画笔描边的方向。</p>
<p><strong>圆度抖动和控制</strong></p>
<p>指定画笔笔迹的圆度在描边中的改变方式。若要指定抖动的最大百分比，请输入一个指明画笔长短轴之间的比率的百分比。若要指定希望如何控制画笔笔迹的圆度变化，请从“控制”弹出式菜单中选取一个选项：</p>
<p><strong>关</strong></p>
<p>指定不控制画笔笔迹的圆度变化。</p>
<p><strong>渐隐</strong></p>
<p>按指定数量步长在 100% 和“最小圆度”值之间渐隐画笔笔迹的圆度。</p>
<p><strong>钢笔压力、钢笔斜度、光笔轮、旋转</strong></p>
<p>依据钢笔压力、钢笔斜度、钢笔拇指轮位置或钢笔的旋转在 100% 和“最小圆度”值之间改变画笔笔迹的圆度。</p>
<p><strong>最小圆度</strong></p>
<p>指定当“圆度抖动”或“圆度控制”启用时画笔笔迹的最小圆度。输入一个指明画笔长短轴之间的比率的百分比。</p>
<p><strong>画笔投影</strong></p>
<p>指定当您使用光笔绘画时，光笔将更改为倾斜状态并将旋转光笔以改变笔尖形状。</p>
<h3 id="传递转换画笔选项"><a class="markdownIt-Anchor" href="#传递转换画笔选项"></a> 传递/转换画笔选项</h3>
<p>转换画笔选项确定油彩在描边路线中的改变方式。</p>
<p><img data-src="pa_19.png" alt="Photoshop 传递画笔选项"></p>
<p>无动态绘画的画笔描边（左图）和有动态绘画的画笔描边（右图）</p>
<p><strong>不透明度抖动和控制</strong></p>
<p>指定画笔描边中油彩不透明度如何变化，最高值（但不超过）是选项栏中指定的不透明度值。要指定油彩不透明度可以改变的百分比，请键入数字或使用滑块来输入值。若要指定希望如何控制画笔笔迹的不透明度变化，请从“控制”弹出式菜单中选取一个选项：</p>
<p><strong>关</strong></p>
<p>指定不控制画笔笔迹的不透明度变化。</p>
<p><strong>渐隐</strong></p>
<p>按指定数量的步长将油彩不透明度从选项栏中的不透明度值渐隐到 0。</p>
<p><strong>钢笔压力、钢笔斜度或光笔轮</strong></p>
<p>可依据钢笔压力、钢笔斜度或钢笔拇指轮的位置来改变颜料的不透明度。</p>
<p><strong>流量抖动和控制</strong></p>
<p>指定画笔描边中油彩流量如何变化，最高（但不超过）值是选项栏中指定的流量值。</p>
<p>要指定油彩流量可以改变的百分比，请键入数字或使用滑块来输入值。若要指定希望如何控制画笔笔迹的流量变化，请从“控制”弹出式菜单中选取一个选项：</p>
<p><strong>关</strong></p>
<p>指定不控制画笔笔迹的流量变化。</p>
<p><strong>渐隐</strong></p>
<p>按指定数量的步长将油彩流量从选项栏中的流量值渐隐到 0。</p>
<p><strong>钢笔压力、钢笔斜度或光笔轮</strong></p>
<p>可依据钢笔压力、钢笔斜度或钢笔拇指轮的位置来改变油彩的流量。</p>
<h3 id="标准画笔笔尖形状选项"><a class="markdownIt-Anchor" href="#标准画笔笔尖形状选项"></a> 标准画笔笔尖形状选项</h3>
<p>对于标准画笔笔尖，可设置“画笔设置”面板中的以下选项：</p>
<h4 id="大小"><a class="markdownIt-Anchor" href="#大小"></a> 大小</h4>
<p>控制画笔大小。输入以像素为单位的值，或拖动滑块。</p>
<p><img data-src="pa_06.png" alt="具有不同直径值的画笔描边"></p>
<h4 id="使用取样大小"><a class="markdownIt-Anchor" href="#使用取样大小"></a> 使用取样大小</h4>
<p>将画笔复位到它的原始直径。只有在画笔笔尖形状是通过采集图像中的像素样本创建的情况下，此选项才可用。</p>
<h4 id="翻转-x"><a class="markdownIt-Anchor" href="#翻转-x"></a> 翻转 X</h4>
<p>改变画笔笔尖在其 <em>x</em> 轴上的方向。</p>
<p><img data-src="pa_07.png" alt="Photoshop 翻转 X"></p>
<p>将画笔笔尖在其 x 轴上翻转<br>
<strong>A.</strong> 处在默认位置的画笔笔尖 <strong>B.</strong> 选中了“翻转 X”时 <strong>C.</strong> 选中了“翻转 X”和“翻转 Y”时</p>
<h4 id="翻转-y"><a class="markdownIt-Anchor" href="#翻转-y"></a> 翻转 Y</h4>
<p>改变画笔笔尖在其 <em>y</em> 轴上的方向。</p>
<p><img data-src="pa_08.png" alt="Photoshop 翻转 Y"></p>
<p>将画笔笔尖在其 y 轴上翻转<br>
<strong>A.</strong> 处在默认位置的画笔笔尖 <strong>B.</strong> 选中了“翻转 Y”时 <strong>C.</strong> 选中了“翻转 Y”和“翻转 X”时</p>
<h4 id="角度"><a class="markdownIt-Anchor" href="#角度"></a> 角度</h4>
<p>指定椭圆画笔或样本画笔的长轴从水平方向旋转的角度。键入度数，或在预览框中拖动水平轴。</p>
<p><img data-src="pa_09.png" alt="Photoshop 角度"></p>
<p>带角度的画笔创建雕刻状描边</p>
<h4 id="圆度"><a class="markdownIt-Anchor" href="#圆度"></a> 圆度</h4>
<p>指定画笔短轴和长轴之间的比率。输入百分比值，或在预览框中拖动点。100% 表示圆形画笔，0% 表示线性画笔，介于两者之间的值表示椭圆画笔。</p>
<p><img data-src="pa_10.png" alt="Photoshop 圆度"></p>
<p>调整圆度以压缩画笔笔尖形状</p>
<h4 id="硬度"><a class="markdownIt-Anchor" href="#硬度"></a> 硬度</h4>
<p>控制画笔硬度中心的大小。键入数字，或者使用滑块输入画笔直径的百分比值。不能更改样本画笔的硬度。</p>
<p><img data-src="pa_11.png" alt="Photoshop 硬度"></p>
<p>具有不同硬度值的画笔描边</p>
<h4 id="间距"><a class="markdownIt-Anchor" href="#间距"></a> 间距</h4>
<p>控制描边中两个画笔笔迹之间的距离。如果要更改间距，请键入数字，或使用滑块输入画笔直径的百分比值。当取消选择此选项时，光标的速度将确定间距。</p>
<p><img data-src="pa_12.png" alt="Photoshop 间距"></p>
<p>增大间距可使画笔急速改变</p>
<h4 id="注意"><a class="markdownIt-Anchor" href="#注意"></a> 注意:</h4>
<p>当使用预设画笔时，按 [ 键可减小画笔宽度；按 ] 键可增加宽度。对于硬边圆、柔边圆和书法画笔，按 Shift+ [ 键可减小画笔硬度；按 Shift+ ] 键可增加画笔硬度。</p>
<h2 id="常用辨析"><a class="markdownIt-Anchor" href="#常用辨析"></a> 常用辨析</h2>
<ul>
<li>常用的<strong>19号笔刷</strong>其实主要就是<code>大小抖动</code>+<code>流量抖动</code>+<code>建立</code>构成的。</li>
<li>常用的<strong>喷枪</strong>就是 <code>柔角笔尖形状</code>+ <code>流量抖动</code>+<code>建立</code>构成的。或者说，广义上的喷枪可以由任意一个笔刷加上<code>建立</code>选项构成。</li>
<li>能否<strong>混色</strong>不是由笔刷决定的，而是由<strong>笔的类型</strong>决定的。<strong>混合画笔工具</strong>可以让颜色混合，而普通 <strong>画笔工具</strong>则不可以。混合画笔工具的混色不仅仅是上下颜色的融合，而且会把下面的色调带到现有的笔刷之中，即使后面没有了下层其他颜色，画笔也会持续维持混色一段时间直至完全衰减。如下图：</li>
</ul>
<p><img data-src="image-20200519171159376.png" alt="image-20200519171159376"></p>
<ul>
<li>要想实现颜色混合，比如<code>红+绿=黄</code>，任何有透明度的笔刷都可以实现。但如果想让这些颜色像是都粘在了刷子上一样后面会一起蹭出来，或是变化涂料的湿度，或是想要“新的涂料上去后下面的涂料被浸湿并聚集在新笔迹两侧”的效果，则需要使用 <strong>混合画笔工具</strong>。</li>
<li>水彩的核心是<code>低流量</code>+<code>建立</code>+<code>散布</code>+<code>双重画笔</code>+<code>流量抖动</code>+<code>大小抖动</code>。其中，在纸上氤氲散开的效果主要是由双重画笔中的辅助画笔完成的</li>
</ul>
]]></content>
      <tags>
        <tag>art</tag>
        <tag>painting</tag>
        <tag>ps</tag>
      </tags>
  </entry>
  <entry>
    <title>Python调用非相同文件夹下的MATLAB文件</title>
    <url>/2018/08/23/py-call-matlab-in-dif-folder/</url>
    <content><![CDATA[<h1 id="问题"><a class="markdownIt-Anchor" href="#问题"></a> 问题</h1>
<p>Python如何调用非相同文件夹下的MATLAB文件。</p>
<h1 id="解决方案"><a class="markdownIt-Anchor" href="#解决方案"></a> 解决方案</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matlab.engine</span><br><span class="line">eng = matlab.engine.start_matlab()</span><br><span class="line">eng.addpath(<span class="string">&#x27;./matlab_source_code&#x27;</span>)</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>python</tag>
        <tag>matlab</tag>
      </tags>
  </entry>
  <entry>
    <title>Pycharm中使用虚拟环境</title>
    <url>/2018/08/27/pycharm-virtual-env/</url>
    <content><![CDATA[<h1 id="问题"><a class="markdownIt-Anchor" href="#问题"></a> 问题</h1>
<p>如何在Pycharm中使用用于某个app的特定的虚拟环境</p>
<h1 id="解决方案"><a class="markdownIt-Anchor" href="#解决方案"></a> 解决方案</h1>
<p>Once a virtual environment is created, it can be added to the list of available interpreters, as a local interpreter.</p>
<h2 id="to-add-an-existing-virtual-environment-to-the-list-of-available-interpreters"><a class="markdownIt-Anchor" href="#to-add-an-existing-virtual-environment-to-the-list-of-available-interpreters"></a> To add an existing virtual environment to the list of available interpreters</h2>
<ol>
<li>In the <a href="https://www.jetbrains.com/help/pycharm-edu/project-interpreter.html">Project Interpreter</a> page, click ⚙ .</li>
<li>In the drop-down list, choose  Add .</li>
<li>In the <a href="https://www.jetbrains.com/help/pycharm-edu/select-path-dialog.html">Select Python Interpreter</a> dialog box that opens, choose the desired Python executable, and click OK.</li>
</ol>
]]></content>
      <tags>
        <tag>python</tag>
        <tag>pycharm</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 在类的静态函数中调用另一个静态函数</title>
    <url>/2020/03/04/python-call-static-in-static/</url>
    <content><![CDATA[<p>有两种常见解决办法：</p>
<ol>
<li>调用目标函数的<code>__func__()</code>方法。</li>
<li>使用<code>CLASS_NAME.target_func()</code>方法。这种方法更加干净、Pythonic。</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Klass</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod  </span><span class="comment"># use as decorator</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">stat_func</span>():</span><br><span class="line">        <span class="keyword">return</span> <span class="number">42</span></span><br><span class="line"></span><br><span class="line">    _ANS = stat_func.__func__()  <span class="comment"># call the staticmethod</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">method</span>(<span class="params">self</span>):</span><br><span class="line">        ret = Klass.stat_func()</span><br><span class="line">        <span class="keyword">return</span> ret</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python的赋值与深浅拷贝实例解析</title>
    <url>/2020/02/11/python-copy/</url>
    <content><![CDATA[<h2 id="对象是一个定值"><a class="markdownIt-Anchor" href="#对象是一个定值"></a> 对象是一个定值</h2>
<p>此时三种方法的作用实际上是相同的。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"></span><br><span class="line">a = <span class="string">&quot;亚丝娜&quot;</span></span><br><span class="line">b = a</span><br><span class="line">c = copy.copy(a)</span><br><span class="line">d = copy.deepcopy(a)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;源：id(a)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(a))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;赋值：id(b)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(b))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;浅拷贝：id(c)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(c))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;深拷贝：id(d)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(d))</span><br></pre></td></tr></table></figure>
<span id="more"></span>
<p>输出如下:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">源：<span class="built_in">id</span>(a)-&gt;&gt;&gt; 4394180400</span><br><span class="line">赋值：<span class="built_in">id</span>(b)-&gt;&gt;&gt; 4394180400</span><br><span class="line">浅拷贝：<span class="built_in">id</span>(c)-&gt;&gt;&gt; 4394180400</span><br><span class="line">深拷贝：<span class="built_in">id</span>(d)-&gt;&gt;&gt; 4394180400</span><br></pre></td></tr></table></figure>
<p>如果a的值被更改，只有a本身的id会改变，bcd都不变。</p>
<h2 id="对象是一个引用"><a class="markdownIt-Anchor" href="#对象是一个引用"></a> 对象是一个引用</h2>
<ul>
<li>首先，元组，数组，字典，类等的本质都是引用，或称之为“指针”，每个引用指向的实体都是有其相应地址的，比如这里的<code>“亚丝娜”</code>在内存中有一个具体的地址，而<code>[“亚丝娜”]</code>则是一个对于内存中“亚丝娜”实体的一个引用集，这个引用集本身也有一个独特的地址。</li>
<li>对于不可变对象，Python 用引用计数的方式管理它们，所以 Python 不会对值相同的不可变对象，申请单独的内存空间。只会记录它的引用次数。</li>
<li>使用“引用集”赋值是把引用集本身的地址赋给了左边的变量，即一个引用的引用。</li>
<li>使用赋值的方法得到的对象，当原“引用集”中的任何引用发生任何改变时，其都会随着改变，就像一个快捷方式。但如果原“引用集”直接被覆盖了，则不会随之改变。</li>
</ul>
<h3 id="例"><a class="markdownIt-Anchor" href="#例"></a> 例：</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 一位数组更改内层元素</span></span><br><span class="line">a=[<span class="string">&quot;亚丝娜&quot;</span>]</span><br><span class="line">b=a</span><br><span class="line">b = a</span><br><span class="line">c = copy.copy(a)</span><br><span class="line">d = copy.deepcopy(a)</span><br><span class="line"></span><br><span class="line">a[<span class="number">0</span>] = <span class="string">&quot;桐人&quot;</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;源：id(a)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(a))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;赋值：id(b)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(b))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;浅拷贝：id(c)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(c))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;深拷贝：id(d)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(d))</span><br><span class="line"><span class="built_in">print</span>(a,b,c,d)</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">源：id(a)-&gt;&gt;&gt; 4585988416</span></span><br><span class="line"><span class="string">赋值：id(b)-&gt;&gt;&gt; 4585988416</span></span><br><span class="line"><span class="string">浅拷贝：id(c)-&gt;&gt;&gt; 4585374256</span></span><br><span class="line"><span class="string">深拷贝：id(d)-&gt;&gt;&gt; 4585117648</span></span><br><span class="line"><span class="string">[&#x27;桐人&#x27;] [&#x27;桐人&#x27;] [&#x27;亚丝娜&#x27;] [&#x27;亚丝娜&#x27;]</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 一位数组完全变更</span></span><br><span class="line">a=[<span class="string">&quot;亚丝娜&quot;</span>]</span><br><span class="line">b=a</span><br><span class="line">b = a</span><br><span class="line">c = copy.copy(a)</span><br><span class="line">d = copy.deepcopy(a)</span><br><span class="line"></span><br><span class="line">a=[<span class="string">&quot;利兹&quot;</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;源：id(a)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(a))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;赋值：id(b)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(b))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;浅拷贝：id(c)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(c))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;深拷贝：id(d)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(d))</span><br><span class="line"><span class="built_in">print</span>(a,b,c,d)</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">源：id(a)-&gt;&gt;&gt; 4586047600</span></span><br><span class="line"><span class="string">赋值：id(b)-&gt;&gt;&gt; 4583430096</span></span><br><span class="line"><span class="string">浅拷贝：id(c)-&gt;&gt;&gt; 4585223344</span></span><br><span class="line"><span class="string">深拷贝：id(d)-&gt;&gt;&gt; 4585988416</span></span><br><span class="line"><span class="string">[&#x27;利兹&#x27;] [&#x27;亚丝娜&#x27;] [&#x27;亚丝娜&#x27;] [&#x27;亚丝娜&#x27;]</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 二维数组更改最内层元素</span></span><br><span class="line">a=[[<span class="string">&quot;亚丝娜&quot;</span>]]</span><br><span class="line">b=a</span><br><span class="line">b = a</span><br><span class="line">c = copy.copy(a)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;源（重赋值前）：id(a)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(a))</span><br><span class="line">d = copy.deepcopy(a)</span><br><span class="line"></span><br><span class="line">a[<span class="number">0</span>][<span class="number">0</span>]=<span class="string">&quot;利兹&quot;</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;源：id(a)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(a))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;赋值：id(b)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(b))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;浅拷贝：id(c)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(c))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;深拷贝：id(d)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(d))</span><br><span class="line"><span class="built_in">print</span>(a,b,c,d)</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">源（重赋值前）：id(a)-&gt;&gt;&gt; 4586327008</span></span><br><span class="line"><span class="string">源：id(a)-&gt;&gt;&gt; 4586327008</span></span><br><span class="line"><span class="string">赋值：id(b)-&gt;&gt;&gt; 4586327008</span></span><br><span class="line"><span class="string">浅拷贝：id(c)-&gt;&gt;&gt; 4586041088</span></span><br><span class="line"><span class="string">深拷贝：id(d)-&gt;&gt;&gt; 4585375216</span></span><br><span class="line"><span class="string">[[&#x27;利兹&#x27;]] [[&#x27;利兹&#x27;]] [[&#x27;利兹&#x27;]] [[&#x27;亚丝娜&#x27;]]</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 二维数组更改第一维</span></span><br><span class="line">a=[[<span class="string">&quot;亚丝娜&quot;</span>]]</span><br><span class="line">b=a</span><br><span class="line">b = a</span><br><span class="line">c = copy.copy(a)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;源（重赋值前）：id(a)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(a))</span><br><span class="line">d = copy.deepcopy(a)</span><br><span class="line"></span><br><span class="line">a[<span class="number">0</span>]=[<span class="string">&quot;利兹&quot;</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;源：id(a)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(a))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;赋值：id(b)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(b))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;浅拷贝：id(c)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(c))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;深拷贝：id(d)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(d))</span><br><span class="line"><span class="built_in">print</span>(a,b,c,d)</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">源（重赋值前）：id(a)-&gt;&gt;&gt; 4585239328</span></span><br><span class="line"><span class="string">源：id(a)-&gt;&gt;&gt; 4585239328</span></span><br><span class="line"><span class="string">赋值：id(b)-&gt;&gt;&gt; 4585239328</span></span><br><span class="line"><span class="string">浅拷贝：id(c)-&gt;&gt;&gt; 4586082944</span></span><br><span class="line"><span class="string">深拷贝：id(d)-&gt;&gt;&gt; 4586327008</span></span><br><span class="line"><span class="string">[[&#x27;利兹&#x27;]] [[&#x27;利兹&#x27;]] [[&#x27;亚丝娜&#x27;]] [[&#x27;亚丝娜&#x27;]]</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 二维数组完全变更</span></span><br><span class="line">a=[[<span class="string">&quot;亚丝娜&quot;</span>]]</span><br><span class="line">b=a</span><br><span class="line">b = a</span><br><span class="line">c = copy.copy(a)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;源（重赋值前）：id(a)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(a))</span><br><span class="line">d = copy.deepcopy(a)</span><br><span class="line"></span><br><span class="line">a=[[<span class="string">&quot;利兹&quot;</span>]]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;源：id(a)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(a))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;赋值：id(b)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(b))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;浅拷贝：id(c)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(c))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;深拷贝：id(d)-&gt;&gt;&gt;&quot;</span>, <span class="built_in">id</span>(d))</span><br><span class="line"><span class="built_in">print</span>(a,b,c,d)</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">源（重赋值前）：id(a)-&gt;&gt;&gt; 4586082944</span></span><br><span class="line"><span class="string">源：id(a)-&gt;&gt;&gt; 4585468704</span></span><br><span class="line"><span class="string">赋值：id(b)-&gt;&gt;&gt; 4586082944</span></span><br><span class="line"><span class="string">浅拷贝：id(c)-&gt;&gt;&gt; 4586327008</span></span><br><span class="line"><span class="string">深拷贝：id(d)-&gt;&gt;&gt; 4586041088</span></span><br><span class="line"><span class="string">[[&#x27;利兹&#x27;]] [[&#x27;亚丝娜&#x27;]] [[&#x27;亚丝娜&#x27;]] [[&#x27;亚丝娜&#x27;]]</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>赋值是完全的快捷方式。</li>
<li>浅拷贝的实质是对一个“引用集”的所有引用的拷贝，即拷贝了一份“引用集”中记录的所有的这些的不可变对象的地址，但只拷贝了一层，或称并没有把这些对象本身拷贝一遍。</li>
<li>如果引用集里还有引用集x，那么浅拷贝对x的作用和赋值相同，即如果x里的元素变了，浅拷贝的结果还是会跟着变。</li>
<li>深拷贝把拷贝对象里面的所有层的引用集全部做了拷贝动作，直到引用到不可变变量，所以可以说深拷贝出来的结果和其拷贝对象没有任何耦合关系了。</li>
</ul>
<h2 id="简要版本"><a class="markdownIt-Anchor" href="#简要版本"></a> 简要版本</h2>
<ul>
<li>由于 Python 内部引用计数的特性，对于不可变对象，浅拷贝和深拷贝的作用是一致的，就相当于复制了一份副本，原对象内部的不可变对象的改变，不会影响到复制对象。</li>
<li>浅拷贝的拷贝。其实是拷贝了原始元素的引用（内存地址），所以当拷贝可变对象时，原对象内可变对象的对应元素的改变，会在复制对象的对应元素上，有所体现。</li>
<li>深拷贝在遇到可变对象时，又在内部做了新建了一个副本。所以，不管它内部的元素如何变化，都不会影响到原来副本的可变对象。</li>
</ul>
<h2 id="参考"><a class="markdownIt-Anchor" href="#参考"></a> 参考</h2>
<p><a href="https://juejin.im/post/5c6943266fb9a049ed316931">5张图彻底理解Python中的浅拷贝与深拷贝</a></p>
]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python Data Visualization Libs Comparing</title>
    <url>/2018/08/11/python-data-visualization/</url>
    <content><![CDATA[<h1 id="python-data-visualization-comparing-5-tools"><a class="markdownIt-Anchor" href="#python-data-visualization-comparing-5-tools"></a> Python Data Visualization — Comparing 5 Tools</h1>
<h3 id="背景介绍"><a class="markdownIt-Anchor" href="#背景介绍"></a> 背景介绍</h3>
<p>本次由于项目需要，要将深度学习预测出来的数据（41x9的矩阵）和Label矩阵进行对比，所以需要进行3D可视化，因而对比了几个常见的python数据可视化库。</p>
<span id="more"></span>
<h4 id="简单说下对比结果"><a class="markdownIt-Anchor" href="#简单说下对比结果"></a> 简单说下对比结果：</h4>
<ol>
<li>
<p>最终采用Plotly库，因为其完美支持3D绘图，并且提供可交互的HTML5格式输出，这对于需要不断调整角度和大小的数据观察来说至关重要。效果如下图：你不但可以得到漂亮的绘图，还可以通过鼠标左右键、滚轮轻松调整尺度、方向等关键参数，更可以通过右上角的各种工具进行进一步调整。当然，其也支持3D图的Subplot。</p>
<p><img data-src="0069RVTdly1fu6sramtv3j317u0nsjyv.jpg" alt="image-20180811231857431"></p>
<ol start="2">
<li>Plotly 库的缺点：这个库并不是完全免费的。尽管这样，基本不会影响你的正常使用，除非你用for循环高速下载成百上千张图片。其每天画图数目是无限的，不过保存只有100张限额。其有在线和离线两种模式，在线支持直接保存，离线很麻烦。另外，实际上离线会比在线更快。</li>
<li>Bokeh：这个库在二位统计绘图上是有很大吸引力的。图像质量很高，提供的配色很精美，并且也支持鼠标交互，支持多幅图共享一份数据并且交互时同步变化，特色明显。但对3D画图支持较差。</li>
</ol>
</li>
</ol>
<h4 id="下面是引文"><a class="markdownIt-Anchor" href="#下面是引文"></a> 下面是<a href="https://codeburst.io/overview-of-python-data-visualization-tools-e32e1f716d10">引文</a>：</h4>
<h3 id="introduction"><a class="markdownIt-Anchor" href="#introduction"></a> Introduction</h3>
<p>Big data and analytics can be beautifully presented by using visualization tools in Python. Python is a great programming language with variety of options. It is object oriented, semantically structured and great for scripting programs as well as connecting other programmable components. Python is a favorite tool for programmers and data scientists because it’s easy to learn, and the extensive list of built-in features and importable libraries contribute to increased productivity. The Python language has been around for nearly 30 years and the numerous user contributed libraries (e.g. Pandas) have many use cases, such as image modification, data analysis, and server automation. This means that sometimes it can be really difficult to pick the right tool for data analysis or visualization and figure out which one to use. For this purpose, different visualization methods in Python have been summarized, rendered and explained. The techniques were done within the same amount of time and same data sets to demonstrate the difference between each output. The point of the comparison is to understand which visualization tool is the simplest and visually presentable at the same time.</p>
<h3 id="essential-visualization-tools"><a class="markdownIt-Anchor" href="#essential-visualization-tools"></a> Essential Visualization Tools</h3>
<p>The most common type of visualization is a simple bar chart. It is popular and commonly used type of visualization to make comparison between values and variety of categories. It can be vertically or horizontally oriented by adjusting x and y axes, depending on what kind of information or categories the chart requires to present. Parameters need to be identified, such as axes, similarities, title and decided on what exactly the visualization supposed to show. To make a simple bar chart, a number some of the most popular tools and libraries that have been invented for plotting the data could be utilized. These include the most used and common tools such as: Pandas, Seaborn, Bokeh, Pygal and Ploty.</p>
<p>Python libraries overview with analyzed examples below contain illustrative samples of the tools with data-set taken from <a href="https://mchb.hrsa.gov/whusa10/hstat/mh/pages/237mm.html">Women’s Health USA</a>. The data includes maternal mortality rates evaluated by age in five rows and titles in two columns to keep it simple. Same data set is being used for all examples that are demonstrated below. Additionally, just like any other programming language issues, errors or questions with the libraries can be found on stack overflow page by Google search.</p>
<h4 id="pandas"><a class="markdownIt-Anchor" href="#pandas"></a> Pandas</h4>
<p>First tool is Pandas. The Pandas name is derived from panel data, a term for multidimensional structured data-set. It is a free software that was developed by Wes McKinney in 2008 while working at Applied Quantitative Research Capital Management global firm based in Greenwich, Connecticut, United States. It all started when the company needed a productive, easy to use tool to analyze quantitative data on financial data-sets. By the end of 2009, Wes McKinney convinced management to permit him to open source the library and it is being supported by other contributors ever since, to make it even better.</p>
<p>The Pandas library became highly optimized for usage, with useful written code that provides high function and rich data structured design. It is fast and easy to implement and contains a software library that is used within Python for powerful data analysis and manipulating data visualization.</p>
<p>The main feature of Pandas is data-frame that supplies built in options for plotting visualization in two dimension tabular style. It is column oriented with row and columns structured style. Pandas works great with other libraries to create a wide variety of plots. Pandas data structure can have different written values as well as labels and their axes.</p>
<p>To start the data visualization, first step is to load the library and import the data. Usually, the data stored in .csv (comma separated values) file, where each column is separated by comma, and each row by a new line. To create a bar plot with Pandas the following Python input code can be used.</p>
<p>import numpy as np<br>
import pandas as pd<br>
mortality_age = pd.read_csv(“mortality_by_age.csv”)<br>
mortality_age = mortality_age.sort_values(‘Deaths per 100,000 Live Births:’, ascending = False)[:5]<br>
mortality_age.plot(kind = “bar”)</p>
<p>That code executes the plot with detailed columns and title with default colors and background. Figure 1 shows the following plot output.</p>
<p><img data-src="1*grNVtaqUzJi76I-X_dXuPA.png" alt="img"></p>
<p>Pandas Simple Bar Chart Input Example</p>
<p>The simple form of this plot looks acceptable and easy to read. The bar chart looks nice and clean. However, it is impossible to customize the graph into more detailed visualization just by using Pandas.</p>
<h4 id="seaborn"><a class="markdownIt-Anchor" href="#seaborn"></a> Seaborn</h4>
<p>Second tool is Seaborn. This tool integrates great with Pandas. It was invented and developed by Michael Waskom in 2014. It is another open-source software library for data analysis and visualization. Seaborn is a popular library for making appealing statistical data graphs in Python. It provides high level of graphic interface for drawing platform and helps to easily identify patterns and draw attention to key elements. It includes built in themes for styling of informative data plots. It uses grid object method that connects the structure of the figure to the visual structure of the given data set. The main goal of this method is to simplify complicated plots. Additional, Seaborn offers variety of styles that allow to modify colors and make it look even more appealing.</p>
<p>To run the example, the following code below is needed:</p>
<p>import pandas as pd<br>
import seaborn as sns<br>
import matplotlib.pyplot as plt<br>
mortality_age = pd.read_csv(“mortality_by_age.csv”)<br>
mortality_age = mortality_age.sort_values(‘Deaths per 100,000 Live Births:’,<br>
ascending = False)[:5]<br>
sns.set(style=”darkgrid”)<br>
mortality_age_plot = sns.barplot(x=mortality_age<br>
[“Age Range”], y=mortality_age[“Deaths per 100,000 Live Births:”],<br>
palette = “muted”, order=mortality_age[“Age Range”].tolist())<br>
plt.xticks(rotation=90)<br>
plt.show()</p>
<p>That code executes the plot with detailed titles, nicely colored bars and grid. Figure 2 shows what the bar chart looks like.</p>
<p><img data-src="0069RVTdly1fu6rjp7se5j30dp0bsmx7.jpg" alt="img"></p>
<p>Seaborn Simple Bar Chart Input Example</p>
<p>This method made it possible to rotate x and y axis to make the categories and titles readable. The visual graphic looks appealing and more exciting than the previous one.</p>
<h4 id="bokeh"><a class="markdownIt-Anchor" href="#bokeh"></a> Bokeh</h4>
<p>Third tool is Bokeh. It is different from the previous two methods. It was developed by Anaconda’s development team in 2012 with funding from Defence Advanced Research Projects Agency. Bokeh is an open source and free to use for any type of project. It is versatile, integrates great with javascript and novel graphics style. It is an interactive library that was created for modern web browsers to visualize highly interactive plots and data applications. Bokeh’s method can create any kind of graphical plot including dash boards and variety of charts.</p>
<p>The simple visualization of a bar chart is in the example below. It shows the standard method to plot the data.</p>
<p>from bokeh.charts import Bar, output_file, show<br>
mortality_age = pd.read_csv(“mortality_by_age.csv”)<br>
data = {<br>
‘Age Range’: mortality_age[‘Age Range’],<br>
‘Deaths per 100,000 Live Births’: mortality_age[‘Deaths per 100,000 Live Births:’]<br>
}</p>
<p># x-axis labels pulled from the interpreter column, stacking labels from sample column<br>
bar = Bar(data, values=’Deaths per 100,000 Live Births’,<br>
label=’Deaths per 100,000 Live Births’,<br>
stack=’Age Range’, agg=’mean’,<br>
title=”Maternal Deaths per 100,000 Live Births”,<br>
legend=’top_right’, width=400)</p>
<p>output_file(“barchart.html”)<br>
show(bar)</p>
<p>The code opens up a browser’s window and displays an HTML page with the plot. Figure 3 below displays the plotted output.</p>
<p><img data-src="0069RVTdly1fu6rjqg2yoj309w0ecaap.jpg" alt="img"></p>
<p>Bokeh Simple Bar Chart Output Example</p>
<p>The graph looks much nicer and cleaner. Bokeh method has a lot of customization option and functionality. Even thought it looks nice, it does not make sense to use for a simple bar visualization.</p>
<h4 id="pygal"><a class="markdownIt-Anchor" href="#pygal"></a> Pygal</h4>
<p>Forth tool is Pygal. It is a part of Python’s library that exports vector charts in different shapes and styles. It was created by a developer named Florian Mounier in 2012. It is also an open source free library and has been widely used because of its high customization options and simplicity at the same time. Options for creating visualizations are wide open and include pie charts, bar graphs, histograms, maps and so on. It all depends on the required look and feel of the graphic.</p>
<p>To create a simple bar chart the following input code can be used:</p>
<p>import pygal<br>
horizontalbar_chart = pygal.HorizontalBar()<br>
horizontalbar_chart.title = ‘Maternal Mortality By Age (in %)’<br>
horizontalbar_chart.add(‘Under 20 Years:’, 7.1)<br>
horizontalbar_chart.add(‘20–24 Years:’, 8.1)<br>
horizontalbar_chart.add(‘25–29 Years:’, 9.4)<br>
horizontalbar_chart.add(‘30–34 Years: ‘, 12.1)<br>
horizontalbar_chart.add(’35 Years and Older:’, 32.2)<br>
horizontalbar_chart.render()</p>
<p>The output of the vector file looks really nice and visually appealing in style. It does not provide a zooming effect same as in the previous method, however it includes tool-tip hover state. It can be embedded into a web-page by using tag or code. Figure 4 displays the plotted output.</p>
<p><img data-src="0069RVTdly1fu6rjoiov8j30b0089q32.jpg" alt="img"></p>
<p>Pygal Simple Bar Chart Input Example</p>
<p>The interactive and vector nature of the image could be utilized widely in websites and data applications.</p>
<h4 id="plotly"><a class="markdownIt-Anchor" href="#plotly"></a> Plotly</h4>
<p>Fifth tool is Plotly, also named as <a href="http://Plot.ly">Plot.ly</a> because of its main platform online. It is an interactive online visualization tool that is being used for data analytics, scientific graphs and other visualization. It contains a great API including one for Python. There are lot of interactive, professional quality visualizations online that were created with this module.<br>
Plotly was developed by multiple developers, including Alex Johnson, Chris Parmer, Jack Parmer and Matthew Sundquist. The tool was named one of the ‘’Top 20 Hottest Innovative Companies in Canada’’ by the Canadian Innovation Exchange.<br>
It is different from other Python’s libraries by being an interactive online tool for creating the renderings. Therefore, everything that is being created with this tool is posted on the web. The great thing about Plotly is that it integrates well with pandas.<br>
The simplest way to use it is through Plotly’s online tools and import the data by uploading the data set file. It has many convenient features to interact with, extract and visualize the data. Additionally, the tool accepts many formats, such as .xls, .xlsx, or .csv files.</p>
<p>Figure 5 shows the user interface and settings within the dashboard of the online tool.</p>
<p><img data-src="0069RVTdly1fu6rjr8fztj30o70dngm0.jpg" alt="img"></p>
<p>Plotly User Interface Tool Online</p>
<p>Figure 5 above shows the resulted bar chart after executing provided parameters setup and imported data sets file.</p>
<p>The process generated an amazing and beautiful highly interactive bar chart with tool-tips and varieties of other tool options such as zooming effect, panning, selecting, auto-scale, moving, resetting and so on. It is easily modified by clicking on different parts and parameters of the graph without code knowledge.</p>
<h3 id="conclusions"><a class="markdownIt-Anchor" href="#conclusions"></a> Conclusions</h3>
<p>All the Big Data without proper visualization extremly difficult to analyze. Python is one of the most innovative and popular tool for data visualization. The good news that it does not take much to create visualization in Python since this language has been around for over twenty years and accumulated exclusive libraries. There are multiple tools and options to visualize the data. However, having variety of options complicates the matter and create confusion for users. Identifying proper method that should be used depends on a project requirements and expectations. The proper way is to test different techniques and understand which one is appropriate.</p>
<p>Various visualization methods have been demonstrated by using same data-set to plot a simple bar chart. By using most common techniques demonstrated here, Pandas is the simplest method for basic plots. While Seaborn is great for creating visually appealing statistical charts that include color. Bokeh works great for more complicated visualizations and ideal for web based interactive presentations. Pygal works well for generating vector and interactive files. However, it does not have flexibility as other methods. Plotly is the most useful and easiest option for creating web based highly interactive visualizations.</p>
]]></content>
      <tags>
        <tag>python</tag>
        <tag>visualization</tag>
      </tags>
  </entry>
  <entry>
    <title>Python并行编程</title>
    <url>/2018/08/22/python-parallel-programming/</url>
    <content><![CDATA[<p>Python 的多线程可以优化许多高耗时的阻塞性步骤。比如机器学习中的储存模型等步骤，如果串行储存，会消耗掉大量时间在存模型上，GPU好的时候甚至比训练时间还长。。。</p>
<span id="more"></span>
<h2 id="先祭上自己的代码实现"><a class="markdownIt-Anchor" href="#先祭上自己的代码实现"></a> 先祭上自己的代码实现</h2>
<h4 id="定义部分"><a class="markdownIt-Anchor" href="#定义部分"></a> 定义部分</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line">lock = threading.Lock()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">save_models</span>(<span class="params">opt, net, epoch, train_loss, best_loss, test_loss</span>):</span><br><span class="line">    <span class="comment"># Save a temp model</span></span><br><span class="line">    train_loss = <span class="built_in">float</span>(train_loss)</span><br><span class="line">    best_loss = <span class="built_in">float</span>(best_loss)</span><br><span class="line">    test_loss = <span class="built_in">float</span>(test_loss)</span><br><span class="line">    <span class="keyword">if</span> opt.SAVE_TEMP_MODEL:</span><br><span class="line">        net.save(epoch, train_loss / opt.NUM_TRAIN, <span class="string">&quot;temp_model.dat&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Save the best model</span></span><br><span class="line">    <span class="keyword">if</span> test_loss / opt.NUM_TEST &lt; best_loss:</span><br><span class="line">        best_loss = test_loss / opt.NUM_TEST</span><br><span class="line">        net.save(epoch, train_loss / opt.NUM_TRAIN, <span class="string">&quot;best_model.dat&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> best_loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyThread</span>(threading.Thread):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, opt, net, epoch, train_loss, best_loss, test_loss</span>):</span><br><span class="line">        threading.Thread.__init__(self)</span><br><span class="line">        self.opt = opt</span><br><span class="line">        self.net = net</span><br><span class="line">        self.epoch = epoch</span><br><span class="line">        self.train_loss = train_loss</span><br><span class="line">        self.best_loss = best_loss</span><br><span class="line">        self.test_loss = test_loss</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">self</span>):</span><br><span class="line">        lock.acquire()</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            self.best_loss = save_models(self.opt, self.net, self.epoch, self.train_loss, self.best_loss, self.test_loss)</span><br><span class="line">        <span class="keyword">finally</span>:</span><br><span class="line">            lock.release()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="调用部分"><a class="markdownIt-Anchor" href="#调用部分"></a> 调用部分</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">threads = []</span><br><span class="line"><span class="keyword">if</span> epoch &gt; <span class="number">0</span>:</span><br><span class="line">    threads[epoch-<span class="number">1</span>].join()</span><br><span class="line">    best_loss_temp = threads[epoch-<span class="number">1</span>].best_loss</span><br><span class="line">    <span class="keyword">if</span> best_loss_temp != best_loss:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;==&gt; Best Model Renewed.&quot;</span>)</span><br><span class="line">        best_loss = best_loss_temp</span><br><span class="line">        threads.append(MyThread(opt, net, epoch, train_loss, best_loss, test_loss))</span><br><span class="line">        threads[epoch].start()</span><br></pre></td></tr></table></figure>
<h2 id="再引用一下廖雪峰的部分教程"><a class="markdownIt-Anchor" href="#再引用一下廖雪峰的部分教程"></a> 再引用一下<a href="https://www.liaoxuefeng.com">廖雪峰</a>的部分<a href="https://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000/00143192823818768cd506abbc94eb5916192364506fa5d000">教程</a>：</h2>
<p>多任务可以由多进程完成，也可以由一个进程内的多线程完成。</p>
<p>我们前面提到了进程是由若干线程组成的，一个进程至少有一个线程。</p>
<p>由于线程是操作系统直接支持的执行单元，因此，高级语言通常都内置多线程的支持，Python也不例外，并且，Python的线程是真正的Posix Thread，而不是模拟出来的线程。</p>
<p>Python的标准库提供了两个模块：<code>_thread</code>和<code>threading</code>，<code>_thread</code>是低级模块，<code>threading</code>是高级模块，对<code>_thread</code>进行了封装。绝大多数情况下，我们只需要使用<code>threading</code>这个高级模块。</p>
<p>启动一个线程就是把一个函数传入并创建<code>Thread</code>实例，然后调用<code>start()</code>开始执行：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time, threading</span><br><span class="line"></span><br><span class="line"><span class="comment"># 新线程执行的代码:</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loop</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;thread %s is running...&#x27;</span> % threading.current_thread().name)</span><br><span class="line">    n = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> n &lt; <span class="number">5</span>:</span><br><span class="line">        n = n + <span class="number">1</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;thread %s &gt;&gt;&gt; %s&#x27;</span> % (threading.current_thread().name, n))</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;thread %s ended.&#x27;</span> % threading.current_thread().name)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;thread %s is running...&#x27;</span> % threading.current_thread().name)</span><br><span class="line">t = threading.Thread(target=loop, name=<span class="string">&#x27;LoopThread&#x27;</span>)</span><br><span class="line">t.start()</span><br><span class="line">t.join()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;thread %s ended.&#x27;</span> % threading.current_thread().name)</span><br></pre></td></tr></table></figure>
<p>执行结果如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">thread MainThread <span class="keyword">is</span> running...</span><br><span class="line">thread LoopThread <span class="keyword">is</span> running...</span><br><span class="line">thread LoopThread &gt;&gt;&gt; <span class="number">1</span></span><br><span class="line">thread LoopThread &gt;&gt;&gt; <span class="number">2</span></span><br><span class="line">thread LoopThread &gt;&gt;&gt; <span class="number">3</span></span><br><span class="line">thread LoopThread &gt;&gt;&gt; <span class="number">4</span></span><br><span class="line">thread LoopThread &gt;&gt;&gt; <span class="number">5</span></span><br><span class="line">thread LoopThread ended.</span><br><span class="line">thread MainThread ended.</span><br></pre></td></tr></table></figure>
<p>由于任何进程默认就会启动一个线程，我们把该线程称为主线程，主线程又可以启动新的线程，Python的<code>threading</code>模块有个<code>current_thread()</code>函数，它永远返回当前线程的实例。主线程实例的名字叫<code>MainThread</code>，子线程的名字在创建时指定，我们用<code>LoopThread</code>命名子线程。名字仅仅在打印时用来显示，完全没有其他意义，如果不起名字Python就自动给线程命名为<code>Thread-1</code>，<code>Thread-2</code>……</p>
<h3 id="lock"><a class="markdownIt-Anchor" href="#lock"></a> Lock</h3>
<p>多线程和多进程最大的不同在于，多进程中，同一个变量，各自有一份拷贝存在于每个进程中，互不影响，而多线程中，所有变量都由所有线程共享，所以，任何一个变量都可以被任何一个线程修改，因此，线程之间共享数据最大的危险在于多个线程同时改一个变量，把内容给改乱了。</p>
<p>如果我们要确保<code>balance</code>计算正确，就要给<code>change_it()</code>上一把锁，当某个线程开始执行<code>change_it()</code>时，我们说，该线程因为获得了锁，因此其他线程不能同时执行<code>change_it()</code>，只能等待，直到锁被释放后，获得该锁以后才能改。由于锁只有一个，无论多少线程，同一时刻最多只有一个线程持有该锁，所以，不会造成修改的冲突。创建一个锁就是通过<code>threading.Lock()</code>来实现：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">balance = <span class="number">0</span></span><br><span class="line">lock = threading.Lock()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run_thread</span>(<span class="params">n</span>):</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100000</span>):</span><br><span class="line">        <span class="comment"># 先要获取锁:</span></span><br><span class="line">        lock.acquire()</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="comment"># 放心地改吧:</span></span><br><span class="line">            change_it(n)</span><br><span class="line">        <span class="keyword">finally</span>:</span><br><span class="line">            <span class="comment"># 改完了一定要释放锁:</span></span><br><span class="line">            lock.release()</span><br></pre></td></tr></table></figure>
<p>当多个线程同时执行<code>lock.acquire()</code>时，只有一个线程能成功地获取锁，然后继续执行代码，其他线程就继续等待直到获得锁为止。</p>
<p>获得锁的线程用完后一定要释放锁，否则那些苦苦等待锁的线程将永远等待下去，成为死线程。所以我们用<code>try...finally</code>来确保锁一定会被释放。</p>
<p>锁的好处就是确保了某段关键代码只能由一个线程从头到尾完整地执行，坏处当然也很多，首先是阻止了多线程并发执行，包含锁的某段代码实际上只能以单线程模式执行，效率就大大地下降了。其次，由于可以存在多个锁，不同的线程持有不同的锁，并试图获取对方持有的锁时，可能会造成死锁，导致多个线程全部挂起，既不能执行，也无法结束，只能靠操作系统强制终止。</p>
<h3 id="多核cpu"><a class="markdownIt-Anchor" href="#多核cpu"></a> 多核CPU</h3>
<p>如果你不幸拥有一个多核CPU，你肯定在想，多核应该可以同时执行多个线程。</p>
<p>如果写一个死循环的话，会出现什么情况呢？</p>
<p>打开Mac OS X的Activity Monitor，或者Windows的Task Manager，都可以监控某个进程的CPU使用率。</p>
<p>我们可以监控到一个死循环线程会100%占用一个CPU。</p>
<p>如果有两个死循环线程，在多核CPU中，可以监控到会占用200%的CPU，也就是占用两个CPU核心。</p>
<p>要想把N核CPU的核心全部跑满，就必须启动N个死循环线程。</p>
<p>试试用Python写个死循环：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> threading, multiprocessing</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loop</span>():</span><br><span class="line">    x = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        x = x ^ <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(multiprocessing.cpu_count()):</span><br><span class="line">    t = threading.Thread(target=loop)</span><br><span class="line">    t.start()</span><br></pre></td></tr></table></figure>
<p>启动与CPU核心数量相同的N个线程，在4核CPU上可以监控到CPU占用率仅有102%，也就是仅使用了一核。</p>
<p>但是用C、C++或Java来改写相同的死循环，直接可以把全部核心跑满，4核就跑到400%，8核就跑到800%，为什么Python不行呢？</p>
<p>因为Python的线程虽然是真正的线程，但解释器执行代码时，有一个GIL锁：Global Interpreter Lock，任何Python线程执行前，必须先获得GIL锁，然后，每执行100条字节码，解释器就自动释放GIL锁，让别的线程有机会执行。这个GIL全局锁实际上把所有线程的执行代码都给上了锁，所以，多线程在Python中只能交替执行，即使100个线程跑在100核CPU上，也只能用到1个核。</p>
<p>GIL是Python解释器设计的历史遗留问题，通常我们用的解释器是官方实现的CPython，要真正利用多核，除非重写一个不带GIL的解释器。</p>
<p>所以，在Python中，可以使用多线程，但不要指望能有效利用多核。如果一定要通过多线程利用多核，那只能通过C扩展来实现，不过这样就失去了Python简单易用的特点。</p>
<p>不过，也不用过于担心，Python虽然不能利用多线程实现多核任务，但可以通过多进程实现多核任务。多个Python进程有各自独立的GIL锁，互不影响。</p>
<h2 id="threadlocal"><a class="markdownIt-Anchor" href="#threadlocal"></a> ThreadLocal</h2>
<p>在多线程环境下，每个线程都有自己的数据。一个线程使用自己的局部变量比使用全局变量好，因为局部变量只有线程自己能看见，不会影响其他线程，而全局变量的修改必须加锁。</p>
<p>但是局部变量也有问题，就是在函数调用的时候，传递起来很麻烦：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">process_student</span>(<span class="params">name</span>):</span><br><span class="line">    std = Student(name)</span><br><span class="line">    <span class="comment"># std是局部变量，但是每个函数都要用它，因此必须传进去：</span></span><br><span class="line">    do_task_1(std)</span><br><span class="line">    do_task_2(std)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">do_task_1</span>(<span class="params">std</span>):</span><br><span class="line">    do_subtask_1(std)</span><br><span class="line">    do_subtask_2(std)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">do_task_2</span>(<span class="params">std</span>):</span><br><span class="line">    do_subtask_2(std)</span><br><span class="line">    do_subtask_2(std)</span><br></pre></td></tr></table></figure>
<p>每个函数一层一层调用都这么传参数那还得了？用全局变量？也不行，因为每个线程处理不同的<code>Student</code>对象，不能共享。</p>
<p>如果用一个全局<code>dict</code>存放所有的<code>Student</code>对象，然后以<code>thread</code>自身作为<code>key</code>获得线程对应的<code>Student</code>对象如何？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">global_dict = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">std_thread</span>(<span class="params">name</span>):</span><br><span class="line">    std = Student(name)</span><br><span class="line">    <span class="comment"># 把std放到全局变量global_dict中：</span></span><br><span class="line">    global_dict[threading.current_thread()] = std</span><br><span class="line">    do_task_1()</span><br><span class="line">    do_task_2()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">do_task_1</span>():</span><br><span class="line">    <span class="comment"># 不传入std，而是根据当前线程查找：</span></span><br><span class="line">    std = global_dict[threading.current_thread()]</span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">do_task_2</span>():</span><br><span class="line">    <span class="comment"># 任何函数都可以查找出当前线程的std变量：</span></span><br><span class="line">    std = global_dict[threading.current_thread()]</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>
<p>这种方式理论上是可行的，它最大的优点是消除了<code>std</code>对象在每层函数中的传递问题，但是，每个函数获取<code>std</code>的代码有点丑。</p>
<p>有没有更简单的方式？</p>
<p><code>ThreadLocal</code>应运而生，不用查找<code>dict</code>，<code>ThreadLocal</code>帮你自动做这件事：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建全局ThreadLocal对象:</span></span><br><span class="line">local_school = threading.local()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">process_student</span>():</span><br><span class="line">    <span class="comment"># 获取当前线程关联的student:</span></span><br><span class="line">    std = local_school.student</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Hello, %s (in %s)&#x27;</span> % (std, threading.current_thread().name))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">process_thread</span>(<span class="params">name</span>):</span><br><span class="line">    <span class="comment"># 绑定ThreadLocal的student:</span></span><br><span class="line">    local_school.student = name</span><br><span class="line">    process_student()</span><br><span class="line"></span><br><span class="line">t1 = threading.Thread(target= process_thread, args=(<span class="string">&#x27;Alice&#x27;</span>,), name=<span class="string">&#x27;Thread-A&#x27;</span>)</span><br><span class="line">t2 = threading.Thread(target= process_thread, args=(<span class="string">&#x27;Bob&#x27;</span>,), name=<span class="string">&#x27;Thread-B&#x27;</span>)</span><br><span class="line">t1.start()</span><br><span class="line">t2.start()</span><br><span class="line">t1.join()</span><br><span class="line">t2.join()</span><br></pre></td></tr></table></figure>
<p>执行结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Hello, Alice (<span class="keyword">in</span> Thread-A)</span><br><span class="line">Hello, Bob (<span class="keyword">in</span> Thread-B)</span><br></pre></td></tr></table></figure>
<p>全局变量<code>local_school</code>就是一个<code>ThreadLocal</code>对象，每个<code>Thread</code>对它都可以读写<code>student</code>属性，但互不影响。你可以把<code>local_school</code>看成全局变量，但每个属性如<code>local_school.student</code>都是线程的局部变量，可以任意读写而互不干扰，也不用管理锁的问题，<code>ThreadLocal</code>内部会处理。</p>
<p>可以理解为全局变量<code>local_school</code>是一个<code>dict</code>，不但可以用<code>local_school.student</code>，还可以绑定其他变量，如<code>local_school.teacher</code>等等。</p>
<p><code>ThreadLocal</code>最常用的地方就是为每个线程绑定一个数据库连接，HTTP请求，用户身份信息等，这样一个线程的所有调用到的处理函数都可以非常方便地访问这些资源。</p>
<h2 id="python如何从线程中返回值"><a class="markdownIt-Anchor" href="#python如何从线程中返回值"></a> <a href="https://zhuanlan.zhihu.com/p/21458868">Python如何从线程中返回值</a></h2>
<p>Python 从多线程中返回值，有多种方法：</p>
<p>1、常见的有写一个自己的多线程类，写一个方法返回。</p>
<p>2、可以设置一个全局的队列返回值。</p>
<p>3、也可以用multiprocessing.pool.ThreadPool 。</p>
<p>下面黄哥写一个类从线程中返回值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> threading <span class="keyword">import</span> Thread</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">foo</span>(<span class="params">number</span>):</span><br><span class="line">    time.sleep(<span class="number">20</span>)</span><br><span class="line">    <span class="keyword">return</span> number</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyThread</span>(<span class="title class_ inherited__">Thread</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, number</span>):</span><br><span class="line">        Thread.__init__(self)</span><br><span class="line">        self.number = number</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">self</span>):</span><br><span class="line">        self.result = foo(self.number)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_result</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">thd1 = MyThread(<span class="number">3</span>)</span><br><span class="line">thd2 = MyThread(<span class="number">5</span>)</span><br><span class="line">thd1.start()</span><br><span class="line">thd2.start()</span><br><span class="line">thd1.join()</span><br><span class="line">thd2.join()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> thd1.get_result()</span><br><span class="line"><span class="built_in">print</span> thd2.get_result()</span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>python</tag>
        <tag>multi-thread</tag>
      </tags>
  </entry>
  <entry>
    <title>python 函数参数的传递(参数带星号的说明)</title>
    <url>/2018/04/03/python-param-star/</url>
    <content><![CDATA[<p>本文转载自<a href="http://www.cnblogs.com/smiler/archive/2010/08/02/1790132.html">CNBLOGS</a></p>
<p>python中函数参数的传递是通过赋值来传递的。函数参数的使用又有俩个方面值得注意：1.函数参数是如何定义的 2.在调用函数的过程中参数是如何被解析</p>
<span id="more"></span>
<p>先看第一个问题，在python中函数参数的定义主要有四种方式：</p>
<h2 id="1-farg1arg2"><a class="markdownIt-Anchor" href="#1-farg1arg2"></a> 1. F(arg1,arg2,…)</h2>
<p>这 是最常见的定义方式，一个函数可以定义任意个参数，每个参数间用逗号分割，用这种方式定义的函数在调用的的时候也必须在函数名后的小括号里提供个数相等的 值（实际参数），而且顺序必须相同，也就是说在这种调用方式中，形参和实参的个数必须一致，而且必须一一对应，也就是说第一个形参对应这第一个实参。例 如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">a</span>(<span class="params">x,y</span>):</span><br><span class="line"><span class="built_in">print</span> x,y</span><br></pre></td></tr></table></figure>
<p>调用该函数，a(1,2)则x取1，y取2，形参与实参相对应，如果a(1)或者a(1,2,3)则会报错。</p>
<h2 id="2-farg1arg2value2"><a class="markdownIt-Anchor" href="#2-farg1arg2value2"></a> 2. F(arg1,arg2=value2,…)</h2>
<p>这种方式就是第一种的改进版，提供了默认值</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">a</span>(<span class="params">x,y=<span class="number">3</span></span>):</span><br><span class="line"><span class="built_in">print</span> x,y</span><br></pre></td></tr></table></figure>
<p>调用该函数，a(1,2)同样还是x取1，y取2，但是如果a(1)，则不会报错了，这个时候x还是1，y则为默认的3。上面这俩种方式，还可以更换参数位置，比如a(y=8,x=3)用这种形式也是可以的。</p>
<h2 id="3-farg1"><a class="markdownIt-Anchor" href="#3-farg1"></a> 3. F(*arg1)</h2>
<p>上 面俩个方式是有多少个形参，就传进去多少个实参，但有时候会不确定有多少个参数，则此时第三种方式就比较有用，它以一个*加上形参名的方式来表示这个函数 的实参个数不定，可能为0个也可能为n个。注意一点是，不管有多少个，在函数内部都被存放在以形参名为标识符的tuple中。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">a</span>(<span class="params">*x</span>):</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(x)==<span class="number">0</span>:</span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;None&#x27;</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"><span class="built_in">print</span> x</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a(<span class="number">1</span>)</span><br><span class="line">(<span class="number">1</span>,)        <span class="comment">#存放在元组中</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a()</span><br><span class="line"><span class="literal">None</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a(m=<span class="number">1</span>,y=<span class="number">2</span>,z=<span class="number">3</span>)</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">File <span class="string">&quot;&lt;pyshell#16&gt;&quot;</span>, line <span class="number">1</span>, <span class="keyword">in</span> -toplevel-</span><br><span class="line">a(m=<span class="number">1</span>,y=<span class="number">2</span>,z=<span class="number">3</span>)</span><br><span class="line">TypeError: a() got an unexpected keyword argument <span class="string">&#x27;m&#x27;</span></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">File <span class="string">&quot;&lt;pyshell#25&gt;&quot;</span>, line <span class="number">1</span>, <span class="keyword">in</span> -toplevel-</span><br><span class="line">a(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">TypeError: a() takes exactly <span class="number">0</span> arguments (<span class="number">2</span> given)</span><br></pre></td></tr></table></figure>
<h2 id="4-farg1"><a class="markdownIt-Anchor" href="#4-farg1"></a> 4. F(**arg1)</h2>
<p>形参名前加俩个*表示，参数在函数内部将被存放在以形式名为标识符的dictionary中，这时调用函数的方法则需要采用arg1=value1,arg2=value2这样的形式。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">a</span>(<span class="params">**x</span>):<span class="keyword">if</span> <span class="built_in">len</span>(x)==<span class="number">0</span>:<span class="built_in">print</span> <span class="string">&#x27;None&#x27;</span><span class="keyword">else</span>:<span class="built_in">print</span> x  &gt;&gt;&gt; a()<span class="literal">None</span>&gt;&gt;&gt; a(x=<span class="number">1</span>,y=<span class="number">2</span>)&#123;<span class="string">&#x27;y&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;x&#x27;</span>: <span class="number">1</span>&#125;      <span class="comment">#存放在字典中&gt;&gt;&gt; a(1,2)            #这种调用则报错Traceback (most recent call last):</span></span><br><span class="line">File <span class="string">&quot;&lt;pyshell#25&gt;&quot;</span>, line <span class="number">1</span>, <span class="keyword">in</span> -toplevel-</span><br><span class="line">a(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">TypeError: a() takes exactly <span class="number">0</span> arguments (<span class="number">2</span> given)</span><br></pre></td></tr></table></figure>
<p>上面介绍了四种定义方式，接下来看函数参数在调用过程中是怎么被解析的,其实只要记住上面这四种方法优先级依次降低，先1，后2，再3，最后4，也就是先把方式1中的arg解析，然后解析方式2中的arg=value，再解析方式3，即是把多出来的arg这种形式的实参组成个tuple传进去，最后把剩下的key=value这种形式的实参组成一个dictionary传给带俩个星号的形参，也就方式4。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">test</span>(<span class="params">x,y=<span class="number">1</span>,*a,**b</span>):</span><br><span class="line">    <span class="built_in">print</span> x,y,a,b</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>test(<span class="number">1</span>)</span><br><span class="line"><span class="number">1</span> <span class="number">1</span> () &#123;&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>test(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line"><span class="number">1</span> <span class="number">2</span> () &#123;&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>test(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line"><span class="number">1</span> <span class="number">2</span> (<span class="number">3</span>,) &#123;&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>test(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line"><span class="number">1</span> <span class="number">2</span> (<span class="number">3</span>, <span class="number">4</span>) &#123;&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>test(x=<span class="number">1</span>,y=<span class="number">2</span>)</span><br><span class="line"><span class="number">1</span> <span class="number">2</span> () &#123;&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>test(<span class="number">1</span>,a=<span class="number">2</span>)</span><br><span class="line"><span class="number">1</span> <span class="number">1</span> () &#123;<span class="string">&#x27;a&#x27;</span>: <span class="number">2</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>test(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,a=<span class="number">4</span>)</span><br><span class="line"><span class="number">1</span> <span class="number">2</span> (<span class="number">3</span>,) &#123;<span class="string">&#x27;a&#x27;</span>: <span class="number">4</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>test(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,y=<span class="number">4</span>)</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">File <span class="string">&quot;&lt;pyshell#52&gt;&quot;</span>, line <span class="number">1</span>, <span class="keyword">in</span> -toplevel-</span><br><span class="line">test(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,y=<span class="number">4</span>)</span><br><span class="line">TypeError: test() got multiple values <span class="keyword">for</span> keyword argument <span class="string">&#x27;y&#x27;</span></span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>第一把Pytorch实现LSTM经验总结</title>
    <url>/2018/03/26/pytorch-first-lstm/</url>
    <content><![CDATA[<h2 id="lstm模型简介"><a class="markdownIt-Anchor" href="#lstm模型简介"></a> LSTM模型简介</h2>
<h3 id="整体认识"><a class="markdownIt-Anchor" href="#整体认识"></a> 整体认识：</h3>
<ul>
<li>
<p>下图是LSTM模型的基本“细胞”，在处理一个句子时，每个单词都对应一个“细胞”。</p>
<img data-src="/2018/03/26/pytorch-first-lstm/LSTM3-chain.png" class title="The repeating module in an LSTM contains four interacting layers">
<img data-src="/2018/03/26/pytorch-first-lstm/LSTM2-notation.png" class title="Notion used above">
<span id="more"></span>
<h3 id="具体意义"><a class="markdownIt-Anchor" href="#具体意义"></a> 具体意义：</h3>
</li>
<li>
<p>贯穿 $$C_{t-1}$$ 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">C_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的一条线中包含的信息是连贯的全文/句中蕴含的信息，可以理解为主干内容。</p>
<img data-src="/2018/03/26/pytorch-first-lstm/LSTM3-C-line.png" class>
</li>
<li>
<p>LSTM 和普通 RNN 相比, 多出了三个控制器. (输入控制, 输出控制, 忘记控制)</p>
<img data-src="/2018/03/26/pytorch-first-lstm/LSTM3-focus-f.png" class title="忘记控制，把已经不重要的信息过滤掉">
<img data-src="/2018/03/26/pytorch-first-lstm/LSTM3-focus-i.png" class title="输入控制，把有价值的信息放到主干中">
<img data-src="/2018/03/26/pytorch-first-lstm/LSTM3-focus-o.png" class title="输出控制，把本节点和主干中的重要信息输出">
</li>
<li>
<p>更详细的内容请参见：<a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">LSTM始祖级博客</a></p>
</li>
<li>
<p>LSTM有两种 Input-&gt;Output 模式，一种是一对一，一种是多对一，如下图:</p>
<img data-src="/2018/03/26/pytorch-first-lstm/LSTM_many_to_one_many_to_many.jpg" class title="LSTM Paterns">
<p>其中，这里的“多”和“一”指的是输入和输出节点。输入节点在我们这个例子中意味着一句话的几个单词，每个单词都会输出一个hidden层的TensorFlow，而如果我们把每个Tensor都考虑再后续的层中，比如在给句子中的每个单词标注词性的时候，那么就是“多”个单词 -&gt; “多”个输出（打上的标签）；而像是句子分类情况下，就是“多”个单词 -&gt; “一”个输出（句子的具体分类）。</p>
</li>
</ul>
<h2 id="采坑笔记实践"><a class="markdownIt-Anchor" href="#采坑笔记实践"></a> 采坑笔记（实践）</h2>
<ul>
<li>
<p>送入DataLoader中的数据一定要是numpy数组，不能是list</p>
</li>
<li>
<p>进入DataLoader中的数据如果有好几层，必须保证每一层都是list不能是numpy。如一个三层数组，最内层inner是np.array，则要做的操作是：np.array(list[list[list(inner), …],…])，否则会报各种奇怪的错误</p>
</li>
<li>
<p>计算loss的criterion中的各个output、label等必须是autograd.Variable变量而不是torch.tensor类型</p>
</li>
<li>
<p>nn.CrossEntropyLoss(output, labels)中的labels的类型必须是torch.LongTensor而不是torch.FloatTensor</p>
</li>
<li>
<p>读取数据最好还是老老实实用Dataloader，否则还是同样的，数据格式可能会出意想不到的错误</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Beibei</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, trainData, train_num, test_num, train=<span class="literal">True</span></span>):</span><br><span class="line">        self.train = train</span><br><span class="line">        self.train_num = train_num</span><br><span class="line">        self.test_num = test_num</span><br><span class="line">        <span class="keyword">if</span> self.train:</span><br><span class="line">            self.train_data = trainData[:train_num]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.test_data = trainData[train_num:train_num+test_num]</span><br><span class="line">            </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="keyword">if</span> self.train:</span><br><span class="line">            sentence, label = self.train_data[index]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            sentence, label = self.test_data[index]</span><br><span class="line">        send2word = get_wordvecs(sentence=sentence)</span><br><span class="line">        <span class="keyword">return</span> send2word, label</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">if</span> self.train:</span><br><span class="line">            <span class="keyword">return</span> self.train_num</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> self.test_num</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>注意在一个cell里面定义了函数，有时候会顺便再同一个cell里面定义了一把随意的输入数据测试一把，但是千万记住不要把函数的输入形参搞成了你定义的那个测试量，否则会在暗地里炸的体无完肤</p>
</li>
<li>
<p>数据需要处理的部分最好放在Dataset的类里面返回值处处理，这样会节省空间和内存。如果把这些预处理提前一次性做了，尤其是Word2Vec这种操作，会吃掉大量内存</p>
</li>
<li>
<p>loss.backward(retain_variables=True)#retain_graph=True)的作用：</p>
</li>
</ul>
<blockquote>
<p>After <code>loss.backward</code> you cannot do another <code>loss.backward</code> unless <code>retain_variables</code> is true.</p>
<p>In plain words, the backward proc will consume the intermediate saved Tensors (Variables) used for backpropagation unless you explicitly tell PyTorch to retain them.</p>
</blockquote>
<ul>
<li>由上述解答可知，retain_variables=True语句确保了用于计算后向传播的中间变量不会在计算中被销毁。</li>
<li>又由下可知，目前最好使用的方式是retain_graph=True</li>
</ul>
<blockquote>
<p>It is essentially the same, <code>retain_variables</code> argument has been deprecated in favor of <code>retain_graph</code>.</p>
</blockquote>
<ul>
<li>
<p>当batch参数放在第一个时，欲得到一个batch中每个句子的预测中最相近的一个值和其对应的序号：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">values, indices = torch.<span class="built_in">max</span>(tensor, <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>LSTM在pytorch中的输入输出信息的顺序是：(sentence,batch,word2vec)这样不太自然，用下列写法可以更正至(batch,sentence,word2vec)：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="我的代码实现"><a class="markdownIt-Anchor" href="#我的代码实现"></a> 我的代码实现：</h2>
<h3 id="many-to-one"><a class="markdownIt-Anchor" href="#many-to-one"></a> Many to One</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.autograd</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> torch.nn.init <span class="keyword">as</span> init</span><br><span class="line">torch.manual_seed(<span class="number">233</span>)</span><br><span class="line">random.seed(<span class="number">233</span>)</span><br><span class="line">np.random.seed(<span class="number">233</span>)</span><br><span class="line">EMBEDDING_DIM = <span class="number">200</span></span><br><span class="line">HIDDEN_DIM    = <span class="number">640</span></span><br><span class="line">BATCH_SIZE    = <span class="number">256</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Neural Networks model : LSTM</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LSTM</span>(nn.Module):</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, embedding_dim, hidden_dim, tagset_size</span>):</span><br><span class="line">        <span class="built_in">super</span>(LSTM, self).__init__()</span><br><span class="line">        self.hidden_dim = hidden_dim</span><br><span class="line">        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=<span class="literal">False</span>)</span><br><span class="line">        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)</span><br><span class="line">        self.hidden = self.init_hidden()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_hidden</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> (Variable(torch.zeros(<span class="number">1</span>, <span class="number">20</span>, self.hidden_dim)),</span><br><span class="line">                Variable(torch.zeros(<span class="number">1</span>, <span class="number">20</span>, self.hidden_dim)))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, wordvecs</span>):</span><br><span class="line">        lstm_out, self.hidden = self.lstm(wordvecs, self.hidden)</span><br><span class="line">        tag_space = self.hidden2tag(lstm_out[:,-<span class="number">1</span>,:])</span><br><span class="line">        tag_scores = F.softmax(tag_space)</span><br><span class="line">        self.hidden = self.init_hidden()</span><br><span class="line">        <span class="keyword">return</span> tag_scores</span><br></pre></td></tr></table></figure>
<h3 id="many-to-many"><a class="markdownIt-Anchor" href="#many-to-many"></a> Many to many</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.autograd</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> torch.nn.init <span class="keyword">as</span> init</span><br><span class="line">torch.manual_seed(<span class="number">233</span>)</span><br><span class="line">random.seed(<span class="number">233</span>)</span><br><span class="line">np.random.seed(<span class="number">233</span>)</span><br><span class="line">EMBEDDING_DIM = <span class="number">200</span></span><br><span class="line">HIDDEN_DIM    = <span class="number">640</span></span><br><span class="line">BATCH_SIZE    = <span class="number">256</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Neural Networks model : LSTM</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LSTM</span>(nn.Module):</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, embedding_dim, hidden_dim, tagset_size</span>):</span><br><span class="line">        <span class="built_in">super</span>(LSTM, self).__init__()</span><br><span class="line">        self.hidden_dim = hidden_dim</span><br><span class="line">        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=<span class="literal">False</span>)</span><br><span class="line">        self.hidden2tag = nn.Linear(hidden_dim*<span class="number">20</span>, tagset_size)</span><br><span class="line">        self.hidden = self.init_hidden()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_hidden</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> (Variable(torch.zeros(<span class="number">1</span>, <span class="number">20</span>, self.hidden_dim)),</span><br><span class="line">                Variable(torch.zeros(<span class="number">1</span>, <span class="number">20</span>, self.hidden_dim)))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, wordvecs</span>):</span><br><span class="line">        lstm_out, self.hidden = self.lstm(wordvecs, self.hidden)</span><br><span class="line">        tag_space = self.hidden2tag(lstm_out.view(-<span class="number">1</span>, self.hidden_dim*<span class="number">20</span>))</span><br><span class="line">        tag_scores = F.softmax(tag_space)</span><br><span class="line">        self.hidden = self.init_hidden()</span><br><span class="line">        <span class="keyword">return</span> tag_scores</span><br></pre></td></tr></table></figure>
<p>两者最大的差别在于在lstm的输出之后是取output[:,-1,:]，即截取一句话的最后一个节点的Hidden层的输出（Many to One），还是要所有的输出，即output.view(-1, self.hidden_dim*20)，把batch的维度和sentence的维度打平，把两维降到一维。</p>
]]></content>
      <tags>
        <tag>machine-learning</tag>
        <tag>pytorch</tag>
        <tag>lstm</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch Lighting 完全攻略</title>
    <url>/2021/03/11/pytorch-lightning/</url>
    <content><![CDATA[<h2 id="写在前面"><a class="markdownIt-Anchor" href="#写在前面"></a> 写在前面</h2>
<p>Pytorch-Lightning这个库我“发现”过两次。第一次发现时，感觉它很重很难学，而且似乎自己也用不上。但是后面随着做的项目开始出现了一些稍微高阶的要求，我发现我总是不断地在相似工程代码上花费大量时间，Debug也是这些代码花的时间最多，而且渐渐产生了一个矛盾之处：如果想要更多更好的功能，如TensorBoard支持，Early Stop，LR Scheduler，分布式训练，快速测试等，代码就无可避免地变得越来越长，看起来也越来越乱，同时核心的训练逻辑也渐渐被这些工程代码盖过。那么有没有更好的解决方案，甚至能一键解决所有这些问题呢？</p>
<span id="more"></span>
<p>于是我第二次发现了Pytorch-Lightning。</p>
<p>真香。</p>
<p>但是问题还是来了。这个框架并没有因为香而变得更加易学。官网的教程很丰富，可以看出来开发者们在努力做了。但是很多相连的知识点都被分布在了不同的版块里，还有一些核心的理解要点并没有被强调出来，而是小字带过，这让我想做一个普惠的教程，包含所有我在学习过程中认为重要的概念，好用的参数，一些注意点、坑点，大量的示例代码段和一些核心问题的集中讲解。</p>
<p>最后，第三部分提供了一个我总结出来的易用于大型项目、容易迁移、易于复用的模板，有兴趣的可以去<a href="https://github.com/miracleyoo/pytorch-lightning-template">GitHub</a>试用。</p>
<h2 id="crucial"><a class="markdownIt-Anchor" href="#crucial"></a> Crucial</h2>
<ul>
<li>
<p>Pytorch-Lighting 的一大特点是把模型和系统分开来看。模型是像Resnet18， RNN之类的纯模型， 而系统定义了一组模型如何相互交互，如GAN（生成器网络与判别器网络）、Seq2Seq（Encoder与Decoder网络）和Bert。同时，有时候问题只涉及一个模型，那么这个系统则可以是一个通用的系统，用于描述模型如何使用，并可以被复用到很多其他项目。</p>
</li>
<li>
<p>Pytorch-Lighting 的核心设计思想是“自给自足”。每个网络也同时包含了如何训练、如何测试、优化器定义等内容。</p>
</li>
</ul>
<p><img data-src="plres.png" alt="img"></p>
<h2 id="推荐使用方法"><a class="markdownIt-Anchor" href="#推荐使用方法"></a> 推荐使用方法</h2>
<p>这一部分放在最前面，因为全文内容太长，如果放后面容易忽略掉这部分精华。</p>
<p>Pytorch-Lightning 是一个很好的库，或者说是pytorch的抽象和包装。它的好处是可复用性强，易维护，逻辑清晰等。缺点也很明显，这个包需要学习和理解的内容还是挺多的，或者换句话说，很重。如果直接按照官方的模板写代码，小型project还好，如果是大型项目，有复数个需要调试验证的模型和数据集，那就不太好办，甚至更加麻烦了。经过几天的摸索和调试，我总结出了下面这样一套好用的模板，也可以说是对Pytorch-Lightning的进一步抽象。</p>
<p>欢迎大家尝试这一套代码风格，如果用习惯的话还是相当方便复用的，也不容易半道退坑。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root-</span><br><span class="line">	|-data</span><br><span class="line">		|-__init__.py</span><br><span class="line">		|-data_interface.py</span><br><span class="line">		|-xxxdataset1.py</span><br><span class="line">		|-xxxdataset2.py</span><br><span class="line">		|-...</span><br><span class="line">	|-model</span><br><span class="line">		|-__init__.py</span><br><span class="line">		|-model_interface.py</span><br><span class="line">		|-xxxmodel1.py</span><br><span class="line">		|-xxxmodel2.py</span><br><span class="line">		|-...</span><br><span class="line">	|-main.py	</span><br></pre></td></tr></table></figure>
<p>如果对每个模型直接上plmodule，对于已有项目、别人的代码等的转换将相当耗时。另外，这样的话，你需要给每个模型都加上一些相似的代码，如<code>training_step</code>，<code>validation_step</code>。显然，这并不是我们想要的，如果真的这样做，不但不易于维护，反而可能会更加杂乱。同理，如果把每个数据集类都直接转换成pl的DataModule，也会面临相似的问题。基于这样的考量，我建议使用上述架构：</p>
<ul>
<li>
<p>主目录下只放一个<code>main.py</code>文件。</p>
</li>
<li>
<p><code>data</code>和<code>modle</code>两个文件夹中放入<code>__init__.py</code>文件，做成包。这样方便导入。两个<code>init</code>文件分别是：</p>
<ul>
<li><code>from .data_interface import DInterface</code></li>
<li><code>from .model_interface import MInterface</code></li>
</ul>
</li>
<li>
<p>在<code>data_interface </code>中建立一个<code>class DInterface(pl.LightningDataModule):</code>用作所有数据集文件的接口。<code>__init__()</code>函数中import相应Dataset类，<code>setup()</code>进行实例化，并老老实实加入所需要的的<code>train_dataloader</code>, <code>val_dataloader</code>, <code>test_dataloader</code>函数。这些函数往往都是相似的，可以用几个输入args控制不同的部分。</p>
</li>
<li>
<p>同理，在<code>model_interface </code>中建立<code>class MInterface(pl.LightningModule):</code>类，作为模型的中间接口。<code>__init__()</code>函数中import相应模型类，然后老老实实加入<code>configure_optimizers</code>, <code>training_step</code>, <code>validation_step</code>等函数，用一个接口类控制所有模型。不同部分使用输入参数控制。</p>
</li>
<li>
<p><code>main.py</code>函数只负责：</p>
<ul>
<li>定义parser，添加parse项。</li>
<li>选好需要的<code>callback</code>函数们。</li>
<li>实例化<code>MInterface</code>, <code>DInterface</code>, <code>Trainer</code>。</li>
</ul>
<p>完事。</p>
</li>
</ul>
<h2 id="lightning-module"><a class="markdownIt-Anchor" href="#lightning-module"></a> Lightning Module</h2>
<h3 id="简介"><a class="markdownIt-Anchor" href="#简介"></a> 简介</h3>
<p><a href="https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html">主页面</a></p>
<ul>
<li>
<p>三个核心组件：</p>
<ul>
<li>模型</li>
<li>优化器</li>
<li>Train/Val/Test步骤</li>
</ul>
</li>
<li>
<p>数据流伪代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">outs = []</span><br><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> data:</span><br><span class="line">    out = training_step(batch)</span><br><span class="line">    outs.append(out)</span><br><span class="line">training_epoch_end(outs)</span><br></pre></td></tr></table></figure>
<p>等价Lightning代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">training_step</span>(<span class="params">self, batch, batch_idx</span>):</span><br><span class="line">    prediction = ...</span><br><span class="line">    <span class="keyword">return</span> prediction</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">training_epoch_end</span>(<span class="params">self, training_step_outputs</span>):</span><br><span class="line">    <span class="keyword">for</span> prediction <span class="keyword">in</span> predictions:</span><br><span class="line">        <span class="comment"># do something with these</span></span><br></pre></td></tr></table></figure>
<p>我们需要做的，就是像填空一样，填这些函数。</p>
</li>
</ul>
<h3 id="组件与函数"><a class="markdownIt-Anchor" href="#组件与函数"></a> 组件与函数</h3>
<p><a href="https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html#lightningmodule-api">API页面</a></p>
<ul>
<li>
<p>一个Pytorch-Lighting 模型必须含有的部件是：</p>
<ul>
<li>
<p><code>init</code>: 初始化，包括模型和系统的定义。</p>
</li>
<li>
<p><a href="https://pytorch-lightning.readthedocs.io/en/latest/api/pytorch_lightning.core.lightning.html#pytorch_lightning.core.lightning.LightningModule.training_step"><code>training_step(self, batch, batch_idx)</code></a>: 即每个batch的处理函数。</p>
<blockquote>
<p>参数：</p>
<ul>
<li><strong>batch</strong> (<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor"><code>Tensor</code></a> | (<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor"><code>Tensor</code></a>, …) | [<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor"><code>Tensor</code></a>, …]) – The output of your <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader"><code>DataLoader</code></a>. A tensor, tuple or list.</li>
<li><strong>batch_idx</strong> (<a href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a>) – Integer displaying index of this batch</li>
<li><strong>optimizer_idx</strong> (<a href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a>) – When using multiple optimizers, this argument will also be present.</li>
<li><strong>hiddens</strong> (<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor"><code>Tensor</code></a>) – Passed in if <a href="https://pytorch-lightning.readthedocs.io/en/latest/api/pytorch_lightning.trainer.trainer.html#pytorch_lightning.trainer.trainer.Trainer.params.truncated_bptt_steps"><code>truncated_bptt_steps</code></a> &gt; 0.</li>
</ul>
<p>返回值：Any of.</p>
<ul>
<li><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor"><code>Tensor</code></a> - The loss tensor</li>
<li><code>dict</code> - A dictionary. Can include any keys, but must include the key <code>'loss'</code></li>
<li><code>None</code> - Training will skip to the next batch</li>
</ul>
</blockquote>
<p>返回值无论如何也需要有一个loss量。如果是字典，要有这个key。没loss这个batch就被跳过了。例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">training_step</span>(<span class="params">self, batch, batch_idx</span>):</span><br><span class="line">    x, y, z = batch</span><br><span class="line">    out = self.encoder(x)</span><br><span class="line">    loss = self.loss(out, x)</span><br><span class="line">    <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"><span class="comment"># Multiple optimizers (e.g.: GANs)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">training_step</span>(<span class="params">self, batch, batch_idx, optimizer_idx</span>):</span><br><span class="line">    <span class="keyword">if</span> optimizer_idx == <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># do training_step with encoder</span></span><br><span class="line">    <span class="keyword">if</span> optimizer_idx == <span class="number">1</span>:</span><br><span class="line">        <span class="comment"># do training_step with decoder</span></span><br><span class="line">        </span><br><span class="line"><span class="comment"># Truncated back-propagation through time</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">training_step</span>(<span class="params">self, batch, batch_idx, hiddens</span>):</span><br><span class="line">    <span class="comment"># hiddens are the hidden states from the previous truncated backprop step</span></span><br><span class="line">    ...</span><br><span class="line">    out, hiddens = self.lstm(data, hiddens)</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&#x27;loss&#x27;</span>: loss, <span class="string">&#x27;hiddens&#x27;</span>: hiddens&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><a href="https://pytorch-lightning.readthedocs.io/en/latest/common/optimizers.html#automatic-optimization"><code>configure_optimizers</code></a>: 优化器定义，返回一个优化器，或数个优化器，或两个List（优化器，Scheduler）。如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># most cases</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">configure_optimizers</span>(<span class="params">self</span>):</span><br><span class="line">    opt = Adam(self.parameters(), lr=<span class="number">1e-3</span>)</span><br><span class="line">    <span class="keyword">return</span> opt</span><br><span class="line"></span><br><span class="line"><span class="comment"># multiple optimizer case (e.g.: GAN)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">configure_optimizers</span>(<span class="params">self</span>):</span><br><span class="line">    generator_opt = Adam(self.model_gen.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line">    disriminator_opt = Adam(self.model_disc.parameters(), lr=<span class="number">0.02</span>)</span><br><span class="line">    <span class="keyword">return</span> generator_opt, disriminator_opt</span><br><span class="line"></span><br><span class="line"><span class="comment"># example with learning rate schedulers</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">configure_optimizers</span>(<span class="params">self</span>):</span><br><span class="line">    generator_opt = Adam(self.model_gen.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line">    disriminator_opt = Adam(self.model_disc.parameters(), lr=<span class="number">0.02</span>)</span><br><span class="line">    discriminator_sched = CosineAnnealing(discriminator_opt, T_max=<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">return</span> [generator_opt, disriminator_opt], [discriminator_sched]</span><br><span class="line"></span><br><span class="line"><span class="comment"># example with step-based learning rate schedulers</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">configure_optimizers</span>(<span class="params">self</span>):</span><br><span class="line">    gen_opt = Adam(self.model_gen.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line">    dis_opt = Adam(self.model_disc.parameters(), lr=<span class="number">0.02</span>)</span><br><span class="line">    gen_sched = &#123;<span class="string">&#x27;scheduler&#x27;</span>: ExponentialLR(gen_opt, <span class="number">0.99</span>),</span><br><span class="line">                 <span class="string">&#x27;interval&#x27;</span>: <span class="string">&#x27;step&#x27;</span>&#125;  <span class="comment"># called after each training step</span></span><br><span class="line">    dis_sched = CosineAnnealing(discriminator_opt, T_max=<span class="number">10</span>) <span class="comment"># called every epoch</span></span><br><span class="line">    <span class="keyword">return</span> [gen_opt, dis_opt], [gen_sched, dis_sched]</span><br><span class="line"></span><br><span class="line"><span class="comment"># example with optimizer frequencies</span></span><br><span class="line"><span class="comment"># see training procedure in `Improved Training of Wasserstein GANs`, Algorithm 1</span></span><br><span class="line"><span class="comment"># https://arxiv.org/abs/1704.00028</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">configure_optimizers</span>(<span class="params">self</span>):</span><br><span class="line">    gen_opt = Adam(self.model_gen.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line">    dis_opt = Adam(self.model_disc.parameters(), lr=<span class="number">0.02</span>)</span><br><span class="line">    n_critic = <span class="number">5</span></span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">        &#123;<span class="string">&#x27;optimizer&#x27;</span>: dis_opt, <span class="string">&#x27;frequency&#x27;</span>: n_critic&#125;,</span><br><span class="line">        &#123;<span class="string">&#x27;optimizer&#x27;</span>: gen_opt, <span class="string">&#x27;frequency&#x27;</span>: <span class="number">1</span>&#125;</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li>
<p>可以指定的部件有：</p>
<ul>
<li><code>forward</code>: 和正常的<code>nn.Module</code>一样，用于inference。内部调用时：<code>y=self(batch)</code></li>
<li><code>training_step_end</code>: 只在使用多个node进行训练且结果涉及如softmax之类需要全部输出联合运算的步骤时使用该函数。同理，<code>validation_step_end</code>/<code>test_step_end</code>。</li>
<li><code>training_epoch_end</code>:
<ul>
<li>在一个训练epoch结尾处被调用。</li>
<li>输入参数：一个List，List的内容是前面<code>training_step()</code>所返回的每次的内容。</li>
<li>返回：None</li>
</ul>
</li>
<li><code>validation_step(self, batch, batch_idx)</code>/<code>test_step(self, batch, batch_idx)</code>:
<ul>
<li>没有返回值限制，不一定非要输出一个<code>val_loss</code>。</li>
</ul>
</li>
<li><code>validation_epoch_end</code>/<code>test_epoch_end</code>:</li>
</ul>
</li>
<li>
<p>工具函数有：</p>
<ul>
<li>
<p><code>freeze</code>：冻结所有权重以供预测时候使用。仅当已经训练完成且后面只测试时使用。</p>
</li>
<li>
<p><code>print</code>：尽管自带的<code>print</code>函数也可以使用，但如果程序运行在分布式系统时，会打印多次。而使用<code>self.print()</code>则只会打印一次。</p>
</li>
<li>
<p><code>log</code>：像是TensorBoard等log记录器，对于每个log的标量，都会有一个相对应的横坐标，它可能是batch number或epoch number。而<code>on_step</code>就表示把这个log出去的量的横坐标表示为当前batch，而<code>on_epoch</code>则表示将log的量在整个epoch上进行累积后log，横坐标为当前epoch。</p>
<table>
<thead>
<tr>
<th>LightningMoule Hook</th>
<th>on_step</th>
<th>on_epoch</th>
<th>prog_bar</th>
<th>logger</th>
</tr>
</thead>
<tbody>
<tr>
<td>training_step</td>
<td>T</td>
<td>F</td>
<td>F</td>
<td>T</td>
</tr>
<tr>
<td>training_step_end</td>
<td>T</td>
<td>F</td>
<td>F</td>
<td>T</td>
</tr>
<tr>
<td>training_epoch_end</td>
<td>F</td>
<td>T</td>
<td>F</td>
<td>T</td>
</tr>
<tr>
<td>validation_step*</td>
<td>F</td>
<td>T</td>
<td>F</td>
<td>T</td>
</tr>
<tr>
<td>validation_step_end*</td>
<td>F</td>
<td>T</td>
<td>F</td>
<td>T</td>
</tr>
<tr>
<td>validation_epoch_end*</td>
<td>F</td>
<td>T</td>
<td>F</td>
<td>T</td>
</tr>
</tbody>
</table>
<p><code>*</code> also applies to the test loop</p>
<blockquote>
<p>参数</p>
<ul>
<li><strong>name</strong> (<a href="https://docs.python.org/3/library/stdtypes.html#str"><code>str</code></a>) – key name</li>
<li><strong>value</strong> (<a href="https://docs.python.org/3/library/typing.html#typing.Any"><code>Any</code></a>) – value name</li>
<li><strong>prog_bar</strong> (<a href="https://docs.python.org/3/library/functions.html#bool"><code>bool</code></a>) – if True logs to the progress bar</li>
<li><strong>logger</strong> (<a href="https://docs.python.org/3/library/functions.html#bool"><code>bool</code></a>) – if True logs to the logger</li>
<li><strong>on_step</strong> (<a href="https://docs.python.org/3/library/typing.html#typing.Optional"><code>Optional</code></a>[<a href="https://docs.python.org/3/library/functions.html#bool"><code>bool</code></a>]) – if True logs at this step. None auto-logs at the training_step but not validation/test_step</li>
<li><strong>on_epoch</strong> (<a href="https://docs.python.org/3/library/typing.html#typing.Optional"><code>Optional</code></a>[<a href="https://docs.python.org/3/library/functions.html#bool"><code>bool</code></a>]) – if True logs epoch accumulated metrics. None auto-logs at the val/test step but not training_step</li>
<li><strong>reduce_fx</strong> (<a href="https://docs.python.org/3/library/typing.html#typing.Callable"><code>Callable</code></a>) – reduction function over step values for end of epoch. Torch.mean by default</li>
<li><strong>tbptt_reduce_fx</strong> (<a href="https://docs.python.org/3/library/typing.html#typing.Callable"><code>Callable</code></a>) – function to reduce on truncated back prop</li>
<li><strong>tbptt_pad_token</strong> (<a href="https://docs.python.org/3/library/functions.html#int"><code>int</code></a>) – token to use for padding</li>
<li><strong>enable_graph</strong> (<a href="https://docs.python.org/3/library/functions.html#bool"><code>bool</code></a>) – if True, will not auto detach the graph</li>
<li><strong>sync_dist</strong> (<a href="https://docs.python.org/3/library/functions.html#bool"><code>bool</code></a>) – if True, reduces the metric across GPUs/TPUs</li>
<li><strong>sync_dist_op</strong> (<a href="https://docs.python.org/3/library/typing.html#typing.Union"><code>Union</code></a>[<a href="https://docs.python.org/3/library/typing.html#typing.Any"><code>Any</code></a>, <a href="https://docs.python.org/3/library/stdtypes.html#str"><code>str</code></a>]) – the op to sync across GPUs/TPUs</li>
<li><strong>sync_dist_group</strong> (<a href="https://docs.python.org/3/library/typing.html#typing.Optional"><code>Optional</code></a>[<a href="https://docs.python.org/3/library/typing.html#typing.Any"><code>Any</code></a>]) – the ddp group</li>
</ul>
</blockquote>
</li>
<li>
<p><code>log_dict</code>：和<code>log</code>函数唯一的区别就是，<code>name</code>和<code>value</code>变量由一个字典替换。表示同时log多个值。如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">values = &#123;<span class="string">&#x27;loss&#x27;</span>: loss, <span class="string">&#x27;acc&#x27;</span>: acc, ..., <span class="string">&#x27;metric_n&#x27;</span>: metric_n&#125;</span><br><span class="line">self.log_dict(values)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><code>save_hyperparameters</code>：储存<code>init</code>中输入的所有超参。后续访问可以由<code>self.hparams.argX</code>方式进行。同时，超参表也会被存到文件中。</p>
</li>
</ul>
</li>
<li>
<p>函数内建变量：</p>
<ul>
<li><code>device</code>：可以使用<code>self.device</code>来构建设备无关型tensor。如：<code>z = torch.rand(2, 3, device=self.device)</code>。</li>
<li><code>hparams</code>：含有所有前面存下来的输入超参。</li>
<li><code>precision</code>：精确度。常见32和16。</li>
</ul>
</li>
</ul>
<h3 id="要点"><a class="markdownIt-Anchor" href="#要点"></a> 要点</h3>
<ul>
<li>如果准备使用DataParallel，在写<code>training_step</code>的时候需要调用forward函数，<code>z=self(x)</code></li>
</ul>
<h3 id="模板"><a class="markdownIt-Anchor" href="#模板"></a> 模板</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LitModel</span>(pl.LightningModule):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">...</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">...</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">training_step</span>(<span class="params">...</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">training_step_end</span>(<span class="params">...</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">training_epoch_end</span>(<span class="params">...</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">validation_step</span>(<span class="params">...</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">validation_step_end</span>(<span class="params">...</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">validation_epoch_end</span>(<span class="params">...</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_step</span>(<span class="params">...</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_step_end</span>(<span class="params">...</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_epoch_end</span>(<span class="params">...</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">configure_optimizers</span>(<span class="params">...</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">any_extra_hook</span>(<span class="params">...</span>)</span><br></pre></td></tr></table></figure>
<h2 id="trainer"><a class="markdownIt-Anchor" href="#trainer"></a> Trainer</h2>
<h3 id="基础使用"><a class="markdownIt-Anchor" href="#基础使用"></a> 基础使用</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = MyLightningModule()</span><br><span class="line"></span><br><span class="line">trainer = Trainer()</span><br><span class="line">trainer.fit(model, train_dataloader, val_dataloader)</span><br></pre></td></tr></table></figure>
<p>如果连<code>validation_step</code>都没有，那<code>val_dataloader</code>也就算了。</p>
<h3 id="伪代码与hooks"><a class="markdownIt-Anchor" href="#伪代码与hooks"></a> 伪代码与hooks</h3>
<p><a href="https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html#hooks">Hooks页面</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">...</span>):</span><br><span class="line">    on_fit_start()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> global_rank == <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># prepare data is called on GLOBAL_ZERO only</span></span><br><span class="line">        prepare_data()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> gpu/tpu <span class="keyword">in</span> gpu/tpus:</span><br><span class="line">        train_on_device(model.copy())</span><br><span class="line"></span><br><span class="line">    on_fit_end()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_on_device</span>(<span class="params">model</span>):</span><br><span class="line">    <span class="comment"># setup is called PER DEVICE</span></span><br><span class="line">    setup()</span><br><span class="line">    configure_optimizers()</span><br><span class="line">    on_pretrain_routine_start()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> epochs:</span><br><span class="line">        train_loop()</span><br><span class="line"></span><br><span class="line">    teardown()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_loop</span>():</span><br><span class="line">    on_train_epoch_start()</span><br><span class="line">    train_outs = []</span><br><span class="line">    <span class="keyword">for</span> train_batch <span class="keyword">in</span> train_dataloader():</span><br><span class="line">        on_train_batch_start()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ----- train_step methods -------</span></span><br><span class="line">        out = training_step(batch)</span><br><span class="line">        train_outs.append(out)</span><br><span class="line"></span><br><span class="line">        loss = out.loss</span><br><span class="line"></span><br><span class="line">        backward()</span><br><span class="line">        on_after_backward()</span><br><span class="line">        optimizer_step()</span><br><span class="line">        on_before_zero_grad()</span><br><span class="line">        optimizer_zero_grad()</span><br><span class="line"></span><br><span class="line">        on_train_batch_end(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> should_check_val:</span><br><span class="line">            val_loop()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># end training epoch</span></span><br><span class="line">    logs = training_epoch_end(outs)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">val_loop</span>():</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    torch.set_grad_enabled(<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    on_validation_epoch_start()</span><br><span class="line">    val_outs = []</span><br><span class="line">    <span class="keyword">for</span> val_batch <span class="keyword">in</span> val_dataloader():</span><br><span class="line">        on_validation_batch_start()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># -------- val step methods -------</span></span><br><span class="line">        out = validation_step(val_batch)</span><br><span class="line">        val_outs.append(out)</span><br><span class="line"></span><br><span class="line">        on_validation_batch_end(out)</span><br><span class="line"></span><br><span class="line">    validation_epoch_end(val_outs)</span><br><span class="line">    on_validation_epoch_end()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># set up for train</span></span><br><span class="line">    model.train()</span><br><span class="line">    torch.set_grad_enabled(<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h3 id="推荐参数"><a class="markdownIt-Anchor" href="#推荐参数"></a> 推荐参数</h3>
<p><a href="https://pytorch-lightning.readthedocs.io/en/latest/common/trainer.html#trainer-flags">参数介绍（附视频）</a></p>
<p><a href="https://pytorch-lightning.readthedocs.io/en/latest/common/trainer.html#trainer-class-api">类定义与默认参数</a></p>
<ul>
<li>
<p><code>default_root_dir</code>：默认存储地址。所有的实验变量和权重全部会被存到这个文件夹里面。推荐是，每个模型有一个独立的文件夹。每次重新训练会产生一个新的<code>version_x</code>子文件夹。</p>
</li>
<li>
<p><code>max_epochs</code>：最大训练周期数。<code>trainer = Trainer(max_epochs=1000)</code></p>
</li>
<li>
<p><code>min_epochs</code>：至少训练周期数。当有Early Stop时使用。</p>
</li>
<li>
<p><code>auto_scale_batch_size</code>：在进行任何训练前自动选择合适的batch size。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># default used by the Trainer (no scaling of batch size)</span></span><br><span class="line">trainer = Trainer(auto_scale_batch_size=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># run batch size scaling, result overrides hparams.batch_size</span></span><br><span class="line">trainer = Trainer(auto_scale_batch_size=<span class="string">&#x27;binsearch&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># call tune to find the batch size</span></span><br><span class="line">trainer.tune(model)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><code>auto_select_gpus</code>：自动选择合适的GPU。尤其是在有GPU处于独占模式时候，非常有用。</p>
</li>
<li>
<p><code>auto_lr_find</code>：自动找到合适的初始学习率。使用了该<a href="https://arxiv.org/abs/1506.01186">论文</a>的技术。当且仅当执行<code>trainer.tune(model)</code>代码时工作。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># run learning rate finder, results override hparams.learning_rate</span></span><br><span class="line">trainer = Trainer(auto_lr_find=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># run learning rate finder, results override hparams.my_lr_arg</span></span><br><span class="line">trainer = Trainer(auto_lr_find=<span class="string">&#x27;my_lr_arg&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># call tune to find the lr</span></span><br><span class="line">trainer.tune(model)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><code>precision</code>：精确度。正常是32，使用16可以减小内存消耗，增大batch。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># default used by the Trainer</span></span><br><span class="line">trainer = Trainer(precision=<span class="number">32</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 16-bit precision</span></span><br><span class="line">trainer = Trainer(precision=<span class="number">16</span>, gpus=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><code>val_check_interval</code>：进行Validation测试的周期。正常为1，训练1个epoch测试4次是0.25，每1000 batch测试一次是1000。</p>
<blockquote>
<ul>
<li>use (float) to check within a training epoch：此时这个值为一个epoch的百分比。每百分之多少测试一次。</li>
<li>use (int) to check every n steps (batches)：每多少个batch测试一次。</li>
</ul>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># default used by the Trainer</span></span><br><span class="line">trainer = Trainer(val_check_interval=<span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># check validation set 4 times during a training epoch</span></span><br><span class="line">trainer = Trainer(val_check_interval=<span class="number">0.25</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># check validation set every 1000 training batches</span></span><br><span class="line"><span class="comment"># use this when using iterableDataset and your dataset has no length</span></span><br><span class="line"><span class="comment"># (ie: production cases with streaming data)</span></span><br><span class="line">trainer = Trainer(val_check_interval=<span class="number">1000</span>)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><a href="https://pytorch-lightning.readthedocs.io/en/latest/common/trainer.html#gpus"><code>gpus</code></a>：控制使用的GPU数。当设定为None时，使用cpu。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># default used by the Trainer (ie: train on CPU)</span></span><br><span class="line">trainer = Trainer(gpus=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># equivalent</span></span><br><span class="line">trainer = Trainer(gpus=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># int: train on 2 gpus</span></span><br><span class="line">trainer = Trainer(gpus=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># list: train on GPUs 1, 4 (by bus ordering)</span></span><br><span class="line">trainer = Trainer(gpus=[<span class="number">1</span>, <span class="number">4</span>])</span><br><span class="line">trainer = Trainer(gpus=<span class="string">&#x27;1, 4&#x27;</span>) <span class="comment"># equivalent</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># -1: train on all gpus</span></span><br><span class="line">trainer = Trainer(gpus=-<span class="number">1</span>)</span><br><span class="line">trainer = Trainer(gpus=<span class="string">&#x27;-1&#x27;</span>) <span class="comment"># equivalent</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># combine with num_nodes to train on multiple GPUs across nodes</span></span><br><span class="line"><span class="comment"># uses 8 gpus in total</span></span><br><span class="line">trainer = Trainer(gpus=<span class="number">2</span>, num_nodes=<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># train only on GPUs 1 and 4 across nodes</span></span><br><span class="line">trainer = Trainer(gpus=[<span class="number">1</span>, <span class="number">4</span>], num_nodes=<span class="number">4</span>)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><a href="https://pytorch-lightning.readthedocs.io/en/latest/common/trainer.html#limit-train-batches"><code>limit_train_batches</code></a>：使用训练数据的百分比。如果数据过多，或正在调试，可以使用这个。值的范围为0~1。同样，有<code>limit_test_batches</code>，<code>limit_val_batches</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># default used by the Trainer</span></span><br><span class="line">trainer = Trainer(limit_train_batches=<span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># run through only 25% of the training set each epoch</span></span><br><span class="line">trainer = Trainer(limit_train_batches=<span class="number">0.25</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># run through only 10 batches of the training set each epoch</span></span><br><span class="line">trainer = Trainer(limit_train_batches=<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><a href="https://pytorch-lightning.readthedocs.io/en/latest/common/trainer.html#fast-dev-run"><code>fast_dev_run</code></a>：bool量。如果设定为true，会只执行一个batch的train, val 和 test，然后结束。仅用于debug。</p>
<blockquote>
<p>Setting this argument will disable tuner, checkpoint callbacks, early stopping callbacks, loggers and logger callbacks like <code>LearningRateLogger</code> and runs for only 1 epoch</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># default used by the Trainer</span></span><br><span class="line">trainer = Trainer(fast_dev_run=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># runs 1 train, val, test batch and program ends</span></span><br><span class="line">trainer = Trainer(fast_dev_run=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># runs 7 train, val, test batches and program ends</span></span><br><span class="line">trainer = Trainer(fast_dev_run=<span class="number">7</span>)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="fit函数"><a class="markdownIt-Anchor" href="#fit函数"></a> .fit()函数</h3>
<p><code>Trainer.fit(model, train_dataloader=None, val_dataloaders=None, datamodule=None)</code>：输入第一个量一定是model，然后可以跟一个LigntningDataModule或一个普通的Train DataLoader。如果定义了Val step，也要有Val DataLoader。</p>
<blockquote>
<p>参数</p>
<ul>
<li><strong>datamodule</strong> (<a href="https://docs.python.org/3/library/typing.html#typing.Optional"><code>Optional</code></a>[<a href="https://pytorch-lightning.readthedocs.io/en/latest/api/pytorch_lightning.core.datamodule.html#pytorch_lightning.core.datamodule.LightningDataModule"><code>LightningDataModule</code></a>]) – A instance of <code>LightningDataModule</code>.</li>
<li><strong>model</strong> (<a href="https://pytorch-lightning.readthedocs.io/en/latest/api/pytorch_lightning.core.lightning.html#pytorch_lightning.core.lightning.LightningModule"><code>LightningModule</code></a>) – Model to fit.</li>
<li><strong>train_dataloader</strong> (<a href="https://docs.python.org/3/library/typing.html#typing.Optional"><code>Optional</code></a>[<a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader"><code>DataLoader</code></a>]) – A Pytorch DataLoader with training samples. If the model has a predefined train_dataloader method this will be skipped.</li>
<li><strong>val_dataloaders</strong> (<a href="https://docs.python.org/3/library/typing.html#typing.Union"><code>Union</code></a>[<a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader"><code>DataLoader</code></a>, <a href="https://docs.python.org/3/library/typing.html#typing.List"><code>List</code></a>[<a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader"><code>DataLoader</code></a>], <a href="https://docs.python.org/3/library/constants.html#None"><code>None</code></a>]) – Either a single Pytorch Dataloader or a list of them, specifying validation samples. If the model has a predefined val_dataloaders method this will be skipped</li>
</ul>
</blockquote>
<h3 id="其他要点"><a class="markdownIt-Anchor" href="#其他要点"></a> 其他要点</h3>
<ul>
<li><code>.test()</code>若非直接调用，不会运行。<code>trainer.test()</code></li>
<li><code>.test()</code>会自动load最优模型。</li>
<li><code>model.eval()</code> and <code>torch.no_grad()</code> 在进行测试时会被自动调用。</li>
<li>默认情况下，<code>Trainer()</code>运行于CPU上。</li>
</ul>
<h3 id="使用样例"><a class="markdownIt-Anchor" href="#使用样例"></a> 使用样例</h3>
<ol>
<li>手动添加命令行参数：</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> argparse <span class="keyword">import</span> ArgumentParser</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">hparams</span>):</span><br><span class="line">    model = LightningModule()</span><br><span class="line">    trainer = Trainer(gpus=hparams.gpus)</span><br><span class="line">    trainer.fit(model)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    parser = ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--gpus&#x27;</span>, default=<span class="literal">None</span>)</span><br><span class="line">    args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    main(args)</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>自动添加所有<code>Trainer</code>会用到的命令行参数：</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> argparse <span class="keyword">import</span> ArgumentParser</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">args</span>):</span><br><span class="line">    model = LightningModule()</span><br><span class="line">    trainer = Trainer.from_argparse_args(args)</span><br><span class="line">    trainer.fit(model)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    parser = ArgumentParser()</span><br><span class="line">    parser = Trainer.add_argparse_args(</span><br><span class="line">        <span class="comment"># group the Trainer arguments together</span></span><br><span class="line">        parser.add_argument_group(title=<span class="string">&quot;pl.Trainer args&quot;</span>)</span><br><span class="line">    )</span><br><span class="line">    args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    main(args)</span><br></pre></td></tr></table></figure>
<ol start="3">
<li>混合式，既使用<code>Trainer</code>相关参数，又使用一些自定义参数，如各种模型超参：</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> argparse <span class="keyword">import</span> ArgumentParser</span><br><span class="line"><span class="keyword">import</span> pytorch_lightning <span class="keyword">as</span> pl</span><br><span class="line"><span class="keyword">from</span> pytorch_lightning <span class="keyword">import</span> LightningModule, Trainer</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">args</span>):</span><br><span class="line">    model = LightningModule()</span><br><span class="line">    trainer = Trainer.from_argparse_args(args)</span><br><span class="line">    trainer.fit(model)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    parser = ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--batch_size&#x27;</span>, default=<span class="number">32</span>, <span class="built_in">type</span>=<span class="built_in">int</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--hidden_dim&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">128</span>)</span><br><span class="line">    parser = Trainer.add_argparse_args(</span><br><span class="line">        <span class="comment"># group the Trainer arguments together</span></span><br><span class="line">        parser.add_argument_group(title=<span class="string">&quot;pl.Trainer args&quot;</span>)</span><br><span class="line">    )</span><br><span class="line">    args = parser.parse_args()</span><br><span class="line">	</span><br><span class="line">    main(args)</span><br></pre></td></tr></table></figure>
<h3 id="所有参数"><a class="markdownIt-Anchor" href="#所有参数"></a> 所有参数</h3>
<blockquote>
<p><code>Trainer.``__init__</code>(<em>logger=True</em>, <em>checkpoint_callback=True</em>, <em>callbacks=None</em>, <em>default_root_dir=None</em>, <em>gradient_clip_val=0</em>, <em>process_position=0</em>, <em>num_nodes=1</em>, <em>num_processes=1</em>, <em>gpus=None</em>, <em>auto_select_gpus=False</em>, <em>tpu_cores=None</em>, <em>log_gpu_memory=None</em>, <em>progress_bar_refresh_rate=None</em>, <em>overfit_batches=0.0</em>, <em>track_grad_norm=- 1</em>, <em>check_val_every_n_epoch=1</em>, <em>fast_dev_run=False</em>, <em>accumulate_grad_batches=1</em>, <em>max_epochs=None</em>, <em>min_epochs=None</em>, <em>max_steps=None</em>, <em>min_steps=None</em>, <em>limit_train_batches=1.0</em>, <em>limit_val_batches=1.0</em>, <em>limit_test_batches=1.0</em>, <em>limit_predict_batches=1.0</em>, <em>val_check_interval=1.0</em>, <em>flush_logs_every_n_steps=100</em>, <em>log_every_n_steps=50</em>, <em>accelerator=None</em>, <em>sync_batchnorm=False</em>, <em>precision=32</em>, <em>weights_summary=‘top’</em>, <em>weights_save_path=None</em>, <em>num_sanity_val_steps=2</em>, <em>truncated_bptt_steps=None</em>, <em>resume_from_checkpoint=None</em>, <em>profiler=None</em>, <em>benchmark=False</em>, <em>deterministic=False</em>, <em>reload_dataloaders_every_epoch=False</em>, <em>auto_lr_find=False</em>, <em>replace_sampler_ddp=True</em>, <em>terminate_on_nan=False</em>, <em>auto_scale_batch_size=False</em>, <em>prepare_data_per_node=True</em>, <em>plugins=None</em>, <em>amp_backend=‘native’</em>, <em>amp_level=‘O2’</em>, <em>distributed_backend=None</em>, <em>move_metrics_to_cpu=False</em>, <em>multiple_trainloader_mode=‘max_size_cycle’</em>, <em>stochastic_weight_avg=False</em>)</p>
</blockquote>
<h3 id="log和return-loss到底在做什么"><a class="markdownIt-Anchor" href="#log和return-loss到底在做什么"></a> Log和return loss到底在做什么</h3>
<p>To add a training loop use the training_step method</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LitClassifier</span>(pl.LightningModule):</span><br><span class="line"></span><br><span class="line">     <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model</span>):</span><br><span class="line">         <span class="built_in">super</span>().__init__()</span><br><span class="line">         self.model = model</span><br><span class="line"></span><br><span class="line">     <span class="keyword">def</span> <span class="title function_">training_step</span>(<span class="params">self, batch, batch_idx</span>):</span><br><span class="line">         x, y = batch</span><br><span class="line">         y_hat = self.model(x)</span><br><span class="line">         loss = F.cross_entropy(y_hat, y)</span><br><span class="line">         <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure>
<ul>
<li>无论是<code>training_step</code>，还是<code>validation_step</code>，<code>test_step</code>返回值都是<code>loss</code>。返回的loss会被用一个list收集起来。</li>
</ul>
<p>Under the hood, Lightning does the following (pseudocode):</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># put model in train mode</span></span><br><span class="line">model.train()</span><br><span class="line">torch.set_grad_enabled(<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">losses = []</span><br><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> train_dataloader:</span><br><span class="line">    <span class="comment"># forward</span></span><br><span class="line">    loss = training_step(batch)</span><br><span class="line">    losses.append(loss.detach())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># backward</span></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># apply and clear grads</span></span><br><span class="line">    optimizer.step()</span><br><span class="line">    optimizer.zero_grad()</span><br></pre></td></tr></table></figure>
<h4 id="training-epoch-level-metrics"><a class="markdownIt-Anchor" href="#training-epoch-level-metrics"></a> Training epoch-level metrics</h4>
<p>If you want to calculate epoch-level metrics and log them, use the <code>.log</code> method</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">training_step</span>(<span class="params">self, batch, batch_idx</span>):</span><br><span class="line">    x, y = batch</span><br><span class="line">    y_hat = self.model(x)</span><br><span class="line">    loss = F.cross_entropy(y_hat, y)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># logs metrics for each training_step,</span></span><br><span class="line">    <span class="comment"># and the average across the epoch, to the progress bar and logger</span></span><br><span class="line">    self.log(<span class="string">&#x27;train_loss&#x27;</span>, loss, on_step=<span class="literal">True</span>, on_epoch=<span class="literal">True</span>, prog_bar=<span class="literal">True</span>, logger=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure>
<ul>
<li>如果在<code>x_step</code>函数中使用了<code>.log()</code>函数，那么这个量将会被逐步记录下来。每一个<code>log</code>出去的变量都会被记录下来，每一个<code>step</code>会集中生成一个字典dict，而每个epoch都会把这些字典收集起来，形成一个字典的list。</li>
</ul>
<p>The .log object automatically reduces the requested metrics across the full epoch. Here’s the pseudocode of what it does under the hood:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">outs = []</span><br><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> train_dataloader:</span><br><span class="line">    <span class="comment"># forward</span></span><br><span class="line">    out = training_step(val_batch)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># backward</span></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># apply and clear grads</span></span><br><span class="line">    optimizer.step()</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">epoch_metric = torch.mean(torch.stack([x[<span class="string">&#x27;train_loss&#x27;</span>] <span class="keyword">for</span> x <span class="keyword">in</span> outs]))</span><br></pre></td></tr></table></figure>
<h4 id="train-epoch-level-operations"><a class="markdownIt-Anchor" href="#train-epoch-level-operations"></a> Train epoch-level operations</h4>
<p>If you need to do something with all the outputs of each training_step, override training_epoch_end yourself.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">training_step</span>(<span class="params">self, batch, batch_idx</span>):</span><br><span class="line">    x, y = batch</span><br><span class="line">    y_hat = self.model(x)</span><br><span class="line">    loss = F.cross_entropy(y_hat, y)</span><br><span class="line">    preds = ...</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&#x27;loss&#x27;</span>: loss, <span class="string">&#x27;other_stuff&#x27;</span>: preds&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">training_epoch_end</span>(<span class="params">self, training_step_outputs</span>):</span><br><span class="line">   <span class="keyword">for</span> pred <span class="keyword">in</span> training_step_outputs:</span><br><span class="line">       <span class="comment"># do something</span></span><br></pre></td></tr></table></figure>
<p>The matching pseudocode is:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">outs = []</span><br><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> train_dataloader:</span><br><span class="line">    <span class="comment"># forward</span></span><br><span class="line">    out = training_step(val_batch)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># backward</span></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># apply and clear grads</span></span><br><span class="line">    optimizer.step()</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">training_epoch_end(outs)</span><br></pre></td></tr></table></figure>
<h2 id="datamodule"><a class="markdownIt-Anchor" href="#datamodule"></a> DataModule</h2>
<p><a href="https://pytorch-lightning.readthedocs.io/en/latest/extensions/datamodules.html">主页面</a></p>
<h3 id="介绍"><a class="markdownIt-Anchor" href="#介绍"></a> 介绍</h3>
<ul>
<li>
<p>首先，这个<code>DataModule</code>和之前写的Dataset完全不冲突。前者是后者的一个包装，并且这个包装可以被用于多个torch Dataset 中。在我看来，其最大的作用就是把各种train/val/test划分、DataLoader初始化之类的重复代码通过包装类的方式得以被简单的复用。</p>
</li>
<li>
<p>具体作用项目：</p>
<ul>
<li>Download instructions：下载</li>
<li>Processing instructions：处理</li>
<li>Split instructions：分割</li>
<li>Train dataloader：训练集Dataloader</li>
<li>Val dataloader(s)：验证集Dataloader</li>
<li>Test dataloader(s)：测试集Dataloader</li>
</ul>
</li>
<li>
<p>其次，<code>pl.LightningDataModule</code>相当于一个功能加强版的torch Dataset，加强的功能包括：</p>
<ul>
<li><code>prepare_data(self)</code>：
<ul>
<li>最最开始的时候，进行一些无论GPU有多少只要执行一次的操作，如写入磁盘的下载操作、分词操作(tokenize)等。</li>
<li>这里是一劳永逸式准备数据的函数。</li>
<li>由于只在单线程中调用，不要在这个函数中进行<code>self.x=y</code>似的赋值操作。</li>
<li>但如果是自己用而不是给大众分发的话，这个函数可能并不需要调用，因为数据提前处理好就好了。</li>
</ul>
</li>
<li><code>setup(self, stage=None)</code>：
<ul>
<li>实例化数据集（Dataset），并进行相关操作，如：清点类数，划分train/val/test集合等。</li>
<li>参数<code>stage</code>用于指示是处于训练周期(<code>fit</code>)还是测试周期(<code>test</code>)，其中，<code>fit</code>周期需要构建train和val两者的数据集。</li>
<li>setup函数不需要返回值。初始化好的train/val/test set直接赋值给self即可。</li>
</ul>
</li>
<li><code>train_dataloader/val_dataloader/test_dataloader</code>：
<ul>
<li>初始化<code>DataLoader</code>。</li>
<li>返回一个DataLoader量。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="示例"><a class="markdownIt-Anchor" href="#示例"></a> 示例</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MNISTDataModule</span>(pl.LightningDataModule):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, data_dir: <span class="built_in">str</span> = <span class="string">&#x27;./&#x27;</span>, batch_size: <span class="built_in">int</span> = <span class="number">64</span>, num_workers: <span class="built_in">int</span> = <span class="number">8</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.data_dir = data_dir</span><br><span class="line">        self.batch_size = batch_size</span><br><span class="line">        self.num_workers = num_workers</span><br><span class="line"></span><br><span class="line">        self.transform = transforms.Compose([</span><br><span class="line">            transforms.ToTensor(),</span><br><span class="line">            transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))</span><br><span class="line">        ])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># self.dims is returned when you call dm.size()</span></span><br><span class="line">        <span class="comment"># Setting default dims here because we know them.</span></span><br><span class="line">        <span class="comment"># Could optionally be assigned dynamically in dm.setup()</span></span><br><span class="line">        self.dims = (<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">        self.num_classes = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">prepare_data</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># download</span></span><br><span class="line">        MNIST(self.data_dir, train=<span class="literal">True</span>, download=<span class="literal">True</span>)</span><br><span class="line">        MNIST(self.data_dir, train=<span class="literal">False</span>, download=<span class="literal">True</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">setup</span>(<span class="params">self, stage=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># Assign train/val datasets for use in dataloaders</span></span><br><span class="line">        <span class="keyword">if</span> stage == <span class="string">&#x27;fit&#x27;</span> <span class="keyword">or</span> stage <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            mnist_full = MNIST(self.data_dir, train=<span class="literal">True</span>, transform=self.transform)</span><br><span class="line">            self.mnist_train, self.mnist_val = random_split(mnist_full, [<span class="number">55000</span>, <span class="number">5000</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Assign test dataset for use in dataloader(s)</span></span><br><span class="line">        <span class="keyword">if</span> stage == <span class="string">&#x27;test&#x27;</span> <span class="keyword">or</span> stage <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            self.mnist_test = MNIST(self.data_dir, train=<span class="literal">False</span>, transform=self.transform)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train_dataloader</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> DataLoader(self.mnist_train, batch_size=self.batch_size, num_workers=self.num_workers)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">val_dataloader</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> DataLoader(self.mnist_val, batch_size=self.batch_size, num_workers=self.num_workers)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_dataloader</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> DataLoader(self.mnist_test, batch_size=self.batch_size, num_workers=self.num_workers)</span><br></pre></td></tr></table></figure>
<h3 id="要点-2"><a class="markdownIt-Anchor" href="#要点-2"></a> 要点</h3>
<ul>
<li>若在DataModule中定义了一个<code>self.dims</code> 变量，后面可以调用<code>dm.size()</code>获取该变量。</li>
</ul>
<h2 id="saving-and-loading"><a class="markdownIt-Anchor" href="#saving-and-loading"></a> Saving and Loading</h2>
<p><a href="https://pytorch-lightning.readthedocs.io/en/latest/common/weights_loading.html">主页面</a></p>
<h3 id="saving"><a class="markdownIt-Anchor" href="#saving"></a> Saving</h3>
<ul>
<li>
<p><a href="https://pytorch-lightning.readthedocs.io/en/latest/extensions/generated/pytorch_lightning.callbacks.ModelCheckpoint.html#pytorch_lightning.callbacks.ModelCheckpoint">ModelCheckpoint</a>: 自动储存的callback module。默认情况下training过程中只会自动储存最新的模型与相关参数，而用户可以通过这个module自定义。如观测一个<code>val_loss</code>的量，并储存top 3好的模型，且同时储存最后一个epoch的模型，等等。例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pytorch_lightning.callbacks <span class="keyword">import</span> ModelCheckpoint</span><br><span class="line"></span><br><span class="line"><span class="comment"># saves a file like: my/path/sample-mnist-epoch=02-val_loss=0.32.ckpt</span></span><br><span class="line">checkpoint_callback = ModelCheckpoint(</span><br><span class="line">    monitor=<span class="string">&#x27;val_loss&#x27;</span>,</span><br><span class="line">    filename=<span class="string">&#x27;sample-mnist-&#123;epoch:02d&#125;-&#123;val_loss:.2f&#125;&#x27;</span>,</span><br><span class="line">    save_top_k=<span class="number">3</span>,</span><br><span class="line">    mode=<span class="string">&#x27;min&#x27;</span>,</span><br><span class="line">    save_last=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">trainer = pl.Trainer(gpus=<span class="number">1</span>, max_epochs=<span class="number">3</span>, progress_bar_refresh_rate=<span class="number">20</span>, callbacks=[checkpoint_callback])</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>另外，也可以手动存储checkpoint: <code>trainer.save_checkpoint(&quot;example.ckpt&quot;)</code></p>
</li>
<li>
<p><code>ModelCheckpoint</code> Callback中，如果<code>save_weights_only =True</code>，那么将会只储存模型的权重（相当于<code>model.save_weights(filepath)</code>），反之会储存整个模型（相当于<code>model.save(filepath)</code>）。</p>
</li>
</ul>
<h3 id="loading"><a class="markdownIt-Anchor" href="#loading"></a> Loading</h3>
<ul>
<li>
<p>load一个模型，包括它的weights、biases和超参数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = MyLightingModule.load_from_checkpoint(PATH)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(model.learning_rate)</span><br><span class="line"><span class="comment"># prints the learning_rate you used in this checkpoint</span></span><br><span class="line"></span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line">y_hat = model(x)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>load模型时替换一些超参数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LitModel</span>(<span class="title class_ inherited__">LightningModule</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_dim, out_dim</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.save_hyperparameters()</span><br><span class="line">        self.l1 = nn.Linear(self.hparams.in_dim, self.hparams.out_dim)</span><br><span class="line">        </span><br><span class="line"><span class="comment"># if you train and save the model like this it will use these values when loading</span></span><br><span class="line"><span class="comment"># the weights. But you can overwrite this</span></span><br><span class="line">LitModel(in_dim=<span class="number">32</span>, out_dim=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># uses in_dim=32, out_dim=10</span></span><br><span class="line">model = LitModel.load_from_checkpoint(PATH)</span><br><span class="line"></span><br><span class="line"><span class="comment"># uses in_dim=128, out_dim=10</span></span><br><span class="line">model = LitModel.load_from_checkpoint(PATH, in_dim=<span class="number">128</span>, out_dim=<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>完全load训练状态：load包括模型的一切，以及和训练相关的一切参数，如<code>model, epoch, step, LR schedulers, apex</code>等</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = LitModel()</span><br><span class="line">trainer = Trainer(resume_from_checkpoint=<span class="string">&#x27;some/path/to/my_checkpoint.ckpt&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># automatically restores model, epoch, step, LR schedulers, apex, etc...</span></span><br><span class="line">trainer.fit(model)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="callbacks"><a class="markdownIt-Anchor" href="#callbacks"></a> Callbacks</h2>
<ul>
<li>Callback 是一个自包含的程序，可以与训练流程交织在一起，而不会污染主要的研究逻辑。</li>
<li>Callback 并非只会在epoch结尾调用。pytorch-lightning 提供了数十个hook（接口，调用位置）可供选择，也可以自定义callback，实现任何想实现的模块。</li>
<li>推荐使用方式是，随问题和项目变化的操作，这些函数写到lightning module里面，而相对独立，相对辅助性的，需要复用的内容则可以定义单独的模块，供后续方便地插拔使用。</li>
</ul>
<h3 id="callbacks推荐"><a class="markdownIt-Anchor" href="#callbacks推荐"></a> Callbacks推荐</h3>
<p><a href="https://pytorch-lightning.readthedocs.io/en/latest/extensions/callbacks.html#built-in-callbacks">内建Callbacks</a></p>
<ul>
<li>
<p><code>EarlyStopping(monitor='early_stop_on', min_delta=0.0, patience=3, verbose=False, mode='min', strict=True)</code>：根据某个值，在数个epoch没有提升的情况下提前停止训练。</p>
<blockquote>
<p>参数：</p>
<ul>
<li><strong>monitor</strong> (<a href="https://docs.python.org/3/library/stdtypes.html#str"><code>str</code></a>) – quantity to be monitored. Default: <code>'early_stop_on'</code>.</li>
<li><strong>min_delta</strong> (<a href="https://docs.python.org/3/library/functions.html#float"><code>float</code></a>) – minimum change in the monitored quantity to qualify as an improvement, i.e. an absolute change of less than min_delta, will count as no improvement. Default: <code>0.0</code>.</li>
<li><strong>patience</strong> (<a href="https://docs.python.org/3/library/functions.html#int"><code>int</code></a>) – number of validation epochs with no improvement after which training will be stopped. Default: <code>3</code>.</li>
<li><strong>verbose</strong> (<a href="https://docs.python.org/3/library/functions.html#bool"><code>bool</code></a>) – verbosity mode. Default: <code>False</code>.</li>
<li><strong>mode</strong> (<a href="https://docs.python.org/3/library/stdtypes.html#str"><code>str</code></a>) – one of <code>'min'</code>, <code>'max'</code>. In <code>'min'</code> mode, training will stop when the quantity monitored has stopped decreasing and in <code>'max'</code> mode it will stop when the quantity monitored has stopped increasing.</li>
<li><strong>strict</strong> (<a href="https://docs.python.org/3/library/functions.html#bool"><code>bool</code></a>) – whether to crash the training if monitor is not found in the validation metrics. Default: <code>True</code>.</li>
</ul>
</blockquote>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pytorch_lightning <span class="keyword">import</span> Trainer</span><br><span class="line"><span class="keyword">from</span> pytorch_lightning.callbacks <span class="keyword">import</span> EarlyStopping</span><br><span class="line"></span><br><span class="line">early_stopping = EarlyStopping(<span class="string">&#x27;val_loss&#x27;</span>)</span><br><span class="line">trainer = Trainer(callbacks=[early_stopping])</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><code>ModelCheckpoint</code>：见上文<strong>Saving and Loading</strong>.</p>
</li>
<li>
<p><code>PrintTableMetricsCallback</code>：在每个epoch结束后打印一份结果整理表格。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pl_bolts.callbacks <span class="keyword">import</span> PrintTableMetricsCallback</span><br><span class="line"></span><br><span class="line">callback = PrintTableMetricsCallback()</span><br><span class="line">trainer = pl.Trainer(callbacks=[callback])</span><br><span class="line">trainer.fit(...)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ------------------------------</span></span><br><span class="line"><span class="comment"># at the end of every epoch it will print</span></span><br><span class="line"><span class="comment"># ------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># loss│train_loss│val_loss│epoch</span></span><br><span class="line"><span class="comment"># ──────────────────────────────</span></span><br><span class="line"><span class="comment"># 2.2541470527648926│2.2541470527648926│2.2158432006835938│0</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="logging"><a class="markdownIt-Anchor" href="#logging"></a> Logging</h2>
<ul>
<li>
<p><a href="https://pytorch-lightning.readthedocs.io/en/latest/extensions/logging.html">Logging</a>：Logger默认是TensorBoard，但可以指定各种主流Logger<a href="https://pytorch-lightning.readthedocs.io/en/latest/extensions/logging.html#supported-loggers">框架</a>，<a href="http://xn--Comet-gv5i.ml">如Comet.ml</a>，MLflow，Netpune，或直接CSV文件。可以同时使用复数个logger。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pytorch_lightning <span class="keyword">import</span> loggers <span class="keyword">as</span> pl_loggers</span><br><span class="line"></span><br><span class="line"><span class="comment"># Default</span></span><br><span class="line">tb_logger = pl_loggers.TensorBoardLogger(</span><br><span class="line">    save_dir=os.getcwd(),</span><br><span class="line">    version=<span class="literal">None</span>,</span><br><span class="line">    name=<span class="string">&#x27;lightning_logs&#x27;</span></span><br><span class="line">)</span><br><span class="line">trainer = Trainer(logger=tb_logger)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Or use the same format as others</span></span><br><span class="line">tb_logger = pl_loggers.TensorBoardLogger(<span class="string">&#x27;logs/&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># One Logger</span></span><br><span class="line">comet_logger = pl_loggers.CometLogger(save_dir=<span class="string">&#x27;logs/&#x27;</span>)</span><br><span class="line">trainer = Trainer(logger=comet_logger)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Save code snapshot</span></span><br><span class="line">logger = pl_loggers.TestTubeLogger(<span class="string">&#x27;logs/&#x27;</span>, create_git_tag=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Multiple Logger</span></span><br><span class="line">tb_logger = pl_loggers.TensorBoardLogger(<span class="string">&#x27;logs/&#x27;</span>)</span><br><span class="line">comet_logger = pl_loggers.CometLogger(save_dir=<span class="string">&#x27;logs/&#x27;</span>)</span><br><span class="line">trainer = Trainer(logger=[tb_logger, comet_logger])</span><br></pre></td></tr></table></figure>
<p>默认情况下，每50个batch log一次，可以通过调整参数</p>
</li>
<li>
<p>如果想要log输出非scalar（标量）的内容，如图片，文本，直方图等等，可以直接调用<code>self.logger.experiment.add_xxx()</code>来实现所需操作。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">training_step</span>(<span class="params">...</span>):</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment"># the logger you used (in this case tensorboard)</span></span><br><span class="line">    tensorboard = self.logger.experiment</span><br><span class="line">    tensorboard.add_image()</span><br><span class="line">    tensorboard.add_histogram(...)</span><br><span class="line">    tensorboard.add_figure(...)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>使用log：如果是TensorBoard，那么：<code>tensorboard --logdir ./lightning_logs</code>。在Jupyter Notebook中，可以使用：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Start tensorboard.</span></span><br><span class="line">%load_ext tensorboard</span><br><span class="line">%tensorboard --logdir lightning_logs/</span><br></pre></td></tr></table></figure>
<p>在行内打开TensorBoard。</p>
</li>
<li>
<p>小技巧：如果在局域网内开启了TensorBoard，加上flag <code>--bind_all</code>即可使用主机名访问：</p>
<p><code>tensorboard --logdir lightning_logs --bind_all</code> -&gt; <code>http://SERVER-NAME:6006/</code></p>
</li>
</ul>
<h3 id="同时使用tensorboard和csv-logger"><a class="markdownIt-Anchor" href="#同时使用tensorboard和csv-logger"></a> 同时使用TensorBoard和CSV Logger</h3>
<p>如果同时使用两个Logger，PL会有睿智操作：如果保存根目录相同，他们会依次建立两个version文件夹，令人窒息。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pytorch_lightning.loggers <span class="keyword">import</span> TensorBoardLogger, CSVLogger</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_loggers</span>():</span><br><span class="line">    loggers = []</span><br><span class="line">    loggers.append(TensorBoardLogger(</span><br><span class="line">        save_dir=<span class="string">&#x27;lightning_logs&#x27;</span>, name=<span class="string">&#x27;tb&#x27;</span></span><br><span class="line">    ))</span><br><span class="line"></span><br><span class="line">    loggers.append(CSVLogger(</span><br><span class="line">        save_dir=<span class="string">&#x27;lightning_logs&#x27;</span>, name=<span class="string">&#x27;csv&#x27;</span></span><br><span class="line">    ))</span><br><span class="line"></span><br><span class="line">    loggers.append(CometLogger(</span><br><span class="line">        save_dir=<span class="string">&#x27;lightning_logs&#x27;</span>, name=<span class="string">&#x27;tt&#x27;</span></span><br><span class="line">    ))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loggers</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_callbacks</span>(<span class="params">logger</span>):</span><br><span class="line">    callbacks = []</span><br><span class="line">    dirpath = <span class="string">f&#x27;lightning_logs/<span class="subst">&#123;logger.name&#125;</span>/version_<span class="subst">&#123;logger.version&#125;</span>/checkpoints&#x27;</span></span><br><span class="line">    callbacks.append(ModelCheckpoint(</span><br><span class="line">        dirpath=dirpath,</span><br><span class="line">        monitor=<span class="string">&#x27;loss_epoch&#x27;</span>,</span><br><span class="line">        filename=<span class="string">&#x27;&#123;epoch:02d&#125;-&#123;val_loss:.2f&#125;&#x27;</span>,</span><br><span class="line">        save_top_k=<span class="number">3</span>,</span><br><span class="line">        mode=<span class="string">&#x27;max&#x27;</span>,</span><br><span class="line">        save_last=<span class="literal">True</span></span><br><span class="line">    ))</span><br><span class="line">    <span class="keyword">return</span> callbacks</span><br><span class="line"></span><br><span class="line">loggers = load_loggers()</span><br><span class="line">callbacks = load_callbacks(loggers[<span class="number">0</span>])</span><br><span class="line">trainer = pl.Trainer(logger=loggers, callbacks=callbacks)</span><br></pre></td></tr></table></figure>
<h2 id="transfer-learning"><a class="markdownIt-Anchor" href="#transfer-learning"></a> Transfer Learning</h2>
<p><a href="https://pytorch-lightning.readthedocs.io/en/latest/starter/introduction_guide.html#transfer-learning">主页面</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ImagenetTransferLearning</span>(<span class="title class_ inherited__">LightningModule</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># init a pretrained resnet</span></span><br><span class="line">        backbone = models.resnet50(pretrained=<span class="literal">True</span>)</span><br><span class="line">        num_filters = backbone.fc.in_features</span><br><span class="line">        layers = <span class="built_in">list</span>(backbone.children())[:-<span class="number">1</span>]</span><br><span class="line">        self.feature_extractor = nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># use the pretrained model to classify cifar-10 (10 image classes)</span></span><br><span class="line">        num_target_classes = <span class="number">10</span></span><br><span class="line">        self.classifier = nn.Linear(num_filters, num_target_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        self.feature_extractor.<span class="built_in">eval</span>()</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            representations = self.feature_extractor(x).flatten(<span class="number">1</span>)</span><br><span class="line">        x = self.classifier(representations)</span><br><span class="line">        ...</span><br></pre></td></tr></table></figure>
<h2 id="关于device操作"><a class="markdownIt-Anchor" href="#关于device操作"></a> 关于device操作</h2>
<p>LightningModules know what device they are on! Construct tensors on the device directly to avoid CPU-&gt;Device transfer.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># bad</span></span><br><span class="line">t = torch.rand(<span class="number">2</span>, <span class="number">2</span>).cuda()</span><br><span class="line"></span><br><span class="line"><span class="comment"># good (self is LightningModule)</span></span><br><span class="line">t = torch.rand(<span class="number">2</span>, <span class="number">2</span>, device=self.device)</span><br></pre></td></tr></table></figure>
<p>For tensors that need to be model attributes, it is best practice to register them as buffers in the modules’s <code>__init__</code> method:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># bad</span></span><br><span class="line">self.t = torch.rand(<span class="number">2</span>, <span class="number">2</span>, device=self.device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># good</span></span><br><span class="line">self.register_buffer(<span class="string">&quot;t&quot;</span>, torch.rand(<span class="number">2</span>, <span class="number">2</span>))</span><br></pre></td></tr></table></figure>
<p>前面两段是教程中的文本。然而实际上有一个暗坑：</p>
<p>如果你使用了一个中继的<code>pl.LightningModule</code>，而这个module里面实例化了某个普通的<code>nn.Module</code>，而这个模型中又需要内部生成一些tensor，比如图片每个通道的mean，std之类，那么如果你从<code>pl.LightningModule</code>中pass一个<code>self.device</code>，实际上在一开始这个<code>self.device</code>永远是<code>cpu</code>。所以如果你在调用的<code>nn.Module</code>的<code>__init__()</code>中初始化，使用<code>to(device)</code>或干脆什么都不用，结果就是它永远都在<code>cpu</code>上。</p>
<p>但是，经过实验，虽然<code>pl.LightningModule</code>在<code>__init__()</code>阶段<code>self.device</code>还是<code>cpu</code>，当进入了<code>training_step()</code>之后，就迅速变为了<code>cuda</code>。所以，对于子模块，最佳方案是，使用一个<code>forward</code>中传入的量，如<code>x</code>，作为一个reference变量，用<code>type_as</code>函数将在模型中生成的tensor都放到和这个参考变量相同的device上即可。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RDNFuse</span>(nn.Module):</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_norm_func</span>(<span class="params">self, ref</span>):</span><br><span class="line">        self.mean = torch.tensor(np.array(self.mean_sen), dtype=torch.float32).type_as(ref)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">hasattr</span>(self, <span class="string">&#x27;mean&#x27;</span>):</span><br><span class="line">            self.init_norm_func(x)</span><br></pre></td></tr></table></figure>
<h2 id="关于limit_train_batches选项"><a class="markdownIt-Anchor" href="#关于limit_train_batches选项"></a> 关于<code>limit_train_batches</code>选项</h2>
<p>这里涉及到一个问题，就是每个epoch使用部分数据而非全部时，程序将会怎么工作。</p>
<blockquote>
<p>The shuffling happens when the iterator is created. In the case of the for loop, that happens just before the for loop starts. You can create the iterator manually with:</p>
</blockquote>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Iterator gets created, the data has been shuffled at this point.</span></span><br><span class="line">data_iterator = <span class="built_in">iter</span>(namesTrainLoader)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>By default the data loader uses <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.RandomSampler"><code>torch.utils.data.RandomSampler</code></a> if you set <code>shuffle=True</code> (without providing your own sampler). Its implementation is very straight forward and you can see where the data is shuffled when the iterator is created by looking at the <a href="https://github.com/pytorch/pytorch/blob/f3e620ee83f080283445aa1a7242d40e30eb6a7f/torch/utils/data/sampler.py#L103-L107"><code>RandomSampler.__iter__</code></a> method:</p>
</blockquote>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>):</span><br><span class="line">    n = <span class="built_in">len</span>(self.data_source)</span><br><span class="line">    <span class="keyword">if</span> self.replacement:</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">iter</span>(torch.randint(high=n, size=(self.num_samples,), dtype=torch.int64).tolist())</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">iter</span>(torch.randperm(n).tolist())</span><br></pre></td></tr></table></figure>
<blockquote>
<p>The return statement is the important part, where the shuffling takes place. It simply creates a random permutation of the indices.</p>
<p>That means you will see your entire dataset every time you fully consume the iterator, just in a different order every time. Therefore there is no data lost (not including cases with <code>drop_last=True</code>) and your model will see all data at every epoch.</p>
</blockquote>
<p>总结下来，如果使用了<code>shuffle=True</code>选项，那么即使每次都不跑完整个epoch，你还是有机会见到所有的数据的。数据集的shuffle发生在<code>iter</code>被创建的时候，在我们一般的代码中，也就是内层for循环开始时。但如果你没有选择<code>shuffle=True</code>，那你将永远只能看到你设定的前面N个数据。</p>
<h2 id="points"><a class="markdownIt-Anchor" href="#points"></a> Points</h2>
<ul>
<li>
<p><code>pl.seed_everything(1234)</code>：对所有相关的随机量固定种子。</p>
</li>
<li>
<p>使用LR Scheduler时候，不用自己<code>.step()</code>。它也被Trainer自动处理了。<a href="https://pytorch-lightning.readthedocs.io/en/latest/common/optimizers.html?highlight=scheduler#">Optimization 主页面</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Single optimizer</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> epochs:</span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> data:</span><br><span class="line">        loss = model.training_step(batch, batch_idx, ...)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> scheduler <span class="keyword">in</span> schedulers:</span><br><span class="line">        scheduler.step()</span><br><span class="line">        </span><br><span class="line"><span class="comment"># Multiple optimizers</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> epochs:</span><br><span class="line">  <span class="keyword">for</span> batch <span class="keyword">in</span> data:</span><br><span class="line">     <span class="keyword">for</span> opt <span class="keyword">in</span> optimizers:</span><br><span class="line">        disable_grads_for_other_optimizers()</span><br><span class="line">        train_step(opt)</span><br><span class="line">        opt.step()</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> scheduler <span class="keyword">in</span> schedulers:</span><br><span class="line">     scheduler.step()</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>关于划分train和val集合的方法。与PL无关，但很常用，两个例子：</p>
<ol>
<li><code>random_split(range(10), [3, 7], generator=torch.Generator().manual_seed(42))</code></li>
<li>如下：</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader, random_split</span><br><span class="line"><span class="keyword">from</span> torchvision.datasets <span class="keyword">import</span> MNIST</span><br><span class="line"></span><br><span class="line">mnist_full = MNIST(self.data_dir, train=<span class="literal">True</span>, transform=self.transform)</span><br><span class="line">self.mnist_train, self.mnist_val = random_split(mnist_full, [<span class="number">55000</span>, <span class="number">5000</span>])</span><br></pre></td></tr></table></figure>
<p>Parameters：</p>
<ul>
<li><strong>dataset</strong> (<a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset"><em>Dataset</em></a>) – Dataset to be split</li>
<li><strong>lengths</strong> (<em>sequence</em>) – lengths of splits to be produced</li>
<li><strong>generator</strong> (<a href="https://pytorch.org/docs/stable/generated/torch.Generator.html#torch.Generator"><em>Generator</em></a>) – Generator used for the random permutation.</li>
</ul>
</li>
<li>
<p>如果使用了<code>PrintTableMetricsCallback</code>，那么<code>validation_step</code>不要return内容，否则会炸。</p>
</li>
</ul>
]]></content>
      <tags>
        <tag>deep-learning</tag>
        <tag>pytorch</tag>
        <tag>pytorch-lightning</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch官方模型实现分析</title>
    <url>/2020/07/11/pytorch-official-network-analysis/</url>
    <content><![CDATA[<h2 id="resnet"><a class="markdownIt-Anchor" href="#resnet"></a> Resnet</h2>
<h3 id="如何应对不同尺寸输入"><a class="markdownIt-Anchor" href="#如何应对不同尺寸输入"></a> 如何应对不同尺寸输入</h3>
<p>在网络最后添加一个<code>AdaptiveAvgPool2d(output_size)</code>函数，它的作用是无论输入图片形状如何，最终都会转换为给定输出尺寸。而Resnet中，这个<code>output_size</code>被设置为了<code>(1,1)</code>，即无论输入的图片尺寸为多少，只要其大小足以扛得住网络前面的一系列pooling layers，到最后的输出尺寸大于等于<code>(1,1)</code>，其每个Channel就会被这一层压缩成一个点，即最后只会得到一个与Channel数目相等的向量。这个向量被送到了FC层。</p>
<span id="more"></span>
<h3 id="如何应对channel数目不合适问题"><a class="markdownIt-Anchor" href="#如何应对channel数目不合适问题"></a> 如何应对Channel数目不合适问题</h3>
<p>由于兼容了各种大小和尺寸的模型，所以有时难免会出现如Channel数目无法被4整除（BottleNeck Layer要求）的情况。这里，它使用了<code>1x1 conv</code>的方法。由于每个block的输出都要加到输入上，如果这个整除不了，结果就是Channel数目不匹配无法做Residual。这里的操作是，如果输出<code>Channel数*4 != 输入Channel数</code>，那么就直接让输入先用<code>1x1 conv</code>改变维度到<code>输出Channel数*4</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> stride != <span class="number">1</span> <span class="keyword">or</span> self.inplanes != planes * block.expansion:</span><br><span class="line">    downsample = nn.Sequential(</span><br><span class="line">        conv1x1(self.inplanes, planes * block.expansion, stride),</span><br><span class="line">        norm_layer(planes * block.expansion),</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
<h3 id="如何应对不同总layer数的resnet使用不同的layer-block的问题"><a class="markdownIt-Anchor" href="#如何应对不同总layer数的resnet使用不同的layer-block的问题"></a> 如何应对不同总Layer数的Resnet使用不同的Layer Block的问题</h3>
<p>在Resnet中，resnet18, 34使用的是双层<code>3x3 conv</code>的<code>Basic Block</code>，而resnet50, 101, 152则使用的是<code>1x1conv -&gt; 3x3 conv -&gt; 1x1 conv</code>的结构。为了获得最大的兼容性，这里官方模型将<code>Basic Block</code>和<code>Bottleneck Block</code>分别定义为两个class，即子模块，然后对于不同尺寸的resnet分别输入不同的模块。</p>
<h3 id="为什么定义了conv3x3和conv1x1两个函数"><a class="markdownIt-Anchor" href="#为什么定义了conv3x3和conv1x1两个函数"></a> 为什么定义了conv3x3和conv1x1两个函数</h3>
<p>这两个函数看似画蛇添足多此一举，但实际上在我的理解中，他们避免了一些重复变量的输入，更直观地反映了该层的功能：<code>1x1</code>或<code>3x3</code>，也潜在地避免了一些错误，并优化了理解。</p>
]]></content>
      <tags>
        <tag>deep-learning</tag>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch 学习笔记 --入门</title>
    <url>/2018/03/19/pytorch-start/</url>
    <content><![CDATA[<h1 id="pytorch-学习笔记-入门"><a class="markdownIt-Anchor" href="#pytorch-学习笔记-入门"></a> Pytorch 学习笔记 --入门</h1>
<ul>
<li>
<p>搭建一个模型的步骤：</p>
<ol>
<li>
<p>import需要的模块</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br></pre></td></tr></table></figure>
<span id="more"></span>
</li>
<li>
<p>Load需要的数据。数据分为trainset和testset，著名的一些数据集如Imagenet, CIFAR10, MNIST等可以直接在torchvision.dataset中Load。trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,                                          shuffl =True, num_workers=2) 语句的作用是把读进来的数据分好batch，做好shuffle。num_workers表示使用的进程数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">  transform = transforms.Compose(</span><br><span class="line">    [transforms.ToTensor(),</span><br><span class="line">       transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])</span><br><span class="line">  </span><br><span class="line">  trainset = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">True</span>,</span><br><span class="line">                                          download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">trainloader = torch.utils.data.DataLoader(trainset, batch_size=<span class="number">4</span>,</span><br><span class="line">                                            shuffle=<span class="literal">True</span>, num_workers=<span class="number">2</span>)</span><br><span class="line">  </span><br><span class="line">  testset = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">False</span>,</span><br><span class="line">                                         download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">testloader = torch.utils.data.DataLoader(testset, batch_size=<span class="number">4</span>,</span><br><span class="line">                                           shuffle=<span class="literal">False</span>, num_workers=<span class="number">2</span>)</span><br><span class="line">  </span><br><span class="line">  classes = (<span class="string">&#x27;plane&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;deer&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;frog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;ship&#x27;</span>, <span class="string">&#x27;truck&#x27;</span>)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>定义一个卷积神经网络</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">  <span class="comment"># autograd.Variable的作用是在于对于一个给定的变量，当定义了forward函数后自动生成backward函数，便于后面计算backward函数的梯度。同理，F的作用是对于一个给定的函数，...</span></span><br><span class="line">  <span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn <span class="comment"># 引用神经网络的各个层时要导入的模块</span></span><br><span class="line">  <span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F </span><br><span class="line">  </span><br><span class="line">  <span class="keyword">class</span> <span class="title class_">Net</span>(nn.Module):</span><br><span class="line">      <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">      这个类当实例化并给喂进来数据后会自动执行从input到output的过程</span></span><br><span class="line"><span class="string">      &#x27;&#x27;&#x27;</span></span><br><span class="line">      <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>): </span><br><span class="line">          <span class="comment"># 这里的init要写的东西是之后你的网络里面会用到的所有的层</span></span><br><span class="line">          <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">          self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">6</span>, <span class="number">5</span>)</span><br><span class="line">          self.pool = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">          self.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>)</span><br><span class="line">          self.fc1 = nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">          self.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line">  </span><br><span class="line">      <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">          <span class="comment"># 这里是前向函数，要顺序从raw数据一层一层写下来，后向函数会自动定义</span></span><br><span class="line">          x = self.pool(F.relu(self.conv1(x)))</span><br><span class="line">          x = self.pool(F.relu(self.conv2(x)))</span><br><span class="line">          x = x.view(-<span class="number">1</span>, <span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>)</span><br><span class="line">          x = F.relu(self.fc1(x))</span><br><span class="line">          x = F.relu(self.fc2(x))</span><br><span class="line">          x = self.fc3(x)</span><br><span class="line">          <span class="keyword">return</span> x</span><br><span class="line">      net = Net() <span class="comment"># 初始化一个实例神经网络</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p>定义一个Loss函数和优化器</p>
</li>
<li>
<p>定义一个Loss函数和优化器</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line">criterion = nn.CrossEntropyLoss() <span class="comment"># criterion定义的是Loss函数</span></span><br><span class="line">optimizer = optim.SGD(net.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>) <span class="comment"># optimizer定义的是优化方式。它作用于梯度。</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p>用训练集训练网络</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):  <span class="comment"># epoch表示把相同的训练集重复训练的次数</span></span><br><span class="line"></span><br><span class="line">    running_loss = <span class="number">0.0</span> <span class="comment"># 这个是用来计算每个步长(这里的2000)内loss函数结果的平均值</span></span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(trainloader, <span class="number">0</span>):</span><br><span class="line">        <span class="comment"># get the inputs</span></span><br><span class="line">        inputs, labels = data</span><br><span class="line"></span><br><span class="line">        <span class="comment"># wrap them in Variable</span></span><br><span class="line">        inputs, labels = Variable(inputs), Variable(labels)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># zero the parameter gradients</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># forward + backward + optimize</span></span><br><span class="line">        outputs = net(inputs)</span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># print statistics</span></span><br><span class="line">        running_loss += loss.data[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">2000</span> == <span class="number">1999</span>:    <span class="comment"># print every 2000 mini-batches</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;[%d, %5d] loss: %.3f&#x27;</span> %</span><br><span class="line">                  (epoch + <span class="number">1</span>, i + <span class="number">1</span>, running_loss / <span class="number">2000</span>))</span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>在测试集上测试网络</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 整体准确率测试</span></span><br><span class="line">correct = <span class="number">0</span></span><br><span class="line">total = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> testloader:</span><br><span class="line">    images, labels = data</span><br><span class="line">    outputs = net(Variable(images))</span><br><span class="line">    <span class="comment"># 这里的1表示的axis，0表示每一列的max；1表示每一行的max，返回第一个参数是行的最大值，第二个参数是该最大值的位置</span></span><br><span class="line">    _, predicted = torch.<span class="built_in">max</span>(outputs.data, <span class="number">1</span>) </span><br><span class="line">    total += labels.size(<span class="number">0</span>)</span><br><span class="line">    correct += (predicted == labels).<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy of the network on the 10000 test images: %d %%&#x27;</span> % (</span><br><span class="line">    <span class="number">100</span> * correct / total))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 分类准确率测试</span></span><br><span class="line">class_correct = <span class="built_in">list</span>(<span class="number">0.</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>))</span><br><span class="line">class_total = <span class="built_in">list</span>(<span class="number">0.</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>))</span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> testloader:</span><br><span class="line">    images, labels = data</span><br><span class="line">    outputs = net(Variable(images))</span><br><span class="line">    _, predicted = torch.<span class="built_in">max</span>(outputs.data, <span class="number">1</span>)</span><br><span class="line">    c = (predicted == labels).squeeze()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">        label = labels[i]</span><br><span class="line">        class_correct[label] += c[i]</span><br><span class="line">        class_total[label] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Accuracy of %5s : %2d %%&#x27;</span> % (</span><br><span class="line">        classes[i], <span class="number">100</span> * class_correct[i] / class_total[i]))</span><br></pre></td></tr></table></figure>
</li>
</ol>
</li>
<li>
<p>在GPU上训练：网络和变量（input和label）在定义后需要调用cuda()方法。如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">net.cuda() <span class="comment"># 使用GPU</span></span><br><span class="line">inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>多GPU并行计算：nn.DataParallel。使用GPU，并在多GPU时并行计算的代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = Model(input_size, output_size) </span><br><span class="line"><span class="keyword">if</span> torch.cuda.device_count() &gt; <span class="number">1</span>: <span class="comment"># 如果有多个GPU就并行</span></span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&quot;Let&#x27;s use&quot;</span>, torch.cuda.device_count(), <span class="string">&quot;GPUs!&quot;</span>)</span><br><span class="line">  <span class="comment"># dim = 0 [30, xxx] -&gt; [10, ...], [10, ...], [10, ...] on 3 GPUs</span></span><br><span class="line">  model = nn.DataParallel(model)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available(): <span class="comment"># 如果有GPU就用GPU</span></span><br><span class="line">   model.cuda()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 把数据放到并行的GPU上并输出每块GPU上分配到的数据</span></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> rand_loader:</span><br><span class="line">    <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">        input_var = Variable(data.cuda())</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        input_var = Variable(data)</span><br><span class="line"></span><br><span class="line">    output = model(input_var)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Outside: input size&quot;</span>, input_var.size(),</span><br><span class="line">          <span class="string">&quot;output_size&quot;</span>, output.size())</span><br></pre></td></tr></table></figure>
</li>
</ul>
]]></content>
      <tags>
        <tag>machine-learning</tag>
        <tag>deep-learning</tag>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>限制Win10中应用程序的CPU使用率</title>
    <url>/2018/08/28/restrict-win10-cpu/</url>
    <content><![CDATA[<h1 id="问题"><a class="markdownIt-Anchor" href="#问题"></a> 问题</h1>
<p>如何限制Windows下某个特定应用程序的CPU使用率。</p>
<h1 id="解决方案"><a class="markdownIt-Anchor" href="#解决方案"></a> 解决方案</h1>
<p><strong>通过在Win10中为某些应用程序分配更少的内核来限制CPU使用率</strong></p>
<ol>
<li>打开任务管理器</li>
</ol>
<p><img data-src="006tNbRwgy1fupx4d1fxdj31b215ub29.jpg" alt="image-20180828121424616"></p>
<span id="more"></span>
<ol start="2">
<li>进入<code>Details</code>选项卡，找到CPU消耗剧烈的目标程序，右键选择<code>Set affinity</code></li>
</ol>
<p><img data-src="006tNbRwgy1fupx4rpj4jj31b215u7wh.jpg" alt="image-20180828121552884"></p>
<ol start="3">
<li>点选掉合适量的CPU内核</li>
</ol>
<p><img data-src="006tNbRwgy1fupx797p23j31b01601kx.jpg" alt="image-20180828121647347"></p>
]]></content>
      <tags>
        <tag>windows</tag>
      </tags>
  </entry>
  <entry>
    <title>Curriculum Vitae -- Zhongyang Zhang</title>
    <url>/2099/10/03/resume/</url>
    <content><![CDATA[<p>The following document is my resume:</p>
<span id="more"></span>
<div class="pdf-container" data-target="cv.pdf" data-height="500px"></div>
<figure>
<img data-src="cv.png" alt="Resume_ZhongyangZhang_HUST"><figcaption aria-hidden="true">Resume_ZhongyangZhang_HUST</figcaption>
</figure>
]]></content>
      <tags>
        <tag>Resume</tag>
      </tags>
  </entry>
  <entry>
    <title>强化学习基础</title>
    <url>/2019/01/19/rl-basic/</url>
    <content><![CDATA[<p><strong>本文引用了莫烦大大和几位知乎答主的部分文字，由于时间较长，无法一一确认，在这里统一感谢。如有侵害到您版权的行为，请您尽快联系我修改，感谢。</strong></p>
<h2 id="reinforcement-learning-basic"><a class="markdownIt-Anchor" href="#reinforcement-learning-basic"></a> Reinforcement Learning Basic</h2>
<h3 id="定义"><a class="markdownIt-Anchor" href="#定义"></a> 定义</h3>
<p>强化学习涉及一个智能体，一组“状态”S<img data-src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4611d85173cd3b508e67077d4a1252c9c05abca2" alt="S">和每个状态下的动作集合A<img data-src="7daff47fa58cdfd29dc333def748ff5fa4c923e3" alt="A">。通过执行一个行动 ，该智能体从一个状态转移到另一个状态。在一个特定的状态下执行一个动作时，智能体还可以得到一个奖励。<br>
智能体的目标是最大化其奖励的累加。这个潜在的奖励是所有未来可以拿到的奖励值的期望的加权和。</p>
<span id="more"></span>
<p>例如，假设现在你要上地铁，奖励就是你所花的时间的相反数。一种策略就是车门一开就往上挤，但是还有很多人要下车，逆着人流往上挤也会花费不少时间，这个时候你花的总时间可能是：</p>
<ul>
<li>0秒钟等待时间+15秒挤上去的时间<br>
在接下来的一天，很巧合，你决定先让别人下车。虽然这个时候看起来等待的时间稍微增加了，但是下车的人也会下的更顺畅，这个时候你可能花的时间是：</li>
<li>5秒等待时间+0秒挤上去的时间。</li>
</ul>
<h3 id="理解"><a class="markdownIt-Anchor" href="#理解"></a> 理解</h3>
<p><strong>状态State</strong>和<strong>动作Action</strong>存在映射关系，也就是一个state可以对应一个action，或者对应不同动作的概率（常常用概率来表示，概率最高的就是最值得执行的动作）。状态与动作的关系其实就是输入与输出的关系，而状态State到动作Action的过程就称之为一个**策略Policy，**一般用π表示，也就是需要找到以下关系(其中a是action，s是state)：</p>
<p><strong>一一对应表示</strong>：a=π(s)</p>
<p><strong>概率表示</strong>：π(a|s)</p>
<h2 id="基本方法对比"><a class="markdownIt-Anchor" href="#基本方法对比"></a> 基本方法对比</h2>
<table>
<thead>
<tr>
<th>Method name</th>
<th>Net Classes Num</th>
<th>Net Num</th>
<th>Net types</th>
<th>Input</th>
<th>Output</th>
<th>Update method</th>
<th>Use Memory</th>
<th>Policy</th>
</tr>
</thead>
<tbody>
<tr>
<td>Q-L</td>
<td>0</td>
<td>0</td>
<td></td>
<td>state</td>
<td>values of actions</td>
<td>round update</td>
<td>F</td>
<td>OFF</td>
</tr>
<tr>
<td>SARSA</td>
<td>0</td>
<td>0</td>
<td></td>
<td>state</td>
<td>value of actions</td>
<td>round update</td>
<td>F</td>
<td>ON</td>
</tr>
<tr>
<td>DQN</td>
<td>1</td>
<td>2</td>
<td>target net &amp; Eval net</td>
<td>state</td>
<td>values of actions</td>
<td>round update</td>
<td>T</td>
<td></td>
</tr>
<tr>
<td>PG</td>
<td>1</td>
<td>1</td>
<td>policy net</td>
<td>state</td>
<td>prob of actions</td>
<td>round update</td>
<td>T</td>
<td></td>
</tr>
<tr>
<td>AC</td>
<td>2</td>
<td>2</td>
<td>actor net &amp; critic net</td>
<td>state</td>
<td>prob of actions &amp; rewards</td>
<td>step update</td>
<td>F</td>
<td>OFF</td>
</tr>
<tr>
<td>DDPG</td>
<td>2</td>
<td>4</td>
<td>(actor &amp; critic)x(target &amp; eval)</td>
<td>state &amp; (state, action)</td>
<td>continuous action value &amp;  reward</td>
<td>step update</td>
<td>T</td>
<td>OFF</td>
</tr>
</tbody>
</table>
<h3 id="规律与注解"><a class="markdownIt-Anchor" href="#规律与注解"></a> 规律与注解</h3>
<ul>
<li>只定义了一个网络类的方法都是回合制更新</li>
<li>除了DDPG其他方法的输入都是state</li>
<li>回合制更新也叫蒙特卡洛更新（<strong>Monte-carlo update</strong>），单步更新也叫当时差距更新（<strong>Temporal-difference update</strong>）</li>
</ul>
<h2 id="q-learning"><a class="markdownIt-Anchor" href="#q-learning"></a> Q-Learning</h2>
<h3 id="定义-2"><a class="markdownIt-Anchor" href="#定义-2"></a> 定义</h3>
<p><strong>Q-学习</strong>是强化学习的一种方法。Q-学习就是要学习的政策，告诉智能体什么情况下采取什么行动。Q-learning不需要对环境进行建模，即使是对带有随机因素的转移函数或者奖励函数也不需要进行特别的改动就可以进行。<br>
对于任何有限的<a href="https://zh.wikipedia.org/wiki/%E9%A6%AC%E5%8F%AF%E5%A4%AB%E6%B1%BA%E7%AD%96%E9%81%8E%E7%A8%8B" title="马可夫决策过程">马可夫决策过程</a>（FMDP），Q-learning可以找到一个可以最大化所有步骤的奖励期望的策略。<a href="https://zh.wikipedia.org/wiki/Q%E5%AD%A6%E4%B9%A0#cite_note-auto-1">[1]</a>，在给定一个部分随机的策略和无限的探索时间，Q-learning可以给出一个最佳的动作选择策略。“Q”这个字母在强化学习中表示一个动作的质量（quality )。<a href="https://zh.wikipedia.org/wiki/Q%E5%AD%A6%E4%B9%A0#cite_note-:0-2">[2]</a><br>
Q-Learning 最简单的实现方式就是将值存储在一个表格中，但是这种方式受限于状态和动作空间的数目。</p>
<p><strong>输入</strong>：状态（State）<br>
<strong>输出</strong>：该状态下可能采取的各种动作（Action）时对应的Q值</p>
<h3 id="算法"><a class="markdownIt-Anchor" href="#算法"></a> 算法</h3>
<p><img data-src="1*B8tGarFYboV9maL93sF45Q.png" alt></p>
<h2 id="sarsa"><a class="markdownIt-Anchor" href="#sarsa"></a> SARSA</h2>
<p>SARSA非常像Q-learning。SARSA和Q-learning的关键区别在于SARSA是一种on-policy算法。这意味着SARSA是根据当前策略执行的动作而不是贪婪策略来学习q值的。</p>
<p><strong>输入</strong>：状态（State）<br>
<strong>输出</strong>：该状态下可能采取的各种动作（Action）时对应的Q值</p>
<h3 id="算法-2"><a class="markdownIt-Anchor" href="#算法-2"></a> 算法</h3>
<p><img data-src="1*NdEQk3LeJfkzImOiQij_NA.png" alt></p>
<h2 id="dqn"><a class="markdownIt-Anchor" href="#dqn"></a> DQN</h2>
<p><strong>输入（1）</strong>：状态（State）</p>
<p><strong>输出（1）</strong>：该状态下可能采取的各种动作（Action）时对应的Q值</p>
<p><strong>输入（2）</strong>：状态（State）和动作（Action）</p>
<p><strong>输出（2）</strong>：该状态下采取该动作（Action）时对应的Q值</p>
<p><strong>目标</strong>：找到一个最优的策略Policy从而使Reward最多</p>
<p><strong>Loss</strong>：$$L(w)=E[(r+\gamma max_{a’}Q(s’,a’,w)-Q(s,a,w))^2]$$</p>
<p><strong>特点</strong>：</p>
<ol>
<li>不是直接输出当前状态下各动作的概率，每种动作都可能以其对应概率被选到，而是输出当前状态下选择各动作后带来的Q值，直接选择最大的，并随机以一定的可能性选择其他动作。</li>
<li>是一种 off-policy 离线学习法，它能学习当前经历着的, 也能学习过去经历过的, 甚至是学习别人的经历。</li>
</ol>
<p><strong>类比</strong>：Q表。这里的神经网络的功能就好比一个Q表，输入要查找的内容，输出相应值。</p>
<h3 id="原理图"><a class="markdownIt-Anchor" href="#原理图"></a> 原理图</h3>
<p><img data-src="006tKfTcgy1g0lby5lsouj30yi0k841d.jpg" alt></p>
<h3 id="算法-3"><a class="markdownIt-Anchor" href="#算法-3"></a> 算法</h3>
<p><img data-src="006tKfTcly1g0eb38iqwoj30y00rmq5g.jpg" alt="更新算法"></p>
<p><img data-src="006tKfTcly1g0e2yu8s6zj30cc06wmx6.jpg" alt="网络更新方法"></p>
<h3 id="为何使用两个网络"><a class="markdownIt-Anchor" href="#为何使用两个网络"></a> 为何使用两个网络？</h3>
<blockquote>
<p>The second modification to online Q-learning aimed at further improving the stability of our method with neural networks is to use a separate network for gen- erating the targets yj in the Q-learning update. More precisely, every C updates we clone the network Q to obtain a target network Q^ and use Q^ for generating the Q-learning targets yj for the following C updates to Q. This modification makes the algorithm more stable compared to standard online Q-learning, where an update that increases Q(st,at) often also increases Q(st 1 1,a) for all a and hence also increases the target yj, possibly leading to oscillations or divergence of the policy. Generating the targets using an older set of parameters adds a delay between the time an update to Q is made and the time the update affects the targets yj, making divergence or oscillations much more unlikely.</p>
</blockquote>
<p>简单地说，每隔一段时间copy一次Eval Net成为Target Net减小了每次更新带来的震动，即使得对<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><mo stretchy="false">(</mo><msub><mi>s</mi><mi>t</mi></msub><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Q(s_t,a)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">Q</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">a</span><span class="mclose">)</span></span></span></span>做出的更新不会马上影响到<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><mo stretchy="false">(</mo><msub><mi>s</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Q(s_{t+1},a)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">Q</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">a</span><span class="mclose">)</span></span></span></span></p>
<h3 id="工程实现关键点"><a class="markdownIt-Anchor" href="#工程实现关键点"></a> 工程实现关键点</h3>
<ol>
<li>DQN网络的更新方法：同时初始化两个定义相同的网络，一个是Target Net，一个是Eval Net。前者是作为Q值的目标值出现的一个网络，且其的更新较为落后，往往是Eval Net更新千百轮之后才把后者的参数完全拷贝一份到自身；而后者则是每次学习过程必更新，总是最新的网络参数，用作估计值。</li>
<li>有一个记忆库用来储存之前的记忆，每次训练时随机抽一个batch扔到网络里训练。</li>
<li>Fixed Q-targets和记忆库都是打乱经历相关性的机理，也使得神经网络更新更有效率。</li>
<li>刚初始化后的前面n轮是不用网络而完全随机预测的，并把结果存下来训练网络。</li>
</ol>
<h3 id="核心代码"><a class="markdownIt-Anchor" href="#核心代码"></a> 核心代码</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (t &gt; learning_starts <span class="keyword">and</span></span><br><span class="line">        t % learning_freq == <span class="number">0</span> <span class="keyword">and</span></span><br><span class="line">        replay_buffer.can_sample(batch_size)):</span><br><span class="line">    <span class="comment"># Use the replay buffer to sample a batch of transitions</span></span><br><span class="line">    <span class="comment"># Note: done_mask[i] is 1 if the next state corresponds to the end of an episode,</span></span><br><span class="line">    <span class="comment"># in which case there is no Q-value at the next state; at the end of an</span></span><br><span class="line">    <span class="comment"># episode, only the current state reward contributes to the target</span></span><br><span class="line">    obs_batch, act_batch, rew_batch, next_obs_batch, done_mask = replay_buffer.sample(batch_size)</span><br><span class="line">    <span class="comment"># Convert numpy nd_array to torch variables for calculation</span></span><br><span class="line">    obs_batch = Variable(torch.from_numpy(obs_batch).<span class="built_in">type</span>(dtype) / <span class="number">255.0</span>)</span><br><span class="line">    act_batch = Variable(torch.from_numpy(act_batch).long())</span><br><span class="line">    rew_batch = Variable(torch.from_numpy(rew_batch))</span><br><span class="line">    next_obs_batch = Variable(torch.from_numpy(next_obs_batch).<span class="built_in">type</span>(dtype) / <span class="number">255.0</span>)</span><br><span class="line">    not_done_mask = Variable(torch.from_numpy(<span class="number">1</span> - done_mask)).<span class="built_in">type</span>(dtype)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> USE_CUDA:</span><br><span class="line">        act_batch = act_batch.cuda()</span><br><span class="line">        rew_batch = rew_batch.cuda()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute current Q value, q_func takes only state and output value for every state-action pair</span></span><br><span class="line">    <span class="comment"># We choose Q based on action taken.</span></span><br><span class="line">    current_Q_values = Q(obs_batch).gather(<span class="number">1</span>, act_batch.unsqueeze(<span class="number">1</span>))</span><br><span class="line">    <span class="comment"># Compute next Q value based on which action gives max Q values</span></span><br><span class="line">    <span class="comment"># Detach variable from the current graph since we don&#x27;t want gradients for next Q to propagated</span></span><br><span class="line">    next_max_q = target_Q(next_obs_batch).detach().<span class="built_in">max</span>(<span class="number">1</span>)[<span class="number">0</span>]</span><br><span class="line">    next_Q_values = not_done_mask * next_max_q</span><br><span class="line">    <span class="comment"># Compute the target of the current Q values</span></span><br><span class="line">    target_Q_values = rew_batch + (gamma * next_Q_values)</span><br><span class="line">    <span class="comment"># Compute Bellman error</span></span><br><span class="line">    bellman_error = target_Q_values - current_Q_values</span><br><span class="line">    <span class="comment"># clip the bellman error between [-1 , 1]</span></span><br><span class="line">    clipped_bellman_error = bellman_error.clamp(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="comment"># Note: clipped_bellman_delta * -1 will be right gradient</span></span><br><span class="line">    d_error = clipped_bellman_error * -<span class="number">1.0</span></span><br><span class="line">    <span class="comment"># Clear previous gradients before backward pass</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    <span class="comment"># run backward pass</span></span><br><span class="line">    current_Q_values.backward(d_error.data.unsqueeze(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Perfom the update</span></span><br><span class="line">    optimizer.step()</span><br><span class="line">    num_param_updates += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Periodically update the target network by Q network to target Q network</span></span><br><span class="line">    <span class="keyword">if</span> num_param_updates % target_update_freq == <span class="number">0</span>:</span><br><span class="line">        target_Q.load_state_dict(Q.state_dict())</span><br></pre></td></tr></table></figure>
<h2 id="policy-gradient"><a class="markdownIt-Anchor" href="#policy-gradient"></a> Policy Gradient</h2>
<p><strong>输入</strong>： 状态（State）</p>
<p><strong>输出</strong>：直接是动作（Action）（而非Q值）</p>
<p><strong>公式</strong>：a=π(s, θ) 或 a=π(a|s, θ)</p>
<p><strong>特点</strong>：输出的直接是当前状态下采取各种可能动作的概率。每种动作都可能以其对应概率被选到。另外其相对于基于值的算法如DQN而言可以handle较多action，尤其是连续action空间的问题。</p>
<p><strong>Loss</strong>：$$loss=-log(prob(action))*reward$$</p>
<h3 id="核心代码-2"><a class="markdownIt-Anchor" href="#核心代码-2"></a> 核心代码</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Policy</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Policy, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.state_space = state_space</span><br><span class="line">        self.action_space = action_space</span><br><span class="line"></span><br><span class="line">        self.fc1 = nn.Linear(self.state_space, <span class="number">128</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">128</span>, self.action_space)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.fc1(x)</span><br><span class="line">        <span class="comment">#x = F.dropout(x, 0.5)</span></span><br><span class="line">        x = F.relu(x)</span><br><span class="line">        x = F.softmax(self.fc2(x), dim=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">policy = Policy()</span><br><span class="line">optimizer = torch.optim.Adam(policy.parameters(), lr=learning_rate)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>():</span><br><span class="line"></span><br><span class="line">    episode_durations = []</span><br><span class="line">    <span class="comment">#Batch_history</span></span><br><span class="line">    state_pool = []</span><br><span class="line">    action_pool = []</span><br><span class="line">    reward_pool = []</span><br><span class="line">    steps = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> episode <span class="keyword">in</span> <span class="built_in">range</span>(num_episode):</span><br><span class="line">        state = env.reset()</span><br><span class="line">        state = torch.from_numpy(state).<span class="built_in">float</span>()</span><br><span class="line">        state = Variable(state)</span><br><span class="line"></span><br><span class="line">        env.render()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> count():</span><br><span class="line">            probs = policy(state)</span><br><span class="line">            c = Categorical(probs)</span><br><span class="line">            action = c.sample()</span><br><span class="line"></span><br><span class="line">            action = action.data.numpy().astype(<span class="string">&#x27;int32&#x27;</span>)</span><br><span class="line">            next_state, reward, done, info = env.step(action)</span><br><span class="line">            reward = <span class="number">0</span> <span class="keyword">if</span> done <span class="keyword">else</span> reward <span class="comment"># correct the reward</span></span><br><span class="line">            env.render()</span><br><span class="line"></span><br><span class="line">            state_pool.append(state)</span><br><span class="line">            action_pool.append(<span class="built_in">float</span>(action))</span><br><span class="line">            reward_pool.append(reward)</span><br><span class="line"></span><br><span class="line">            state = next_state</span><br><span class="line">            state = torch.from_numpy(state).<span class="built_in">float</span>()</span><br><span class="line">            state = Variable(state)</span><br><span class="line"></span><br><span class="line">            steps += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> done:</span><br><span class="line">                episode_durations.append(t+<span class="number">1</span>)</span><br><span class="line">                plot_durations(episode_durations)</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># update policy</span></span><br><span class="line">        <span class="keyword">if</span> episode &gt;<span class="number">0</span> <span class="keyword">and</span> episode % batch_size == <span class="number">0</span>:</span><br><span class="line"></span><br><span class="line">            r = <span class="number">0</span></span><br><span class="line">            <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">            for i in reversed(range(steps)):</span></span><br><span class="line"><span class="string">                if reward_pool[i] == 0:</span></span><br><span class="line"><span class="string">                    running_add = 0</span></span><br><span class="line"><span class="string">                else:</span></span><br><span class="line"><span class="string">                    running_add = running_add * gamma +reward_pool[i]</span></span><br><span class="line"><span class="string">                    reward_pool[i] = running_add</span></span><br><span class="line"><span class="string">            &#x27;&#x27;&#x27;</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">reversed</span>(<span class="built_in">range</span>(steps)):</span><br><span class="line">                <span class="keyword">if</span> reward_pool[i] == <span class="number">0</span>:</span><br><span class="line">                    r = <span class="number">0</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    r = r * gamma + reward_pool[i]</span><br><span class="line">                    reward_pool[i] = r</span><br><span class="line"></span><br><span class="line">            <span class="comment">#Normalize reward</span></span><br><span class="line">            reward_mean = np.mean(reward_pool)</span><br><span class="line">            reward_std = np.std(reward_pool)</span><br><span class="line">            reward_pool = (reward_pool-reward_mean)/reward_std</span><br><span class="line"></span><br><span class="line">            <span class="comment">#gradiend desent</span></span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(steps):</span><br><span class="line">                state = state_pool[i]</span><br><span class="line">                action = Variable(torch.FloatTensor([action_pool[i]]))</span><br><span class="line">                reward = reward_pool[i]</span><br><span class="line"></span><br><span class="line">                probs = policy(state)</span><br><span class="line">                c = Categorical(probs)</span><br><span class="line"></span><br><span class="line">                loss = -c.log_prob(action) * reward</span><br><span class="line">                loss.backward()</span><br><span class="line"></span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># clear the batch pool</span></span><br><span class="line">            state_pool = []</span><br><span class="line">            action_pool = []</span><br><span class="line">            reward_pool = []</span><br><span class="line">            steps = <span class="number">0</span></span><br></pre></td></tr></table></figure>
<h2 id="actor-critic"><a class="markdownIt-Anchor" href="#actor-critic"></a> Actor Critic</h2>
<h3 id="定义-3"><a class="markdownIt-Anchor" href="#定义-3"></a> 定义</h3>
<p>结合了 Policy Gradient (Actor) 和 Function Approximation (Critic) 的方法. <code>Actor</code>基于概率选行为, <code>Critic</code> 基于 <code>Actor</code> 的行为评判行为的得分, <code>Actor</code> 根据 <code>Critic</code> 的评分修改选行为的概率。简单说，相对于单纯的Policy Gradient，其不再使用回合制更新网络，而是逐步更新网络。而每一步的reward则是由critic网络给出。</p>
<h3 id="优势"><a class="markdownIt-Anchor" href="#优势"></a> 优势</h3>
<p>可以进行单步更新, 比传统的 Policy Gradient 要快。</p>
<h3 id="劣势"><a class="markdownIt-Anchor" href="#劣势"></a> 劣势</h3>
<p>取决于 Critic 的价值判断, 但是 Critic 难收敛, 再加上 Actor 的更新, 就更难收敛. 为了解决收敛问题。</p>
<h3 id="actor-net"><a class="markdownIt-Anchor" href="#actor-net"></a> Actor Net</h3>
<p><strong>输入</strong>：状态（State）<br>
<strong>输出</strong>：动作（Action）</p>
<h3 id="critic-net"><a class="markdownIt-Anchor" href="#critic-net"></a> Critic Net</h3>
<p><strong>输入</strong>：状态（State）<br>
<strong>输出</strong>：评价（Reward）</p>
<h3 id="loss"><a class="markdownIt-Anchor" href="#loss"></a> Loss:</h3>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>L</mi><mi>o</mi><mi>s</mi><mi>s</mi><mo stretchy="false">(</mo><mi>p</mi><mi>o</mi><mi>l</mi><mi>i</mi><mi>c</mi><mi>y</mi><mi mathvariant="normal">/</mi><mi>a</mi><mi>c</mi><mi>t</mi><mi>o</mi><mi>r</mi><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><mi>l</mi><mi>o</mi><mi>g</mi><mtext> </mtext><mi>p</mi><mi>r</mi><mi>o</mi><mi>b</mi><mo>∗</mo><mo stretchy="false">(</mo><mi>r</mi><mi>e</mi><mi>w</mi><mi>a</mi><mi>r</mi><mi>d</mi><mo>−</mo><mi>c</mi><mi>r</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>c</mi><mtext> </mtext><mi>v</mi><mi>a</mi><mi>l</mi><mi>u</mi><mi>e</mi><mo stretchy="false">)</mo><mspace linebreak="newline"></mspace><mi>L</mi><mi>o</mi><mi>s</mi><mi>s</mi><mo stretchy="false">(</mo><mi>c</mi><mi>r</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>c</mi><mo stretchy="false">)</mo><mo>=</mo><mi>E</mi><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>r</mi><mi>e</mi><mi>w</mi><mi>a</mi><mi>r</mi><mi>d</mi><mo>−</mo><mi>c</mi><mi>r</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>c</mi><mtext> </mtext><mi>v</mi><mi>a</mi><mi>l</mi><mi>u</mi><mi>e</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">Loss(policy/actor)=-log\space prob * (reward-critic\space value)\\
Loss(critic)=E[(reward-critic\space value)^2]
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">L</span><span class="mord mathnormal">o</span><span class="mord mathnormal">s</span><span class="mord mathnormal">s</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">i</span><span class="mord mathnormal">c</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord">/</span><span class="mord mathnormal">a</span><span class="mord mathnormal">c</span><span class="mord mathnormal">t</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord">−</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mspace"> </span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">o</span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">d</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">c</span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">u</span><span class="mord mathnormal">e</span><span class="mclose">)</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">L</span><span class="mord mathnormal">o</span><span class="mord mathnormal">s</span><span class="mord mathnormal">s</span><span class="mopen">(</span><span class="mord mathnormal">c</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">c</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mopen">[</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">d</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.1141079999999999em;vertical-align:-0.25em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">c</span><span class="mspace"> </span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">u</span><span class="mord mathnormal">e</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span></span></p>
<h3 id="核心代码-3"><a class="markdownIt-Anchor" href="#核心代码-3"></a> 核心代码</h3>
<p><strong>注意虽然看似只写了一个网络，但是因为AC网络的输入相同输出不同，只要最后有两个不同的fc层即可。</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> gym, os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> count</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> namedtuple</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.distributions <span class="keyword">import</span> Categorical</span><br><span class="line"></span><br><span class="line"><span class="comment">#Parameters</span></span><br><span class="line">env = gym.make(<span class="string">&#x27;CartPole-v0&#x27;</span>)</span><br><span class="line">env = env.unwrapped</span><br><span class="line"></span><br><span class="line">env.seed(<span class="number">1</span>)</span><br><span class="line">torch.manual_seed(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">state_space = env.observation_space.shape[<span class="number">0</span>]</span><br><span class="line">action_space = env.action_space.n</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#Hyperparameters</span></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">gamma = <span class="number">0.99</span></span><br><span class="line">episodes = <span class="number">20000</span></span><br><span class="line">render = <span class="literal">False</span></span><br><span class="line">eps = np.finfo(np.float32).eps.item()</span><br><span class="line">SavedAction = namedtuple(<span class="string">&#x27;SavedAction&#x27;</span>, [<span class="string">&#x27;log_prob&#x27;</span>, <span class="string">&#x27;value&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Policy</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Policy, self).__init__()</span><br><span class="line">        self.fc1 = nn.Linear(state_space, <span class="number">32</span>)</span><br><span class="line"></span><br><span class="line">        self.action_head = nn.Linear(<span class="number">32</span>, action_space)</span><br><span class="line">        self.value_head = nn.Linear(<span class="number">32</span>, <span class="number">1</span>) <span class="comment"># Scalar Value</span></span><br><span class="line"></span><br><span class="line">        self.save_actions = []</span><br><span class="line">        self.rewards = []</span><br><span class="line">        os.makedirs(<span class="string">&#x27;./AC_CartPole-v0&#x27;</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        action_score = self.action_head(x)</span><br><span class="line">        state_value = self.value_head(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> F.softmax(action_score, dim=-<span class="number">1</span>), state_value</span><br><span class="line"></span><br><span class="line">model = Policy()</span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot</span>(<span class="params">steps</span>):</span><br><span class="line">    ax = plt.subplot(<span class="number">111</span>)</span><br><span class="line">    ax.cla()</span><br><span class="line">    ax.grid()</span><br><span class="line">    ax.set_title(<span class="string">&#x27;Training&#x27;</span>)</span><br><span class="line">    ax.set_xlabel(<span class="string">&#x27;Episode&#x27;</span>)</span><br><span class="line">    ax.set_ylabel(<span class="string">&#x27;Run Time&#x27;</span>)</span><br><span class="line">    ax.plot(steps)</span><br><span class="line">    RunTime = <span class="built_in">len</span>(steps)</span><br><span class="line"></span><br><span class="line">    path = <span class="string">&#x27;./AC_CartPole-v0/&#x27;</span> + <span class="string">&#x27;RunTime&#x27;</span> + <span class="built_in">str</span>(RunTime) + <span class="string">&#x27;.jpg&#x27;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(steps) % <span class="number">200</span> == <span class="number">0</span>:</span><br><span class="line">        plt.savefig(path)</span><br><span class="line">    plt.pause(<span class="number">0.0000001</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">select_action</span>(<span class="params">state</span>):</span><br><span class="line">    state = torch.from_numpy(state).<span class="built_in">float</span>()</span><br><span class="line">    probs, state_value = model(state)</span><br><span class="line">    m = Categorical(probs)</span><br><span class="line">    action = m.sample()</span><br><span class="line">    model.save_actions.append(SavedAction(m.log_prob(action), state_value))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> action.item()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">finish_episode</span>():</span><br><span class="line">    R = <span class="number">0</span></span><br><span class="line">    save_actions = model.save_actions</span><br><span class="line">    policy_loss = []</span><br><span class="line">    value_loss = []</span><br><span class="line">    rewards = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> r <span class="keyword">in</span> model.rewards[::-<span class="number">1</span>]:</span><br><span class="line">        R = r + gamma * R</span><br><span class="line">        rewards.insert(<span class="number">0</span>, R)</span><br><span class="line"></span><br><span class="line">    rewards = torch.tensor(rewards)</span><br><span class="line">    rewards = (rewards - rewards.mean()) / (rewards.std() + eps)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (log_prob , value), r <span class="keyword">in</span> <span class="built_in">zip</span>(save_actions, rewards):</span><br><span class="line">        reward = r - value.item()</span><br><span class="line">        policy_loss.append(-log_prob * reward)</span><br><span class="line">        value_loss.append(F.smooth_l1_loss(value, torch.tensor([r])))</span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss = torch.stack(policy_loss).<span class="built_in">sum</span>() + torch.stack(value_loss).<span class="built_in">sum</span>()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">del</span> model.rewards[:]</span><br><span class="line">    <span class="keyword">del</span> model.save_actions[:]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    running_reward = <span class="number">10</span></span><br><span class="line">    live_time = []</span><br><span class="line">    <span class="keyword">for</span> i_episode <span class="keyword">in</span> count(episodes):</span><br><span class="line">        state = env.reset()</span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> count():</span><br><span class="line">            action = select_action(state)</span><br><span class="line">            state, reward, done, info = env.step(action)</span><br><span class="line">            <span class="keyword">if</span> render: env.render()</span><br><span class="line">            model.rewards.append(reward)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> done <span class="keyword">or</span> t &gt;= <span class="number">1000</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        running_reward = running_reward * <span class="number">0.99</span> + t * <span class="number">0.01</span></span><br><span class="line">        live_time.append(t)</span><br><span class="line">        plot(live_time)</span><br><span class="line">        <span class="keyword">if</span> i_episode % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            modelPath = <span class="string">&#x27;./AC_CartPole_Model/ModelTraing&#x27;</span>+<span class="built_in">str</span>(i_episode)+<span class="string">&#x27;Times.pkl&#x27;</span></span><br><span class="line">            torch.save(model, modelPath)</span><br><span class="line">        finish_episode()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<h2 id="ddpg"><a class="markdownIt-Anchor" href="#ddpg"></a> DDPG</h2>
<h3 id="定义-4"><a class="markdownIt-Anchor" href="#定义-4"></a> 定义</h3>
<p><strong>输入</strong>： 状态（State）</p>
<p><strong>输出</strong>：直接是动作（Action）（而非Q值）</p>
<p><strong>公式</strong>：a=π(s, θ) 或 a=π(a|s, θ)</p>
<p><strong>特点</strong>：输出的直接是当前状态下采取各种可能动作的概率。每种动作都可能以其对应概率被选到。</p>
<p><strong>应用场景</strong>：连续行为场景</p>
<h3 id="由来"><a class="markdownIt-Anchor" href="#由来"></a> 由来</h3>
<p>在RL领域，DDPG主要从：PG -&gt; DPG -&gt; DDPG 发展而来。<br>
Deepmind在2016年提出DDPG，全称是：Deep Deterministic Policy Gradient,是将深度学习神经网络融合进DPG的策略学习方法。<br>
相对于DPG的核心改进是： 采用卷积神经网络作为策略函数μ和Q函数的模拟，即策略网络和Q网络；然后使用深度学习的方法来训练上述神经网络。<br>
Q函数的实现和训练方法，采用了Deepmind 2015年发表的DQN方法。</p>
<h3 id="原理图-2"><a class="markdownIt-Anchor" href="#原理图-2"></a> 原理图</h3>
<p><img data-src="006tKfTcgy1g0lbvxv1tnj30y40kojrs.jpg" alt></p>
<p><img data-src="006tNc79ly1g23g4gt1wdj31760u0k7h.jpg" alt></p>
<h3 id="算法-4"><a class="markdownIt-Anchor" href="#算法-4"></a> 算法</h3>
<p><img data-src="006tKfTcgy1g0lbwow8guj31590u0n12.jpg" alt></p>
]]></content>
      <tags>
        <tag>machine-learning</tag>
        <tag>deep-learning</tag>
        <tag>reinforcement-learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Analyzing Geography Data (Beginners&#39; Tutorial)</title>
    <url>/2021/02/03/satellite-basic/</url>
    <content><![CDATA[<h2 id="数据来源"><a class="markdownIt-Anchor" href="#数据来源"></a> 数据来源</h2>
<h3 id="卫星类型"><a class="markdownIt-Anchor" href="#卫星类型"></a> 卫星类型</h3>
<ol>
<li>
<p>Sentinel-2：提供混合分辨率的13 Bands MSI。分辨率有<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>10</mn><mi>m</mi><mo>×</mo><mn>10</mn><mi>m</mi></mrow><annotation encoding="application/x-tex">10m \times 10m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mord">0</span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">0</span><span class="mord mathnormal">m</span></span></span></span>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>20</mn><mi>m</mi><mo>×</mo><mn>20</mn><mi>m</mi></mrow><annotation encoding="application/x-tex">20m \times 20m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">2</span><span class="mord">0</span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord">0</span><span class="mord mathnormal">m</span></span></span></span>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>60</mn><mi>m</mi><mo>×</mo><mn>60</mn><mi>m</mi></mrow><annotation encoding="application/x-tex">60m \times 60m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">6</span><span class="mord">0</span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">6</span><span class="mord">0</span><span class="mord mathnormal">m</span></span></span></span>，bands中心波长从442.3nm到2185.7nm。</p>
<img data-src="image-20201213154533413.png" alt="image-20201213154533413" style="zoom:33%;">
<span id="more"></span>
</li>
<li>
<p>Planet：这个数据源提供<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mi>m</mi><mo>×</mo><mn>3</mn><mi>m</mi></mrow><annotation encoding="application/x-tex">3m \times 3m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">3</span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span><span class="mord mathnormal">m</span></span></span></span>的4 bands MSI image。分别是R、G、B、NIR。</p>
<ul>
<li>这个数据源似乎只对美国国内的院校机构开放，不过不是很确定，需要的可以试试。</li>
</ul>
<p><img data-src="image-20201213150111581.png" alt="Planet Specification"></p>
</li>
<li>
<p>RapidEyes</p>
</li>
</ol>
<h3 id="sentinel-2-data-source"><a class="markdownIt-Anchor" href="#sentinel-2-data-source"></a> Sentinel-2 Data Source</h3>
<ol>
<li>
<p>USGS Earth Explorer: <a href="https://earthexplorer.usgs.gov/">Link</a>. It support downloading data within five years. And it not only support sentinel-2 data, but also contains many other satellite datasource.</p>
<p><img data-src="image-20201227143234319.png" alt="image-20201227143234319"></p>
</li>
<li>
<p>Copernicus Open Access Hub: <a href="https://scihub.copernicus.eu/dhus/#/home">Link</a>. It supports only one year’s old data. You can request the older data, but not guarante the fetch time.</p>
<p><img data-src="image-20201227145324164.png" alt="image-20201227145324164"></p>
</li>
<li>
<p>Amazon AWS Sentinel-2 Service: <a href="https://registry.opendata.aws/sentinel-2/">Link</a></p>
</li>
</ol>
<h3 id="planet-data-source"><a class="markdownIt-Anchor" href="#planet-data-source"></a> Planet Data Source</h3>
<ul>
<li>官网：<a href="https://www.planet.com/">Link</a></li>
</ul>
<h3 id="specification"><a class="markdownIt-Anchor" href="#specification"></a> Specification</h3>
<ol>
<li><a href="https://sentinel.esa.int/web/sentinel/technical-guides/sentinel-2-msi/msi-instrument">Sentinel-2 MultiSpectral Instrument (MSI) Overview</a></li>
<li><a href="https://www.planet.com/products/satellite-imagery/files/Planet_Combined_Imagery_Product_Specs_December2017.pdf">Sentinel-2 Specification Doc</a></li>
<li><a href="https://www.planet.com/products/planet-imagery/">Planet Specification</a></li>
</ol>
<h2 id="软件与python包简介"><a class="markdownIt-Anchor" href="#软件与python包简介"></a> 软件与Python包简介</h2>
<ul>
<li><a href="http://www.gdal.org/">GDAL</a> –&gt; Fundamental package for processing vector and raster data formats (many modules below depend on this). Used for raster processing.</li>
<li><a href="https://github.com/mapbox/rasterio">Rasterio</a> –&gt; Clean and fast and geospatial raster I/O for Python. <a href="https://rasterio.readthedocs.io/en/latest/quickstart.html">Guidebook</a>.</li>
<li><a href="http://geopandas.org/#description">Geopandas</a> –&gt; Working with geospatial data in Python made easier, combines the capabilities of pandas and shapely.</li>
<li><a href="http://toblerity.org/shapely/manual.html">Shapely</a> –&gt; Python package for manipulation and analysis of planar geometric objects (based on widely deployed <a href="https://trac.osgeo.org/geos/">GEOS</a>).</li>
<li><a href="https://pypi.python.org/pypi/Fiona">Fiona</a> –&gt; Reading and writing spatial data (alternative for geopandas).</li>
<li><a href="https://pypi.python.org/pypi/pyproj?">Pyproj</a> –&gt; Performs cartographic transformations and geodetic computations (based on <a href="http://trac.osgeo.org/proj">PROJ.4</a>).</li>
<li><a href="https://pysal.readthedocs.org/en/latest/">Pysal</a> –&gt; Library of spatial analysis functions written in Python.</li>
<li><a href="http://geopy.readthedocs.io/en/latest/">Geopy</a> –&gt; Geocoding library: coordinates to address &lt;-&gt; address to coordinates.</li>
<li><a href="http://geo.holoviews.org/index.html">GeoViews</a> –&gt; Interactive Maps for the web.</li>
<li><a href="https://networkx.github.io/documentation/networkx-1.10/overview.html">Networkx</a> –&gt; Network analysis and routing in Python (e.g. Dijkstra and A* -algorithms), see <a href="http://gis.stackexchange.com/questions/65056/is-it-possible-to-route-shapefiles-using-python-and-without-arcgis-qgis-or-pgr">this post</a>.</li>
<li><a href="http://scitools.org.uk/cartopy/docs/latest/index.html">Cartopy</a> –&gt; Make drawing maps for data analysis and visualisation as easy as possible.</li>
<li><a href="http://docs.scipy.org/doc/scipy/reference/spatial.html">Scipy.spatial</a> –&gt; Spatial algorithms and data structures.</li>
<li><a href="http://toblerity.org/rtree/">Rtree</a> –&gt; Spatial indexing for Python for quick spatial lookups.</li>
<li><a href="http://www.rsgislib.org/index.html#python-documentation">RSGISLib</a> –&gt; Remote Sensing and GIS Software Library for Python.</li>
<li><a href="https://python-geojson.readthedocs.io/en/latest/">python-geojson</a>-&gt; Deal with geojson format files.</li>
</ul>
<h2 id="sentinel-2-大气校正"><a class="markdownIt-Anchor" href="#sentinel-2-大气校正"></a> Sentinel-2 大气校正</h2>
<p>Sentinel-2一般有两种standard，一个是A级别，一个是C级别。C级别的数据是你可以从任意网站上下载到的数据，它没有经过大气校正，是粗数据，每个区块的反射率可能有不同，不适合直接用作深度学习数据。</p>
<p>经过Sen2Cor软件校正后可以得到A级别的数据。</p>
<p>Sen2Cor是欧空局发布的一个软件，它即可以作为SNAP的插件安装，也可以作为独立命令行软件使用。推荐后者，更为快速、稳定，尤其适用于大量数据时，可以用脚本批处理。<a href="http://step.esa.int/main/snap-supported-plugins/sen2cor/sen2cor_v2-8/">官网链接</a></p>
<h3 id="查询坐标映射"><a class="markdownIt-Anchor" href="#查询坐标映射"></a> 查询坐标映射</h3>
<ul>
<li>地球是圆的。</li>
<li>卫星上拍的一张矩形照片所对应的区域并非是矩形的。</li>
<li>使用卫星图片时要先将其映射到二维展开的坐标系中。</li>
<li>整个地球被分为了许多预先订好的区域。</li>
<li>每个区域有一个编号。</li>
<li>编号可以在<a href="http://epsg.io/">EPSG</a>网站查询。</li>
</ul>
<h2 id="snap"><a class="markdownIt-Anchor" href="#snap"></a> SNAP</h2>
<ul>
<li>
<p>欧空局自己用作处理Sentinel-2的软件。<a href="https://step.esa.int/main/download/snap-download/">Link</a></p>
</li>
<li>
<p>只用来处理Sentinel-2，尤其是预处理，包括校正，reprojection，粗crop，统一各个bands分辨率等等，非常好用。因为是亲儿子，所以甚至可以直接读取Sentinel-2每个文件的压缩包，总之十分便利。</p>
</li>
<li>
<p>比较古老，interface有年代感，功能也相较于其他软件比较局限。</p>
</li>
<li>
<p>推荐用作第一步预处理。</p>
</li>
<li>
<p>使用流程：<code>读取-&gt;剪裁-&gt;correction-&gt;resize-&gt;reprojection-&gt;导出</code>。</p>
</li>
<li>
<p>大部分需要用到的功能都在<code>Raster-&gt;Geometric</code>中</p>
</li>
<li>
<p>经过尝试、搜索、确认，SNAP并不提供便利的选定区域截图，或是依据shapefile剪裁，所以目前最佳的方法是，先通过zoom地图和改变窗口大小确保需要的部分大致在view的可视范围内，然后右键，选择<code>Spatial Subset from View</code>，然后可视区域即可被剪裁。注意，这只是粗剪裁，所以尽量多包括一点，也不要少任何一部分。剪裁后的内容可以后续在ArcGIS Pro中进一步处理。</p>
<img data-src="image-20201227155911702.png" alt="image-20201227155911702" style="zoom:40%;">
</li>
<li>
<p>展示图：</p>
<img data-src="image-20201227155421761.png" alt="image-20201227155421761" style="zoom:33%;">
<p><img data-src="image-20201227155558109.png" alt="image-20201227155558109"></p>
</li>
</ul>
<h2 id="arcgis-pro"><a class="markdownIt-Anchor" href="#arcgis-pro"></a> ArcGIS Pro</h2>
<ul>
<li>
<p>我能找到的最强大的可用于卫星图像处理的软件。</p>
</li>
<li>
<p>专业，美观，支持format多，有着强大的raster functions。</p>
</li>
<li>
<p>版权软件，下载之前先确认自己学校或公司是否提供License。</p>
</li>
<li>
<p>有时导出raster会出现随机bug，导致：导出可能是纯黑的图片，导出部分没有按照期望剪裁等。很恶心，但似乎也没有更好的选择。</p>
</li>
<li>
<p>解决导出问题：</p>
<ol>
<li>关闭导出窗口，重新操作，多试几次。可以解决绝大部分问题。</li>
<li>和剪裁、mask等有关的问题可以先使用raster function进行这些操作，再直接导出前面操作的结果layer。</li>
</ol>
</li>
<li>
<p>关于剪裁后的卫星图片和原始图片有着明显亮度对比度区别的问题：</p>
<ol>
<li>
<p>首先，这不是一个bug，而是一个feature。。。实际上的卫星图都很暗沉的，所以软件原生提供一个“显示方法”的函数，调整图片曲线，使得显示的图片比较亮，容易看清楚细节。然而，剪裁后的图片有着不一样的统计值，所以在有些显示函数下，显示的结果和剪裁前结果不同。</p>
<img data-src="image-20201227155342029.png" alt="image-20201227155342029" style="zoom:33%;">
</li>
<li>
<p>但是不用担心，因为导出时候并不会考虑这个显示函数。即：剪裁前后的导出图像数值是相同的。</p>
</li>
</ol>
</li>
<li>
<p>下面是两张展示图：</p>
</li>
</ul>
<p><img data-src="image-20201227155051608.png" alt="image-20201227155051608"></p>
<p><img data-src="image-20201227155259214.png" alt="image-20201227155259214"></p>
<h2 id="qgis"><a class="markdownIt-Anchor" href="#qgis"></a> QGIS</h2>
<ul>
<li>
<p>开源软件，支持很多插件，比如直接下载Sentinel-2数据，Sen2Cor等。<a href="https://qgis.org/en/site/">Link</a></p>
</li>
<li>
<p>支持很多format的数据。</p>
</li>
<li>
<p>问题是，不稳定，效率低，容易崩溃（软件&amp;心态），甚至左侧Explorer遇到大文件夹都要经常转很久才能进去，或是干脆就直接转崩了。我怀疑他们要分析每个文件夹所有文件之后再显示列表。。。总之，慎重。</p>
<p><img data-src="image-20201227160344273.png" alt="image-20201227160344273"></p>
</li>
</ul>
<h2 id="pythonic-method"><a class="markdownIt-Anchor" href="#pythonic-method"></a> Pythonic Method</h2>
<p>虽然前面介绍了几个软件，但是说实话，处理一两个可以，批量处理几十几百甚至几十万就有点力不从心了。所以最后还是狠下心研究了一遍Python处理这些数据的方法，写出了一批适合我项目用的函数。不一定适合所有人，但可以作为参考：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> geopandas <span class="keyword">as</span> gpd</span><br><span class="line"><span class="keyword">from</span> shapely.geometry <span class="keyword">import</span> Point, LineString, Polygon</span><br><span class="line"><span class="keyword">import</span> rasterio <span class="keyword">as</span> rio</span><br><span class="line"><span class="keyword">from</span> rasterio.mask <span class="keyword">import</span> mask</span><br><span class="line"><span class="keyword">from</span> rasterio.warp <span class="keyword">import</span> calculate_default_transform, reproject, Resampling</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">bbox</span>(<span class="params">shp</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; Compute the bounding box of a certain shapefile.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    piece = np.array([i.bounds <span class="keyword">for</span> i <span class="keyword">in</span> shp[<span class="string">&#x27;geometry&#x27;</span>]])</span><br><span class="line">    minx = piece[:,<span class="number">0</span>].<span class="built_in">min</span>()</span><br><span class="line">    miny = piece[:,<span class="number">1</span>].<span class="built_in">min</span>()</span><br><span class="line">    maxx = piece[:,<span class="number">2</span>].<span class="built_in">max</span>()</span><br><span class="line">    maxy = piece[:,<span class="number">3</span>].<span class="built_in">max</span>()</span><br><span class="line">    <span class="keyword">return</span> minx, miny, maxx, maxy</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">edge_length</span>(<span class="params">shp</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; Compute the x and y edge length for a ceratin shapefile.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    minx, miny, maxx, maxy = bbox(shp)</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">round</span>(maxx-minx,<span class="number">3</span>), <span class="built_in">round</span>(maxy-miny,<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">shape2latlong</span>(<span class="params">shp</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; Turn the shapefile unit from meters/other units to lat/long.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> shp.to_crs(epsg=<span class="number">4326</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">bbox_latlong</span>(<span class="params">shp</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; Compute the latitude-longitude bounding box of a certain shapefile.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    shp = shape2latlong(shp)</span><br><span class="line">    <span class="keyword">return</span> bbox(shp)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">bbox_polygon</span>(<span class="params">shp</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; Return the rectangular Polygon bounding box of a certain shapefile.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    minx, miny, maxx, maxy = bbox(shp)</span><br><span class="line">    <span class="keyword">return</span> Polygon([(minx, miny), (minx, maxy), (maxx,maxy), (maxx, miny)])</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">merge_polygon</span>(<span class="params">shp</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; Merge a shapefile to one single polygon.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> shp.dissolve(by=<span class="string">&#x27;Id&#x27;</span>).iloc[<span class="number">0</span>].geometry</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">polygon2geojson</span>(<span class="params">polygon</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; Turn a polygon to a geojson format string.</span></span><br><span class="line"><span class="string">        This is used for rasterio mask operation.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">type</span>(polygon) == Polygon:</span><br><span class="line">        polygon = gpd.GeoSeries(polygon)</span><br><span class="line">    <span class="keyword">return</span> [json.loads(polygon.to_json())[<span class="string">&#x27;features&#x27;</span>][<span class="number">0</span>][<span class="string">&#x27;geometry&#x27;</span>]]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sen2rgb</span>(<span class="params">img, scale=<span class="number">30</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; Turn the 12 channel float32 format sentinel-2 images to a RGB uint8 image. </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> (img[(<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>),]/<span class="number">256</span>*scale).astype(np.uint8)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cropbyshp</span>(<span class="params">raster, shp</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; Crop a raster using a shapefile.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Reproject the shapefile to the same crs of raster.</span></span><br><span class="line">    shp = shp.to_crs(&#123;<span class="string">&quot;init&quot;</span>: <span class="built_in">str</span>(raster.crs)&#125;)</span><br><span class="line">    <span class="comment"># Compute the rectangular Polygon bounding box of a certain shapefile.</span></span><br><span class="line">    bbpoly = bbox_polygon(shp)</span><br><span class="line">    <span class="comment"># Execute the mask operation.</span></span><br><span class="line">    out_img, out_transform = mask(dataset=raster, shapes=polygon2geojson(bbpoly), crop=<span class="literal">True</span>, all_touched=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> out_img</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">write_raster</span>(<span class="params">raster, path</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; Write a created raster object to file.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">with</span> rio.<span class="built_in">open</span>(</span><br><span class="line">        path,</span><br><span class="line">        <span class="string">&#x27;w&#x27;</span>,</span><br><span class="line">        **raster.meta</span><br><span class="line">    ) <span class="keyword">as</span> dst:</span><br><span class="line">        dst.write(raster.read())</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sen_reproject</span>(<span class="params">src, dst_crs, out_path</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; Reproject a raster to a new CRS coordinate, and save it in out_path.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        src: Input raster.</span></span><br><span class="line"><span class="string">        dst_crs: Target CRS. String.</span></span><br><span class="line"><span class="string">        out_path: The path of the output file.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    transform, width, height = calculate_default_transform(</span><br><span class="line">        src.crs, dst_crs, src.width, src.height, *src.bounds)</span><br><span class="line">    kwargs = src.meta.copy()</span><br><span class="line">    kwargs.update(&#123;</span><br><span class="line">        <span class="string">&#x27;crs&#x27;</span>: dst_crs,</span><br><span class="line">        <span class="string">&#x27;transform&#x27;</span>: transform,</span><br><span class="line">        <span class="string">&#x27;width&#x27;</span>: width,</span><br><span class="line">        <span class="string">&#x27;height&#x27;</span>: height</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> rio.<span class="built_in">open</span>(out_path, <span class="string">&#x27;w&#x27;</span>, **kwargs) <span class="keyword">as</span> dst:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, src.count + <span class="number">1</span>):</span><br><span class="line">            reproject(</span><br><span class="line">                source=rio.band(src, i),</span><br><span class="line">                destination=rio.band(dst, i),</span><br><span class="line">                src_transform=src.transform,</span><br><span class="line">                src_crs=src.crs,</span><br><span class="line">                dst_transform=transform,</span><br><span class="line">                dst_crs=dst_crs,</span><br><span class="line">                resampling=Resampling.cubic)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mask_A_by_B</span>(<span class="params">A, B</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; Generate a mask from B, and applied it to A.</span></span><br><span class="line"><span class="string">        All 0 values are excluded.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    mask = B.<span class="built_in">sum</span>(axis=<span class="number">0</span>)&gt;<span class="number">1e-3</span></span><br><span class="line">    masked_A = mask*A</span><br><span class="line">    <span class="keyword">return</span> masked_A</span><br></pre></td></tr></table></figure>
<h2 id="reference"><a class="markdownIt-Anchor" href="#reference"></a> Reference</h2>
<ol>
<li><a href="https://automating-gis-processes.github.io/2016/course-info.html">Python GIS 超完整教程</a></li>
<li><a href="https://zia207.github.io/geospatial-python.io/">Professor Zia’s Personal Website</a></li>
<li><a href="https://blog.csdn.net/sinat_28853941/article/details/78511167">sentinel-2数据下载 大气校正 转ENVI格式</a></li>
<li><a href="https://blog.csdn.net/lidahuilidahui/article/details/102765420">03-SNAP处理Sentinel-2 L2A级数据（一）</a></li>
<li><a href="https://clouds.eos.ubc.ca/~phil/courses/atsc301/html/rasterio_demo.html">UBC Course Notebook</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/31010043">利用Sen2cor对哨兵2号（Sentinel-2）L1C多光谱数据进行辐射定标和大气校正</a></li>
<li><a href="https://sentinelhub-py.readthedocs.io/en/latest/">Documentation of Sentinel Hub Python package</a></li>
<li><a href="https://github.com/sentinel-hub/sentinelhub-py">sentinelhub-py</a></li>
</ol>
]]></content>
      <tags>
        <tag>python</tag>
        <tag>satellite</tag>
      </tags>
  </entry>
  <entry>
    <title>种子班中英文介绍</title>
    <url>/2018/03/08/seed-class-english/</url>
    <content><![CDATA[<h1 id="基于项目信息类专业教育实验班种子班本科培养计划22"><a class="markdownIt-Anchor" href="#基于项目信息类专业教育实验班种子班本科培养计划22"></a> 基于项目信息类专业教育实验班（种子班）本科培养计划(2+2)</h1>
<p><strong>Undergraduate Program for Advanced Project-based Information Science Education (Seeds Class)</strong></p>
<h2 id="一-培养目标"><a class="markdownIt-Anchor" href="#一-培养目标"></a> 一、 培养目标</h2>
<p>Ⅰ. Educational Objectives</p>
<p>以真实科研项目为牵引，通过“干中学”的方式，将专业理论知识的学习与科研项目实训紧密结合，弱化教师课堂讲授，增强学生自主和快速学习能力、创新思维能力和实践动手能力，促进学生的综合素质发展，培养一批兼具技术力和领导力的精英之才。</p>
<span id="more"></span>
<p>This program is designed in a unique “learning-via-doing” approach in that the course study is closely integrated to the research and development practices from real engineering projects. Lecturing time is considerably reduced; however, more credits are contributed to hands-on practical training and interns in order to enhance the students with high self-motivation and quick learning capability, strong innovation initiatives and problem-solving capability. The students are comprehensively trained to produce top-tier elites with solid technical background and outstanding leadership.</p>
<h2 id="二-基本规格要求"><a class="markdownIt-Anchor" href="#二-基本规格要求"></a> 二 基本规格要求</h2>
<p>Ⅱ.Skills Profile</p>
<p>毕业生应获得以下几个方面的知识和能力:</p>
<ol>
<li>具有较扎实的数理基础，具有较强的英语语言能力；</li>
<li>掌握文献检索和撰写科技论文的方法，了解信息学科的发展动态和理论前沿；</li>
<li>掌握信息科学、电子科学、计算机科学的基本理论和方法；</li>
<li>具有设计和开发通信与信息系统、解决实际问题的工程实践能力；</li>
<li>具有较好的人文社科知识和人文素质；</li>
<li>具有较强的团队合作和科技创新精神。</li>
</ol>
<p>Students are expected to acquire the following knowledge or skills:</p>
<ol>
<li>Consolidated background in both mathematics and physicsand strong English capability;</li>
<li>Skills in searching literatures and writing technical report, and familiar with the development trends in the discipline and research frontiers;</li>
<li>Understanding basic theories and skills in information science, electronics science and computer science;</li>
<li>Hands-on engineering experiences in solving real problems in the design and development ofcommunication and information systems;</li>
<li>Sound knowledge in humanities-and-art and good personality;</li>
<li>Cooperative attitude as a team player and strong innovative initiatives.</li>
</ol>
<h2 id="三-培养特色"><a class="markdownIt-Anchor" href="#三-培养特色"></a> 三 培养特色</h2>
<p>Ⅲ. Program Features</p>
<p>以电路、信号处理为基础，电子设备和系统设计及应用为方向，不仅具有扎实的、宽广的理论基础，而且具有较强的工程实践和创新能力。特别是动手能力和快速学习能力强；所学知识能灵活运用，终生不忘；具有高尚的道德情操、优秀的工作作风和出色的协调能力，综合素质突出。</p>
<p>This program focuses on the design and application of electronic devices and systems in circuit and signal processing. Students are required to construct solid and broad theoretical background, and they are enhanced with the hands-on engineering experiences and innovation initiatives. In particular, the students are strong in solving real engineering problems and quick learning; they are able to apply knowledge flexibly in solving real problems in that the knowledge follows the students in a life-long fashion; they are fully-developed with moral integrity, excellent working style and outstanding coordination capability.</p>
<h2 id="四-主干学科"><a class="markdownIt-Anchor" href="#四-主干学科"></a> 四 主干学科</h2>
<p>Ⅳ. Major Disciplines</p>
<p>电子科学与技术</p>
<p>Electronics Science and Technology</p>
<h2 id="五-学制与学位"><a class="markdownIt-Anchor" href="#五-学制与学位"></a> 五 学制与学位</h2>
<p>Ⅴ. Length of schooling and Degree</p>
<p>学制：四年制</p>
<p>Length of Schooling: Four years</p>
<p>授予学位：工学学士</p>
<p>Degrees Conferred: Bachelor of Engineering</p>
<h2 id="六-学时与学分"><a class="markdownIt-Anchor" href="#六-学时与学分"></a> 六 学时与学分</h2>
<p>Ⅵ. Hours/ Credits</p>
<p>种子班学生大一和大二的课程学习跟随信息大类原专业普通班上课，大三和大四则集中单独授课。完成学业最低课内学分（含课程体系与集中性实践教学环节）要求：185</p>
<p>The students in the Seed Class in their year I and II take the same courses together with the students in the same major for information science. The students in the Seed Class in their year III and IV follow the curriculum of their own for separate lecture delivery. Minimum Credits of Curriculum (including course system and intensive practical training / internship): 187</p>
<p>完成学业最低课外学分要求：5</p>
<p>Minimum Extracurricular Credits: 5</p>
]]></content>
      <tags>
        <tag>seed-class</tag>
      </tags>
  </entry>
  <entry>
    <title>全自动种子追番系统</title>
    <url>/2021/02/01/seed-anime-system/</url>
    <content><![CDATA[<p><strong>前言</strong>：你喜欢的番剧更新了。是你喜欢的字幕组的高清资源。里面没有放肆的圣光和暗牧。尽管它也许没在国内放送。你可以在任何设备上观看它，并且可以无缝切换。电视，手机，iPad，电脑都没有问题。它很快。</p>
<p>这将是本篇介绍的全自动全平台订阅追番系统。</p>
<p>出于各种原因，有许多番剧在B站并找不到。即使开了大会员，从国外驾梯回国，还是无法看到一些喜欢的内容。但同时，各大动漫种子站却提供了几乎无所不包的资源，其中包括新番。但依靠种子追番最常见的问题就是难以track，经常会忘记更新，而且每次都需要经过一个<code>搜索-下载种子-下载-整理-观看</code>的过程，确实还是很劝退的。如何搭建一个易于配置、足够简单、全自动化抓取、下载、串流的追番系统，便成为了一个追番人的核心需求。</p>
<span id="more"></span>
<p>下面本文将会带领你认识整套流程，如果你足够经常折腾，大致一个小时之内就可以搭建完成。祝你好运:)</p>
<p>PS: 本文涉及的所有脚本都可以在该<a href="https://github.com/miracleyoo/anime_renamer">GitHub</a>库上找到。</p>
<h2 id="软件与配置">软件与配置</h2>
<ul>
<li>源：动漫种子站。如Nyaa、ACGRIP、动漫花园、萌番组。为了避免河蟹这里就不放链接了，请自行搜索。</li>
<li>订阅与自动下载种子：RSS。</li>
<li>下载器：utorrent。</li>
<li>正则匹配与自动重命名：Python。</li>
<li>串流与自动整理：Plex。</li>
</ul>
<p>由于上面提到的软件都支持Windows和Mac，所以认为该系统适用于两者。</p>
<h2 id="流程">流程</h2>
<p>首先放一张整理出来的流程图：</p>
<figure>
<img data-src="image-20210129014429864.png" alt="image-20210129014429864"><figcaption aria-hidden="true">image-20210129014429864</figcaption>
</figure>
<p>该系统的整体思路是，使用RSS自动嗅探订阅的内容，用utorrent自动下载到番剧指定的目录，使用Python重命名成Plex可以支持的剧集命名格式后，使用Plex整理、匹配元数据，并提供串流服务，让你的电脑本身成为一个视频内容服务器，从而使你可以在家中任何设备上迅速、便捷地观看下载整理好的视频。这对于习惯在电视大屏幕、投影屏或iPad上观看视频的用户而言是十分友好的。</p>
<p>最终达到的效果是：一旦种子源网站上更新了一个你订阅的番剧的种子，你就可以第一时间打开电视、掏出iPad直接观看内容。</p>
<p>另外，由于Plex可以记住你所有视频的观看进度，所以你完全可以在手机上看了前半部分，然后坐到电视机前，从容地无缝继续观看。</p>
<p>效果如下：</p>
<figure>
<img data-src="image-20210129015121641.png" alt="image-20210129015121641"><figcaption aria-hidden="true">image-20210129015121641</figcaption>
</figure>
<figure>
<img data-src="image-20210129015202322.png" alt="image-20210129015202322"><figcaption aria-hidden="true">image-20210129015202322</figcaption>
</figure>
<figure>
<img data-src="image-20210129015424295.png" alt="image-20210129015424295"><figcaption aria-hidden="true">image-20210129015424295</figcaption>
</figure>
<h2 id="源站">源站</h2>
<p>各大动漫压制组、汉化组和搬运组（统称发布组）都会将他们的资源发布到这些源站上。有的源站互为镜像，有的站是爬取的其他站的信息。它们在追新番这项任务上的表现其实都还可以，选一个你自己喜欢的站点即可。</p>
<p>每个发布组都有自己的偏好的番剧，也有他们独特的规矩和讲究。如VCB-Studio就偏好做高清的压制资源，但经常不附带字幕；LIlith由于主要是搬运，所以发布速度快；喵萌开的番比较多，视频质量较高，但并不是所有番剧都是及时发布的。热门番剧往往会在第一时间就有发布组发布，而一些冷门内容的更新速度就无法保证了。另外，A发布组发布X番剧可能是及时的，Y番剧要隔几天；可能B发布组则相反。最简单的方法就是检查上一集最先是由哪个组发布的，哪个组放出的资源又有最多人下载，然后进行综合判断。</p>
<h2 id="rss">RSS</h2>
<p>引用一段Wikipedia的定义：</p>
<blockquote>
<p><strong>RSS</strong>（全称：<a href="https://zh.wikipedia.org/wiki/Resource_Description_Framework">RDF</a> Site Summary；Really Simple Syndication[<a href="https://zh.wikipedia.org/wiki/RSS#cite_note-powers-2003-1-2">2]</a>），中文译作<strong>简易信息聚合</strong>[<a href="https://zh.wikipedia.org/wiki/RSS#cite_note-3">3]</a>，也称<strong>聚合内容</strong>[<a href="https://zh.wikipedia.org/wiki/RSS#cite_note-张锐2015-4">4]</a>，是一种<a href="https://zh.wikipedia.org/wiki/消息來源">消息来源</a>格式规范，用以<strong>聚合经常发布更新资料的网站</strong>，例如<a href="https://zh.wikipedia.org/wiki/部落格">博客</a>文章、新闻、<a href="https://zh.wikipedia.org/wiki/音訊">音频</a>或<a href="https://zh.wikipedia.org/wiki/視訊">视频</a>的网摘。RSS文件（或称做摘要、网络摘要、或频更新，提供到频道）包含全文或是节录的文字，再加上发布者所订阅之网摘资料和授权的元数据。简单来说 RSS 能够让用户订阅个人网站个人博客，当订阅的网站有新文章是能够获得通知。</p>
</blockquote>
<p>RSS的本质是订阅某个信源。信源可以不断更新和推送信息，它往往表现为一个链接。让我们举一个例子。</p>
<p><img data-src="image-20210129020139987.png" alt="image-20210129020139987" style="zoom:50%;"></p>
<p>假设我们想要追一个由喵萌奶茶屋发布的新番<code>IDOLY PRIDE</code>，并且只看简体的1080p版本，那么我们就可以根据其命名风格来生成对应的搜索关键词：<code>【喵萌Production】★01月新番★[偶像荣耀/IDOLY PRIDE][03][1080p][简日双语][招募翻译]</code>是其中一集的命名。那么我们只需要在搜索框中搜索：<code>喵萌Production 偶像荣耀 1080p 简日</code>，即可定位我们需要追的番的特定版本的所有后续资源。</p>
<figure>
<img data-src="image-20210129020710605.png" alt="image-20210129020710605"><figcaption aria-hidden="true">image-20210129020710605</figcaption>
</figure>
<p>然后我们即可把这个搜索结果的网页当做一个信源。具体获取RSS订阅链接的方法每个网站都各不相同，但大致都会有一个类似的按钮出现。点击这个按钮，在弹出的窗口的地址栏即可找到我们需要的RSS订阅链接。</p>
<figure>
<img data-src="image-20210129021051012.png" alt="image-20210129021051012"><figcaption aria-hidden="true">image-20210129021051012</figcaption>
</figure>
<p>复制这个链接，这一步就完成了。你成功地得到了你所需要内容的订阅链接。</p>
<h2 id="utorrent">utorrent</h2>
<ul>
<li><p>utorrent是一个可以下载种子文件和磁力链接的软件，支持Windows、Mac和Linux，也有网页版。</p></li>
<li><p>utorrent支持RSS订阅，相当于每当RSS订阅的信源有了新的内容，utorrent就会自动把它列出来。你也可以设置每当有新内容就自动下载，不过这要视订阅内容而定。每个RSS的自动下载位置可以是不同的文件夹。效果如下：</p>
<p><img data-src="image-20210130113430927.png" alt="image-20210130113430927" style="zoom:50%;"></p></li>
<li><p>utorrent支持文件下载完成或状态改变后执行脚本。这个特点非常重要，下一步需要用。</p></li>
</ul>
<h3 id="rss配置">RSS配置</h3>
<ol type="1">
<li>首先，将上面提到的RSS链接添加到utorrent的订阅中：点击<code>订阅</code>后页面中的小Wi-Fi图标即可添加，也可以右键<code>添加RSS订阅</code>。这时候先不用设置什么，把URL粘贴到第一项，然后定义一个方便识别的别名即可，订阅栏先选择<code>不要自动下载所有项目</code>。待会儿会在下载器设定中详细设置。</li>
</ol>
<p><img data-src="image-20210130113824679.png" alt="image-20210130113824679" style="zoom:50%;"></p>
<p><img data-src="image-20210130114135639.png" alt="image-20210130114135639" style="zoom:50%;"></p>
<ol start="2" type="1">
<li><p>右键左栏<code>订阅</code>中出现的新项，选择<code>RSS下载器</code>，进入下载器详细配置：</p>
<p><img data-src="image-20210130114636832.png" alt="image-20210130114636832" style="zoom:50%;"></p>
<p>这里我们需要修改的只有<code>保存在</code>和<code>订阅</code>两项，前者是这个订阅中所有文件的保存位置，订阅是这套设置将应用于哪个订阅。需要注意的是，文件夹最好为这个番剧的名字，且命名最好遵守以下规则，方便后续匹配：</p>
<ul>
<li>只有一个主名字。如果一个番剧既有中文名，又有日文名，还有罗马字或英语名，请只使用一个名字。使用哪个看你自己，最好是广泛接受的名字。其他语言的名字，其他信息，如字幕组，简体繁体，清晰度等，请分别使用一个中括号括住。整理串流软件由于主要遵循西方影视的命名规则，会直接忽略方括号内的所有内容，所以在方括号里面你可以放入任何你想备注的信息。</li>
<li>一套规则对应一个订阅。整个链条的对应关系是：<code>一个番剧名字-&gt;一条RSS链接-&gt;utorrent中一项RSS订阅-&gt;RSS下载器中一套规则-&gt;一个独立文件夹</code></li>
<li>过滤器如果没有需求，可以留空或<code>*</code>，表示匹配所有。若是在这个订阅链接中还没有完全筛选，那你可以着这里进行另外一波过滤。</li>
</ul></li>
</ol>
<h2 id="重命名">重命名</h2>
<p>首先再解释一下为何需要重命名。正如前文所说，Plex等媒体管理软件主要还是针对欧美剧集的命名方法设计的，且会忽略方括号中所有内容。但国内，至少是番剧的命名，对于集数的命名，恰恰大多会放到方括号中，如<code>[c.c動漫][1月新番][工作細胞 第二季][04][BIG5][1080P][MP4]</code>里面的这个<code>[04]</code>就是集数。另外还有的命名是<code>第04话</code>，<code>[第04话]</code>，<code>- 04 -</code>等。另外，由于某些技术性错误，有些发布组会在某集发布后重新发布修复版本，此时的命名为<code>04v2</code>等。还有很多番剧的最后一集会被添加上END字样表示完结。而这些内容都会对后续的解析造成困难，最好可以将集数这个变量转为某种固定格式。</p>
<p>Python可以很好的完成这项任务。通过正则匹配上述内容，并重新组合，可以轻易的得到想要的结果。写好的脚本如下：</p>
<h3 id="reg_match.py"><code>reg_match.py</code>：</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> os.path <span class="keyword">as</span> op</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> codecs</span><br><span class="line"><span class="keyword">from</span> glob <span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">from</span> pathlib2 <span class="keyword">import</span> Path</span><br><span class="line"></span><br><span class="line">log_name=op.join(op.dirname(op.realpath(__file__)), <span class="string">&#x27;log.txt&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Episode Regular Expression Matching Rules</span></span><br><span class="line">episode_rules = [<span class="string">r&#x27;(.*)\[(\d&#123;1,3&#125;|\d&#123;1,3&#125;\.\d&#123;1,2&#125;)(?:v\d&#123;1,2&#125;)?(?:END)?\](.*)&#x27;</span>,</span><br><span class="line">                 <span class="string">r&#x27;(.*)\[E(\d&#123;1,3&#125;|\d&#123;1,3&#125;\.\d&#123;1,2&#125;)(?:v\d&#123;1,2&#125;)?(?:END)?\](.*)&#x27;</span>,</span><br><span class="line">                 <span class="string">r&#x27;(.*)\[第(\d*\.*\d*)话(?:END)?\](.*)&#x27;</span>,</span><br><span class="line">                 <span class="string">r&#x27;(.*)\[第(\d*\.*\d*)話(?:END)?\](.*)&#x27;</span>,</span><br><span class="line">                 <span class="string">r&#x27;(.*)第(\d*\.*\d*)话(?:END)?(.*)&#x27;</span>,</span><br><span class="line">                 <span class="string">r&#x27;(.*)第(\d*\.*\d*)話(?:END)?(.*)&#x27;</span>,</span><br><span class="line">                 <span class="string">r&#x27;(.*)- (\d&#123;1,3&#125;|\d&#123;1,3&#125;\.\d&#123;1,2&#125;)(?:v\d&#123;1,2&#125;)?(?:END)? (.*)&#x27;</span>]</span><br><span class="line"><span class="comment"># Suffixs of files we are going to rename</span></span><br><span class="line">suffixs = [<span class="string">&#x27;mp4&#x27;</span>, <span class="string">&#x27;mkv&#x27;</span>, <span class="string">&#x27;avi&#x27;</span>, <span class="string">&#x27;mov&#x27;</span>, <span class="string">&#x27;flv&#x27;</span>, <span class="string">&#x27;rmvb&#x27;</span>, <span class="string">&#x27;ass&#x27;</span>, <span class="string">&#x27;idx&#x27;</span>]</span><br><span class="line">sys.stdout = io.TextIOWrapper(buffer=sys.stdout.buffer,encoding=<span class="string">&#x27;utf8&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Parse the input arguments. You can whether input only root, or only path, or both root and name.</span></span><br><span class="line">parser = argparse.ArgumentParser(description=<span class="string">&#x27;Regular Expression Match&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--root&#x27;</span>, default=<span class="string">&#x27;&#x27;</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&#x27;The root directory of the input file.&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--name&#x27;</span>, default=<span class="string">&#x27;&#x27;</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&#x27;The file name of the input file.&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--path&#x27;</span>, default=<span class="string">&#x27;&#x27;</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&#x27;The file full path of the input file.&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">rename</span>(<span class="params">root, name</span>):</span><br><span class="line">    root = Path(root)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> rule <span class="keyword">in</span> episode_rules:</span><br><span class="line">        matchObj = re.<span class="keyword">match</span>(rule, name, re.I)</span><br><span class="line">        <span class="keyword">if</span> matchObj <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            new_name = <span class="string">f&#x27;<span class="subst">&#123;matchObj.group(<span class="number">1</span>)&#125;</span> E<span class="subst">&#123;matchObj.group(<span class="number">2</span>)&#125;</span> <span class="subst">&#123;matchObj.group(<span class="number">3</span>)&#125;</span>&#x27;</span></span><br><span class="line">            <span class="comment"># print(matchObj.group())</span></span><br><span class="line">            <span class="comment"># print(new_name)</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;name&#125;</span> -&gt; <span class="subst">&#123;new_name&#125;</span>&#x27;</span>)</span><br><span class="line">            <span class="keyword">with</span> codecs.<span class="built_in">open</span>(log_name, <span class="string">&#x27;a+&#x27;</span>, <span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                <span class="comment"># f.writelines(f&#x27;&#123;name&#125; -&gt; &#123;new_name&#125;&#x27;)</span></span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;name&#125;</span> -&gt; <span class="subst">&#123;new_name&#125;</span>&#x27;</span>, file=f)</span><br><span class="line"></span><br><span class="line">            os.rename(<span class="built_in">str</span>(root/name), <span class="built_in">str</span>(root/new_name))</span><br><span class="line">            general_check(root, new_name)</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">    general_check(root, name)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">general_check</span>(<span class="params">root, name</span>):</span><br><span class="line">    new_name = <span class="string">&#x27; &#x27;</span>.join(name.split())</span><br><span class="line">    <span class="keyword">if</span> new_name != name:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;name&#125;</span> -&gt; <span class="subst">&#123;new_name&#125;</span>&#x27;</span>)</span><br><span class="line">        <span class="keyword">with</span> codecs.<span class="built_in">open</span>(log_name, <span class="string">&#x27;a+&#x27;</span>, <span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;name&#125;</span> -&gt; <span class="subst">&#123;new_name&#125;</span>&#x27;</span>, file=f)</span><br><span class="line">        os.rename(<span class="built_in">str</span>(root/name), <span class="built_in">str</span>(root/new_name))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    args = parser.parse_args()</span><br><span class="line">    <span class="keyword">if</span> op.isdir(args.path):</span><br><span class="line">        args.root = args.path</span><br><span class="line">        args.path = <span class="string">&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.name != <span class="string">&#x27;&#x27;</span> <span class="keyword">and</span> args.root != <span class="string">&#x27;&#x27;</span>:</span><br><span class="line">        temp = <span class="built_in">str</span>(args.root/args.name)</span><br><span class="line">        <span class="keyword">if</span> op.isdir(temp):</span><br><span class="line">            args.root = temp</span><br><span class="line">            args.name = <span class="string">&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.path != <span class="string">&#x27;&#x27;</span>:</span><br><span class="line">        root, name = op.split(args.path)</span><br><span class="line">        rename(root, name)</span><br><span class="line">    <span class="keyword">elif</span> args.name != <span class="string">&#x27;&#x27;</span> <span class="keyword">and</span> args.root != <span class="string">&#x27;&#x27;</span>:</span><br><span class="line">        rename(args.root, args.name)</span><br><span class="line">    <span class="keyword">elif</span> args.root != <span class="string">&#x27;&#x27;</span>:</span><br><span class="line">        files = []</span><br><span class="line">        <span class="keyword">for</span> suffix <span class="keyword">in</span> suffixs:</span><br><span class="line">            files.extend(Path(args.root).rglob(<span class="string">&#x27;*.&#x27;</span>+suffix))</span><br><span class="line">            files.extend(Path(args.root).rglob(<span class="string">&#x27;*.&#x27;</span>+suffix.upper()))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;Total Files Number: <span class="subst">&#123;<span class="built_in">len</span>(files)&#125;</span>&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> path <span class="keyword">in</span> files:</span><br><span class="line">            root, name = op.split(path)</span><br><span class="line">            rename(root, name)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Please input whether only root, or only path, or both root and name&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>使用的话直接将该文件存到一个新建的<code>reg_match.py</code>文件中即可。使用Python3.6编写，理论支持所有Python3版本。</p>
<p>但是，仅用Python无法直接被utorrent调用，它想要的是像<code>exe</code>或<code>cmd</code>之类的文件，并想传递<strong>下载好的文件所在目录</strong>和<strong>下载好的文件名</strong>进去。这样我们最好创建一个<code>cmd</code>文件，用于接受参数，并传递给Python脚本。</p>
<h3 id="run_after_done.cmd"><code>run_after_done.cmd</code></h3>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">set file_name=%1%</span><br><span class="line">set directory=%2%</span><br><span class="line"></span><br><span class="line">python &lt;YOUR_SCRIPT_PATH&gt;\reg_match.py --name=%file_name% --root=%directory%</span><br></pre></td></tr></table></figure>
<p>其中，<code>&lt;YOUR_SCRIPT_PATH&gt;</code>是你存放上面提到的Python脚本的目录位置。</p>
<h3 id="utorrent配置">utorrent配置</h3>
<p>完成了上面的两个脚本，让我们将其配置到utorrent的<code>当下载完成时运行此程序</code>中。效果就是，每当一个文件下载完成，utorrent都会自动调用这个<code>cmd</code>文件，并且将文件目录和名字都作为参数传递进去。</p>
<p><img data-src="image-20210130122024176.png" alt="image-20210130122024176" style="zoom:50%;"></p>
<p>命令为：<code>&lt;YOUR_CMD_PATH&gt;\run_after_done.cmd "%F" "%D"</code></p>
<p>其中，<code>&lt;YOUR_CMD_PATH&gt;</code>为你存放脚本<code>run_after_done.cmd</code>的目录。推荐将它和Python脚本放在同一个目录下。</p>
<h2 id="plex">Plex</h2>
<p>引用一段Wiki，以方便不熟悉的朋友们了解：</p>
<blockquote>
<p><strong>Plex</strong>是一套<a href="https://zh.wikipedia.org/wiki/媒体播放器">媒体播放器</a>及<a href="https://zh.wikipedia.org/w/index.php?title=媒體伺服器&amp;action=edit&amp;redlink=1">媒体服务器</a>软件，让用户整理在设备上的<a href="https://zh.wikipedia.org/wiki/有聲書">有声书</a>、<a href="https://zh.wikipedia.org/wiki/音樂">音乐</a>、<a href="https://zh.wikipedia.org/wiki/播客">播客</a>、<a href="https://zh.wikipedia.org/wiki/圖片">图片</a>和<a href="https://zh.wikipedia.org/wiki/影片">视频</a>文件，以供<a href="https://zh.wikipedia.org/wiki/串流">流</a>至<a href="https://zh.wikipedia.org/wiki/流動裝置">移动设备</a>、<a href="https://zh.wikipedia.org/wiki/智能電視">智能电视</a>和<a href="https://zh.wikipedia.org/w/index.php?title=電子媒體播放器&amp;action=edit&amp;redlink=1">电子媒体播放器</a>上。Plex可用于<a href="https://zh.wikipedia.org/wiki/Microsoft_Windows">Windows</a>、<a href="https://zh.wikipedia.org/wiki/Android">Android</a>、<a href="https://zh.wikipedia.org/wiki/Linux">Linux</a>、<a href="https://zh.wikipedia.org/wiki/OS_X">OS X</a>和<a href="https://zh.wikipedia.org/wiki/FreeBSD">FreeBSD</a>[<a href="https://zh.wikipedia.org/wiki/Plex#cite_note-Gigaom-2">2]</a>。另外，Plex亦让用户透过该平台观看来自<a href="https://zh.wikipedia.org/wiki/YouTube">YouTube</a>、<a href="https://zh.wikipedia.org/wiki/Vimeo">Vimeo</a>和<a href="https://zh.wikipedia.org/wiki/TED大會">TED</a>等内容提供商的视频。Plex亦与<a href="https://zh.wikipedia.org/w/index.php?title=Bitcasa&amp;action=edit&amp;redlink=1">Bitcasa</a>、<a href="https://zh.wikipedia.org/wiki/Box公司">Box</a>和<a href="https://zh.wikipedia.org/wiki/Dropbox">Dropbox</a>等云端服务兼容[<a href="https://zh.wikipedia.org/wiki/Plex#cite_note-3">3]</a>[<a href="https://zh.wikipedia.org/wiki/Plex#cite_note-4">4]</a>。</p>
<p>用户可透过Plex<a href="https://zh.wikipedia.org/wiki/前端和后端">前端</a>媒体播放器“Plex Media Player”管理及播放在一台运行“Plex Media Server”的远程电脑上的多媒体文件。另外，用户可使用“Plex Online”服务以社区开发的插件收看<a href="https://zh.wikipedia.org/wiki/Netflix">Netflix</a>、<a href="https://zh.wikipedia.org/wiki/Hulu">Hulu</a>和<a href="https://zh.wikipedia.org/wiki/CNN">CNN</a>的视频。[<a href="https://zh.wikipedia.org/wiki/Plex#cite_note-CrunchGear_Interview-5">5]</a></p>
</blockquote>
<p>简单说，就是Plex可以管理你的连续剧集（如番剧）和电影，解析出它们的元数据（如海报，封面，演职员表，简介，分集标题等等），在你的电脑上自动搭建一个<strong>服务器</strong>，向你在其他设备上的Plex软件提供像是Bilibili或Netflix一样的串流服务。形象点说就是，你自己搭建了一个简单的视频网站，数据库是你电脑上的内容，供你自己使用。</p>
<p>另外，Plex不仅支持内网访问，在外网访问也是可以的。内网访问要求终端设备连接到和你的电脑同一个Wi-Fi，而外网则是只要有网络连接就行。当然，内网的速度和清晰度都是更高的。</p>
<p>Plex支持在Windows，Mac，NAS，Docker等位置安装其server，安装过程十分简单，基本一路Next即可。</p>
<p>有了前面的设置，这里就很简单了。假设你的文件结构如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Anime</span><br><span class="line">	|- 工作细胞</span><br><span class="line">		|- Season 1</span><br><span class="line">        	|- 01.mp4</span><br><span class="line">        	|- 02.mp4</span><br><span class="line">        	|...</span><br><span class="line">        	|- 12.mp4</span><br><span class="line">        |- Season 2</span><br><span class="line">        	|- 01.mp4</span><br><span class="line">        	|- ...</span><br><span class="line">	|- 偶像荣耀</span><br><span class="line">		|- 01.mp4</span><br><span class="line">        |- ...</span><br></pre></td></tr></table></figure>
<p>那么，你所需要做的只是：创建一个账户，然后启动你的服务器页面（地址栏输入<a href="https://www.plex.tv/">plex.tv</a>，右上角Launch即可，或是直接点击<a href="https://app.plex.tv/desktop#">Link</a>）：</p>
<p><img data-src="image-20210130123759950.png" alt="image-20210130123759950" style="zoom:50%;"></p>
<p>点击<code>+</code>号，新建一个库，</p>
<p><img data-src="image-20210130123947605.png" alt="image-20210130123947605" style="zoom:50%;"></p>
<p>简单两步，完成！</p>
<p>当然我们这里介绍的仅仅是添加剧集的方法，电影库、音乐库和图片库的添加方法类似。你完全可以把你的照片文件夹放到Plex上，这样你就可以在任何地方看到你的照片啦！另外，由于<strong>服务器</strong>是你自己的电脑，它并不会上传你的文件到某个云端，所以安全性也是较有保障的。</p>
<p>其中电影和电视节目库的最大区别是是否分集和分季。电影的解析针对的是单个的视频文件，而剧集的解析针对的是某个子文件夹。</p>
<p>之后，你可以进入你的库，查看效果。很大一部分内容会直接成功抓取元数据得到漂亮的封面等内容，另一些则会失败。对于失败的内容，如果你不在意其实也不影响观看，只是没有封面和介绍等。如果你介意，可以选择手动协助匹配：</p>
<figure>
<img data-src="image-20210130125127348.png" alt="image-20210130125127348"><figcaption aria-hidden="true">image-20210130125127348</figcaption>
</figure>
<p>匹配失败的主要原因是命名问题。在<code>修复匹配-搜索选项</code>中可以更改用于搜索的命名。另外，有的时候是因为搜索的数据库中没有这个数据，此时，你可以切换<code>代理</code>，很多时候是可以找到匹配的。如果你的命名是日语或英语，那么把搜索的语言相应修改。之后点击搜索即可。</p>
<h2 id="其他">其他</h2>
<h3 id="注意">注意</h3>
<ul>
<li>该方法适用但不仅适用于动漫。其他类型影视剧集也可，只要你能找到合适的订阅源。</li>
<li>本文涉及的所有脚本都可以在该<a href="https://github.com/miracleyoo/anime_renamer">GitHub</a>库上找到。</li>
<li>动漫正版化事业不易，各大网站都投入了巨大的资源来建设更全的正版资源库，请尽最大可能支持正版。请将本方法主要用于观看网盘见类剧集和存在删减的剧集。</li>
</ul>
<h3 id="trouble-shooting">Trouble Shooting</h3>
<p>需要注意的是，由于utorrent在上传时会占用文件，所以有一定概率重命名会失败。解决办法也很简单，如果你觉得有问题的时候，关闭utorrent解除占用，往往需要等上几秒，然后直接将整个<code>Anime</code>文件夹（存放动漫的根文件夹）拖放到下面这个<code>cmd</code>文件上即可：</p>
<p><code>rename_episodes.cmd</code></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> %%i <span class="keyword">in</span> (%*) <span class="keyword">do</span> python &lt;YOUR_SCRIPT_PATH&gt;\reg_match.py --path=%%i</span><br></pre></td></tr></table></figure>
<p>该文件会调用前面提到的Python脚本，并对整个文件夹中的所有有问题的文件名进行重命名。你也可以将有问题的子目录或特定文件拖放上去，或是同时拖放多个文件/文件夹。Python脚本中有着相应的适配。</p>
]]></content>
      <tags>
        <tag>acg</tag>
        <tag>anime</tag>
        <tag>system</tag>
        <tag>torrent</tag>
      </tags>
  </entry>
  <entry>
    <title>优雅地使用ssh免密登录</title>
    <url>/2018/08/27/ssh-no-password/</url>
    <content><![CDATA[<h1 id="问题"><a class="markdownIt-Anchor" href="#问题"></a> 问题</h1>
<p>如何优雅地使用ssh登录，并不需要每次输入密码。</p>
<span id="more"></span>
<h1 id="解决方案"><a class="markdownIt-Anchor" href="#解决方案"></a> 解决方案</h1>
<h2 id="步骤一使用alias或config记住server信息"><a class="markdownIt-Anchor" href="#步骤一使用alias或config记住server信息"></a> 步骤一：使用<em>Alias</em>或<em>config</em>记住Server信息</h2>
<h3 id="添加alias"><a class="markdownIt-Anchor" href="#添加alias"></a> 添加Alias</h3>
<p>如果你正在使用默认的bash，别名<em>alias</em>信息会被保存在<code>~/.bashrc</code>文件中；如果你使用了zsh，那么你需要在<code>~/.zshrc</code>文件中修改。</p>
<p>添加别名操作只需在该文件的任意位置插入以下命令（不过建议加载最前或最后方便管理和查找）：</p>
<p><code>alias new_name=&quot;ssh user@domain -p port_num&quot;</code></p>
<p>并在保存并退出后激活该文件：<code>source ~/.bashrc</code> 或 <code>source ~/.zshrc</code></p>
<h3 id="添加~sshconfig配置"><a class="markdownIt-Anchor" href="#添加~sshconfig配置"></a> 添加~/.ssh/config配置</h3>
<p>打开该文件，并添加如下代码段：</p>
<p><strong>有IdentityFile：</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Host miracle</span><br><span class="line">        HostName `xxx.xxx.xxx.xxx`</span><br><span class="line">        User `username`</span><br><span class="line">        Port `2880`</span><br><span class="line">        IdentityFile `~/xxx/xxx/cert.pem`</span><br><span class="line">        UseKeychain <span class="built_in">yes</span></span><br><span class="line">        AddKeysToAgent <span class="built_in">yes</span></span><br></pre></td></tr></table></figure>
<p><strong>无IdentityFile：</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Host yoo</span><br><span class="line">        HostName `xxx.xxx.xxx.xxx`</span><br><span class="line">        User `username`</span><br><span class="line">        Port `2880`</span><br><span class="line">        UseKeychain <span class="built_in">yes</span></span><br><span class="line">        AddKeysToAgent <span class="built_in">yes</span></span><br></pre></td></tr></table></figure>
<p>其中，IdentityFile、UseKeychain、AddKeysToAgent等项不是必须的。</p>
<p>登录方法：<code>ssh miracle</code>，其中此处的miracle是你给你的Host起的名字。</p>
<p><strong>优点</strong>：方便，更易于管理，并且使用scp等时也会更方便，比如：<code>scp *.mat miracle:~ </code></p>
<h2 id="步骤二免密登录"><a class="markdownIt-Anchor" href="#步骤二免密登录"></a> 步骤二：免密登录</h2>
<ol>
<li>如果你没有使用过rsa密钥对，先生成：<code>ssh-keygen</code> ，选项可以一路Enter</li>
<li>切换到 <em>~/.ssh/</em> 文件夹下将公钥发送到服务器上的某文件夹里：<code>scp -P 2880 ~/.ssh/id_rsa.pub root@xxx.xxx.xxx.xxx:~</code></li>
<li>登录服务器，把PC端的公钥添加至ssh信任列表末尾：<code>cat id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</code></li>
<li>如果服务器上没有生成rsa密钥对，按（1）中操作在服务器上重复</li>
<li>如果做了这些后依然需要你输入一个<em>passphrase</em>：<code>Enter passphrase for /Users/miracle/.ssh/id_rsa:</code>，这个passphase是指你生成ssh密钥时输入的一个字符串，如果你一直按的Enter，这里也直接Enter就好，但是如果不幸你当时输入了一个字符串，那么你需要进行步骤（6）：</li>
<li>Add Identity Using Keychain：<code>ssh-add -K ~/.ssh/id_rsa</code>，之后它会让你输入上面提到的这个字符串，做完这一步之后，你将会永远不用再在登录这台服务器时输入密码</li>
</ol>
]]></content>
      <tags>
        <tag>linux</tag>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title>Jupyter notebook远程访问服务器配置</title>
    <url>/2018/05/15/server-jn/</url>
    <content><![CDATA[<p>1.背景</p>
<p>一直苦恼于本地机器和服务器上都要配置一些机器学习方面的环境，今天花了点时间研究了下Jupter notebook远程访问服务器，所以记录一下。</p>
<p>有些步骤非必须，这里尽量写清楚，读者理解后自行决定如何安装，本文以非root用户安装。</p>
<span id="more"></span>
<p>2.注意事项</p>
<blockquote>
<p>一定要注意检查服务器端的防火墙相应端口有没有打开！！！</p>
<p>位置往往在：</p>
<p>安全-&gt;防火墙-&gt;添加规则-&gt;应用更改</p>
<p>VPC网络-&gt;点击已经创建的VPC网络-&gt;管理配置-&gt;添加规则-&gt;应用更改</p>
</blockquote>
<p>3.安装步骤</p>
<ol>
<li>
<p>登录服务器</p>
</li>
<li>
<p>检查是否有安装jupyter notebook,终端输入jupyter notebook,如果报错就是无，那么就要用下面命令安装。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$sudo pip install pyzmq</span><br><span class="line">$sudo pip install tornado</span><br><span class="line">$sudo pip install jinja2</span><br><span class="line">$sudo pip install jsonschema</span><br><span class="line">$sudo pip install jupyter</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>生成配置文件</p>
</li>
</ol>
<p>jupyter notebook --generate-config</p>
<ol start="4">
<li>生成密码（后续写配置文件、登录Jupyter notebook需要）</li>
</ol>
<p>jupyter notebook password</p>
<p>或打开python终端</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [1]: from IPython.lib import passwd</span><br><span class="line"></span><br><span class="line">In [2]: passwd()</span><br><span class="line">Enter password: </span><br><span class="line">Verify password: </span><br><span class="line">Out[2]: &#x27;sha1:0e422dfccef2:84cfbcbb3ef95872fb8e23be3999c123f862d856&#x27; </span><br></pre></td></tr></table></figure>
<ol start="5">
<li>修改默认配置文件</li>
</ol>
<p>vim ~/.jupyter/jupyter_notebook_config.py</p>
<p>进行如下修改（这里可以自行配置）：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">c.NotebookApp.ip=&#x27;*&#x27;</span><br><span class="line">c.NotebookApp.password = u&#x27;sha:ce...刚才复制的那个密文&#x27;</span><br><span class="line">c.NotebookApp.open_browser = False</span><br><span class="line">c.NotebookApp.port =8888 #随便指定一个端口</span><br><span class="line">c.NotebookApp.allow_root = True</span><br><span class="line">c.IPKernelApp.pylab = &#x27;inline&#x27;</span><br></pre></td></tr></table></figure>
<ol start="6">
<li>启动Jupter notebook</li>
</ol>
<p>jupyter notebook</p>
<ol start="7">
<li>远程访问</li>
</ol>
<p>此时应该可以直接从本地浏览器直接访问http://address_of_remote:8888就可以看到jupyter的登陆界面。（特别注意：服务器上的Jupyter notebook不要关）</p>
<ol start="8">
<li>本地端口转发</li>
</ol>
<p>ssh转发命令：ssh -L <local host><local port>:<remote host>:<remote port> <SSH hostname> 最好是在vim ~/.zshrc   中设置别名如：</SSH></remote></remote></local></local></p>
<p>alias aihubjn1=‘ssh -L localhost:9999:localhost:8989 <a href="mailto:root@saas.aihub.finalshares.com">root@saas.aihub.finalshares.com</a> -p 2880’</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">第一步：启动ssh端口转发</span><br><span class="line">ssh -L localhost:9999:localhost:8989 root@saas.aihub.finalshares.com -p 2880</span><br><span class="line">第二步：在服务器发起jupyter服务</span><br><span class="line">jupyter notebook --port 8989</span><br><span class="line">第三步：本地开启9999</span><br><span class="line">浏览器访问：http://localhost:9999/</span><br></pre></td></tr></table></figure>
<p>这里root为username,登录ssh的账号，saas.aihub.finalshares.com:2880是老师提供的服务器ssh端口，我使用自己的9999端口监听服务器上的8989端口，信息通过ssh转发，在服务器上启动jupyter即可本地登录，爽的飞起。</p>
<ol start="9">
<li>一点小问题</li>
</ol>
<p>由于笔者之前本地转过jupter notebook,改下端口号登录</p>
<p>jupyter notebook --no-browser --port=8889</p>
<p>3.参考文献</p>
<p>（1）<a href="https://zhuanlan.zhihu.com/p/20226040">如何在云端服务器运行Jupyter Notebook？</a></p>
<p>（2）<a href="http://blog.csdn.net/patrick75/article/details/51473884">通过SSH远程使用jupyter notebook</a></p>
<p>（3）<a href="http://www.cnblogs.com/yangxiaolan/p/5778305.html">远程访问jupyter notebook</a></p>
]]></content>
      <tags>
        <tag>machine-learning</tag>
        <tag>linux</tag>
        <tag>server</tag>
      </tags>
  </entry>
  <entry>
    <title>PyTorch中使用指定的GPU</title>
    <url>/2018/05/14/certain-GPU/</url>
    <content><![CDATA[<p><a href="http://www.cnblogs.com/darkknightzh/p/6836568.html">[转]PyTorch中使用指定的GPU</a></p>
<p>PyTorch默认使用从0开始的GPU，如果GPU0正在运行程序，需要指定其他GPU。</p>
<span id="more"></span>
<p>有如下两种方法来指定需要使用的GPU。</p>
<ol>
<li>
<p>类似tensorflow指定GPU的方式，使用CUDA_VISIBLE_DEVICES。</p>
<p>1.1 直接终端中设定：</p>
<p><code>CUDA_VISIBLE_DEVICES=1 python my_script.py</code></p>
</li>
</ol>
<p>​	1.2 python代码中设定：</p>
<p>​	<code>import os os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &quot;2&quot;</code></p>
<p>​	见网址：<a href="http://www.cnblogs.com/darkknightzh/p/6591923.html">http://www.cnblogs.com/darkknightzh/p/6591923.html</a></p>
<ol start="2">
<li>
<p>使用函数 set_device</p>
<p><code>import torch torch.cuda.set_device(id)</code></p>
<p>该函数见 pytorch-master\torch\cuda_<em>init</em>_.py。</p>
<p>不过官方建议使用CUDA_VISIBLE_DEVICES，不建议使用 set_device 函数。</p>
</li>
</ol>
]]></content>
      <tags>
        <tag>machine-learning</tag>
        <tag>pytorch</tag>
        <tag>server</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker与Nivida-Docker的用法与注意事项</title>
    <url>/2020/04/26/docker-et-nvidia/</url>
    <content><![CDATA[<h2 id="docker-images-and-containers">Docker Images and Containers</h2>
<ul>
<li><p>清除所有已经停止的container：<code>docker container prune -f</code> 。其中 <code>-f</code> 表示不弹出确认提示。也可使用<code>docker rm $(docker ps -a -q)</code>来清理。其中，<code>docker rm</code>代表删除container，而<code>docker rmi</code>则是删除image。</p></li>
<li><p>如果你需要实例化一个只用一次的container，那么使用<code>docker run --rm</code>参数，结束后会自动删除。</p>
<span id="more"></span></li>
<li><p><code>docker ps &lt;-a&gt;</code> 可以列出正在运行的/全部的container。其效果和<code>docker container ls &lt;-a&gt;</code>相同。而若想列出全部images，则要使用<code>docker images</code>。</p></li>
<li><p>docker images中的环境变量有四个来源：</p>
<ol type="1">
<li>Dockerfile中通过<code>ENV</code>指令添加的环境变量，如<code>ENV PATH /opt/conda/bin:$PATH</code></li>
<li>Dockerfile中通过修改<code>/root/.bashrc</code>文件使用<code>export</code>命令添加到bash中的环境变量，如<code>export PATH=/OPT/conda/bin:$PATH</code>命令。</li>
<li>在通过image实例化container时添加<code>-e</code>或<code>--env</code>参数来添加到环境中的变量。这个方法有局限性，它不能完成对已有变量的“添加”操作，只能新建一个新的环境变量，如<code>--env NEW_VAR=/opt/conda/bin</code></li>
<li>在<code>docker run</code>末端的container内命令的前面添加一句<code>export</code>引导的命令，如：<code>docker run -it -v $(PWD):/app debian:jessie bash -c 'export PATH=$PATH:/opt/conda/bin; bash'</code>。它的缺点是较为复杂。</li>
</ol>
<p>其中，如果能找到源Dockerfile，最好的方法是通过修改Dockerfile然后重新build得到一个自己的版本。其次是方法三，实在不行使用方法四。如果先进入bash再运行命令可以正常运行，而直接使用<code>docker run</code>出现了环境变量相关的失败提示，很可能是由于Dockerfile写的时候使用的是在<code>/root/.bashrc</code>中添加环境变量的方法所致。</p></li>
<li><p>如果需要一个container长期在后台待机候命，那可以使用<code>-d</code>或<code>--detach</code>选项建立一个一直待机的docker进程。使用方法：</p>
<ol type="1">
<li><code>docker run -itd --name NAME xxx/xxx:xx /bin/bash</code></li>
<li><code>docker exec -it NAME your-command</code></li>
</ol></li>
<li><p>启动时如果需要对本地文件夹和Docker内部文件夹做映射，则使用<code>docker run -v &lt;LOCAL_FOLDER&gt;:&lt;DOCKER_FOLDER&gt;</code> 。 该参数可以复数次出现，如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run \</span><br><span class="line">    -v <span class="variable">$AUDIO_IN</span>:/input \</span><br><span class="line">    -v <span class="variable">$AUDIO_OUT</span>:/output \</span><br><span class="line">    -v <span class="variable">$MODEL_DIRECTORY</span>:/model \</span><br><span class="line">    -e MODEL_PATH=/model \</span><br><span class="line">    researchdeezer/spleeter \</span><br><span class="line">    separate -i /input/audio_1.mp3 /input/audio_2.mp3 -o /output</span><br></pre></td></tr></table></figure></li>
<li><p>docker run所有的参数都应该写在镜像名字<code>xxx/xxx:xx</code>前面，写在其后面的统统会被视作在docker container中运行的命令或命令参数。</p></li>
<li><p>如果你有了一个在后台持续运行的container，且你想弄一个交互性bash，此时你仍需要加上<code>-it</code>参数，同样是在<code>docker exec</code>后，container名字前加需要的参数，restart和start同理。</p></li>
<li><p>如果你对作者的Docker Image不满意，需要修改，此时有两种方法：</p>
<ol type="1">
<li>找到Dockerfile并修改，<code>docker build</code>，<code>docker push</code></li>
<li>使用bash进入一个实例化的Image，在里面做一通操作，出来后使用<code>docker commit -m &lt;YOUR_MESSAGE&gt; -a &lt;AUTHOR_NAME&gt; &lt;CONTAINER_ID&gt; &lt;DOCKERHUB_USERNAME/NEW_IMAGE_NAME:TAG&gt;</code>提交更改使其保存为一个新的镜像，最后使用<code>docker push</code>推送新的镜像到docker hub。如果命名有误或忘记添加docker hub username作为前缀，那么可以使用<code>docker tag &lt;existing-image&gt; &lt;hub-user&gt;/&lt;repo-name&gt;[:&lt;tag&gt;]</code>改名。</li>
</ol>
<p>注意，使用<code>docker push</code>需要有docker hub账号，并在push前使用<code>docker login</code>操作登录。</p></li>
<li><p>一个辨析：<code>docker commit</code>针对的是一个正在运行的container，使其固化为一个image；而<code>docker push</code>推送的则是一个image到docker hub。前者是本地操作，后者是上传操作。</p></li>
<li><p>一个区别：<code>docker start</code>是启动一个已经停止的container，而<code>docker restart</code>则是先stop一个container再start。如果一个container已经停止了，那么二者等效。</p></li>
<li><p>如果想从本机要拷贝一个文件/目录到docker内部，可以使用<code>docker cp [OPTIONS] CONTAINER:SRC_PATH DEST_PATH</code>，如<code>docker cp ./some_file CONTAINER:/work</code>. 注意这里是container而非image。</p></li>
</ul>
<h2 id="dockerfile">Dockerfile</h2>
<ul>
<li>Docker Hub中并不直接提供Dockerfile，但可以通过查看image的“标签”页面看每个image的docker建立操作。但由于Docker build的时候使用git会很方便，所以很多作者会在其Github上发布这些Dockerfile，往往可以查看介绍页面找到链接。</li>
<li>Dockerfile中设置进入点命令：<code>ENTRYPOINT ["spleeter"]</code>。</li>
</ul>
<ol type="1">
<li>这里”spleeter“是一个bin可执行文件。它的效果是：本来需要用户在<code>docker run</code>时输入<code>docker run xxx/xxx:xx spleeter separate</code>， 现在就只用输入<code>docker run xxx/xxx:xx separate</code>了，即run的时候帮你先打了一个命令标记但没给你按回车。</li>
<li>如果你发现自己在运行一个docker image时候提示了某个你没有输入的命令的相关问题，如<code>xxx don't have a parameter yyy, please input aaa, bbb, or ccc</code>，很有可能是Dockerfile中设定了进入点。</li>
<li>如果作者在Dockerfile中设定了进入点，但你需要进入docker进行调试或检查时，可以使用<code>docker run -it --entrypoint bash</code>来切换入点，进入一个bash命令行中调试。</li>
</ol>
<ul>
<li><code>docker build</code>针对的是一个url或是一个本地的文件夹。如果是本地的文件夹，文件夹内需要含有一个以<code>Dockerfile</code>为名的文件，如果需要导入某些文件到Docker Image中，则这些文件需要在正确的位置。
<ol type="1">
<li>如果dockerfile的名字不是<code>Dockerfile</code>，则使用<code>-f/--file &lt;DOCKERFILE_NAME&gt;</code>来指定名称。</li>
<li>如果需要指定输出image的名字和tag，则使用<code>-t/--tag</code>标签，以<code>name:tag</code>命名。</li>
<li>如果build的时候忘记了命名image，则输出的image没有名字和tag，只有一个随机序号。此时如果要重命名，可以用<code>docker tag &lt;SERIAL_NUMBER&gt; &lt;NAME:TAG&gt;</code> 命令。默认tag为latest。</li>
<li>Docker Build示例：
<ul>
<li>本地文件夹：<code>docker build -f &lt;NAME:TAG&gt; &lt;TARGET DICTIONARY&gt;</code></li>
<li>本地文件：<code>docker build - &lt; &lt;Dockerfile_Path&gt;</code></li>
<li>URL：<code>docker build https://github.com/&lt;USERNAME&gt;/&lt;REPONAME&gt;.git#&lt;BRUNCH&gt;:&lt;SUBFOLDERNAME&gt;</code></li>
</ul></li>
</ol></li>
</ul>
<h2 id="nivdia-docker">Nivdia Docker</h2>
<ul>
<li><p>先放<a href="https://github.com/NVIDIA/nvidia-docker">链接</a>。这里是Nvidia Docker的Github仓库。</p></li>
<li><p>再说作用。若想在Docker中运行GPU程序，则普通的Docker是做不到的，程序无法默认在Docker中使用GPU计算资源；另一方面，如果本地已经安装了某个版本的CUDA，但目标程序需要依赖另一个版本，这也是非常麻烦的。而Nvidia Docker的出现则很好解决了这个问题。它相当于在Docker的下面塞进了一层CUDA层，介于Container和OS之间。</p>
<figure>
<img data-src="inner.png" alt="Nvidia Docker 原理图"><figcaption aria-hidden="true">Nvidia Docker 原理图</figcaption>
</figure></li>
<li><p>然后是安装。</p>
<ol type="1">
<li><p>作为前置条件，需要本机上安装有Nvidia Driver，不强制要求CUDA。（不过既然都安到Driver了，不如把本机CUDA也装了）官方教程<a href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#ubuntu-installation">链接</a>。当然，请安装Docker。</p></li>
<li><p>执行以下代码：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Add the package repositories</span></span><br><span class="line">distribution=$(. /etc/os-release;<span class="built_in">echo</span> $ID<span class="variable">$VERSION_ID</span>)</span><br><span class="line">curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -</span><br><span class="line">curl -s -L https://nvidia.github.io/nvidia-docker/<span class="variable">$distribution</span>/nvidia-docker.list | sudo <span class="built_in">tee</span> /etc/apt/sources.list.d/nvidia-docker.list</span><br><span class="line"></span><br><span class="line">sudo apt-get update &amp;&amp; sudo apt-get install -y nvidia-container-toolkit</span><br><span class="line">sudo systemctl restart docker</span><br></pre></td></tr></table></figure>
<p>代码可能会随着Nvidia Docker的的升级而发生变化，最好参阅本章第一条的链接。</p></li>
</ol></li>
<li><p>试运行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#### Test nvidia-smi with the latest official CUDA image</span></span><br><span class="line">docker run --gpus all nvidia/cuda:10.0-base nvidia-smi</span><br><span class="line"></span><br><span class="line"><span class="comment"># Start a GPU enabled container on two GPUs</span></span><br><span class="line">docker run --gpus 2 nvidia/cuda:10.0-base nvidia-smi</span><br><span class="line"></span><br><span class="line"><span class="comment"># Starting a GPU enabled container on specific GPUs</span></span><br><span class="line">docker run --gpus <span class="string">&#x27;&quot;device=1,2&quot;&#x27;</span> nvidia/cuda:10.0-base nvidia-smi</span><br><span class="line">docker run --gpus <span class="string">&#x27;&quot;device=UUID-ABCDEF,1&quot;&#x27;</span> nvidia/cuda:10.0-base nvidia-smi</span><br><span class="line"></span><br><span class="line"><span class="comment"># Specifying a capability (graphics, compute, ...) for my container</span></span><br><span class="line"><span class="comment"># Note this is rarely if ever used this way</span></span><br><span class="line">docker run --gpus all,capabilities=utility nvidia/cuda:10.0-base nvidia-smi</span><br></pre></td></tr></table></figure>
<p>其标志性特点就是一个参数<code>--gpus &lt;PARAMETERS&gt;</code> 一般使用<code>--gpus all</code>即可，其他部分和普通docker一模一样。</p></li>
</ul>
]]></content>
      <tags>
        <tag>deep-learning</tag>
        <tag>docker</tag>
        <tag>nvidia</tag>
        <tag>gpu</tag>
      </tags>
  </entry>
  <entry>
    <title>tensorflow：理解 rank, shape, type</title>
    <url>/2019/02/08/tf-rst/</url>
    <content><![CDATA[<p>tensorflow 使用一种叫 tensor 的数据结构去展示所有的数据，我们可以把 tensor 看成是 n 维的 array 或者 list。在 tensorflow 的各部分图形间流动传递的只能是tensor。</p>
<span id="more"></span>
<h3 id="rank"><a class="markdownIt-Anchor" href="#rank"></a> rank</h3>
<p>rank 就是 tensor 的维数。<br>
例如我们所说的标量(Scalar)：<br>
<code>s = 8</code> 维数为 0，所以它的 rank 为 0。</p>
<p>例如矢量(Vector)：<br>
<code>v = [1, 2, 3]</code>，rank 为 1。</p>
<p>例如矩阵(Matrix)：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">m = [</span><br><span class="line">  [1, 1, 1],</span><br><span class="line">  [2, 2, 2],</span><br><span class="line">  [3, 3, 3]</span><br><span class="line">] # rank 为 2</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>又例如 rank 为 3 的 tensor：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">t = [[[2], [4], [6]], [[8], [10], [12]], [[14], [16], [18]]]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>依次类推……</p>
<h3 id="shape"><a class="markdownIt-Anchor" href="#shape"></a> shape</h3>
<p>tensorflow 用 3 种方式描述一个 tensor 的维数：<br>
rank, shape, 以及 dimension number (维数)<br>
所以 shape 和 rank 的意思的一样的，只是表达的形式不同。</p>
<table>
<thead>
<tr>
<th>rank</th>
<th>shape</th>
<th>dimension</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>[]</td>
<td>0 维</td>
</tr>
<tr>
<td>1</td>
<td>[D0]</td>
<td>1 维</td>
</tr>
<tr>
<td>2</td>
<td>[D0, D1]</td>
<td>2 维</td>
</tr>
<tr>
<td>n</td>
<td>[D0, D1, …, Dn-1]</td>
<td>n 维</td>
</tr>
</tbody>
</table>
<p>shape 写成只包含整数的 list 或者 tuple 形式，例如 [1, 4, 2]</p>
<h3 id="data-type"><a class="markdownIt-Anchor" href="#data-type"></a> data type</h3>
<p>tensor 的数据结构除了 维数(dimensionality)，还有 数据类型(data type)。<br>
例如 32位浮点数(32 bits floating point) 等等，可以从下面的链接中查看完整的：<br>
<a href="https://link.jianshu.com/?t=https://www.tensorflow.org/programmers_guide/dims_types#data_types">https://www.tensorflow.org/programmers_guide/dims_types#data_types</a></p>
]]></content>
      <tags>
        <tag>machine-learning</tag>
        <tag>tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title>Plan of Project Tomasulo Visual</title>
    <url>/2019/10/22/tomasulo/</url>
    <content><![CDATA[<h1 id="aims"><a class="markdownIt-Anchor" href="#aims"></a> Aims</h1>
<ol>
<li>Build a project to visualize the workflow of Tomasulo’s algorithm.</li>
<li>The project should contain at least these parts: Cycle graph, Register info, Pipeline, Data info, Code info and statistics.</li>
<li>We can add some additional components.</li>
</ol>
<span id="more"></span>
<h1 id="points"><a class="markdownIt-Anchor" href="#points"></a> Points</h1>
<ol>
<li>Language: Java</li>
<li>GUI Support: Swing</li>
<li>Collaboration Platform: <a href="https://github.com/miracleyoo/Tomasulo-Visual">GitHub</a></li>
<li>Divide pattern: By components. Each one 2 components.</li>
<li>DDL: Next week(Oct 29)</li>
<li>Algorithm Reference: <a href="https://youtu.be/jyjE6NHtkiA">Youtube</a></li>
</ol>
<h1 id="reference-images"><a class="markdownIt-Anchor" href="#reference-images"></a> Reference Images</h1>
<p>![WinMips64](Plan de Project Tomasulo Visual/image-20191022180533866.png)</p>
<p>![Slides](Plan de Project Tomasulo Visual/image-20191022180615852.png)</p>
<p>![Youtube Course](Plan de Project Tomasulo Visual/image-20191022180646659.png)</p>
]]></content>
      <tags>
        <tag>computer-architecture</tag>
      </tags>
  </entry>
  <entry>
    <title>使用tree生成目录树并显示中文</title>
    <url>/2018/05/14/tree/</url>
    <content><![CDATA[<p>当你想优雅地生成一个指定目录的文件目录树时，相信这个tree工具可以帮助你</p>
<h2 id="安装"><a class="markdownIt-Anchor" href="#安装"></a> 安装</h2>
<p>MacOS：<code>brew install tree</code></p>
<p>Ubuntu：<code>sudo apt-get inatall tree</code></p>
<span id="more"></span>
<h2 id="简介"><a class="markdownIt-Anchor" href="#简介"></a> 简介</h2>
<blockquote>
<p>tree命令可以以目录树的形式显示指定(默认显示这个文件系统)目录的所有文件夹和文件，在Debian或者Ubuntu系统中可以用apt安装：</p>
</blockquote>
<blockquote>
<p>使用方法：</p>
</blockquote>
<blockquote>
<p>但是，默认情况下，tree命令无法显示中文文件或文件夹名，会是一串转义字符。这时可以用选项-N来显示中文文件名：</p>
<p>最简单实用的命令：<code>tree -N</code></p>
</blockquote>
<h2 id="选项"><a class="markdownIt-Anchor" href="#选项"></a> 选项</h2>
<blockquote>
<p>关于tree命令选项的简单介绍如下：</p>
</blockquote>
<ul>
<li>-a 显示所有文件和目录。</li>
<li>-A 使用ASNI绘图字符显示树状图而非以ASCII字符组合。</li>
<li>-C 在文件和目录清单加上色彩，便于区分各种类型。</li>
<li>-d 显示目录名称而非内容。</li>
<li>-D 列出文件或目录的更改时间。</li>
<li>-f 在每个文件或目录之前，显示完整的相对路径名称。</li>
<li>-F 在执行文件，目录，Socket，符号连接，管道名称名称，各自加上”*”,”/”,”=”,”@”,”|”号。</li>
<li>-g 列出文件或目录的所属群组名称，没有对应的名称时，则显示群组识别码。</li>
<li>-i 不以阶梯状列出文件或目录名称。</li>
<li>-I&lt;范本样式&gt; 不显示符合范本样式的文件或目录名称。</li>
<li>-l 如遇到性质为符号连接的目录，直接列出该连接所指向的原始目录。</li>
<li>-n 不在文件和目录清单加上色彩。</li>
<li>-N 直接列出文件和目录名称，包括控制字符。</li>
<li>-p 列出权限标示。</li>
<li>-P&lt;范本样式&gt; 只显示符合范本样式的文件或目录名称。</li>
<li>-q 用”?”号取代控制字符，列出文件和目录名称。</li>
<li>-s 列出文件或目录大小。</li>
<li>-t 用文件和目录的更改时间排序。</li>
<li>-u 列出文件或目录的拥有者名称，没有对应的名称时，则显示用户识别码。</li>
<li>-x 将范围局限在现行的文件系统中，若指定目录下的某些子目录，其存放于另一个文件系统上，则将该子目录予以排除在寻找范围外。</li>
</ul>
]]></content>
      <tags>
        <tag>tool</tag>
        <tag>linux</tag>
        <tag>server</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu的apt-get找不到软件包解决方案</title>
    <url>/2018/08/15/ubuntu-apt-get-fail/</url>
    <content><![CDATA[<p>有时Ubuntu系统自带的apt-get会让人头疼的什么包都安装失败，提示无法找到相应包。</p>
<h2 id="原因"><a class="markdownIt-Anchor" href="#原因"></a> 原因：</h2>
<p><code>apt-get</code>命令太久未更新，或是服务器自带版本过低，需要手动更新并升级相应的库。</p>
<h2 id="解决方案"><a class="markdownIt-Anchor" href="#解决方案"></a> 解决方案：</h2>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get upgrade</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>linux</tag>
        <tag>apt-get</tag>
      </tags>
  </entry>
  <entry>
    <title>Video Classification Investigation Report</title>
    <url>/2019/11/07/video-classification/</url>
    <content><![CDATA[<h1 id="overview"><a class="markdownIt-Anchor" href="#overview"></a> Overview</h1>
<p>Video classification, or in our case, more specifically, action recognition, are studied for a long time. There are many traditional as well as deep learning based method developed to address this problem, and the latest action recognition result trained on a large dataset Kinetics can even reach 98% accuracy. Considering the fact that the action we need to classify is not too much, giving enough data and using the pre-trained model on Kinetics, the result can be quite promising.</p>
<span id="more"></span>
<h1 id="tough-points-in-video-classification"><a class="markdownIt-Anchor" href="#tough-points-in-video-classification"></a> Tough Points in Video Classification</h1>
<ol>
<li>The huge computational cost</li>
<li>How to capture long context and make decision comprehensively</li>
<li>How to design the classification structure which contain spatiotemporal information</li>
<li>How to deal with a smaller dataset</li>
</ol>
<h1 id="approaches-overview"><a class="markdownIt-Anchor" href="#approaches-overview"></a> Approaches overview</h1>
<h2 id="the-core-idea"><a class="markdownIt-Anchor" href="#the-core-idea"></a> The core idea</h2>
<ol>
<li>Try to build a workflow which can combine both spatial information and temporal information.</li>
<li>Try to focus on both frame itself and the motion near each frame.</li>
<li>Try to make decision based on the whole video rather than only parts of it.</li>
<li>Try to decrease the computational cost and remove the long pre-process.</li>
</ol>
<h2 id="two-basic-methods"><a class="markdownIt-Anchor" href="#two-basic-methods"></a> Two basic methods</h2>
<h3 id="single-stream-network"><a class="markdownIt-Anchor" href="#single-stream-network"></a> <a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42455.pdf">Single Stream Network</a></h3>
<p><img data-src="image-20191028125241454.png" alt="image-20191028125241454"></p>
<p>There are four ways of fusion, which means combine the information from each frame together to derive the final answer. They are:</p>
<ol>
<li>Single frame uses single architecture that fuses information from all frames at the last stage.</li>
<li>Late fusion uses two nets with shared parameters, spaced 15 frames apart, and also combines predictions at the end.</li>
<li>Early fusion combines in the first layer by convolving over 10 frames.</li>
<li>Slow fusion involves fusing at multiple stages, a balance between early and late fusion.</li>
</ol>
<h3 id="two-stream-networks"><a class="markdownIt-Anchor" href="#two-stream-networks"></a> <a href="https://arxiv.org/pdf/1406.2199.pdf">Two Stream Networks</a></h3>
<p><img data-src="image-20191028125608889.png" alt="image-20191028125608889"></p>
<p>Video can naturally be decomposed into spatial and temporal components.</p>
<ol>
<li>The spatial part, in the form of individual frame appearance, carries information about scenes and objects depicted in the video.</li>
<li>The temporal part, in the form of motion across the frames, conveys the movement of the observer (the camera) and the objects. In fact, the essence of “motion” is <a href="https://en.wikipedia.org/wiki/Optical_flow">optical flow</a>.</li>
</ol>
<h1 id="improvement-of-methods"><a class="markdownIt-Anchor" href="#improvement-of-methods"></a> Improvement of methods</h1>
<p>Firstly I’d like to show a graph which shows an overview of all previous action classification architectures drawn in the paper <a href="https://arxiv.org/abs/1705.07750">Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset</a>.</p>
<p><img data-src="image-20191028130233266.png" alt="image-20191028130233266"></p>
<p>To summarize, there are these kinds of improved methods:</p>
<ol>
<li>
<p><a href="https://arxiv.org/abs/1411.4389">LRCN</a>: Long-term Recurrent Convolutional Networks for Visual Recognition and Description</p>
<p><img data-src="GenericLRCN_high.png" alt="2 stream architecture"></p>
<p>Send each frame to a CNN at first and then uses the features extracted as the input of LSTM.</p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/1412.0767">C3D</a>: Learning Spatiotemporal Features with 3D Convolutional Networks</p>
<p><img data-src="c3d_high-1572285955778.png" alt="SegNet Architecture"></p>
<p>The first time using 3D Conv to process frames.</p>
</li>
<li>
<p><a href="https://arxiv.org/abs/1502.08029">Conv3D &amp; Attention</a>: Describing Videos by Exploiting Temporal Structure</p>
<p><img data-src="Larochelle_paper_high.png" alt="Attention Mechanism"></p>
<p>Add a attention mask before send the CNN-extracted feature into LSTM.</p>
</li>
<li>
<p><a href="https://arxiv.org/abs/1604.06573">TwoStreamFusion</a>: Convolutional Two-Stream Network Fusion for Video Action Recognition</p>
<p><img data-src="fusion_strategies_high.png" alt="SegNet Architecture"></p>
<p>Fuse two stream in a smarter way and get a better result.</p>
</li>
<li>
<p><a href="https://arxiv.org/abs/1608.00859">TSN</a> :Temporal Segment Networks: Towards Good Practices for Deep Action Recognition</p>
<p><img data-src="tsn_high.png" alt="SegNet Architecture"></p>
<p>Select video snippets not completely randomly, but divide the video into k equal-length parts and choose a snippets randomly from each division.</p>
</li>
<li>
<p><a href="https://arxiv.org/pdf/1704.02895.pdf">ActionVlad</a>:ActionVLAD: Learning spatio-temporal aggregation for action classification</p>
<p><img data-src="actionvlad-1572285243641.png" alt="SegNet Architecture"></p>
<p>In this work, the most notable contribution by the authors is the usage of learnable feature aggregation (VLAD) as compared to normal aggregation using maxpool or avgpool.</p>
</li>
<li>
<p><a href="https://arxiv.org/abs/1704.00389">HiddenTwoStream</a>:Hidden Two-Stream Convolutional Networks for Action Recognition</p>
<p><img data-src="image-20191028134438690.png" alt="image-20191028134438690"></p>
<p>It uses a “MotionNet” to take the place of optical flow.</p>
</li>
<li>
<p><a href="https://arxiv.org/abs/1705.07750">I3D</a>: Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset</p>
<p>Mainly used pretrained network by ImageNet and Kinetics dataset. Also, it use different 3D network for images and optical flows.</p>
</li>
<li>
<p><a href="https://arxiv.org/abs/1711.08200">T3D</a>: Temporal 3D ConvNets: New Architecture and Transfer Learning for Video Classification</p>
<p><img data-src="ttl_layer_high.png" alt="SegNet Architecture"></p>
<p>Transfer a 2-D DenseNet to a 3D one.</p>
</li>
</ol>
<h1 id="result-comparation"><a class="markdownIt-Anchor" href="#result-comparation"></a> Result comparation</h1>
<p><img data-src="image-20191028133828231.png" alt="image-20191028133828231"></p>
<p><img data-src="image-20191028133226300.png" alt="image-20191028133226300"></p>
<h1 id="current-thought"><a class="markdownIt-Anchor" href="#current-thought"></a> Current Thought</h1>
<p>As we can see from the analysis above, the I3D is the most computational efficient and accurate method. Also, the pre-trained model of I3D is provided by the author, so we can also take advantage of it. Now I think we should collect enough data of the corresponding action. Moreover, I noticed that there are many new method on Temporal Action Proposals, Temporal Action Localization and Dense-Captioning Events in Videos appearing this year in the competition ActivityNet, I may research into it to get better result later.</p>
<h1 id="datasets"><a class="markdownIt-Anchor" href="#datasets"></a> Datasets</h1>
<ul>
<li><a href="https://www.crcv.ucf.edu/data/UCF101.php">UCF101</a></li>
<li><a href="https://cs.stanford.edu/people/karpathy/deepvideo/">Sports-1M</a></li>
<li><a href="https://deepmind.com/research/open-source/kinetics">Kinetics</a></li>
<li><a href="http://activity-net.org/download.html">ActivityNet Version 1.3 dataset</a></li>
</ul>
<h1 id="codes"><a class="markdownIt-Anchor" href="#codes"></a> Codes</h1>
<ul>
<li><a href="https://github.com/hassony2/kinetics_i3d_pytorch">I3D models transfered from Tensorflow to PyTorch</a></li>
<li><a href="https://github.com/deepmind/kinetics-i3d">I3D models trained on Kinetics</a></li>
<li><a href="https://github.com/kenshohara/video-classification-3d-cnn-pytorch">Video Classification Using 3D ResNet</a></li>
</ul>
<h1 id="reference"><a class="markdownIt-Anchor" href="#reference"></a> Reference</h1>
<ul>
<li><a href="http://blog.qure.ai/notes/deep-learning-for-videos-action-recognition-review">Deep Learning for Videos: A 2018 Guide to Action Recognition</a></li>
<li><a href="https://arxiv.org/abs/1705.07750">Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset</a></li>
<li><a href="https://github.com/jinwchoi/awesome-action-recognition">Awesome Action Recognition</a></li>
<li><a href="http://activity-net.org/index.html">ActivityNet</a></li>
<li><a href="https://www.sciencedirect.com/science/article/abs/pii/0004370281900242">Determining optical flow</a></li>
</ul>
]]></content>
      <tags>
        <tag>machine-learning</tag>
        <tag>deep-learning</tag>
        <tag>CV</tag>
        <tag>video-classification</tag>
      </tags>
  </entry>
  <entry>
    <title>Win10支持多用户同时登陆方法</title>
    <url>/2018/08/22/win10-multi-user/</url>
    <content><![CDATA[<h2 id="问题"><a class="markdownIt-Anchor" href="#问题"></a> 问题</h2>
<p>普通的（非Win Server）Win10系统并不支持同时多用户登录，只能一个把另一个挤下去才能继续，而且多人共享一个桌面。</p>
<h2 id="解决办法"><a class="markdownIt-Anchor" href="#解决办法"></a> 解决办法</h2>
<p>见GitHub：<a href="https://github.com/stascorp/rdpwrap">链接</a>，stascorp大神写了一个插件，直接安装即可享受多用户同时登录。</p>
<p>可供下载的release包的地址：<a href="https://github.com/stascorp/rdpwrap/releases">链接</a></p>
]]></content>
      <tags>
        <tag>windows</tag>
      </tags>
  </entry>
  <entry>
    <title>Windows不重启电脑将路径加入系统PATH</title>
    <url>/2018/09/15/windows-norestart-set-env/</url>
    <content><![CDATA[<h1 id="问题"><a class="markdownIt-Anchor" href="#问题"></a> 问题</h1>
<p>如何在不重启电脑的情况下将某个路径加入到系统路径PATH中。</p>
<h1 id="解决方案"><a class="markdownIt-Anchor" href="#解决方案"></a> 解决方案</h1>
<p>假设我们需要添加的路径名称为<code>C:\ProgramData\Anaconda3</code></p>
<p>那么在命令行中执行：</p>
<p><code>set PATH=%PATH%C:\ProgramData\Anaconda3;</code></p>
<p>完毕后，可以使用<code>echo %PATH%</code>查看当前系统路径中是否已经完成添加</p>
<h1 id="注意"><a class="markdownIt-Anchor" href="#注意"></a> 注意</h1>
<p>这种添加仅限于在当前命令行中有效，重启命令行请重新操作。</p>
]]></content>
      <tags>
        <tag>windows</tag>
      </tags>
  </entry>
  <entry>
    <title>Word - 高级技巧 - 样式定义/导航窗格/多级列表/自定义目录</title>
    <url>/2018/08/13/word-adv-skill/</url>
    <content><![CDATA[<p>一、样式定义和导航窗格</p>
<h4 id="步骤一-创建一级标题样式设置相应格式"><a class="markdownIt-Anchor" href="#步骤一-创建一级标题样式设置相应格式"></a> 步骤一 创建一级标题样式，设置相应格式</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">操作：开始选项卡-&gt;创建样式-&gt;输入样式名称-&gt;点击修改-&gt;输入指定样式-&gt;单击确定按钮</span><br></pre></td></tr></table></figure>
<span id="more"></span>
<p>一级列表样式格式如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">一级列表：小三宋体加粗，大纲级别1级，1.5倍行距，无特殊格式，其余默认。</span><br></pre></td></tr></table></figure>
<p><img data-src="700.jpg" alt="img"></p>
<p>创建样式</p>
<p><img data-src="684.jpg" alt="img"></p>
<p>样式格式</p>
<p><img data-src="527.jpg" alt="img"></p>
<p>大纲级别设置</p>
<h4 id="步骤二-创建其余标题或内容样式"><a class="markdownIt-Anchor" href="#步骤二-创建其余标题或内容样式"></a> 步骤二 创建其余标题或内容样式</h4>
<p>根据步骤一的方法，依次创建二级标题，三级标题，四级标题，我的正文新样式，其格式对应如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">二级标题：小四宋体加粗，大纲级别2级，1.5倍行距，左侧缩进1字符，无特殊格式，其余默认。</span><br><span class="line">三级标题：小四宋体不加粗，大纲级别3级，1.5倍行距，左侧缩进1.5字符，无特殊格式，其余默认。</span><br><span class="line">四级标题：五号宋体加粗，大纲级别4级，1.5倍行距，左侧缩进2字符，无特殊格式，其余默认。</span><br><span class="line">我的正文：小五宋体不加粗，单倍行距，首行缩进2字符，其余默认。</span><br></pre></td></tr></table></figure>
<p>注：缩进设置方法，单击格式按钮 -&gt; 选择段落。</p>
<p><img data-src="681.jpg" alt="img"></p>
<p>段落设置入口</p>
<p><img data-src="529.jpg" alt="img"></p>
<p>段落缩进设置</p>
<h4 id="步骤三-设置样式至对应内容"><a class="markdownIt-Anchor" href="#步骤三-设置样式至对应内容"></a> 步骤三 设置样式至对应内容</h4>
<p>选中内容单击指定样式快速设置格式，操作简单这里不再赘述，效果如下图所示：</p>
<p><img data-src="700.jpg" alt="img"></p>
<p>样式效果</p>
<p>当然这里为什么需要样式的创建和定义，为什么要这么复杂。主要目的是为后续的操作奠定基础，比如多级列表，目录的自动生成等，使操作更加方便。</p>
<h4 id="步骤四-调出左侧导航窗格"><a class="markdownIt-Anchor" href="#步骤四-调出左侧导航窗格"></a> 步骤四 调出左侧导航窗格</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">操作：视图选项卡 -&gt; 显示栏目勾选导航窗格</span><br></pre></td></tr></table></figure>
<p>由于前面的操作对样式进行了大纲视图的设置，所以调出导航窗口后，你将会看到下面的效果，如果显示内容为空或者效果不佳，请查看操作过程是否由遗漏或出错。</p>
<p><img data-src="700.jpg" alt="img"></p>
<p>导航窗口调出</p>
<h3 id="二-多级列表"><a class="markdownIt-Anchor" href="#二-多级列表"></a> 二、多级列表</h3>
<h4 id="步骤一-定义新的多级列表"><a class="markdownIt-Anchor" href="#步骤一-定义新的多级列表"></a> 步骤一 定义新的多级列表</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">操作：开始选项卡 -&gt; 段落选项 -&gt; 点击多级列表按钮 -&gt; 定义新的多级列表</span><br></pre></td></tr></table></figure>
<p><img data-src="700.jpg" alt="img"></p>
<p>定义新的多级列表</p>
<h4 id="步骤二-设置列表格式"><a class="markdownIt-Anchor" href="#步骤二-设置列表格式"></a> 步骤二 设置列表格式</h4>
<p>1.首先设置一级列表的格式，如下图所示，圈出部分为修改项，其余根据自身情况修改。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">操作：单击要修改的级别 -&gt; 将级别链接到样式(一级标题) -&gt; 起始编号 -&gt; 此级别的编号样式 -&gt; 编号之后选择空格(制表格会影响后续目录生成的效果)</span><br></pre></td></tr></table></figure>
<p><img data-src="700.jpg" alt="img"></p>
<p>设置一级列表格式</p>
<p>2.设置二级列表格式，操作与一级列表一致，只不过此时需要设置包含的级别编号来自，因为二级列表前面的序号需要根据一级列表改变，此时需要设置包含的级别编号来自级别一，操作如图所示：</p>
<p><img data-src="700.jpg" alt="img"></p>
<p>设置二级列表</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入编号的格式1.1，其中小数点为手动添加，其余文本缩进位置等选项，可根据自身要求进行修改。</span><br></pre></td></tr></table></figure>
<p>3.根据二级列表格式的设置步骤，依次设置三级列表和四级列表，最终效果如下</p>
<p><img data-src="700.jpg" alt="img"></p>
<p>多级列表</p>
<p>这样操作的好处相信大家都明白，假如在撰写文档的过程中，需要调整章节或者删减章节的话，标题前面的序号会跟着自动变化，而不至于像个小白一样，重新把编号一个个手动去更改。</p>
<p>当然，如果想定义以下形式的多级列表，也是非常简单的，下面请看步骤：</p>
<p><img data-src="700.jpg" alt="img"></p>
<p>定义新的多级列表</p>
<p>a. 编辑一级列表时，在“输入编号的格式”一栏中，手动输入第章，其中的数字一二三由下面的“此级别的编号样式”给出，如下图所示：</p>
<p><img data-src="560.jpg" alt="img"></p>
<p>编辑一级列表</p>
<p>b. 编辑二三四级列表时，跟之前步骤类似，不过需要勾选“正规形式编号”的选项，如下图所示：</p>
<p><img data-src="563.jpg" alt="img"></p>
<p>编辑二三四级列表</p>
<h3 id="三-自定义目录"><a class="markdownIt-Anchor" href="#三-自定义目录"></a> 三、自定义目录</h3>
<p>目录的引用，也是非常重要的技能，感兴趣的话做好get准备。步骤也相对简单，希望能让你们有所收获，下面将对步骤进行表述和演示。<br>
1.找到自定义目录按钮，操作如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">操作：引用选项卡 -&gt; 目录 -&gt; 自定义目录</span><br></pre></td></tr></table></figure>
<p><img data-src="700.jpg" alt="img"></p>
<p>自定义目录入口</p>
<p>2.设置目录级别对应样式，单击选项按钮，清除默认的目录级别，将目录级别与样式标题进行绑定。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">有效样式：一级标题 -&gt;目录级别： 1</span><br><span class="line">有效样式：二级标题 -&gt;目录级别： 2</span><br><span class="line">有效样式：三级标题 -&gt;目录级别： 3</span><br><span class="line">有效样式：四级标题 -&gt;目录级别： 4</span><br></pre></td></tr></table></figure>
<p><img data-src="700.jpg" alt="img"></p>
<p>绑定样式</p>
<p>3.绑定设置完成后，点击修改按钮，设置每一级的格式，这里示例的格式如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">一级目录：四号宋体，1.5倍行距，无特殊格式，其余默认。</span><br><span class="line">二级目录：小四宋体，1.5倍行距，左侧缩进0.5字符，无特殊格式，其余默认。</span><br><span class="line">三级目录：五号宋体，1.5倍行距，左侧缩进1字符，无特殊格式，其余默认。</span><br><span class="line">四级目录：五号宋体，1.5倍行距，左侧缩进1.5字符，无特殊格式，其余默认。</span><br></pre></td></tr></table></figure>
<p>单击样式窗体中的<strong>目录1</strong>后，单击<strong>修改</strong>按钮修改样式，最后点击<strong>确定</strong>按钮。同理，设置<strong>目录2</strong>，<strong>目录3</strong>，<strong>目录4</strong>样式。</p>
<p><img data-src="700.jpg" alt="img"></p>
<p>目录样式</p>
<p>4.单击目录窗体中确定按钮，此时可看到目录已成功生成，如下图所示：</p>
<p><img data-src="700.jpg" alt="img"></p>
<p>目录生成效果</p>
<p><strong>另外，下面还有两点需要大家注意</strong></p>
<ol>
<li>
<p>当正文内容发生修改时，可在目录区域单击鼠标右键，选择更新域，更新整个目录或只更新页码，即可完成目录的更新操作。</p>
<p><img data-src="700.jpg" alt="img"></p>
<p>更新域</p>
</li>
<li>
<p>当出现标题和序号之前出现若干空格时，出现这种情况一般是多级列表定义的时候设置“编号之后”的格式为“制表符”而造成的。此时需看下多级列表的设置中，有没有将“编号之后”的选项设置为空格。</p>
<p><img data-src="700.jpg" alt="img"></p>
<p>自动生成的目录出现空格问题</p>
</li>
</ol>
<p>以下为改正方法：</p>
<p><img data-src="566.jpg" alt="img"></p>
<p>修复自动生成的目录出现空格问题</p>
<h1 id="word-中图片和表格的自动编号"><a class="markdownIt-Anchor" href="#word-中图片和表格的自动编号"></a> Word 中图片和表格的自动编号</h1>
<p>发表于 <a href="https://cnzhx.net/blog/auto-number-fig-or-table-in-word/">2013-05-24</a> 作者 <a href="https://cnzhx.net/">H Zeng</a><br>
更新于 2015-08-27</p>
<p>使用 Word 编辑长文档经常需要给文档中的图片和表格进行编号，特别是科技文档，如毕业论文。人工给图片和表格编号的缺点想必很多人都曾遇到过，不修改还好，一调整顺序就大乱。Word 其实可以自动给图片和表格分别编号，甚至可以设定编号的格式，在修改文档的时候它还可以自动调整编号。这绝对是编辑长文档所必备的技巧。</p>
<p>因为图片和表格需要分别编号，并且操作方式类似，下面就以图片的自动编号为例进行说明。需要注意的区别是，按照一般的习惯，以及科技文档的要求，图题应该放在图片的下方，而表题应该放在表格的上方。</p>
<p>本文介绍的操作可以做为前面介绍的<a href="https://cnzhx.net/blog/word-styles-for-zzti-thesis/">使用 Word 中的样式来加速论文排版操作</a>的补充。分成两大块来介绍：<a href="https://cnzhx.net/blog/auto-number-fig-or-table-in-word/#insert_caption">添加自动编号</a>、<a href="https://cnzhx.net/blog/auto-number-fig-or-table-in-word/#insert_ref">引用编号</a>。</p>
<p>Word 有内置的题注格式，如果不想用，还可以新建新的格式。在文档中新建之后，以后就可以直接用了。</p>
<h3 id="首先插入题注"><a class="markdownIt-Anchor" href="#首先插入题注"></a> 首先，插入题注。<a href="https://cnzhx.net/blog/auto-number-fig-or-table-in-word/#i-1">¶</a></h3>
<p>插入需要的图片，在图片上单击鼠标右键，选择“<strong>插入题注</strong>”（Insert Caption，如下图所示），</p>
<p><img data-src="word-fig-insert-cation.png" alt="Word 中为图片右键单击选择“插入题注”（Insert Caption）"></p>
<p>Word 中为图片右键单击选择“插入题注”（Insert Caption）</p>
<h3 id="第二调整配置"><a class="markdownIt-Anchor" href="#第二调整配置"></a> 第二，调整配置。</h3>
<p>在弹出的<strong>题注设置对话框</strong>（如下图所示）中输入/设置题注的标题（输入标题时最好在前面自动生成的题注标签和编号后面输入一个空格），选项中的标签、（题注）位置，还可以勾选下面的排除标签选项。</p>
<p><img data-src="006tKfTcly1ftwdfnps37j30e80a8gme.jpg" alt="Word 图片题注对话框"></p>
<p>Word 图片题注对话框</p>
<p>如果已经新建过标签了，可以在选择标签那一栏右边的小箭头那里找到。</p>
<h3 id="第三新建标签"><a class="markdownIt-Anchor" href="#第三新建标签"></a> 第三，新建标签。</h3>
<p>如果默认的题注形式不符合要求，还可以自己创建一个“<strong>新标签</strong>”（New Label），也可以只更改“编号”。比如上面默认的标签是 Figure，我想改成“<strong>图</strong>”。于是单击“新建标签”，在弹出的对话框中输入“图”（不要引号），此时题注对话框的第一行的自动生成部分就符合要求了。</p>
<h3 id="第四修改编号格式"><a class="markdownIt-Anchor" href="#第四修改编号格式"></a> 第四，修改编号格式。</h3>
<p>一般毕业论文中的图和表，其题注的编号需要带上章节号，例如，图1-1 xxx。此时，我们单击“编号”（Numbering），打开“题注编号”（Caption Numbering）对话框，如下图所示。</p>
<p><img data-src="006tKfTcly1ftwdfm5c0dj30fo0ae751.jpg" alt="Word 图片题注编号设置对话框"></p>
<p>Word 图片题注编号设置对话框</p>
<p>选中“包含章节号”（Include chapter number），上面可以选择数字格式，然后就可以在下面选择 Heading 1，下面还有连接符。这个 Heading 1 就是一级标题的意思（一般章标题都用一级标题）。</p>
<p>这些修改完成后，在同一个文档中都是一直有效的。</p>
<p><img data-src="006tKfTcly1ftwdfmflsdj30fo0ae751.jpg" alt="Word 图片题注示例"></p>
<p>Word 图片题注示例</p>
<p>成品如上图所示。如果没有设置上面的那个章标题（1 示例），Word 会报错，不过只要再给文档加入章标题，然后更新一下题注即可。</p>
<h3 id="第五更新题注"><a class="markdownIt-Anchor" href="#第五更新题注"></a> 第五，更新题注。</h3>
<p>每次调整了图片/表格在文档中的顺序，或者是在中间删除/增加了某些图片/表格，整个文档的图片/表格的编号都需要重新编排。一般 Word 会自动完成，如果发现它没有自动完成，可以选中文档全部内容，然后鼠标右键单击，选择菜单中的“更新域”即可。也可以使用 <a href="https://cnzhx.net/blog/shortcuts-for-ms-word-field/">Word 域的快捷键操作</a>以提高效率。</p>
<p>Word 中提供了很多自动完成的功能，几乎都是通过 <a href="http://office.microsoft.com/zh-cn/word-help/HA102749146.aspx">Word 中的域功能</a>来完成的。</p>
<h2 id="2-引用图片表格的编号"><a class="markdownIt-Anchor" href="#2-引用图片表格的编号"></a> 2. 引用图片/表格的编号</h2>
<p>既然图片/表格的编号是自动生成的，我们在行文中引用的时候，比如 图 1-1、表 1-1，也应该使用自动的编号，以方便在调整文档之后图片/表格的编号发生变化时让 Word 自动给引用的编号也做相应的调整。</p>
<p><img data-src="006tKfTcly1ftwdfp9nkbj30j80ei0ty.jpg" alt="Word 插入交叉引用的图片"></p>
<p>Word 插入交叉引用的图片</p>
<p>引用很简单，只要将鼠标光标定位到需要插入引用的位置，然后（步骤编号如上图所示）：</p>
<ol>
<li>单击 Word 工具栏中的“<strong>引用</strong>”（References）选项卡；</li>
<li>单击“<strong>交叉引用</strong>”（Cross-reference）即可打开对话框；</li>
<li>选择要引用的“<strong>类型</strong>”（Reference type）；</li>
<li>选择引用格式（Insert reference to），一般是“<strong>只有标签和编号</strong>”（Only label and number）；</li>
<li>挑选要引用的那幅图；</li>
<li>单击“<strong>插入</strong>”（Insert）；</li>
<li>已完成。</li>
</ol>
<p>为了提高效率，上面的步骤 1~2 可以用快捷键（按顺序）：Alt ——&gt; s ——&gt; r f；而步骤 3~7 可以用 Tab 键配合上、下键和 Enter 键来完成。这样可以达到手不离开键盘就能完成所有操作的目的。</p>
]]></content>
      <tags>
        <tag>word</tag>
      </tags>
  </entry>
  <entry>
    <title>Mac OS下C开发相关事项</title>
    <url>/2018/07/29/xcode-c/</url>
    <content><![CDATA[<h1 id="xcode简明教程mac-os下c开发环境的搭建"><a class="markdownIt-Anchor" href="#xcode简明教程mac-os下c开发环境的搭建"></a> Xcode简明教程（Mac OS下C开发环境的搭建）</h1>
<p>在 Mac OS X 下学习C语言使用 Xcode。Xcode 是由Apple官方开发的IDE，支持C、C++、Objective-C、Swift等，可以用来开发 Mac OS X 和 iOS 上的应用程序。Xcode最初使用GCC作为编译器，后来由于GCC的不配合，改用LLVM/Clang。</p>
<p>Xcode 的安装非常简单，在 APP Store 上直接下载即可，这里不再赘述。</p>
<span id="more"></span>
<h2 id="在xcode上运行c语言程序"><a class="markdownIt-Anchor" href="#在xcode上运行c语言程序"></a> 在Xcode上运行C语言程序</h2>
<p>在 Xcode 上运行C语言程序需要先创建工程，再在工程中添加源代码。</p>
<ol>
<li>打开 Xcode，选择“Create a new Xcode project”创建一个新工程，如下图所示：</li>
</ol>
<p><img data-src="006tNc79ly1ftrj0gvwv6j314c0ngth9.jpg" alt="image-20180729181817554"></p>
<ol start="2">
<li>接下来，选择要创建的工程类型，如下图所示：</li>
</ol>
<p><img data-src="006tNc79ly1ftrj13r485j31420ssjuw.jpg" alt="image-20180729181855118"></p>
<ol start="3">
<li>选择“OS X --&gt; Application --&gt; Command Line Tool”，点击“Next”。Command Line Tool 是“命令行工具”的意思，也就是控制台程序。</li>
</ol>
<p><img data-src="006tNc79ly1ftrj1kdat7j31460t0mzl.jpg" alt="image-20180729181921915"></p>
<p>这里需要填写和工程相关的一些信息：</p>
<ul>
<li>Product Name：产品名称，即工程名称。</li>
<li>Organization Name：组织名称，即公司、个人、协会、团队等的名称。</li>
<li>Organization Identifier：组织标识符，即有别于其他组织的一个标记，例如身份证号、公司网址、组织机构代码证等。</li>
<li>Bundle Identifier：程序标识符，即有别于其他程序的一个标记，由 Organization Identifier + Product Name 组成。</li>
<li>Language：工程所用的编程语言，这里选择C语言。</li>
</ul>
<ol start="4">
<li>点击“Next”，保存文件后即可进入当前工程，如下图所示：</li>
</ol>
<p>左侧是工程目录，主要包含了工程所用到的文件和资源。单击“main.c”，即可进入代码编辑模式，这里 Xcode 已经为我们创建好了一个“Hello World”小程序。点击上方的“运行”按钮，即可在右下角的选项卡中看到输出结果。</p>
<h1 id="修改工作路径使之与当前代码存放目录一致"><a class="markdownIt-Anchor" href="#修改工作路径使之与当前代码存放目录一致"></a> 修改工作路径使之与当前代码存放目录一致</h1>
<p>如下图在Xcode中点击工程名，选择Edit Scheme，之后在Use custom working directory前打钩，并将工作路径修改为**/Users/mac/Desktop/test**。</p>
<p><img data-src="006tNc79ly1ftrjltwyphj30ji084jsl.jpg" alt="image-20180729183848469"></p>
<p><img data-src="006tNc79ly1ftrjmjg1v2j31di0rowkh.jpg" alt="image-20180729183918230"></p>
]]></content>
      <tags>
        <tag>xcode</tag>
        <tag>C-lang</tag>
      </tags>
  </entry>
  <entry>
    <title>“塞尔达”通关感想</title>
    <url>/2019/09/11/zelda/</url>
    <content><![CDATA[<p>距离暑假通关塞尔达已经有了接近一个月的时间了，期间一直想写这么一篇感想，然碍于各种杂事，也有自己拖延症的原因一直没能下笔。总是感觉下笔写下写文字是一项有着其固有的、足够的神圣性的东西，莫非头脑此刻十分清醒，断不愿糟践这一主题。</p>
<span id="more"></span>
<p>每个人心灵的角落里总会存有那么一份两份初始的感动，其如同南极冰架中直接取出的冰核一般晶莹剔透，只是那么遗世独立的存在着。现在妄图追想究竟是哪一刻开始我被这款游戏深深的打动，愿为其废寝忘食、只求能在其中多待一分一秒，确无法想起。但也许那本就不是一瞬的感动，而是如同大漠中被风沙琢磨到光滑的巨石，并非某一粒沙或某一缕风使其如此，但回过头来，还是会不断感叹这一壮举。</p>
<p>那个世界是多么的令人神往！从水中一跃而起的卓拉族、火山中像岩石般刚强的鼓隆族、沙漠中直面缓步前行的格鲁特族、蓝天上直冲云霄的利特族，以及一见之下神秘莫测但融入其中后却又显得淳朴自然的希卡族，都在这片广阔无垠、秘密有如繁星般众多的海拉鲁的大路上默默繁衍生息。而我，则既是一个失忆后的旁观者，又是一个诸多重大事件的参与者，我，行走于这片土地。</p>
<p>这里的人物是有性格的，他们给人感觉并不是一个个单纯的NPC。这里的人都有着自己的生活，他们日出而作，日落而息，有自己的工作与相应的责任，也有和其他人之间的羁绊，甚至有着对未来的展望与希冀。他们不是为了主人公而存在的工具人，而是这片广阔大陆真正的居民、真正的主人。作为一名沉睡已久却背负着拯救这个世界重任的英杰，我感觉自己反而像是一个微不足道的过客，并不是那么人人皆知，甚至为了得到些情报或物资还要想尽办法去讨好那些“该死”的土著。但这种感觉并不坏。我是这个世界中的一员，我和在各处遇到的人不断产生着羁绊，产生着相互间的责任与利益关系，和他么这种距离的联系令人十分舒适。</p>
<p>在这片大陆上，我并不受到任务的约束，尽管确实有各种主线支线任务存在。我在这里是真正自由的，我心灵中的言语是有重量的，它终将如实地反应在这片土地上。我可以选择开着滑翔帆在山谷间放浪形骸、游猎四方，也可以御冰而行，来到世界尽头的原始小岛。我能跟随主线任务开疆拓土，点亮一个个神庙传送点，也能靠着他们周游世界，搜集各处特色服饰、烹调料理、陪村里小孩子玩捉迷藏。海拉鲁大地上有着多种多样、交织缠绕的情感。你既可以感到人鱼公主米法那甄于纯粹的爱恋，那不计一切却甘愿默默无闻、反而从旁支持公主的那种令人心脏仿佛被人被轻轻揪住的浓烈情感，也能从她身上感觉到面临重大责任时的勇于担当、不惧不退。</p>
<p>我真的太喜欢这个米法公主了！！！她赠与我的技能是死亡时刻的治愈。每当我快要撑不住的时候，米法的那句&quot;ミファーの祈り、いつでも使えるよ&quot;中饱含着爱恋与温柔的话语总会让我感到十分的安心，甚至在肉体被治愈之前心灵已经被无数次治愈了。你说等这场战争结束后还来找你玩，然而我已经来了，你却又在哪里呢？？？即使到了后期，没事还是会来卓拉领地转一转，看到米法公主那晶莹剔透的雕像、听着领地内人民对公主由衷的赞颂还是会让人心情多少变得爽朗一些的。</p>
<p>在沙漠中进城那段莫非真的是官方福利？？林克子女装上线真的是让我吃了一鲸，意外的还挺好看哈哈哈。</p>
<p>塞尔达给我留下深刻印象的还有其低多边形、高对比度，又有如油画般的渲染风格。首先做到开放世界的绝非塞尔达，但其对开放世界的再定义与其令人过目不忘的渲染风格的确是有相当独到之处的。这是一个如诗如画的世界，地上摇曳着的小草是那么的水嫩翠绿而惹人疼爱，天空是如此的湛蓝而一尘不染，冰山是如此的冷酷而孤寂，沙漠是如此的狂放不羁，水是单纯而洁净的，虽然并没有逼真的水波图样，但这个世界别具一格的美感着实在我的心中留下了挥之不去又浓墨重彩的一笔。另外，这种渲染风格也大大降低了渲染开销，塞尔达能在switch这个硬件能力并不十分出色的平台上做到如此流畅的效果，和其渲染模式也是分不开的。任天堂显然知道自家switch的硬件实力与游戏定位，成功做到了用一个开销相对很低的渲染模式同时保证了游戏流畅度和可辨识度与可供用户记忆回味的特点，可谓是一举多得。</p>
<p>至于这款游戏在游戏机制上究竟为何如此打动人，除了自己有限的简介之外，也看了不少更专业的评价，看完后更惊觉此为真正神作。研究游戏从业者们的分析，则又得到了不少作为一个单纯的玩家很难发现的观察视角，而这些东西恰恰是使游戏封神更为核心的原因。</p>
<p>首先是塞尔达充分的利用了高度这个要因，使得玩家可以自行登高望远，定位到自己的目标地点。同时，游戏开发者显然希望用户不断攀登到高处，而出现在山顶各处的“呀哈哈”就是一个非常明显的证据。其实每次登顶一处或小山丘或高原雪山，内心深处还是十分渴望听到那一声清脆可爱的呀哈哈的。此外还包括林克使用手中的滑翔伞飞行、持盾滑行等运动方式的引入，都变相激起了玩家更大的攀登欲望。在游戏的诸多鼓励下，用户自然会希望多登高望远，鸟瞰众生，而这样一来，游戏便自然而然的不再需要使用大量的引导标注，如小地图上无处不在的感叹号和问号等符号，而把寻找位置的任务变相委任给了玩家，系统只负责提供一个方位，怎么过去全靠自己。这一点是一个大胆的创新，也使得游戏更加的立体化，而不是让玩家变成离开小地图和诸多标注对世界完全没有概念的盲人选手。</p>
<p>其次是光。即使是在很远的地方，玩家依旧可以看到那引诱人去探索的来自高塔和神庙的橙黄色辉光，它们无疑在潜意识中就给了玩家以连续不断的目标。结合以看似简单实用但其实实现并不简单的望远镜和标记系统，真的是让人能不断从心底涌现出那人类最原初的探索渴望。而这一个又一个的标记，这些远处的神庙与高塔，则在实质上担当了“小目标”的功效，能持续不断的给人提供成就感，而且保证了玩家在任何时候都不至于无事可做，即在这里，你永远不会无聊。</p>
<p>然后是新手教学部分。新手教学部分的节奏把握的很精准，既能让一个从没玩过此类游戏的小白成功上手而不觉得吃力，也能让老鸟不觉得无聊，而这一点往往是游戏设计者很难顾虑到的。塞尔达的玩法其实并不简单，随便一想就能列举出一大堆需要学习才能掌握的技巧，抛开各种战斗技巧不说，光是让玩家理解要解锁瞭望塔、钻进神庙解谜、传送点的点亮、滑翔帆的使用、以及四大异能（炸弹、磁力、冰块、时间锁定）的使用、马的相关动作等都并不是理所当然的，然而在前置的引导部分却都展现的十分自然。对于林克失忆的这个设定也是让我很感兴趣的一点。首先他的失忆给了老国王给予新手教学的理由，也让玩家一开始对海拉鲁的一无所知变得情有可原。由于其失忆前还有着一个十分重要的身份，所以无论玩家走到哪里都会有那么一两个关键人物可以和他展开对话、布置任务，这又在无形中帮助了玩家探索世界，且设计者能籍此将新手教学进行广义的延伸，比如在忍者村学习战斗技巧等。另外，由于失忆前林克的特殊身份，所有的英灵以及塞尔达公主都和他有着千丝万缕的联系，这也实质上推动了剧情的发展。不得不说，这个设定来的实在是太妙。</p>
<p>还有就是最重要的部分——物理系统与系统间的相互作用、相互关联。一个游戏好玩与否其实并不一定在于其引入了多少物理系统，或称自由度，而更多地和这些系统间的相互联系有关。在塞尔达中，就有磁、电、风、水、温度、时间（或相应的冲量）、天气、体力等系统，而这些系统之间都不是孤立的。非孤立的物理系统意味着玩家可能更多地利用生活中的常识，这往往可以激发出玩家更丰富的创造力，从而使得游戏更加生动耐玩。雨天岩壁会湿滑，不适于爬山，但你完全可以找个地方生火挨过去；小岛遥远，你既可以使用造冰能力一个个创造冰块飞过去，也可以拿一把团扇驱动帆船划过去，甚至可以把一个金属物体放到帆杆前面用磁力驱动；把一个物体送到迷宫中墙的对面，你可以解谜题走过去，也可以考虑用气球绑在它上面并用风吹过去…这一切实在太过生动、太过真实、富于创造性，而所有的这些特点都会有一个共同的作用——让游戏更好玩。</p>
<p>而这，不也正是任天堂所一直坚持在做的吗？</p>
]]></content>
      <tags>
        <tag>essay</tag>
        <tag>game</tag>
        <tag>zelda</tag>
      </tags>
  </entry>
  <entry>
    <title>通过zssh进行跨跳板机的文件传输</title>
    <url>/2018/08/27/zssh-file/</url>
    <content><![CDATA[<h1 id="问题"><a class="markdownIt-Anchor" href="#问题"></a> 问题</h1>
<p>当使用了跳板机连接远程服务器时，传输较大文件较为麻烦。</p>
<h1 id="解决方案"><a class="markdownIt-Anchor" href="#解决方案"></a> 解决方案</h1>
<h3 id="使用zssh进行传输"><a class="markdownIt-Anchor" href="#使用zssh进行传输"></a> 使用zssh进行传输</h3>
<ol>
<li>安装软件。Mac端：<code>brew install zssh</code></li>
</ol>
<span id="more"></span>
<h3 id="上传本地文件到服务器"><a class="markdownIt-Anchor" href="#上传本地文件到服务器"></a> 上传本地文件到服务器</h3>
<ol>
<li>用zssh登录到远端服务器：<code>zssh user1@domain1 -p port</code></li>
<li>如果需要进行跳板操作，继续：<code>ssh user2@domain2 -p port</code></li>
<li>切换文件夹到将要接收文件的目录：<code>cd xx/xx/xx</code></li>
<li>进入zssh：按下<code>ctrl+@</code>组合键</li>
<li>接下来，你会进入以<code>zssh &gt;</code>开头的命令行中，此时你实际上是在本机操作</li>
<li>切换到本机待传文件的位置：<code>zssh &gt; cd target_folder</code></li>
<li>开始传输文件到进入zssh前的服务器目录下：<code>zssh &gt; sz 123.txt </code></li>
</ol>
<h3 id="下载服务器文件到本机"><a class="markdownIt-Anchor" href="#下载服务器文件到本机"></a> 下载服务器文件到本机</h3>
<ol>
<li>先将本地目录切换到将要接收文件的文件目录下：<code>cd xxx/xxx/xxx </code></li>
<li>用zssh登录到远端服务器：<code>zssh user1@domain1 -p port</code></li>
<li>如果需要进行跳板操作，继续：<code>ssh user2@domain2 -p port</code></li>
<li>切换文件夹到将要发送文件的目录：<code>cd xx/xx/xx</code></li>
<li>在远程机器上,启动sz, 准备发送文件：<code>sz 123.txt </code></li>
<li>看到一堆乱码，此时按住组合键进入zssh：<code>ctrl+@</code></li>
<li>接住对应的文件：<code>zssh &gt; rz </code></li>
</ol>
<h1 id="提示"><a class="markdownIt-Anchor" href="#提示"></a> 提示</h1>
<ol>
<li>
<p>zssh 相当于一个套在后续服务器端操作上的一层壳，你按下<code>ctrl+@</code>时就回到了你的本机进行操作。</p>
</li>
<li>
<p>传输文件分为两步进行，分别是<code>rz</code>：接收和<code>sz</code>：传输</p>
</li>
<li>
<p>补充命令：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">zssh &gt; pwd //查看本地机器的目录位置</span><br><span class="line">zssh &gt; cd  //xxx/xxx/xxx 切换目录</span><br><span class="line">zssh &gt; ls  //查看当前目录下文件列表</span><br></pre></td></tr></table></figure>
</li>
</ol>
]]></content>
      <tags>
        <tag>machine-learning</tag>
        <tag>tool</tag>
        <tag>linux</tag>
        <tag>server</tag>
      </tags>
  </entry>
  <entry>
    <title>进程与线程</title>
    <url>/2018/08/01/c-project-note/</url>
    <content><![CDATA[<h1 id="进程与线程"><a class="markdownIt-Anchor" href="#进程与线程"></a> 进程与线程</h1>
<p><code>进程是程序执行时的一个实例，即它是程序已经执行到何种程度的数据结构的汇集</code>；从内核的观点看，进程的目的就是担当分配系统资源（CPU时间、内存等）的基本单位；</p>
<p><code>线程是进程的一个执行流，是CPU调度和分派的基本单位，它是比进程更小的能独立运行的基本单位</code>；一个进程由几个线程组成（拥有很多相对独立的执行流的用户程序共享应用程序的大部分数据结构），线程与同属一个进程的其他的线程共享进程所拥有的全部资源；</p>
<span id="more"></span>
<p><code>&quot;进程——资源分配的最小单位，线程——程序执行的最小单位&quot;</code></p>
<p>进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响；<br>
而线程只是一个进程中的不同执行路径线程有自己的堆栈和局部变量，但线程没有单独的地址空间，一个线程死掉就等于整个进程死掉；<br>
所以多进程的程序要比多线程的程序健壮，但在进程切换时，耗费资源较大，效率要差一些，但对于一些要求同时进行并且又要共享某些变量的并发操作，只能用线程，不能用进程；</p>
<h2 id="pthread线程库"><a class="markdownIt-Anchor" href="#pthread线程库"></a> pthread线程库</h2>
<p>头文件：<code>pthread.h</code>，gcc链接时参数：<code>-lpthread</code>；</p>
<p><strong>线程基本函数</strong><br>
<code>int pthread_create(pthread_t *tid, const pthread_attr_t *attr, void *(*func)(void *), void *arg);</code>：创建线程</p>
<ul>
<li><code>tid</code>：输出参数，保存返回的线程ID（与linux系统中的线程ID不一样，这个ID应该理解为一个地址），用无符号长整型表示；</li>
<li><code>attr</code>：输入参数，线程的相关属性，如线程优先级、初始栈大小、是否为守护进程等，一般置为NULL，表示使用默认属性；</li>
<li><code>func</code>：输入参数，一个函数指针（<code>void *job(void *arg);</code>），线程执行的函数；</li>
<li><code>arg</code>：输入参数，函数的参数，如果有多个参数须将其封装为一个结构体；</li>
<li>返回值：成功返回0，失败返回errno值（正数）；</li>
</ul>
<p><code>void pthread_exit(void *status);</code>：退出线程</p>
<ul>
<li><code>status</code>：输入参数，退出状态；</li>
</ul>
<p><code>int pthread_join(pthread_t tid, void **status);</code>：等待线程退出</p>
<ul>
<li><code>tid</code>：输入参数，指定等待的线程ID；</li>
<li><code>status</code>：输出参数，一个二级指针，保存退出值，可为NULL；</li>
<li>返回值：成功返回0，失败返回errno值；</li>
</ul>
<p><code>pthread_t pthread_self(void);</code>：获取当前线程ID</p>
<p><code>int pthread_detach(pthread_t tid);</code>：分离线程</p>
<ul>
<li>变为分离状态的线程，如果线程退出，它的所有资源将全部释放；<br>
而如果不是分离状态，线程必须保留它的线程ID，退出状态直到其它线程对它调用了pthread_join；</li>
<li><code>tid</code>：输入参数，指定的线程ID；</li>
<li>返回值：成功返回0，失败返回errno值；</li>
</ul>
<p><strong>线程ID</strong><br>
主线程：每个进程至少有一个线程，即main()函数的执行线程，称之为主线程；<br>
子线程：由主线程调用<code>pthread_create()</code>创建的线程；</p>
<p>线程不像进程，一个进程中的线程之间是没有父子之分的，都是<code>平级关系</code>；即线程都是一样的, 退出了一个不会影响另外一个；</p>
<p>但是所谓的<code>主线程main</code>，其入口代码是类似这样的方式调用main的：<code>exit(main(...))</code>；<br>
main执行完之后, 会调用exit()，exit()会让整个进程终止，那所有线程自然都会退出；</p>
<p>主线程先退出，子线程继续运行的方法：<br>
在主线程main中调用pthread_exit()，只会使主线程退出；而如果是return，编译器将使其调用进程退出的代码（如_exit()），从而导致进程及其所有线程结束运行；</p>
<p>按照POSIX标准定义，当主线程在子线程终止之前调用pthread_exit()时，子线程是不会退出的；</p>
<p>系统中的线程ID：</p>
<ul>
<li><code>ls /proc/[PID]/task/[TID]/</code>：可查看一个进程下的所有线程ID、及相关信息；</li>
<li><code>ps -eo user,pid,ppid,lwp,nlwp,%cpu,%mem,stat,cmd</code>：lwp即线程ID，nlwp为进程中的线程数量；</li>
</ul>
<p>主线程的线程ID与它所属进程的进程ID相同；</p>
<p>注意：这里的线程ID与<code>pthread_self</code>中的线程ID不是一个概念：<br>
<code>gettid</code>获取的是<code>内核中线程ID</code>，而<code>pthread_self</code>获取的是<code>posix描述的线程ID</code>；</p>
<p>在c语言中，可以用<code>syscall(__NR_gettid);</code>（头文件<code>sys/syscall.h</code>）来获取内核中的线程ID；</p>
<p><strong>互斥锁</strong><br>
就像共享内存中的信号量一样，为了防止多个线程同时使用一个共享的对象（如全局变量），pthread提供了互斥锁这种机制；</p>
<p><strong>初始化</strong><br>
静态初始化：<code>static pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;</code><br>
动态初始化：<code>int pthread_mutex_init(pthread_mutex_t *mutex, const pthread_mutexattr_t *attr);</code></p>
<ul>
<li><code>mutex</code>：输出参数，互斥变量；</li>
<li><code>attr</code>：输入参数，锁属性，NULL值为默认属性；</li>
<li>返回值：成功返回0，失败返回errno值；</li>
</ul>
<p><strong>加锁、释放锁</strong><br>
<code>int pthread_mutex_lock(pthread_mutex_t *mutex);</code>：加锁（阻塞）</p>
<ul>
<li><code>mutex</code>：输入参数，互斥变量；</li>
<li>返回值：成功返回0，失败返回errno值；</li>
</ul>
<p><code>int pthread_mutex_trylock(pthread_mutex_t *mutex);</code>：尝试加锁（非阻塞）</p>
<ul>
<li><code>mutex</code>：输入参数，互斥变量；</li>
<li>返回值：成功返回0，锁繁忙返回<code>EBUSY</code>，失败返回errno值；</li>
</ul>
<p><code>int pthread_mutex_unlock(pthread_mutex_t *mutex);</code>：释放锁</p>
<ul>
<li><code>mutex</code>：输入参数，互斥变量；</li>
<li>返回值：成功返回0，失败返回errno值；</li>
</ul>
<p><strong>销毁</strong><br>
<code>int pthread_mutex_destroy(pthread_mutex_t *mutex);</code></p>
<ul>
<li><code>mutex</code>：输入参数，互斥变量；</li>
<li>返回值：成功返回0，失败返回errno值；</li>
</ul>
<p><strong>条件变量</strong><br>
与互斥锁不同，<strong>条件变量是用来等待而不是用来上锁的，条件变量用来自动阻塞一个线程，直到某特殊情况发生为止；通常条件变量和互斥锁同时使用</strong></p>
<p>条件变量使我们可以睡眠等待某种条件出现；条件变量是利用线程间共享的全局变量进行同步的一种机制，主要包括两个动作：一个线程等待”条件变量的条件成立”而挂起；另一个线程使”条件成立”（给出条件成立信号）；</p>
<p>条件的检测是在互斥锁的保护下进行的；如果一个条件为假，一个线程自动阻塞，并释放等待状态改变的互斥锁；<br>
如果另一个线程改变了条件，它发信号给关联的条件变量，唤醒一个或多个等待它的线程，重新获得互斥锁，重新评价条件；<br>
如果两进程共享可读写的内存，条件变量可以被用来实现这两进程间的线程同步；</p>
<p><strong>相关函数</strong><br>
<code>int pthread_cond_init(pthread_cond_t *cond, pthread_condattr_t *cond_attr);</code>：动态初始化<br>
<code>int pthread_cond_wait(pthread_cond_t *cond, pthread_mutex_t *mutex);</code>：等待条件，阻塞<br>
<code>int pthread_cond_timedwait(pthread_cond_t *cond, pthread_mutex *mutex, const timespec *abstime);</code>：等待条件，超时<br>
<code>int pthread_cond_signal(pthread_cond_t *cond);</code>：通知条件，只唤醒单个等待线程<br>
<code>int pthread_cond_broadcast(pthread_cond_t *cond);</code>：通知条件，唤醒所有等待线程<br>
<code>int pthread_cond_destroy(pthread_cond_t *cond);</code>：销毁<br>
返回值：成功返回0，失败返回errno值；</p>
<p>静态初始化、动态初始化（和互斥锁相似）：<br>
<code>static pthread_cond_t cond = PTHREAD_COND_INITIALIZER;</code>：静态初始化<br>
<code>int pthread_cond_init(pthread_cond_t *cond, pthread_condattr_t *cond_attr);</code>：动态初始化</p>
<p><strong>pthread_cond_wait执行流程</strong><br>
<a href="pthread_cond_wait.jpg"><img data-src="https://ws3.sinaimg.cn/large/006tNc79ly1ftrgwswgi0j30ki0f9dhb.jpg" alt="pthread_cond_wait执行流程"></a></p>
<p>传入给<code>pthread_cond_wait</code>的mutex应为一把已经获取的互斥锁；<br>
pthread_cond_wait调用相当复杂，它是如下执行序列的一个组合：<br>
1）<code>释放互斥锁</code> 并且 <code>将线程挂起</code>（这两个操作是一个<code>原子操作</code>）；<br>
2）线程<code>获得信号</code>，<code>尝试获得互斥锁后被唤醒</code>；</p>
<p>多线程实例</p>
<p><strong>题目</strong><br>
1）有一int型全局变量flag初始值为0；<br>
2）在主线程中启动线程1，将flag设置为1；<br>
3）在主线程中启动线程2，将flag设置为2；<br>
4）主线程main一直阻塞，直到1变为2，或2变为1时才会继续运行；</p>
<p><strong>解决</strong></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;errno.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/types.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/syscall.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> gettid() syscall(__NR_gettid)</span></span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="keyword">volatile</span> <span class="type">int</span> flag = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="type">pthread_mutex_t</span> mutex = PTHREAD_MUTEX_INITIALIZER;</span><br><span class="line"><span class="type">static</span> <span class="type">pthread_cond_t</span> cond = PTHREAD_COND_INITIALIZER;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> *<span class="title function_">job1</span><span class="params">(<span class="type">void</span> *arg)</span>;</span><br><span class="line"><span class="type">void</span> *<span class="title function_">job2</span><span class="params">(<span class="type">void</span> *arg)</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">void</span>)</span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;++++++++++ entry thread_main (pid: %d, tid: %ld) ++++++++++\n&quot;</span>, getpid(), gettid());</span><br><span class="line"></span><br><span class="line">    <span class="type">pthread_t</span> tid1, tid2;</span><br><span class="line">    errno = pthread_create(&amp;tid1, <span class="literal">NULL</span>, job1, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="keyword">if</span>(errno)&#123;</span><br><span class="line">        perror(<span class="string">&quot;pthread_create&quot;</span>);</span><br><span class="line">        <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">    &#125;</span><br><span class="line">    errno = pthread_create(&amp;tid2, <span class="literal">NULL</span>, job2, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="keyword">if</span>(errno)&#123;</span><br><span class="line">        perror(<span class="string">&quot;pthread_create&quot;</span>);</span><br><span class="line">        <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;&lt;thread_main&gt; waiting for 1-&gt;2 or 2-&gt;1\n&quot;</span>);</span><br><span class="line">    errno = pthread_mutex_lock(&amp;mutex);</span><br><span class="line">    <span class="keyword">if</span>(errno)&#123;</span><br><span class="line">        perror(<span class="string">&quot;pthread_mutex_lock&quot;</span>);</span><br><span class="line">        <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">    &#125;</span><br><span class="line">    errno = pthread_cond_wait(&amp;cond, &amp;mutex);</span><br><span class="line">    <span class="keyword">if</span>(errno)&#123;</span><br><span class="line">        perror(<span class="string">&quot;pthread_cond_wait&quot;</span>);</span><br><span class="line">        <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">    &#125;</span><br><span class="line">    errno = pthread_mutex_unlock(&amp;mutex);</span><br><span class="line">    <span class="keyword">if</span>(errno)&#123;</span><br><span class="line">        perror(<span class="string">&quot;pthread_mutex_unlock&quot;</span>);</span><br><span class="line">        <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;&lt;thread_main&gt; wait finish\n&quot;</span>);</span><br><span class="line"></span><br><span class="line">    errno = pthread_join(tid1, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="keyword">if</span>(errno)&#123;</span><br><span class="line">        perror(<span class="string">&quot;pthread_join&quot;</span>);</span><br><span class="line">        <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">    &#125;</span><br><span class="line">    errno = pthread_join(tid2, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="keyword">if</span>(errno)&#123;</span><br><span class="line">        perror(<span class="string">&quot;pthread_join&quot;</span>);</span><br><span class="line">        <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    errno = pthread_cond_destroy(&amp;cond);</span><br><span class="line">    <span class="keyword">if</span>(errno)&#123;</span><br><span class="line">        perror(<span class="string">&quot;pthread_cond_destroy&quot;</span>);</span><br><span class="line">        <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">    &#125;</span><br><span class="line">    errno = pthread_mutex_destroy(&amp;mutex);</span><br><span class="line">    <span class="keyword">if</span>(errno)&#123;</span><br><span class="line">        perror(<span class="string">&quot;pthread_mutex_destroy&quot;</span>);</span><br><span class="line">        <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;---------- leave thread_main (pid: %d, tid: %ld) ----------\n&quot;</span>, getpid(), gettid());</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> *<span class="title function_">job1</span><span class="params">(<span class="type">void</span> *arg)</span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;++++++++++ entry thread_1 (pid: %d, tid: %ld) ++++++++++\n&quot;</span>, getpid(), gettid());</span><br><span class="line"></span><br><span class="line">    usleep(<span class="number">500</span>);</span><br><span class="line"></span><br><span class="line">    errno = pthread_mutex_lock(&amp;mutex);</span><br><span class="line">    <span class="keyword">if</span>(errno)&#123;</span><br><span class="line">        perror(<span class="string">&quot;pthread_mutex_lock&quot;</span>);</span><br><span class="line">        <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;&lt;thread_1&gt; before: %d\n&quot;</span>, flag);</span><br><span class="line">    <span class="keyword">if</span>(flag == <span class="number">2</span>)&#123;</span><br><span class="line">        errno = pthread_cond_signal(&amp;cond);</span><br><span class="line">        <span class="keyword">if</span>(errno)&#123;</span><br><span class="line">            perror(<span class="string">&quot;pthread_cond_signal&quot;</span>);</span><br><span class="line">            <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    flag = <span class="number">1</span>;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;&lt;thread_1&gt; after: %d\n&quot;</span>, flag);</span><br><span class="line"></span><br><span class="line">    errno = pthread_mutex_unlock(&amp;mutex);</span><br><span class="line">    <span class="keyword">if</span>(errno)&#123;</span><br><span class="line">        perror(<span class="string">&quot;pthread_mutex_unlock&quot;</span>);</span><br><span class="line">        <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;---------- leave thread_1 (pid: %d, tid: %ld) ----------\n&quot;</span>, getpid(), gettid());</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> *<span class="title function_">job2</span><span class="params">(<span class="type">void</span> *arg)</span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;++++++++++ entry thread_2 (pid: %d, tid: %ld) ++++++++++\n&quot;</span>, getpid(), gettid());</span><br><span class="line"></span><br><span class="line">    usleep(<span class="number">500</span>);</span><br><span class="line"></span><br><span class="line">    errno = pthread_mutex_lock(&amp;mutex);</span><br><span class="line">    <span class="keyword">if</span>(errno)&#123;</span><br><span class="line">        perror(<span class="string">&quot;pthread_mutex_lock&quot;</span>);</span><br><span class="line">        <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;&lt;thread_2&gt; before: %d\n&quot;</span>, flag);</span><br><span class="line">    <span class="keyword">if</span>(flag == <span class="number">1</span>)&#123;</span><br><span class="line">        errno = pthread_cond_signal(&amp;cond);</span><br><span class="line">        <span class="keyword">if</span>(errno)&#123;</span><br><span class="line">            perror(<span class="string">&quot;pthread_cond_signal&quot;</span>);</span><br><span class="line">            <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    flag = <span class="number">2</span>;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;&lt;thread_2&gt; after: %d\n&quot;</span>, flag);</span><br><span class="line"></span><br><span class="line">    errno = pthread_mutex_unlock(&amp;mutex);</span><br><span class="line">    <span class="keyword">if</span>(errno)&#123;</span><br><span class="line">        perror(<span class="string">&quot;pthread_mutex_unlock&quot;</span>);</span><br><span class="line">        <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;---------- leave thread_2 (pid: %d, tid: %ld) ----------\n&quot;</span>, getpid(), gettid());</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta"># root @ arch in ~/work on git:master x [13:25:47]</span></span><br><span class="line">$ gcc a.c -lpthread</span><br><span class="line">a.c: In function ‘job1’:</span><br><span class="line">a.c:<span class="number">79</span>:<span class="number">18</span>: warning: unused parameter ‘arg’ [-Wunused-parameter]</span><br><span class="line"> <span class="type">void</span> *<span class="title function_">job1</span><span class="params">(<span class="type">void</span> *arg)</span>&#123;</span><br><span class="line">                  ^~~</span><br><span class="line">a.c: In function ‘job2’:</span><br><span class="line">a.c:<span class="number">111</span>:<span class="number">18</span>: warning: unused parameter ‘arg’ [-Wunused-parameter]</span><br><span class="line"> <span class="type">void</span> *<span class="title function_">job2</span><span class="params">(<span class="type">void</span> *arg)</span>&#123;</span><br><span class="line">                  ^~~</span><br><span class="line"></span><br><span class="line"><span class="meta"># root @ arch in ~/work on git:master x [13:25:53]</span></span><br><span class="line">$ ./a.out</span><br><span class="line">++++++++++ entry <span class="title function_">thread_main</span> <span class="params">(pid: <span class="number">88631</span>, tid: <span class="number">88631</span>)</span> ++++++++++</span><br><span class="line">++++++++++ entry <span class="title function_">thread_1</span> <span class="params">(pid: <span class="number">88631</span>, tid: <span class="number">88632</span>)</span> ++++++++++</span><br><span class="line">&lt;thread_main&gt; waiting <span class="keyword">for</span> 1-&gt;2 or 2-&gt;1</span><br><span class="line">++++++++++ entry <span class="title function_">thread_2</span> <span class="params">(pid: <span class="number">88631</span>, tid: <span class="number">88633</span>)</span> ++++++++++</span><br><span class="line">&lt;thread_2&gt; before: 0</span><br><span class="line">&lt;thread_2&gt; after: 2</span><br><span class="line">---------- leave <span class="title function_">thread_2</span> <span class="params">(pid: <span class="number">88631</span>, tid: <span class="number">88633</span>)</span> ----------</span><br><span class="line">&lt;thread_1&gt; before: 2</span><br><span class="line">&lt;thread_1&gt; after: 1</span><br><span class="line">---------- leave <span class="title function_">thread_1</span> <span class="params">(pid: <span class="number">88631</span>, tid: <span class="number">88632</span>)</span> ----------</span><br><span class="line">&lt;thread_main&gt; wait finish</span><br><span class="line">---------- leave <span class="title function_">thread_main</span> <span class="params">(pid: <span class="number">88631</span>, tid: <span class="number">88631</span>)</span> ----------</span><br></pre></td></tr></table></figure>
<h1 id="cc中-constexternstaticvolatile的使用"><a class="markdownIt-Anchor" href="#cc中-constexternstaticvolatile的使用"></a> <a href="http://blog.chinaunix.net/uid-20659461-id-1905243.html">C/C++中 const,extern,static,volatile的使用</a></h1>
<h2 id="1const的用法"><a class="markdownIt-Anchor" href="#1const的用法"></a> 1.const的用法：</h2>
<h3 id="为什么使用const"><a class="markdownIt-Anchor" href="#为什么使用const"></a> 为什么使用const？</h3>
<p>采用符号常量写出的代码更容易维护；指针常常是边读边移动，而不是边写边移动；许多函数参数是只读不写的。const最常见用途是作为数组的界和switch分情况标号（也可以用枚举符代替）</p>
<h3 id="用法1常量"><a class="markdownIt-Anchor" href="#用法1常量"></a> 用法1：常量</h3>
<p>取代了C中的宏定义，声明时必须进行初始化。const限制了常量的使用方式，并没有描述常量应该如何分配。如果编译器知道了某const的所有使用，它甚至可以不为该const分配空间。最简单的常见情况就是常量的值在编译时已知，而且不需要分配存储。―《C++ Program Language》<br>
用const声明的变量虽然增加了分配空间，但是可以保证类型安全。<br>
C标准中，const定义的常量是全局的，C++中视声明位置而定。</p>
<h3 id="用法2指针和常量"><a class="markdownIt-Anchor" href="#用法2指针和常量"></a> 用法2：指针和常量</h3>
<p>使用指针时涉及到两个对象：该指针本身和被它所指的对象。将一个指针的声明用const“预先固定”将使那个对象而不是使这个指针成为常量。要将指针本身而不是被指对象声明为常量，必须使用声明运算符*const。<br>
所以出现在 * 之前的const是作为基础类型的一部分：</p>
<blockquote>
<p>从右向左读的记忆方式：</p>
<p>cp is a const pointer to char.</p>
<p>pc2 is a pointer to const char.</p>
</blockquote>
<h3 id="用法3const修饰函数传入参数"><a class="markdownIt-Anchor" href="#用法3const修饰函数传入参数"></a> 用法3：const修饰函数传入参数</h3>
<p>将函数传入参数声明为const，以指明使用这种参数仅仅是为了效率的原因，而不是想让调用函数能够修改对象的值。同理，将指针参数声明为const，函数将不修改由这个参数所指的对象。</p>
<p>通常修饰指针参数和引用参数：</p>
<h3 id="用法4修饰函数返回值"><a class="markdownIt-Anchor" href="#用法4修饰函数返回值"></a> 用法4：修饰函数返回值</h3>
<p>可以阻止用户修改返回值。返回值也要相应的付给一个常量或常指针。</p>
<h3 id="用法5const修饰成员函数"><a class="markdownIt-Anchor" href="#用法5const修饰成员函数"></a> 用法5：const修饰成员函数</h3>
<p>const对象只能访问const成员函数，而非const对象可以访问任意的成员函数，包括const成员函数；</p>
<p>const对象的成员是不能修改的，而通过指针维护的对象确实可以修改的；</p>
<p>const成员函数不可以修改对象的数据，不管对象是否具有const性质。编译时以是否修改成员数据为依据进行检查。</p>
<h2 id="2static的用法"><a class="markdownIt-Anchor" href="#2static的用法"></a> 2.static的用法：</h2>
<p>静态变量作用范围在一个文件内，程序开始时分配空间，结束时释放空间，默认初始化为0，使用时可以改变其值。</p>
<p>静态变量或静态函数只有本文件内的代码才能访问它，它的名字在其它文件中不可见。</p>
<h3 id="用法1函数内部声明的static变量可作为对象间的一种通信机制"><a class="markdownIt-Anchor" href="#用法1函数内部声明的static变量可作为对象间的一种通信机制"></a> 用法1：函数内部声明的static变量，可作为对象间的一种通信机制</h3>
<p>如果一局部变量被声明为static，那么将只有唯一的一个静态分配的对象，它被用于在该函数的所有调用中表示这个变量。这个对象将只在执行线程第一次到达它的定义使初始化。</p>
<h3 id="用法2局部静态对象"><a class="markdownIt-Anchor" href="#用法2局部静态对象"></a> 用法2：局部静态对象</h3>
<p>对于局部静态对象，构造函数是在控制线程第一次通过该对象的定义时调用。在程序结束时，局部静态对象的析构函数将按照他们被构造的相反顺序逐一调用，没有规定确切时间。</p>
<h3 id="用法3静态成员和静态成员函数"><a class="markdownIt-Anchor" href="#用法3静态成员和静态成员函数"></a> 用法3：静态成员和静态成员函数</h3>
<p>如果一个变量是类的一部分，但却不是该类的各个对象的一部分，它就被成为是一个static静态成员。一个static成员只有唯一的一份副本，而不像常规的非static成员那样在每个对象里各有一份副本。同理，一个需要访问类成员，而不需要针对特定对象去调用的函数，也被称为一个static成员函数。</p>
<p>类的静态成员函数只能访问类的静态成员（变量或函数）。</p>
<h2 id="3extern的用法"><a class="markdownIt-Anchor" href="#3extern的用法"></a> 3.extern的用法：</h2>
<p>extern可以声明其他文件内定义的变量。在一个程序里，一个对象只能定义一次，它可以有多个声明，但类型必须完全一样。如果定义在全局作用域或者名字空间作用域里某一个变量没有初始化，它会被按照默认方式初始化。</p>
<p>将变量或函数声明成外部链接，即该变量或函数名在其它函数中可见。被其修饰的变量（外部变量）是静态分配空间的，即程序开始时分配，结束时释放。</p>
<p>在C++中，还可以指定使用另一语言链接，需要与特定的转换符一起使用。</p>
<p>extern “C” 声明语句</p>
<p>extern “C” { 声明语句块 }</p>
<p>extern 表明该变量在别的地方已经定义过了,在这里要使用那个变量.<br>
static 表示静态的变量，分配内存的时候, 存储在静态区,不存储在栈上面.<br>
static 作用范围是内部连接的关系,和extern有点相反.它和对象本身是分开存储的,extern也是分开存储的,但是extern可以被其他的对象用extern 引用,而static 不可以,只允许对象本身用它.</p>
<h2 id="4volatile的用法"><a class="markdownIt-Anchor" href="#4volatile的用法"></a> 4.volatile的用法：</h2>
<p>类型修正符（type-modifier），限定一个对象可被外部进程（操作系统、硬件或并发进程等）改变。volatile与变量连用，可以让变量被不同的线程访问和修改。声明时语法：<br>
int volatile vInt;<br>
常用于像中断处理程序之类的异步进程进行内存单元访问。<br>
除了基本类型外，对用户定义类型也可以用volatile类型进行修饰。<br>
注意：可以把一个非volatile int赋给volatile int，但是不能把非volatile对象赋给一个volatile对象。<br>
一个有volatile标识符的类只能访问它接口的子集，一个由类的实现者控制的子集。用户只能用const_cast来获得对类型接口的完全访问。此外，volatile向const一样会从类传递到它的成员。</p>
<p>一个定义为volatile的变量是说这变量可能会被意想不到地改变，这样，编译器就不会去假设这个变量的值了。精确地说就是，优化器在用到这个变量时必须每次都小心地重新读取这个变量的值，而不是使用保存在寄存器里的备份。下面是</p>
<h3 id="volatile变量的几个例子"><a class="markdownIt-Anchor" href="#volatile变量的几个例子"></a> volatile变量的几个例子：</h3>
<ol>
<li>并行设备的硬件寄存器（如：状态寄存器）</li>
<li>一个中断服务子程序中会访问到的非自动变量(Non-automatic variables)</li>
<li>多线程应用中被几个任务共享的变量</li>
</ol>
<h3 id="几个问题"><a class="markdownIt-Anchor" href="#几个问题"></a> 几个问题：</h3>
<ol>
<li>一个参数既可以是const还可以是volatile吗？解释为什么。</li>
<li>一个指针可以是volatile 吗？解释为什么。</li>
<li>下面的函数有什么错误：</li>
</ol>
<p><code>int square(volatile int *ptr)&#123;return *ptr * *ptr;&#125;</code></p>
<h3 id="下面是答案"><a class="markdownIt-Anchor" href="#下面是答案"></a> 下面是答案：</h3>
<ol>
<li>是的。一个例子是只读的状态寄存器。它是volatile因为它可能被意想不到地改变。它是const因为程序不应该试图去修改它。</li>
<li>是的。尽管这并不很常见。一个例子是当一个中断服务子程序修改一个指向一个buffer的指针时。</li>
<li>这段代码有点变态。这段代码的目的是用来返回指针<em>ptr指向值的平方，但是，由于</em>ptr指向一个volatile型参数，编译器将产生类似下面的代码：</li>
</ol>
<p><code>int square(volatile int *ptr)&#123;    int a,b;    a = *ptr;    b = *ptr;    return a * b;&#125;</code><br>
由于*ptr的值可能被意想不到地该变，因此a和b可能是不同的。结果，这段代码可能返不是你所期望的平方值！正确的代码如下：</p>
<h1 id="线程函数如何将返回值传给主线程"><a class="markdownIt-Anchor" href="#线程函数如何将返回值传给主线程"></a> 线程函数如何将返回值传给主线程</h1>
<ol>
<li>定义一个 包含 线程函数的 参数和返回值的 数据结构。</li>
</ol>
<p>例子如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">thread_data</span> &#123;</span></span><br><span class="line">   <span class="type">int</span> a;</span><br><span class="line">   <span class="type">int</span> b;</span><br><span class="line">   <span class="type">int</span> result;</span><br><span class="line">&#125; thread_data;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> *<span class="title function_">myThread</span><span class="params">(<span class="type">void</span> *arg)</span></span><br><span class="line">&#123;</span><br><span class="line">   thread_data *tdata=(thread_data *)arg;</span><br><span class="line">   <span class="type">int</span> a=tdata-&gt;a;</span><br><span class="line">   <span class="type">int</span> b=tdata-&gt;b;</span><br><span class="line">   <span class="type">int</span> result=a+b;</span><br><span class="line">   tdata-&gt;result=result;</span><br><span class="line">   pthread_exit(<span class="literal">NULL</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">   <span class="type">pthread_t</span> tid;</span><br><span class="line">   thread_data tdata;</span><br><span class="line">   tdata.a=<span class="number">10</span>;</span><br><span class="line">   tdata.b=<span class="number">32</span>;</span><br><span class="line">   pthread_create(&amp;tid, <span class="literal">NULL</span>, myThread, (<span class="type">void</span> *)&amp;tdata);</span><br><span class="line">   pthread_join(tid, <span class="literal">NULL</span>);</span><br><span class="line">   <span class="built_in">printf</span>(<span class="string">&quot;%d + %d = %d\n&quot;</span>, tdata.a, tdata.b, tdata.result);   </span><br><span class="line">   <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>用pthread_exit() 返回线程函数的返回值，用pthread_join 来接受 线程函数的返回值。<br>
例子如下：</li>
</ol>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">something_worked</span><span class="params">(<span class="type">void</span>)</span> &#123;</span><br><span class="line">    <span class="comment">/* thread operation might fail, so here&#x27;s a silly example */</span></span><br><span class="line">    <span class="type">void</span> *p = <span class="built_in">malloc</span>(<span class="number">10</span>);</span><br><span class="line">    <span class="built_in">free</span>(p);</span><br><span class="line">    <span class="keyword">return</span> p ? <span class="number">1</span> : <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> *<span class="title function_">myThread</span><span class="params">(<span class="type">void</span> *result)</span></span><br><span class="line">&#123;</span><br><span class="line">   <span class="keyword">if</span> (something_worked()) &#123;</span><br><span class="line">       ((<span class="type">int</span>)result) = <span class="number">42</span>;</span><br><span class="line">       pthread_exit(result);</span><br><span class="line">   &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">       pthread_exit(<span class="number">0</span>);</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">   <span class="type">pthread_t</span> tid;</span><br><span class="line">   <span class="type">void</span> *status = <span class="number">0</span>;</span><br><span class="line">   <span class="type">int</span> result;</span><br><span class="line">   pthread_create(&amp;tid, <span class="literal">NULL</span>, myThread, &amp;result);</span><br><span class="line">   pthread_join(tid, &amp;status);</span><br><span class="line">   <span class="keyword">if</span> (status != <span class="number">0</span>) &#123;</span><br><span class="line">       <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>,result);</span><br><span class="line">   &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">       <span class="built_in">printf</span>(<span class="string">&quot;thread failed\n&quot;</span>);</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="c线程传递多个参数demo"><a class="markdownIt-Anchor" href="#c线程传递多个参数demo"></a> C++线程传递多个参数demo</h1>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/*pthread_join使一个线程等待另一个线程结束；pthread_join( t)等待线程t退出，并释放t线程所占用的资源。</span></span><br><span class="line"><span class="comment">  代码中如果没有pthread_join()，主线程会很快结束从而使整个进程结束，从而使创建的线程没有机会开始执行就结束了。</span></span><br><span class="line"><span class="comment">   加入pthread_join()后，主线程会一直等待直到等待的线程结束自己才结束，使创建的线程有机会执行。*/</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">stu</span>  </span></span><br><span class="line"><span class="class">&#123;</span>  </span><br><span class="line">  <span class="type">int</span> age;</span><br><span class="line">  <span class="type">char</span> *name;</span><br><span class="line">  <span class="type">long</span> <span class="type">long</span> len;</span><br><span class="line">&#125;;  </span><br><span class="line"> </span><br><span class="line"><span class="comment">//传递多个参数</span></span><br><span class="line"><span class="type">void</span> *<span class="title function_">thread2</span><span class="params">(<span class="type">void</span> *data)</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">stu</span> *<span class="title">stu1</span> =</span> (<span class="keyword">struct</span> stu*)data; </span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot; age = %d\n name = %s\n len = %lld\n&quot;</span>,stu1-&gt;age, stu1-&gt;name, stu1-&gt;len); </span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">void</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="type">pthread_t</span> id2;</span><br><span class="line">  <span class="type">int</span> ret;</span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">stu</span> <span class="title">student</span>;</span></span><br><span class="line"> </span><br><span class="line">  student.age=<span class="number">10</span>;</span><br><span class="line">  student.name=<span class="string">&quot;Hello World!&quot;</span>;</span><br><span class="line">  student.len = <span class="number">12345678901111</span>;</span><br><span class="line"> </span><br><span class="line">  ret=pthread_create(&amp;id2,<span class="literal">NULL</span>,thread2,(<span class="type">void</span> *)&amp;student);</span><br><span class="line">  <span class="keyword">if</span>(ret!=<span class="number">0</span>)&#123;</span><br><span class="line">    <span class="built_in">printf</span> (<span class="string">&quot;Create pthread2 error!\n&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line"> </span><br><span class="line">  <span class="comment">//主进程等待线程id2执行结束,不然有可能主进程先执行完而执行不到id2线程的情况</span></span><br><span class="line">  pthread_join(id2, <span class="literal">NULL</span>);</span><br><span class="line"> </span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="number">2.</span>编译</span><br><span class="line"> <span class="meta"># g++ test.cpp -pthread</span></span><br></pre></td></tr></table></figure>
<h1 id="c语言多线程编程-线程的基本函数"><a class="markdownIt-Anchor" href="#c语言多线程编程-线程的基本函数"></a> C语言多线程编程-线程的基本函数</h1>
<h2 id="1-线程操作函数"><a class="markdownIt-Anchor" href="#1-线程操作函数"></a> 1 线程操作函数</h2>
<h3 id="11-线程创建函数"><a class="markdownIt-Anchor" href="#11-线程创建函数"></a> <strong>1.1 线程创建函数</strong></h3>
<p>int pthread_create (pthread_t * restrict <strong>tidp</strong>, const pthread_attr_t *restrict <strong>attr</strong>, void *(*start_rtn) (<strong>void *</strong>), void *restrict <strong>arg</strong>);</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">说明：创建一个具有指定参数的线程。</span><br><span class="line"></span><br><span class="line">形参：</span><br><span class="line">    tidp       要创建的线程的线程id指针</span><br><span class="line">    attr       创建线程时的线程属性</span><br><span class="line">    start_rtn  返回值是<span class="type">void</span>类型的指针函数</span><br><span class="line">    arg        start_rtn的形参</span><br><span class="line"></span><br><span class="line">返回值：若是成功建立线程返回<span class="number">0</span>,否则返回错误的编号</span><br><span class="line"></span><br><span class="line">头文件：<span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"></span><br><span class="line">由<span class="keyword">restrict</span> 修饰的指针是最初唯一对指针所指向的对象进行存取的方法，仅当第二个指针基于第一个时，才能对对象进行存取</span><br><span class="line"></span><br><span class="line"><span class="type">pthread_t</span>类型定义如下</span><br><span class="line">        <span class="keyword">typedef</span> <span class="type">unsigned</span> <span class="type">long</span> <span class="type">int</span> <span class="type">pthread_t</span></span><br><span class="line">打印时要使用%lu或%u方式</span><br><span class="line"><span class="number">123456789101112131415161718</span></span><br></pre></td></tr></table></figure>
<h3 id="12-等待线程结束函数"><a class="markdownIt-Anchor" href="#12-等待线程结束函数"></a> <strong>1.2 等待线程结束函数</strong></h3>
<p>int pthread_join(pthread_t thread, void **retval);</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">说明：这个函数是一个线程阻塞的函数，调用它的函数将一直等待到被等待的线程结束为止，当函数返回时，被等待线程的资源被收回</span><br><span class="line"></span><br><span class="line">形参：</span><br><span class="line">    thread     被等待的线程标识符</span><br><span class="line">    retval     一个用户定义的指针，它可以用来存储被等待线程的返回值</span><br><span class="line"></span><br><span class="line">返回值：成功返回<span class="number">0</span>,否则返回错误的编号</span><br><span class="line"></span><br><span class="line">头文件：<span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="number">12345678910</span></span><br></pre></td></tr></table></figure>
<h3 id="13-线程退出函数"><a class="markdownIt-Anchor" href="#13-线程退出函数"></a> <strong>1.3 线程退出函数</strong></h3>
<p>void pthread_exit(void *retval);</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">说明：终止调用它的线程并返回一个指向某个对象的指针</span><br><span class="line"></span><br><span class="line">形参：</span><br><span class="line">    retval     函数的返回指针，只要pthread_join中的第二个参数retval不是<span class="literal">NULL</span>，这个值将被传递给retval</span><br><span class="line"></span><br><span class="line">返回值：无</span><br><span class="line"></span><br><span class="line">头文件：<span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="number">123456789</span></span><br></pre></td></tr></table></figure>
<h3 id="14-线程取消函数"><a class="markdownIt-Anchor" href="#14-线程取消函数"></a> <strong>1.4 线程取消函数</strong></h3>
<p>int pthread_cancel(pthread_t thread);</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">说明：取消某个线程的执行</span><br><span class="line"></span><br><span class="line">形参：</span><br><span class="line">    thread     要取消线程的标识符ID</span><br><span class="line"></span><br><span class="line">返回值：若是成功返回<span class="number">0</span>,否则返回错误的编号</span><br><span class="line"></span><br><span class="line">头文件：<span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="number">123456789</span></span><br></pre></td></tr></table></figure>
<p>其他说明：一个线程能够被取消并终止执行需要满足两个条件(1) 线程是否可以被取消，默认可以被取消；(2) 线程处于可取消点才能取消，可以设置线程为<strong>立即取消</strong>或<strong>只能在取消点</strong>被取消。</p>
<h3 id="15-设置可取消状态函数"><a class="markdownIt-Anchor" href="#15-设置可取消状态函数"></a> <strong>1.5 设置可取消状态函数</strong></h3>
<p>int pthread_setcancelstate (int state, int *oldstate);</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">说明：设置当前线程的可取消性状态</span><br><span class="line"></span><br><span class="line">形参：</span><br><span class="line">    state     要更新的心状态值</span><br><span class="line">    oldstate  原来存储的状态</span><br><span class="line"></span><br><span class="line">state的合法值：</span><br><span class="line">    PTHREAD_CANCEL_DISABLE  针对目标线程的取消请求将处于未决状态，请求未处理但仍然存在，除非该线程修改自己的状态，否则不会被取消</span><br><span class="line">    PTHREAD_CANCEL_ENABLE   针对目标线程的取消请求将被传递，此状态为创建线程时的默认状态</span><br><span class="line"></span><br><span class="line">返回值：成功返回<span class="number">0</span>，否则返回错误编号以指明错误</span><br><span class="line"><span class="number">123456789101112</span></span><br></pre></td></tr></table></figure>
<h3 id="16-设置取消类型函数"><a class="markdownIt-Anchor" href="#16-设置取消类型函数"></a> <strong>1.6 设置取消类型函数</strong></h3>
<p>int pthread_setcanceltype (int type, int *oldtype);</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">说明：设置当前线程的取消类型，即设置在接收到取消操作后是立即终止还是在取消点终止</span><br><span class="line"></span><br><span class="line">形参：</span><br><span class="line">    type     为调用线程新的可取消性</span><br><span class="line">    oldtype  存储原来的类型</span><br><span class="line"></span><br><span class="line">type的合法值如下：</span><br><span class="line">    PTHREAD_CANCEL_ASYNCHRONOUS  可随时执行新的或未决的取消请求</span><br><span class="line">    PTHREAD_CANCEL_DEFERRED      目标线程到达一个取消点之前，取消请求将一直处于未决状态；此类型为创建线程时的默认类型</span><br><span class="line"></span><br><span class="line">返回值：成功返回<span class="number">0</span>，否则返回错误编号以指明错误</span><br><span class="line"><span class="number">123456789101112</span></span><br></pre></td></tr></table></figure>
<h3 id="17-获取当前线程id函数"><a class="markdownIt-Anchor" href="#17-获取当前线程id函数"></a> <strong>1.7 获取当前线程ID函数</strong></h3>
<p>pthread_t pthread_self (void);</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">说明：获取当前调用线程的 thread <span class="title function_">identifier</span><span class="params">(标识号)</span></span><br><span class="line">形参：无</span><br><span class="line">返回值：当前线程的线程ID标识</span><br><span class="line">头文件：<span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line">12345</span><br></pre></td></tr></table></figure>
<h3 id="18-分离释放线程函数"><a class="markdownIt-Anchor" href="#18-分离释放线程函数"></a> <strong>1.8 分离释放线程函数</strong></h3>
<p>int pthread_detach (pthread_t thread);</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">说明：线程资源释放方式设置函数</span><br><span class="line"></span><br><span class="line">形参：</span><br><span class="line">    thread     要释放线程的标识符ID</span><br><span class="line"></span><br><span class="line">返回值：若是成功返回<span class="number">0</span>,否则返回错误的编号</span><br><span class="line"></span><br><span class="line">头文件：<span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="number">123456789</span></span><br></pre></td></tr></table></figure>
<ul>
<li>其他说明：linux线程执行和windows不同，pthread有两种状态joinable状态和unjoinable状态。
<ul>
<li>一个线程<strong>默认的状态</strong>是joinable，如果线程是joinable状态，当线程函数自己返回退出时或<strong>pthread_exit</strong>时都不会释放线程所占用堆栈和线程描述符（总计8K多），只有当你调用了<strong>pthread_join</strong>之后这些资源才会被释放。</li>
<li>若是unjoinable状态的线程，这些资源在线程函数退出时或<strong>pthread_exit</strong>时自动会被释放。</li>
<li>unjoinable属性可以在pthread_create时指定，或在线程创建后在线程中pthread_detach自己设置， 如：pthread_detach(pthread_self())，将状态改为unjoinable状态，确保资源的释放。如果线程状态为joinable，需要在之后适时调用pthread_join。</li>
</ul>
</li>
</ul>
<h3 id="19-比较两个线程是否是同一线程"><a class="markdownIt-Anchor" href="#19-比较两个线程是否是同一线程"></a> <strong>1.9 比较两个线程是否是同一线程</strong></h3>
<p>int pthread_equal (pthread_t thread1, pthread_t thread2);</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">说明：判断两个线程ID是否是同一个</span><br><span class="line"></span><br><span class="line">形参：</span><br><span class="line">    thread1     要比较的线程的标识符ID1</span><br><span class="line">    thread2     要比较的线程的标识符ID2</span><br><span class="line"></span><br><span class="line">返回值：不相等返回<span class="number">0</span>，相等非零</span><br><span class="line"></span><br><span class="line">头文件：<span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="number">12345678910</span></span><br></pre></td></tr></table></figure>
<h3 id="110-线程私有数据操作函数"><a class="markdownIt-Anchor" href="#110-线程私有数据操作函数"></a> <strong>1.10 线程私有数据操作函数</strong></h3>
<p><strong>创建线程私有数据</strong><br>
int pthread_key_create (pthread_key_t *key, void (*destr_function) (void *));</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">说明：创建线程私有数据TSD，提供线程私有的全局变量。使用同名而不同内存地址的线程私有数据结构</span><br><span class="line"></span><br><span class="line">形参：</span><br><span class="line">    key       线程私有数据</span><br><span class="line">    第二个参数  如果第二个参数不为空，在线程退出时将以key所关联数据为参数调用其指向的资源释放函数，以释放分配的缓冲区</span><br><span class="line"></span><br><span class="line">其他说明：不论哪个线程调用pthread_key_create()函数，所创建的key都是所有线程可访问的，但各个线程可根据自己的需要往key中填入不同的值</span><br><span class="line">相当于提供了同名不同值的全局变量,各线程对自己私有数据操作互相不影响</span><br><span class="line"><span class="number">123456789</span></span><br></pre></td></tr></table></figure>
<p><strong>注销线程私有数据</strong><br>
int pthread_key_delete (pthread_key_t *key);</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">该函数并不检查当前是否有线程正是用该TSD，也不会调用清理函数(destr_function)</span><br><span class="line">将TSD释放以供下一次调用pthread_key_create()使用</span><br><span class="line"><span class="number">123</span></span><br></pre></td></tr></table></figure>
<p><strong>读写线程私有数据</strong><br>
写 int pthread_setspecific (pthread_key_t key, const void *pointer);<br>
读 void pthread_getspecific (pthread_key_t key);</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">函数pthread_setspecific()将pointer的值(非内容)与key相关联</span><br><span class="line">函数pthread_getspecific()将与key相关联的数据读出来</span><br><span class="line">所有数据都设置为<span class="type">void</span> *，因此可以指向任何类型的数据</span><br><span class="line"><span class="number">1234</span></span><br></pre></td></tr></table></figure>
<h2 id="2-线程属性函数"><a class="markdownIt-Anchor" href="#2-线程属性函数"></a> <strong>2. 线程属性函数</strong></h2>
<p>属性对象是不透明的，而且不能通过赋值直接进行修改。系统提供了一组函数，用于初始化、配置和销毁线程属性。</p>
<h3 id="21-初始化一个线程对象的属性"><a class="markdownIt-Anchor" href="#21-初始化一个线程对象的属性"></a> <strong>2.1 初始化一个线程对象的属性</strong></h3>
<p>int pthread_attr_init (pthread_attr_t *attr);</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">说明：pthread_attr_init实现时为属性对象分配了动态内存空间</span><br><span class="line">     Posix线程中的线程属性<span class="type">pthread_attr_t</span>主要包括scope属性、detach属性、堆栈地址、堆栈大小、优先级</span><br><span class="line">形参：</span><br><span class="line">    attr       指向一个线程属性的指针</span><br><span class="line"></span><br><span class="line">返回值：若是成功返回<span class="number">0</span>,否则返回错误的编号</span><br><span class="line"></span><br><span class="line">头文件：<span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="number">123456789</span></span><br></pre></td></tr></table></figure>
<h3 id="22-销毁一个线程属性对象"><a class="markdownIt-Anchor" href="#22-销毁一个线程属性对象"></a> <strong>2.2 销毁一个线程属性对象</strong></h3>
<p>int pthread_attr_destroy (pthread_attr_t *attr);</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">说明：经pthread_attr_destroy去除初始化之后的<span class="type">pthread_attr_t</span>结构被pthread_create函数调用，将会导致其返回错误</span><br><span class="line"></span><br><span class="line">形参：</span><br><span class="line">    attr       指向一个线程属性的指针</span><br><span class="line"></span><br><span class="line">返回值：若是成功返回<span class="number">0</span>,否则返回错误的编号</span><br><span class="line"></span><br><span class="line">头文件：<span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="number">123456789</span></span><br></pre></td></tr></table></figure>
<h3 id="23-获取线程分离状态属性"><a class="markdownIt-Anchor" href="#23-获取线程分离状态属性"></a> <strong>2.3 获取线程分离状态属性</strong></h3>
<p>int pthread_attr_getdetachstate (pthread_attr_t *attr, int *detachstate);</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">说明：获取线程分离状态属性；pthread_detach()分离释放线程资源函数</span><br><span class="line"></span><br><span class="line">形参：</span><br><span class="line">    attr          指向一个线程属性的指针</span><br><span class="line">    detachstate   保存返回的分离状态属性</span><br><span class="line"></span><br><span class="line">返回值：若是成功返回<span class="number">0</span>,否则返回错误的编号</span><br><span class="line"></span><br><span class="line">头文件：<span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="number">12345678910</span></span><br></pre></td></tr></table></figure>
<h3 id="24-修改线程分离状态属性"><a class="markdownIt-Anchor" href="#24-修改线程分离状态属性"></a> <strong>2.4 修改线程分离状态属性</strong></h3>
<p>int pthread_attr_setdetachstate (pthread_attr_t *attr, int detachstate);</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">说明：修改线程分离状态属性；pthread_detach()分离释放线程资源函数</span><br><span class="line"></span><br><span class="line">形参：</span><br><span class="line">    attr         指向一个线程属性的指针</span><br><span class="line">    detachstate  有两个取值</span><br><span class="line">PTHREAD_CREATE_JOINABLE（可连接），使用attr创建的所有线程处于可连接状态，线程终止不会回收相关资源，需在其他线程调用pthread_detach()或pthread_join()函数</span><br><span class="line">PTHREAD_CREATE_DETACHED(分离)，使用attr创建的所有线程处于分离状态，这类线程终止带有此状态的线程相关资源将被系统收回</span><br><span class="line"></span><br><span class="line">返回值：若是成功返回<span class="number">0</span>,否则返回错误的编号</span><br><span class="line"></span><br><span class="line">头文件：<span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="number">123456789101112</span></span><br></pre></td></tr></table></figure>
<h3 id="25-获取线程间的cpu亲缘性"><a class="markdownIt-Anchor" href="#25-获取线程间的cpu亲缘性"></a> <strong>2.5 获取线程间的CPU亲缘性</strong></h3>
<p>int pthread_attr_getaffinity_np (pthread_attr_t *attr, size_t cpusetsize, cpu_set_t *cpuset);</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">说明：获取线程的CPU亲缘属性</span><br><span class="line"></span><br><span class="line">形参：</span><br><span class="line">    attr         指向一个线程属性的指针</span><br><span class="line">    cpusetsize   指向CPU组的缓冲区大小</span><br><span class="line">    cpuset       指向CPU组的指针</span><br><span class="line"></span><br><span class="line">返回值：若是成功返回<span class="number">0</span>,否则返回错误的编号</span><br><span class="line"></span><br><span class="line">头文件：<span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="number">1234567891011</span></span><br></pre></td></tr></table></figure>
<h3 id="26-设置线程的cpu亲缘性"><a class="markdownIt-Anchor" href="#26-设置线程的cpu亲缘性"></a> <strong>2.6 设置线程的CPU亲缘性</strong></h3>
<p>int pthread_attr_setaffinity_np (pthread_attr_t *attr, size_t cpusetsize, const cpu_set_t *cpuset);</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">说明：通过指定cupset来设置线程的CPU亲缘性</span><br><span class="line"></span><br><span class="line">形参：</span><br><span class="line">    attr         指向一个线程属性的指针</span><br><span class="line">    cpusetsize   指向CPU组的缓冲区大小</span><br><span class="line">    cpuset       指向CPU组的指针</span><br><span class="line"></span><br><span class="line">返回值：若是成功返回<span class="number">0</span>,否则返回错误的编号</span><br><span class="line"></span><br><span class="line">头文件：<span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="number">1234567891011</span></span><br></pre></td></tr></table></figure>
<h3 id="27-获取线程的作用域"><a class="markdownIt-Anchor" href="#27-获取线程的作用域"></a> <strong>2.7 获取线程的作用域</strong></h3>
<p>int pthread_attr_getscope (pthread_attr_t *attr, int *scope);</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">说明：指定了作用域也就指定了线程与谁竞争资源</span><br><span class="line"></span><br><span class="line">形参：</span><br><span class="line">    attr       指向一个线程属性的指针</span><br><span class="line">    scope      返回线程的作用域</span><br><span class="line"></span><br><span class="line">返回值：若是成功返回<span class="number">0</span>,否则返回错误的编号</span><br><span class="line"></span><br><span class="line">头文件：<span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="number">12345678910</span></span><br></pre></td></tr></table></figure>
<h3 id="28-设置线程的作用域"><a class="markdownIt-Anchor" href="#28-设置线程的作用域"></a> <strong>2.8 设置线程的作用域</strong></h3>
<p>int pthread_attr_setscope (pthread_attr_t *attr, int scope);</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">说明：指定了作用域也就指定了线程与谁竞争资源</span><br><span class="line"></span><br><span class="line">形参：</span><br><span class="line">    attr       指向一个线程属性的指针</span><br><span class="line">    scope      线程的作用域，可以取如下值</span><br><span class="line">PTHREAD_SCOPE_SYSTEM  与系统中所有进程中线程竞争</span><br><span class="line">PTHREAD_SCOPE_PROCESS 与当前进程中的其他线程竞争</span><br><span class="line"></span><br><span class="line">返回值：若是成功返回<span class="number">0</span>,否则返回错误的编号</span><br><span class="line"></span><br><span class="line">头文件：<span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="number">123456789101112</span></span><br></pre></td></tr></table></figure>
<h3 id="29-获取线程的栈保护区大小"><a class="markdownIt-Anchor" href="#29-获取线程的栈保护区大小"></a> <strong>2.9 获取线程的栈保护区大小</strong></h3>
<p>int pthread_attr_getguardsize (pthread_attr_t *attr, size_t *guardsize);</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">说明：获取线程的栈保护区大小</span><br><span class="line"></span><br><span class="line">形参：</span><br><span class="line">    attr       指向一个线程属性的指针</span><br><span class="line">    guardsize  返回获取的栈保护区大小</span><br><span class="line"></span><br><span class="line">返回值：若是成功返回<span class="number">0</span>,否则返回错误的编号</span><br><span class="line"></span><br><span class="line">头文件：<span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="number">12345678910</span></span><br></pre></td></tr></table></figure>
<h3 id="210-设置线程的栈保护区大小"><a class="markdownIt-Anchor" href="#210-设置线程的栈保护区大小"></a> <strong>2.10 设置线程的栈保护区大小</strong></h3>
<p>int pthread_attr_setguardsize (pthread_attr_t *attr, size_t *guardsize);</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">说明：参数提供了对栈指针溢出的保护。默认为系统页大小，如果设置为<span class="number">0</span>表示没有保护区。</span><br><span class="line">     大于<span class="number">0</span>，则会为每个使用 attr 创建的线程提供大小至少为 guardsize 字节的溢出保护区</span><br><span class="line"></span><br><span class="line">形参：</span><br><span class="line">    attr       指向一个线程属性的指针</span><br><span class="line">    guardsize  线程的栈保护区大小</span><br><span class="line"></span><br><span class="line">返回值：若是成功返回<span class="number">0</span>,否则返回错误的编号</span><br><span class="line"></span><br><span class="line">头文件：<span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="number">1234567891011</span></span><br></pre></td></tr></table></figure>
<h3 id="211-获取线程的堆栈信息栈地址和栈大小"><a class="markdownIt-Anchor" href="#211-获取线程的堆栈信息栈地址和栈大小"></a> <strong>2.11 获取线程的堆栈信息（栈地址和栈大小）</strong></h3>
<p>int pthread_attr_getstack (pthread_attr_t *attr, void **stackaddr, size_t *stacksize);</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">说明：获取线程的堆栈地址和大小</span><br><span class="line"></span><br><span class="line">形参：</span><br><span class="line">    attr       指向一个线程属性的指针</span><br><span class="line">    stackaddr  返回获取的栈地址</span><br><span class="line">    stacksize  返回获取的栈大小</span><br><span class="line"></span><br><span class="line">返回值：若是成功返回<span class="number">0</span>,否则返回错误的编号</span><br><span class="line"></span><br><span class="line">头文件：<span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="number">1234567891011</span></span><br></pre></td></tr></table></figure>
<h3 id="212-设置线程的堆栈区"><a class="markdownIt-Anchor" href="#212-设置线程的堆栈区"></a> <strong>2.12 设置线程的堆栈区</strong></h3>
<p>int pthread_attr_setstack (pthread_attr_t *attr, void *stackaddr, size_t stacksize);</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">说明：设置堆栈区，将导致pthread_attr_setguardsize失效</span><br><span class="line"></span><br><span class="line">形参：</span><br><span class="line">    attr       指向一个线程属性的指针</span><br><span class="line">    stackaddr  线程的堆栈地址：应该是可移植的，对齐页边距的，可以用posix_memalign来进行获取</span><br><span class="line">    stacksize  线程的堆栈大小：应该是页大小的整数倍</span><br><span class="line"></span><br><span class="line">返回值：若是成功返回<span class="number">0</span>,否则返回错误的编号</span><br><span class="line"></span><br><span class="line">头文件：<span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="number">1234567891011</span></span><br></pre></td></tr></table></figure>
<h3 id="213-获取线程堆栈地址"><a class="markdownIt-Anchor" href="#213-获取线程堆栈地址"></a> <strong>2.13 获取线程堆栈地址</strong></h3>
<p>int pthread_attr_getstackaddr (pthread_attr_t *attr, void **stackaddr);</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">说明：函数已过时，一般用pthread_attr_getstack来代替</span><br><span class="line"></span><br><span class="line">形参：</span><br><span class="line">    attr       指向一个线程属性的指针</span><br><span class="line">    stackaddr  返回获取的栈地址</span><br><span class="line"></span><br><span class="line">返回值：若是成功返回<span class="number">0</span>,否则返回错误的编号</span><br><span class="line"></span><br><span class="line">头文件：<span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="number">12345678910</span></span><br></pre></td></tr></table></figure>
<h3 id="214-设置线程堆栈地址"><a class="markdownIt-Anchor" href="#214-设置线程堆栈地址"></a> <strong>2.14 设置线程堆栈地址</strong></h3>
<p>int pthread_attr_setstackaddr (pthread_attr_t *attr, void *stackaddr);</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">说明：函数已过时，一般用pthread_attr_setstack来代替</span><br><span class="line"></span><br><span class="line">形参：</span><br><span class="line">    attr       指向一个线程属性的指针</span><br><span class="line">    stackaddr  设置线程堆栈地址</span><br><span class="line"></span><br><span class="line">返回值：若是成功返回<span class="number">0</span>,否则返回错误的编号</span><br><span class="line"></span><br><span class="line">头文件：<span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="number">12345678910</span></span><br></pre></td></tr></table></figure>
<h3 id="215-获取线程堆栈大小"><a class="markdownIt-Anchor" href="#215-获取线程堆栈大小"></a> <strong>2.15 获取线程堆栈大小</strong></h3>
<p>int pthread_attr_getstacksize (pthread_attr_t *attr, size_t *stacksize);</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">说明：获取线程堆栈大小</span><br><span class="line"></span><br><span class="line">形参：</span><br><span class="line">    attr       指向一个线程属性的指针</span><br><span class="line">    stacksize  返回线程的堆栈大小</span><br><span class="line"></span><br><span class="line">返回值：若是成功返回<span class="number">0</span>,否则返回错误的编号</span><br><span class="line"></span><br><span class="line">头文件：<span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="number">12345678910</span></span><br></pre></td></tr></table></figure>
<h3 id="216-设置线程堆栈大小"><a class="markdownIt-Anchor" href="#216-设置线程堆栈大小"></a> <strong>2.16 设置线程堆栈大小</strong></h3>
<p>int pthread_attr_setstacksize (pthread_attr_t *attr, size_t stacksize);</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">说明：设置线程堆栈大小</span><br><span class="line"></span><br><span class="line">形参：</span><br><span class="line">    attr       指向一个线程属性的指针</span><br><span class="line">    stacksize  设置线程的堆栈大小,<span class="built_in">stack</span>属性的合法值包括</span><br><span class="line">    PTHREAD_STACK_MIN 该线程的用户栈大小将使用默认堆栈大小，为某个线程所需最小堆栈大小，但对于所有线程，这个大小可能无法接受</span><br><span class="line">    具体指定的大小       使用线程的用户堆栈大小的数值，必须不小于最小堆栈大小PTHREAD_STACK_MIN</span><br><span class="line"></span><br><span class="line">返回值：若是成功返回<span class="number">0</span>,否则返回错误的编号</span><br><span class="line"></span><br><span class="line">头文件：<span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="number">123456789101112</span></span><br></pre></td></tr></table></figure>
<h3 id="217-获取线程的调度策略"><a class="markdownIt-Anchor" href="#217-获取线程的调度策略"></a> <strong>2.17 获取线程的调度策略</strong></h3>
<p>int pthread_attr_getschedpolicy (pthread_attr_t *attr, int *policy);</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">说明：获取线程的调度策略</span><br><span class="line"></span><br><span class="line">形参：</span><br><span class="line">    attr       指向一个线程属性的指针</span><br><span class="line">    policy     返回线程的调度策略</span><br><span class="line"></span><br><span class="line">返回值：若是成功返回<span class="number">0</span>,否则返回错误的编号</span><br><span class="line"></span><br><span class="line">头文件：<span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line">        <span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sched.h&gt;</span></span></span><br><span class="line"><span class="number">1234567891011</span></span><br></pre></td></tr></table></figure>
<p>按照如下方法使用sched_get_priority_max ( )和sched_get_priority_min ( )，可以得到优先级的最大值和最小值。<br>
调用形式</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sched.h&gt;</span> </span></span><br><span class="line"><span class="type">int</span> <span class="title function_">sched_get_priority_max</span><span class="params">(<span class="type">int</span> policy)</span>;  </span><br><span class="line"><span class="type">int</span> <span class="title function_">sched_get_priority_min</span><span class="params">(<span class="type">int</span> policy)</span>; <span class="number">123</span></span><br></pre></td></tr></table></figure>
<p>两个函数都以调度策略policy为参数，目的是获得对应调度策略的优先级值，而且都返回调度策略的最大或最小优先级值。</p>
<h3 id="218-设置线程的调度策略"><a class="markdownIt-Anchor" href="#218-设置线程的调度策略"></a> <strong>2.18 设置线程的调度策略</strong></h3>
<p>int pthread_attr_setschedpolicy (pthread_attr_t *attr, int policy);</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">说明：设置线程的调度策略</span><br><span class="line"></span><br><span class="line">形参：</span><br><span class="line">    attr       指向一个线程属性的指针</span><br><span class="line">    policy     线程的调度策略，posix指定了<span class="number">3</span>种调度策略属性：</span><br><span class="line">               SCHED_FIFO    先入先出策略</span><br><span class="line">               SCHED_RR      轮转调度，类似于 FIFO，但加上了时间轮片算法</span><br><span class="line">               SCHED_OTHER   系统默认策略</span><br><span class="line"></span><br><span class="line">SCHED_OTHER是不支持优先级使用的</span><br><span class="line">SCHED_FIFO和SCHED_RR支持优先级的使用，他们分别为<span class="number">1</span>和<span class="number">99</span>，数值越大优先级越高</span><br><span class="line"></span><br><span class="line">返回值：若是成功返回<span class="number">0</span>,否则返回错误的编号</span><br><span class="line"></span><br><span class="line">头文件：<span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line">        <span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sched.h&gt;</span></span></span><br><span class="line"><span class="number">1234567891011121314151617</span></span><br></pre></td></tr></table></figure>
<h3 id="219-获取线程的调度参数"><a class="markdownIt-Anchor" href="#219-获取线程的调度参数"></a> <strong>2.19 获取线程的调度参数</strong></h3>
<p>int pthread_attr_getschedparam (pthread_attr_t *attr, struct sched_param *param);</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">说明：获取线程的调度参数</span><br><span class="line"></span><br><span class="line">形参：</span><br><span class="line">    attr       指向一个线程属性的指针</span><br><span class="line">    param      返回获取的调度参数</span><br><span class="line"></span><br><span class="line">返回值：若是成功返回<span class="number">0</span>,否则返回错误的编号</span><br><span class="line"></span><br><span class="line">头文件：<span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line">        <span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sched.h&gt;</span></span></span><br><span class="line"><span class="number">1234567891011</span></span><br></pre></td></tr></table></figure>
<h3 id="220-设置线程的调度参数"><a class="markdownIt-Anchor" href="#220-设置线程的调度参数"></a> <strong>2.20 设置线程的调度参数</strong></h3>
<p>int pthread_attr_setschedparam (pthread_attr_t *attr, const struct sched_param *param);</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">说明：设置线程的调度参数，用于设置优先级</span><br><span class="line"></span><br><span class="line">形参：</span><br><span class="line">    attr       指向一个线程属性的指针</span><br><span class="line">    param      要设置的调度参数，sched_param结构体至少需要定义这个数据成员</span><br><span class="line">               struct sched_param </span><br><span class="line">               &#123;</span><br><span class="line">                    int sched_priority;     /* Scheduling priority */</span><br><span class="line">               &#125;;</span><br><span class="line">    sched_param可能还有其他的数据成员，以及多个用来返回和设置最小优先级、最大优先级、调度器、参数等的函数。</span><br><span class="line">    如果调度策略是SCHED_FIFO或SCHED_RR，那么要求具有值的唯一成员是sched_priority。</span><br><span class="line"></span><br><span class="line">返回值：若是成功返回0,否则返回错误的编号</span><br><span class="line"></span><br><span class="line">头文件：#include &lt;pthread.h&gt;</span><br><span class="line">        #include &lt;sched.h&gt;</span><br><span class="line">1234567891011121314151617</span><br></pre></td></tr></table></figure>
<h3 id="221-获取线程是否继承调度属性"><a class="markdownIt-Anchor" href="#221-获取线程是否继承调度属性"></a> <strong>2.21 获取线程是否继承调度属性</strong></h3>
<p>int pthread_attr_getinheritsched (pthread_attr_t *attr, int *inheritsched);</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">说明：获取线程是否继承调度属性</span><br><span class="line"></span><br><span class="line">形参：</span><br><span class="line">    attr          指向一个线程属性的指针</span><br><span class="line">    inheritsched  返回继承调度属性的设置</span><br><span class="line"></span><br><span class="line">返回值：若是成功返回<span class="number">0</span>,否则返回错误的编号</span><br><span class="line"></span><br><span class="line">头文件：<span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line">        <span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sched.h&gt;</span></span></span><br><span class="line"><span class="number">1234567891011</span></span><br></pre></td></tr></table></figure>
<h3 id="222-设置线程是否继承调度属性"><a class="markdownIt-Anchor" href="#222-设置线程是否继承调度属性"></a> <strong>2.22 设置线程是否继承调度属性</strong></h3>
<p>int pthread_attr_setinheritsched (pthread_attr_t *attr, int inheritsched);</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">说明：设置线程是否继承调度属性</span><br><span class="line"></span><br><span class="line">形参：</span><br><span class="line">    attr          指向一个线程属性的指针</span><br><span class="line">    inheritsched  设置线程是否继承调度属性，可能取值如下</span><br><span class="line"></span><br><span class="line">    PTHREAD_INHERIT_SCHED  调度属性将继承于正创建的线程。忽略在 pthread_create() 的attr定义中的调度属性设置</span><br><span class="line">    PTHREAD_EXPLICIT_SCHED 调度属性将被设置为pthread_create()的attr中指定的属性值</span><br><span class="line"></span><br><span class="line">返回值：若是成功返回<span class="number">0</span>,否则返回错误的编号</span><br><span class="line"></span><br><span class="line">头文件：<span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line">        <span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sched.h&gt;</span></span></span><br></pre></td></tr></table></figure>
<h1 id="多线程实例"><a class="markdownIt-Anchor" href="#多线程实例"></a> 多线程实例</h1>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> NUM_THREADS 5      <span class="comment">//线程个数</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> *<span class="title function_">say_hello</span><span class="params">(<span class="type">void</span> *args)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Hello Runoob！\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">//定义线程的 id 变量，多个变量使用数组</span></span><br><span class="line">    <span class="type">pthread_t</span> tids[NUM_THREADS];</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; NUM_THREADS; ++i) &#123;</span><br><span class="line">        <span class="comment">//参数依次是：创建的线程id，线程参数，调用的函数，传入的函数参数</span></span><br><span class="line">        <span class="type">int</span> ret = pthread_create(&amp;tids[i], <span class="literal">NULL</span>, say_hello, <span class="literal">NULL</span>);</span><br><span class="line">        <span class="keyword">if</span> (ret != <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;pthread_create error: error_code = %d\n&quot;</span>, ret);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//等各个线程退出后，进程才结束，否则进程强制结束了，线程可能还没反应过来；</span></span><br><span class="line">    pthread_exit(<span class="literal">NULL</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//g++ test.cpp -lpthread -o test1234567891011121314151617181920212223242526</span></span><br></pre></td></tr></table></figure>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> NUM_THREADS 5      <span class="comment">//线程个数</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> *<span class="title function_">print_hello</span><span class="params">(<span class="type">void</span> *threadid)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">// 对传入的参数进行强制类型转换，由无类型指针变为整形数指针，然后再读取</span></span><br><span class="line">    <span class="type">int</span> tid = *((<span class="type">int</span>*)threadid);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Hello Runoob! 线程 ID, %d\n&quot;</span>, tid);</span><br><span class="line">    pthread_exit(<span class="literal">NULL</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">pthread_t</span> threads[NUM_THREADS];</span><br><span class="line">    <span class="type">int</span> index[NUM_THREADS];</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; NUM_THREADS; ++i) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;main() : 创建线程, %d\n&quot;</span>, i);</span><br><span class="line">        index[i] = i;</span><br><span class="line">        <span class="type">int</span> ret = pthread_create(&amp;threads[i], <span class="literal">NULL</span>, print_hello, (<span class="type">void</span>*)&amp;(index[i]));</span><br><span class="line">        <span class="keyword">if</span> (ret != <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;pthread_create error: error_code = %d\n&quot;</span>, ret);</span><br><span class="line">            <span class="built_in">exit</span>(<span class="number">-1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    pthread_exit(<span class="literal">NULL</span>);</span><br><span class="line">&#125;<span class="number">123456789101112131415161718192021222324252627282930</span></span><br></pre></td></tr></table></figure>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">//通过结构体传递多个参数。可以在线程回调中传递任意的数据类型，因为它指向 void</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> NUM_THREADS 5      <span class="comment">//线程个数</span></span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">thread_data</span>&#123;</span></span><br><span class="line">    <span class="type">int</span> thread_id;</span><br><span class="line">    <span class="type">double</span> message;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> *<span class="title function_">print_hello</span><span class="params">(<span class="type">void</span> *threadarg)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">thread_data</span> *<span class="title">my_data</span> =</span>  (<span class="keyword">struct</span> thread_data *) threadarg;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Thread ID : %d\n&quot;</span>, my_data-&gt;thread_id);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Message : %f\n&quot;</span>, my_data-&gt;message);</span><br><span class="line"></span><br><span class="line">    pthread_exit(<span class="literal">NULL</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">//定义线程的 id 变量，多个变量使用数组</span></span><br><span class="line">    <span class="type">pthread_t</span> threads[NUM_THREADS];</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">thread_data</span> <span class="title">td</span>[<span class="title">NUM_THREADS</span>];</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; NUM_THREADS; ++i) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;main() : creating thread, %d\n&quot;</span>, i);</span><br><span class="line">        td[i].thread_id = i;</span><br><span class="line">        td[i].message = i;</span><br><span class="line">        <span class="type">int</span> ret = pthread_create(&amp;threads[i], <span class="literal">NULL</span>, print_hello, (<span class="type">void</span>*)&amp;(td[i]));</span><br><span class="line">        <span class="keyword">if</span> (ret != <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;pthread_create error: error_code = %d\n&quot;</span>, ret);</span><br><span class="line">            <span class="built_in">exit</span>(<span class="number">-1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//等各个线程退出后，进程才结束，否则进程强制结束了，线程可能还没反应过来；</span></span><br><span class="line">    pthread_exit(<span class="literal">NULL</span>);</span><br><span class="line">&#125;<span class="number">1234567891011121314151617181920212223242526272829303132333435363738394041</span></span><br></pre></td></tr></table></figure>
<h3 id="输出结果"><a class="markdownIt-Anchor" href="#输出结果"></a> 输出结果</h3>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">main() : creating thread, <span class="number">0</span></span><br><span class="line">main() : creating thread, <span class="number">1</span></span><br><span class="line">Thread ID : <span class="number">0</span></span><br><span class="line">Message : <span class="number">0.000000</span></span><br><span class="line">main() : creating thread, <span class="number">2</span></span><br><span class="line">Thread ID : <span class="number">1</span></span><br><span class="line">main() : creating thread, <span class="number">3</span></span><br><span class="line">Message : <span class="number">1.000000</span></span><br><span class="line">Thread ID : <span class="number">2</span></span><br><span class="line">main() : creating thread, <span class="number">4</span></span><br><span class="line">Message : <span class="number">2.000000</span></span><br><span class="line">Thread ID : <span class="number">3</span></span><br><span class="line">Thread ID : <span class="number">4</span></span><br><span class="line">Message : <span class="number">3.000000</span></span><br><span class="line">Message : <span class="number">4.000000</span></span><br></pre></td></tr></table></figure>
<h1 id="linux中fork同时创建多个子进程的方法"><a class="markdownIt-Anchor" href="#linux中fork同时创建多个子进程的方法"></a> linux中fork同时创建多个子进程的方法</h1>
<h2 id="第一种方法验证通过"><a class="markdownIt-Anchor" href="#第一种方法验证通过"></a> 第一种方法：验证通过</h2>
<p>特点：同时创建多个子进程，每个子进程可以执行不同的任务，程序 可读性较好，便于分析，易扩展为多个子进程</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">void</span>)</span> </span><br><span class="line">&#123; </span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;before fork(), pid = %d\n&quot;</span>, getpid()); </span><br><span class="line">  <span class="type">pid_t</span> p1 = fork(); </span><br><span class="line">  <span class="keyword">if</span>( p1 == <span class="number">0</span> )</span><br><span class="line">  &#123; </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;in child 1, pid = %d\n&quot;</span>, getpid()); </span><br><span class="line">    <span class="comment">//while(1);//进入子进程1的处理函数</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>; <span class="comment">//若此处没有return 0 p1 进程也会执行 pid_t p2=fork()语句</span></span><br><span class="line">  &#125; </span><br><span class="line">  <span class="type">pid_t</span> p2 = fork(); </span><br><span class="line">  <span class="keyword">if</span>( p2 == <span class="number">0</span> ) </span><br><span class="line">  &#123; </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;in child 2, pid = %d\n&quot;</span>, getpid()); </span><br><span class="line">    <span class="comment">//while(1);//进入子进程2的处理函数</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>; <span class="comment">//子进程结束，跳回父进程</span></span><br><span class="line">    Printf(<span class="string">&quot;hello world&quot;</span>);<span class="comment">//没有打印</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="type">int</span> st1, st2; </span><br><span class="line">  waitpid( p1, &amp;st1, <span class="number">0</span>); </span><br><span class="line">  waitpid( p2, &amp;st2, <span class="number">0</span>); </span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;in parent, child 1 pid = %d\n&quot;</span>, p1); </span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;in parent, child 2 pid = %d\n&quot;</span>, p2); </span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;in parent, pid = %d\n&quot;</span>, getpid()); </span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;in parent, child 1 exited with %d\n&quot;</span>, st1); </span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;in parent, child 2 exited with %d\n&quot;</span>, st2); </span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>; </span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>
<p>##第二种方法：for 循环方法</p>
<p>特点：其实每次循环只是创建了单个进程，并没有同时创建多个进程</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;sys/types.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> </span><br><span class="line">&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;This is parent process%d\n&quot;</span>,getpid()); </span><br><span class="line">  <span class="type">pid_t</span> p1,p2; </span><br><span class="line">  <span class="type">int</span> i; </span><br><span class="line">  <span class="keyword">for</span>(i=<span class="number">0</span>;i&lt;=<span class="number">2</span>;i++)</span><br><span class="line">  &#123; </span><br><span class="line">    <span class="keyword">if</span>((p1=fork())==<span class="number">0</span>)</span><br><span class="line">    &#123; </span><br><span class="line">      <span class="built_in">printf</span>(<span class="string">&quot;This is child_1 process%d\n&quot;</span>,getpid()); </span><br><span class="line">      <span class="keyword">return</span> <span class="number">0</span>;<span class="comment">//这个地方非常关键 </span></span><br><span class="line">    &#125; </span><br><span class="line">    wait(p1,<span class="literal">NULL</span>,<span class="number">0</span>); <span class="comment">//父进程等待p1子进程执行后才能继续fork其他子进程</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;This is parent process%d\n&quot;</span>,getpid()); </span><br><span class="line">  &#125;</span><br><span class="line">&#125; </span><br><span class="line"><span class="comment">//注意：标注的 return 0 对程序结果影响很大</span></span><br></pre></td></tr></table></figure>
<p>正确的使用Linux中的用fork()由一个父进程创建同时多个子进程的格式如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> status,i;</span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++)</span><br><span class="line">&#123;</span><br><span class="line">  status = fork();</span><br><span class="line">  <span class="keyword">if</span> (status == <span class="number">0</span> || status == <span class="number">-1</span>) </span><br><span class="line">    <span class="keyword">break</span>;<span class="comment">//每次循环时，如果发现是子进程就直接从创建子进程的循环中跳出来，不让你进入循环，这样就保证了每次只有父进程来做循环创建子进程的工作</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (status == <span class="number">-1</span>)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="comment">//error</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (status == <span class="number">0</span>) <span class="comment">//每个子进程都会执行的代码</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="comment">//child&#x27;s sub process</span></span><br><span class="line">  <span class="keyword">while</span>(<span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="comment">//parent process</span></span><br><span class="line">  <span class="keyword">while</span>(<span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>fock 的意思是复制进程， 就是把当前的程序再加载一次， 不同之处在，加载后，所有的状态和当前进程是一样的(包括变量)。 fock 不象线程需提供一个函数做为入口， fock后，新进程的入口就在 fock的下一条语句。返回：子进程中为0，父进程中为子进程I D，出错为-1</p>
<h1 id="进程间通信-管道"><a class="markdownIt-Anchor" href="#进程间通信-管道"></a> 进程间通信 管道</h1>
<h2 id="匿名管道pipe"><a class="markdownIt-Anchor" href="#匿名管道pipe"></a> 匿名管道pipe</h2>
<p>如果你使用过Linux的命令，那么对于管道这个名词你一定不会感觉到陌生，因为我们通常通过符号”|”来使用管道；</p>
<p>但是管道的真正定义是什么呢？<br>
管道是一个进程连接数据流到另一个进程的通道，它通常是用作把一个进程的输出通过管道连接到另一个进程的输入；</p>
<p>举个例子，在shell中输入命令：<code>ls -l | grep string</code><br>
我们知道ls命令（其实也是一个进程）会把当前目录中的文件都列出来，但是它不会直接输出，而是把本来要输出到屏幕上的数据通过管道输出到grep这个进程中，作为grep这个进程的输入，然后这个进程对输入的信息进行筛选，把存在string的信息的字符串（以行为单位）打印在屏幕上；</p>
<p><strong>匿名管道pipe</strong><br>
<code>int pipe(filedes[2]);</code>：创建一个匿名管道</p>
<ul>
<li>头文件：<code>unistd.h</code></li>
<li><code>filedes[2]</code>：输出参数，用于接收pipe返回的两个文件描述符；<code>filedes[0]</code>读管道、<code>filedes[1]</code>写管道</li>
<li>返回值：成功返回0，失败返回-1，并设置errno</li>
</ul>
<p>匿名管道实质上是一个<code>先进先出（FIFO）的队列</code>：<br>
<code>filedes[0]</code>是队头（front），<code>filedes[1]</code>是队尾（rear）；</p>
<p>数据从队尾进，从队头出，遵循先进先出的原则；</p>
<p>pipe()创建的管道，其实是一个在内核中的缓冲区，该缓冲区的大小一般为一页，即4K字节；</p>
<p>先来看一个简单的例子：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;errno.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> *argv[])</span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(argc &lt; <span class="number">3</span>)&#123;</span><br><span class="line">        <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">&quot;usage: %s parent_sendmsg child_sendmsg\n&quot;</span>, argv[<span class="number">0</span>]);</span><br><span class="line">        <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> pipes[<span class="number">2</span>];</span><br><span class="line">    <span class="keyword">if</span>(pipe(pipes) &lt; <span class="number">0</span>)&#123;</span><br><span class="line">        perror(<span class="string">&quot;pipe&quot;</span>);</span><br><span class="line">        <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">pid_t</span> pid = fork();</span><br><span class="line">    <span class="keyword">if</span>(pid &lt; <span class="number">0</span>)&#123;</span><br><span class="line">        perror(<span class="string">&quot;fork&quot;</span>);</span><br><span class="line">        <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">    &#125;<span class="keyword">else</span> <span class="keyword">if</span>(pid &gt; <span class="number">0</span>)&#123;</span><br><span class="line">        <span class="type">char</span> buf[BUFSIZ + <span class="number">1</span>];</span><br><span class="line">        <span class="type">int</span> nbuf;</span><br><span class="line">        <span class="built_in">strcpy</span>(buf, argv[<span class="number">1</span>]);</span><br><span class="line">        write(pipes[<span class="number">1</span>], buf, <span class="built_in">strlen</span>(buf));</span><br><span class="line"></span><br><span class="line">        sleep(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        nbuf = read(pipes[<span class="number">0</span>], buf, BUFSIZ);</span><br><span class="line">        buf[nbuf] = <span class="number">0</span>;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;parent_proc(%d) recv_from_child: %s\n&quot;</span>, getpid(), buf);</span><br><span class="line"></span><br><span class="line">        close(pipes[<span class="number">0</span>]);</span><br><span class="line">        close(pipes[<span class="number">1</span>]);</span><br><span class="line">    &#125;<span class="keyword">else</span> <span class="keyword">if</span>(pid == <span class="number">0</span>)&#123;</span><br><span class="line">        <span class="type">char</span> buf[BUFSIZ + <span class="number">1</span>];</span><br><span class="line">        <span class="type">int</span> nbuf = read(pipes[<span class="number">0</span>], buf, BUFSIZ);</span><br><span class="line">        buf[nbuf] = <span class="number">0</span>;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;child_proc(%d) recv_from_parent: %s\n&quot;</span>, getpid(), buf);</span><br><span class="line"></span><br><span class="line">        <span class="built_in">strcpy</span>(buf, argv[<span class="number">2</span>]);</span><br><span class="line">        write(pipes[<span class="number">1</span>], buf, <span class="built_in">strlen</span>(buf));</span><br><span class="line"></span><br><span class="line">        close(pipes[<span class="number">0</span>]);</span><br><span class="line">        close(pipes[<span class="number">1</span>]);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta"># root @ arch in ~/work on git:master x [14:44:49]</span></span><br><span class="line">$ gcc a.c</span><br><span class="line"></span><br><span class="line"><span class="meta"># root @ arch in ~/work on git:master x [14:44:52]</span></span><br><span class="line">$ ./a.out from_parent from_child</span><br><span class="line"><span class="title function_">child_proc</span><span class="params">(<span class="number">4335</span>)</span> recv_from_parent: from_parent</span><br><span class="line"><span class="title function_">parent_proc</span><span class="params">(<span class="number">4334</span>)</span> recv_from_child: from_child</span><br></pre></td></tr></table></figure>
<p>注意到父进程的<code>sleep(1);</code>语句：<br>
fork调用之前，父进程创建了一个匿名管道，假设文件描述符为<code>filedes[] = &#123;3, 4&#125;</code>，即3为队头，4为队尾；<br>
fork调用之后，创建了一个子进程，子进程也拥有了这两个文件描述符，引用计数都分别加1；</p>
<p>因为实质上在内核中只存在一个管道缓冲区，是父进程创建的，只不过子进程通过fork也拥有了它的引用；<br>
所以，如果父进程发送msg之后，子进程没有及时的读取走数据，那么会被父进程后面的read读取，违背了我们的目的；</p>
<p>所以，一般是不建议上面这种做法的，通常做法是：<br>
一个进程要么往管道里写数据，要么从管道里读数据；<br>
如果既需要读又需要写，那么需要创建两个匿名管道，一个专门读取数据，一个专门写入数据；</p>
<p>比如这样：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;errno.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> *argv[])</span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(argc &lt; <span class="number">3</span>)&#123;</span><br><span class="line">        <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">&quot;usage: %s parent_sendmsg child_sendmsg\n&quot;</span>, argv[<span class="number">0</span>]);</span><br><span class="line">        <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> pipes1[<span class="number">2</span>], pipes2[<span class="number">2</span>];</span><br><span class="line">    <span class="keyword">if</span>(pipe(pipes1) &lt; <span class="number">0</span> || pipe(pipes2) &lt; <span class="number">0</span>)&#123;</span><br><span class="line">        perror(<span class="string">&quot;pipe&quot;</span>);</span><br><span class="line">        <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">pid_t</span> pid = fork();</span><br><span class="line">    <span class="keyword">if</span>(pid &lt; <span class="number">0</span>)&#123;</span><br><span class="line">        perror(<span class="string">&quot;fork&quot;</span>);</span><br><span class="line">        <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">    &#125;<span class="keyword">else</span> <span class="keyword">if</span>(pid &gt; <span class="number">0</span>)&#123;</span><br><span class="line">        close(pipes1[<span class="number">0</span>]);</span><br><span class="line">        close(pipes2[<span class="number">1</span>]);</span><br><span class="line"></span><br><span class="line">        <span class="type">char</span> buf[BUFSIZ + <span class="number">1</span>];</span><br><span class="line">        <span class="built_in">strcpy</span>(buf, argv[<span class="number">1</span>]);</span><br><span class="line">        write(pipes1[<span class="number">1</span>], buf, <span class="built_in">strlen</span>(buf));</span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> nbuf = read(pipes2[<span class="number">0</span>], buf, BUFSIZ);</span><br><span class="line">        buf[nbuf] = <span class="number">0</span>;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;parent_proc(%d) recv_msg: %s\n&quot;</span>, getpid(), buf);</span><br><span class="line"></span><br><span class="line">        close(pipes1[<span class="number">1</span>]);</span><br><span class="line">        close(pipes2[<span class="number">0</span>]);</span><br><span class="line">    &#125;<span class="keyword">else</span> <span class="keyword">if</span>(pid == <span class="number">0</span>)&#123;</span><br><span class="line">        close(pipes1[<span class="number">1</span>]);</span><br><span class="line">        close(pipes2[<span class="number">0</span>]);</span><br><span class="line"></span><br><span class="line">        <span class="type">char</span> buf[BUFSIZ + <span class="number">1</span>];</span><br><span class="line">        <span class="type">int</span> nbuf = read(pipes1[<span class="number">0</span>], buf, BUFSIZ);</span><br><span class="line">        buf[nbuf] = <span class="number">0</span>;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;child_proc(%d) recv_msg: %s\n&quot;</span>, getpid(), buf);</span><br><span class="line"></span><br><span class="line">        <span class="built_in">strcpy</span>(buf, argv[<span class="number">2</span>]);</span><br><span class="line">        write(pipes2[<span class="number">1</span>], buf, <span class="built_in">strlen</span>(buf));</span><br><span class="line"></span><br><span class="line">        close(pipes1[<span class="number">0</span>]);</span><br><span class="line">        close(pipes2[<span class="number">1</span>]);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta"># root @ arch in ~/work on git:master x [15:17:04] C:130</span></span><br><span class="line">$ gcc a.c</span><br><span class="line"></span><br><span class="line"><span class="meta"># root @ arch in ~/work on git:master x [15:17:07]</span></span><br><span class="line">$ ./a.out parent child</span><br><span class="line"><span class="title function_">child_proc</span><span class="params">(<span class="number">4622</span>)</span> recv_msg: parent</span><br><span class="line"><span class="title function_">parent_proc</span><span class="params">(<span class="number">4621</span>)</span> recv_msg: child</span><br></pre></td></tr></table></figure>
<p><strong>默认的阻塞模式</strong><br>
pipe()创建的管道默认是阻塞模式的，阻塞和非阻塞的区别与socket的阻塞、非阻塞很相似：</p>
<p><strong>管道读写规则</strong><br>
当没有数据可读时</p>
<ul>
<li><code>O_NONBLOCK</code>关闭：read调用阻塞，即进程暂停执行，一直等到有数据来到为止；</li>
<li><code>O_NONBLOCK</code>打开：read调用返回-1，errno值为EAGAIN；</li>
</ul>
<p>当管道满的时候</p>
<ul>
<li><code>O_NONBLOCK</code>关闭：write调用阻塞，直到有进程读走数据；</li>
<li><code>O_NONBLOCK</code>打开：调用返回-1，errno值为EAGAIN；</li>
</ul>
<p>如果所有管道写端对应的文件描述符被关闭，则read返回0；<br>
如果所有管道读端对应的文件描述符被关闭，则write操作会产生信号SIGPIPE；</p>
<p>当要写入的数据量不大于PIPE_BUF时，linux将保证写入的原子性；<br>
当要写入的数据量大于PIPE_BUF时，linux将不再保证写入的原子性；</p>
<p>PIPE_BUF的大小为4096字节，注意，这不是管道的缓冲区大小，这个大小和写入的原子性有关；<br>
所谓原子性：</p>
<ul>
<li>阻塞模式时且<code>n&lt;PIPE_BUF</code>：写入具有原子性，如果没有足够的空间供n个字节全部写入，则阻塞直到有足够空间将n个字节全部写入管道；</li>
<li>非阻塞模式时且<code>n&lt;PIPE_BUF</code>：写入具有原子性，立即全部成功写入，否则一个都不写入，返回错误；</li>
<li>阻塞模式时且<code>n&gt;PIPE_BUF</code>：不具有原子性，可能中间有其他进程穿插写入，直到将n字节全部写入才返回，否则阻塞等待写入；</li>
<li>非阻塞模式时且<code>n&gt;PIPE_BUF</code>：不具有原子性，如果管道满的，则立即失败，一个都不写入，返回错误，如果不满，则返回写入的字节数，即部分写入，写入时可能有其他进程穿插写入；</li>
</ul>
<p><strong>设置为非阻塞模式</strong><br>
获取fd的flags值：<code>int flags = fcntl(fd, F_GETFL, 0);</code><br>
设置为非阻塞fd：<code>fcntl(fd, F_SETFL, flags | O_NONBLOCK);</code><br>
设置为阻塞fd：<code>fcntl(fd, F_SETFL, flags &amp; ~O_NONBLOCK);</code></p>
<h1 id="linux进程间通信使用匿名管道"><a class="markdownIt-Anchor" href="#linux进程间通信使用匿名管道"></a> Linux进程间通信——使用匿名管道</h1>
<h2 id="一-什么是管道"><a class="markdownIt-Anchor" href="#一-什么是管道"></a> 一、什么是管道</h2>
<p>如果你使用过Linux的命令，那么对于管道这个名词你一定不会感觉到陌生，因为我们通常通过符号“|&quot;来使用管道，但是管理的真正定义是什么呢？管道是一个进程连接数据流到另一个进程的通道，它通常是用作把一个进程的输出通过管道连接到另一个进程的输入。</p>
<p>举个例子，在shell中输入命令：ls -l | grep string，我们知道ls命令（其实也是一个进程）会把当前目录中的文件都列出来，但是它不会直接输出，而是把本来要输出到屏幕上的数据通过管道输出到grep这个进程中，作为grep这个进程的输入，然后这个进程对输入的信息进行筛选，把存在string的信息的字符串（以行为单位）打印在屏幕上。</p>
<h2 id="二-使用popen函数"><a class="markdownIt-Anchor" href="#二-使用popen函数"></a> 二、使用popen函数</h2>
<h3 id="1-popen函数和pclose函数介绍"><a class="markdownIt-Anchor" href="#1-popen函数和pclose函数介绍"></a> 1、popen函数和pclose函数介绍</h3>
<p>有静就有动，有开就有关，与此相同，与popen函数相对应的函数是pclose函数，它们的原型如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line">FILE* <span class="title function_">popen</span> <span class="params">(<span class="type">const</span> <span class="type">char</span> *command, <span class="type">const</span> <span class="type">char</span> *open_mode)</span>;</span><br><span class="line"><span class="type">int</span> <span class="title function_">pclose</span><span class="params">(FILE *stream_to_close)</span>;</span><br></pre></td></tr></table></figure>
<p>poen函数允许一个程序将另一个程序作为新进程来启动，并可以传递数据给它或者通过它接收数据。command是要运行的程序名和相应的参数。open_mode只能是&quot;r（只读）&quot;和&quot;w（只写）&quot;的其中之一。注意，popen函数的返回值是一个FILE类型的指针，而Linux把一切都视为文件，也就是说我们可以使用stdio I/O库中的文件处理函数来对其进行操作。</p>
<p>如果open_mode是&quot;r&quot;，主调用程序就可以使用被调用程序的输出，通过函数返回的FILE指针，就可以能过stdio函数（如fread）来读取程序的输出；如果open_mode是&quot;w&quot;，主调用程序就可以向被调用程序发送数据，即通过stdio函数（如fwrite）向被调用程序写数据，而被调用程序就可以在自己的标准输入中读取这些数据。</p>
<p>pclose函数用于关闭由popen创建出的关联文件流。pclose只在popen启动的进程结束后才返回，如果调用pclose时被调用进程仍在运行，pclose调用将等待该进程结束。它返回关闭的文件流所在进程的退出码。</p>
<h3 id="2-例子"><a class="markdownIt-Anchor" href="#2-例子"></a> 2、例子</h3>
<p>很多时候，我们根本就不知道输出数据的长度，为了避免定义一个非常大的数组作为缓冲区，我们可以以块的方式来发送数据，一次读取一个块的数据并发送一个块的数据，直到把所有的数据都发送完。下面的例子就是采用这种方式的数据读取和发送方式。源文件名为popen.c，代码如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">	FILE *read_fp = <span class="literal">NULL</span>;</span><br><span class="line">	FILE *write_fp = <span class="literal">NULL</span>;</span><br><span class="line">	<span class="type">char</span> buffer[BUFSIZ + <span class="number">1</span>];</span><br><span class="line">	<span class="type">int</span> chars_read = <span class="number">0</span>;</span><br><span class="line">	<span class="comment">//初始化缓冲区</span></span><br><span class="line">	<span class="built_in">memset</span>(buffer, <span class="string">&#x27;\0&#x27;</span>, <span class="keyword">sizeof</span>(buffer));</span><br><span class="line">	<span class="comment">//打开ls和grep进程</span></span><br><span class="line">	read_fp = popen(<span class="string">&quot;ls -l&quot;</span>, <span class="string">&quot;r&quot;</span>);</span><br><span class="line">	write_fp = popen(<span class="string">&quot;grep rwxrwxr-x&quot;</span>, <span class="string">&quot;w&quot;</span>);</span><br><span class="line">	<span class="comment">//两个进程都打开成功</span></span><br><span class="line">	<span class="keyword">if</span>(read_fp &amp;&amp; write_fp)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="comment">//读取一个数据块</span></span><br><span class="line">		chars_read = fread(buffer, <span class="keyword">sizeof</span>(<span class="type">char</span>), BUFSIZ, read_fp);</span><br><span class="line">		<span class="keyword">while</span>(chars_read &gt; <span class="number">0</span>)</span><br><span class="line">		&#123;</span><br><span class="line">			buffer[chars_read] = <span class="string">&#x27;\0&#x27;</span>;</span><br><span class="line">			<span class="comment">//把数据写入grep进程</span></span><br><span class="line">			fwrite(buffer, <span class="keyword">sizeof</span>(<span class="type">char</span>), chars_read, write_fp);</span><br><span class="line">			<span class="comment">//还有数据可读，循环读取数据，直到读完所有数据</span></span><br><span class="line">			chars_read = fread(buffer, <span class="keyword">sizeof</span>(<span class="type">char</span>), BUFSIZ, read_fp);</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">//关闭文件流</span></span><br><span class="line">		pclose(read_fp);</span><br><span class="line">		pclose(write_fp);</span><br><span class="line">		<span class="built_in">exit</span>(EXIT_SUCCESS);</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>从运行结果来看，达到了信息筛选的目的。程序在进程ls中读取数据，再把数据发送到进程grep中进行筛选处理，相当于在shell中直接输入命令：ls -l | grep rwxrwxr-x。</p>
<h3 id="3-popen的实现方式及优缺点"><a class="markdownIt-Anchor" href="#3-popen的实现方式及优缺点"></a> 3、popen的实现方式及优缺点</h3>
<p>当请求popen调用运行一个程序时，它首先启动shell，即系统中的sh命令，然后将command字符串作为一个参数传递给它。</p>
<p>这样就带来了一个优点和一个缺点。优点是：在Linux中所有的参数扩展都是由shell来完成的。所以在启动程序（command中的命令程序）之前先启动shell来分析命令字符串，也就可以使各种shell扩展（如通配符）在程序启动之前就全部完成，这样我们就可以通过popen启动非常复杂的shell命令。</p>
<p>而它的缺点就是：对于每个popen调用，不仅要启动一个被请求的程序，还要启动一个shell，即每一个popen调用将启动两个进程，从效率和资源的角度看，popen函数的调用比正常方式要慢一些。</p>
<h2 id="三-pipe调用"><a class="markdownIt-Anchor" href="#三-pipe调用"></a> 三、pipe调用</h2>
<p>如果说popen是一个高级的函数，pipe则是一个底层的调用。与popen函数不同的是，它在两个进程之间传递数据不需要启动一个shell来解释请求命令，同时它还提供对读写数据的更多的控制。</p>
<p>pipe函数的原型如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">pipe</span><span class="params">(<span class="type">int</span> file_descriptor[<span class="number">2</span>])</span>;</span><br></pre></td></tr></table></figure>
<p>我们可以看到pipe函数的定义非常特别，该函数在数组中墙上两个新的文件描述符后返回0，如果返回返回-1，并设置errno来说明失败原因。</p>
<p>数组中的两个文件描述符以一种特殊的方式连接起来，数据基于先进先出的原则，写到file_descriptor[1]的所有数据都可以从file_descriptor[0]读回来。由于数据基于先进先出的原则，所以读取的数据和写入的数据是一致的。</p>
<h2 id="特别提醒"><a class="markdownIt-Anchor" href="#特别提醒"></a> 特别提醒：</h2>
<h3 id="1-从函数的原型我们可以看到它跟popen函数的一个重大区别是popen函数是基于文件流file工作的而pipe是基于文件描述符工作的所以在使用pipe后数据必须要用底层的read和write调用来读取和发送"><a class="markdownIt-Anchor" href="#1-从函数的原型我们可以看到它跟popen函数的一个重大区别是popen函数是基于文件流file工作的而pipe是基于文件描述符工作的所以在使用pipe后数据必须要用底层的read和write调用来读取和发送"></a> 1、从函数的原型我们可以看到，它跟popen函数的一个重大区别是，popen函数是基于文件流（FILE）工作的，而pipe是基于文件描述符工作的，所以在使用pipe后，数据必须要用底层的read和write调用来读取和发送。</h3>
<p>2、不要用file_descriptor[0]写数据，也不要用file_descriptor[1]读数据，其行为未定义的，但在有些系统上可能会返回-1表示调用失败。数据只能从file_descriptor[0]中读取，数据也只能写入到file_descriptor[1]，不能倒过来。</p>
<h2 id="例子"><a class="markdownIt-Anchor" href="#例子"></a> 例子：</h2>
<p>首先，我们在原先的进程中创建一个管道，然后再调用fork创建一个新的进程，最后通过管道在两个进程之间传递数据。源文件名为pipe.c，代码如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="type">int</span> data_processed = <span class="number">0</span>;</span><br><span class="line">	<span class="type">int</span> filedes[<span class="number">2</span>];</span><br><span class="line">	<span class="type">const</span> <span class="type">char</span> data[] = <span class="string">&quot;Hello pipe!&quot;</span>;</span><br><span class="line">	<span class="type">char</span> buffer[BUFSIZ + <span class="number">1</span>];</span><br><span class="line">	<span class="type">pid_t</span> pid;</span><br><span class="line">	<span class="comment">//清空缓冲区</span></span><br><span class="line">	<span class="built_in">memset</span>(buffer, <span class="string">&#x27;\0&#x27;</span>, <span class="keyword">sizeof</span>(buffer));</span><br><span class="line">	<span class="keyword">if</span>(pipe(filedes) == <span class="number">0</span>)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="comment">//创建管道成功</span></span><br><span class="line">		<span class="comment">//通过调用fork创建子进程</span></span><br><span class="line">		pid = fork();</span><br><span class="line">		<span class="keyword">if</span>(pid == <span class="number">-1</span>)</span><br><span class="line">		&#123;</span><br><span class="line">			<span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">&quot;Fork failure&quot;</span>);</span><br><span class="line">			<span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span>(pid == <span class="number">0</span>)</span><br><span class="line">		&#123;</span><br><span class="line">			<span class="comment">//子进程中</span></span><br><span class="line">			<span class="comment">//读取数据</span></span><br><span class="line">			data_processed = read(filedes[<span class="number">0</span>], buffer, BUFSIZ);</span><br><span class="line">			<span class="built_in">printf</span>(<span class="string">&quot;Read %d bytes: %s\n&quot;</span>, data_processed, buffer);</span><br><span class="line">			<span class="built_in">exit</span>(EXIT_SUCCESS);</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">else</span></span><br><span class="line">		&#123;</span><br><span class="line">			<span class="comment">//父进程中</span></span><br><span class="line">			<span class="comment">//写数据</span></span><br><span class="line">			data_processed = write(filedes[<span class="number">1</span>], data, <span class="built_in">strlen</span>(data));</span><br><span class="line">			<span class="built_in">printf</span>(<span class="string">&quot;Wrote %d bytes: %s\n&quot;</span>, data_processed, data);</span><br><span class="line">			<span class="comment">//休眠2秒，主要是为了等子进程先结束，这样做也只是纯粹为了输出好看而已</span></span><br><span class="line">			<span class="comment">//父进程其实没有必要等等子进程结束</span></span><br><span class="line">			sleep(<span class="number">2</span>);</span><br><span class="line">			<span class="built_in">exit</span>(EXIT_SUCCESS);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可见，子进程读取了父进程写到filedes[1]中的数据，如果在父进程中没有sleep语句，父进程可能在子进程结束前结束，这样你可能将看到两个输入之间有一个命令提示符分隔。</p>
<h2 id="四-把管道用作标准输入和标准输出"><a class="markdownIt-Anchor" href="#四-把管道用作标准输入和标准输出"></a> 四、把管道用作标准输入和标准输出</h2>
<p>下面来介绍一种用管道来连接两个进程的更简洁方法，我们可以把文件描述符设置为一个已知值，一般是标准输入0或标准输出1。这样做最大的好处是可以调用标准程序，即那些不需要以文件描述符为参数的程序。</p>
<p>为了完成这个工作，我们还需要两个函数的辅助，它们分别是dup函数或dup2函数，它们的原型如下</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">dup</span><span class="params">(<span class="type">int</span> file_descriptor)</span>;</span><br><span class="line"><span class="type">int</span> <span class="title function_">dup2</span><span class="params">(<span class="type">int</span> file_descriptor_one, <span class="type">int</span> file_descriptor_two)</span>;</span><br></pre></td></tr></table></figure>
<p>dup调用创建一个新的文件描述符与作为它的参数的那个已有文件描述符指向同一个文件或管道。对于dup函数而言，新的文件描述总是取最小的可用值。而dup2所创建的新文件描述符或者与int file_descriptor_two相同，或者是第一个大于该参数的可用值。所以当我们首先关闭文件描述符0后调用dup，那么新的文件描述符将是数字0.</p>
<h2 id="例子-2"><a class="markdownIt-Anchor" href="#例子-2"></a> 例子</h2>
<p>在下面的例子中，首先打开管道，然后fork一个子进程，然后在子进程中，使标准输入指向读管道，然后关闭子进程中的读管道和写管道，只留下标准输入，最后调用execlp函数来启动一个新的进程od，但是od并不知道它的数据来源是管道还是终端。父进程则相对简单，它首先关闭读管道，然后在写管道中写入数据，再关闭写管道就完成了它的任务。源文件为pipe2.c，代码如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="type">int</span> data_processed = <span class="number">0</span>;</span><br><span class="line">	<span class="type">int</span> pipes[<span class="number">2</span>];</span><br><span class="line">	<span class="type">const</span> <span class="type">char</span> data[] = <span class="string">&quot;123&quot;</span>;</span><br><span class="line">	<span class="type">pid_t</span> pid;</span><br><span class="line">	<span class="keyword">if</span>(pipe(pipes) == <span class="number">0</span>)</span><br><span class="line">	&#123;</span><br><span class="line">		pid = fork();</span><br><span class="line">		<span class="keyword">if</span>(pid == <span class="number">-1</span>)</span><br><span class="line">		&#123;</span><br><span class="line">			<span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">&quot;Fork failure!\n&quot;</span>);</span><br><span class="line">			<span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span>(pid == <span class="number">0</span>)</span><br><span class="line">		&#123;</span><br><span class="line">			<span class="comment">//子进程中</span></span><br><span class="line">			<span class="comment">//使标准输入指向fildes[0]</span></span><br><span class="line">			close(<span class="number">0</span>);</span><br><span class="line">			dup(pipes[<span class="number">0</span>]);</span><br><span class="line">			<span class="comment">//关闭pipes[0]和pipes[1]，只剩下标准输入</span></span><br><span class="line">			close(pipes[<span class="number">0</span>]);</span><br><span class="line">			close(pipes[<span class="number">1</span>]);</span><br><span class="line">			<span class="comment">//启动新进程od</span></span><br><span class="line">			execlp(<span class="string">&quot;od&quot;</span>, <span class="string">&quot;od&quot;</span>, <span class="string">&quot;-c&quot;</span>, <span class="number">0</span>);</span><br><span class="line">			<span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">else</span></span><br><span class="line">		&#123;</span><br><span class="line">			<span class="comment">//关闭pipes[0],因为父进程不用读取数据</span></span><br><span class="line">			close(pipes[<span class="number">0</span>]);</span><br><span class="line">			data_processed = write(pipes[<span class="number">1</span>], data, <span class="built_in">strlen</span>(data));</span><br><span class="line">			<span class="comment">//写完数据后，关闭pipes[1]</span></span><br><span class="line">			close(pipes[<span class="number">1</span>]);</span><br><span class="line">			<span class="built_in">printf</span>(<span class="string">&quot;%d - Wrote %d bytes\n&quot;</span>, getpid(), data_processed);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="built_in">exit</span>(EXIT_SUCCESS);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>从运行结果中可以看出od进程正确地完成了它的任务，与在shell中直接输入od -c和123的效果一样。</p>
<h2 id="五-关于管道关闭后的读操作的讨论"><a class="markdownIt-Anchor" href="#五-关于管道关闭后的读操作的讨论"></a> 五、关于管道关闭后的读操作的讨论</h2>
<p>现在有这样一个问题，假如父进程向管道file_pipe[1]写数据，而子进程在管道file_pipe[0]中读取数据，当父进程没有向file_pipe[1]写数据时，子进程则没有数据可读，则子进程会发生什么呢？再者父进程把file_pipe[1]关闭了，子进程又会有什么反应呢？</p>
<p>当写数据的管道没有关闭，而又没有数据可读时，read调用通常会阻塞，但是当写数据的管道关闭时，read调用将会返回0而不是阻塞。注意，这与读取一个无效的文件描述符不同，read一个无效的文件描述符返回-1。</p>
<h1 id="等待所有子进程结束"><a class="markdownIt-Anchor" href="#等待所有子进程结束"></a> 等待所有子进程结束</h1>
<p><strong>C语言方法一</strong>：<a href="http://stackoverflow.com/questions/1510922/waiting-for-all-child-processes-before-parent-resumes-execution-unix">http://stackoverflow.com/questions/1510922/waiting-for-all-child-processes-before-parent-resumes-execution-unix</a></p>
<p>通过不指定pid的方式调用waitpid方法，每次等待一个子进程结束，直到所有子进程都结束（waitpid()返回0）</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span> (pid = waitpid(<span class="number">-1</span>, <span class="literal">NULL</span>, <span class="number">0</span>)) &#123;</span><br><span class="line">   <span class="keyword">if</span> (errno == ECHILD) &#123;</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>C语言方法二</strong>：<a href="http://stackoverflow.com/questions/19461744/make-parent-wait-for-all-child-processes">http://stackoverflow.com/questions/19461744/make-parent-wait-for-all-child-processes</a></p>
<p>通过调用wait方法，每次等待一个子进程结束，直到所有子进程都结束（wait()返回0）</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">pid_t</span> child_pid, wpid;</span><br><span class="line"><span class="type">int</span> status = <span class="number">0</span>;</span><br><span class="line"><span class="comment">//Father code (before child processes start)</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> id=<span class="number">0</span>; id&lt;n; id++) &#123;</span><br><span class="line">    <span class="keyword">if</span> ((child_pid = fork()) == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">//child code</span></span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">while</span> ((wpid = wait(&amp;status)) &gt; <span class="number">0</span>); <span class="comment">// this way, the father waits for all the child processes </span></span><br><span class="line"><span class="comment">//Father code (After all child processes end)</span></span><br></pre></td></tr></table></figure>
<p><strong>Python方法</strong>：<a href="http://stackoverflow.com/questions/2993487/spawning-and-waiting-for-child-processes-in-python">http://stackoverflow.com/questions/2993487/spawning-and-waiting-for-child-processes-in-python</a></p>
<p>每创建一个子进程，都将该子进程的pid记录到一个pid的集合中，等所有子进程都创建完毕，逐个wait这个子进程pid集合中的每一个子进程，直到所有子进程都结束</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">pids.append(subprocess.Popen([RESIZECMD, lot, of, options])</span><br><span class="line"><span class="keyword">for</span> pid in pids:</span><br><span class="line">	pid.wait()</span><br></pre></td></tr></table></figure>
<h1 id="附件本次课设程序代码"><a class="markdownIt-Anchor" href="#附件本次课设程序代码"></a> 附件：本次课设程序代码</h1>
<h3 id="多进程求和器"><a class="markdownIt-Anchor" href="#多进程求和器"></a> 多进程求和器</h3>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">//  main.c</span></span><br><span class="line"><span class="comment">//  test</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//  Created by miracleyoo on 2018/7/27.</span></span><br><span class="line"><span class="comment">//  Copyright © 2018年 miracleyoo. All rights reserved.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/time.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ULLINT unsigned long long</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> INPUT 0</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> OUTPUT 1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">timeval</span> <span class="title">start</span>;</span></span><br><span class="line">    gettimeofday(&amp;start,<span class="literal">NULL</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="type">int</span> file_descriptors[<span class="number">2</span>];</span><br><span class="line">    <span class="type">int</span> N,M;</span><br><span class="line">    <span class="type">int</span> cmplen = <span class="number">0</span>;</span><br><span class="line">    <span class="type">int</span> i=<span class="number">0</span>;</span><br><span class="line">    <span class="type">int</span> returned_count;</span><br><span class="line">    signal(SIGCHLD, SIG_IGN);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/* 读取文件 */</span></span><br><span class="line">    FILE *fp = <span class="literal">NULL</span>;</span><br><span class="line">    <span class="type">char</span> buff[<span class="number">2</span>][<span class="number">255</span>];</span><br><span class="line">    <span class="type">char</span> * Ms, * Ns;</span><br><span class="line">    fp = fopen(<span class="string">&quot;input.txt&quot;</span>, <span class="string">&quot;r+&quot;</span>);</span><br><span class="line">    <span class="built_in">fscanf</span>(fp,<span class="string">&quot;%s&quot;</span>,buff[<span class="number">0</span>]);</span><br><span class="line">    <span class="built_in">fscanf</span>(fp,<span class="string">&quot;%s&quot;</span>,buff[<span class="number">1</span>]);</span><br><span class="line">    </span><br><span class="line">    Ns = strtok(buff[<span class="number">0</span>], <span class="string">&quot;=&quot;</span>);</span><br><span class="line">    Ns = strtok(<span class="literal">NULL</span>, <span class="string">&quot;=&quot;</span>);</span><br><span class="line">    N = atoi(Ns);</span><br><span class="line">    </span><br><span class="line">    Ms = strtok(buff[<span class="number">1</span>], <span class="string">&quot;=&quot;</span>);</span><br><span class="line">    Ms = strtok(<span class="literal">NULL</span>, <span class="string">&quot;=&quot;</span>);</span><br><span class="line">    M = atoi(Ms);</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;==&gt; Multi-Process summation program running...\n\n&quot;</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;==&gt; M:%d,N:%d\n&quot;</span>,M,N);</span><br><span class="line">    </span><br><span class="line">    cmplen = M/N;</span><br><span class="line">    <span class="comment">/*定义子进程号 */</span></span><br><span class="line">    <span class="type">pid_t</span> pid=<span class="number">0</span>;</span><br><span class="line">    <span class="comment">/*创建无名管道*/</span></span><br><span class="line">    pipe(file_descriptors);</span><br><span class="line">    <span class="comment">/*创建子进程*/</span></span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">0</span>;i&lt;N;i++)&#123;</span><br><span class="line">        <span class="keyword">if</span>((pid = fork()) == <span class="number">-1</span>) &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;Error in fork\n&quot;</span>);</span><br><span class="line">            <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (pid == <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">break</span>;<span class="comment">//每次循环时，发现是子进程就直接从创建子进程的循环中跳出来</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/*执行子进程*/</span></span><br><span class="line">    <span class="keyword">if</span>(pid == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="type">int</span> start_numC,cmplenC,resC;</span><br><span class="line">        start_numC = i*cmplen+<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span>(i==N<span class="number">-1</span>)&#123;</span><br><span class="line">            cmplenC = M-cmplen*i;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span>&#123;</span><br><span class="line">            cmplenC = cmplen;</span><br><span class="line">        &#125;</span><br><span class="line">        resC = (<span class="number">2</span>*start_numC+cmplenC<span class="number">-1</span>)*cmplenC/<span class="number">2</span>;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;==&gt; Now child process (i:%d) is running, the partly result is: %d\n&quot;</span>,i,resC);</span><br><span class="line">        <span class="comment">/*子进程向父进程写数据，关闭管道的读端*/</span></span><br><span class="line">        close(file_descriptors[INPUT]);</span><br><span class="line">        write(file_descriptors[OUTPUT], &amp;resC , <span class="keyword">sizeof</span>(resC));</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">/*执行父进程*/</span></span><br><span class="line">        wait(<span class="literal">NULL</span>);</span><br><span class="line">        <span class="type">int</span> buf=<span class="number">0</span>,buf_old=<span class="number">0</span>,sum=<span class="number">0</span>;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;==&gt; Now parent process is running...\n&quot;</span>);</span><br><span class="line">        <span class="comment">/*父进程从管道读取子进程写的数据，关闭管道的写端*/</span></span><br><span class="line">        close(file_descriptors[OUTPUT]);</span><br><span class="line">        <span class="keyword">while</span>(<span class="number">1</span>)&#123;</span><br><span class="line">            returned_count = (<span class="type">int</span>)read(file_descriptors[INPUT], &amp;buf, <span class="keyword">sizeof</span>(buf));</span><br><span class="line">            <span class="keyword">if</span>(buf_old==buf)&#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            sum += buf;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;%d bytes of data received from spawned process: %d\n&quot;</span>,</span><br><span class="line">                   returned_count, buf);</span><br><span class="line">            buf_old = buf;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;\nSum:%d\n&quot;</span>,sum);</span><br><span class="line">        FILE *fpo = <span class="literal">NULL</span>;</span><br><span class="line">        fpo = fopen(<span class="string">&quot;output.txt&quot;</span>, <span class="string">&quot;w+&quot;</span>);</span><br><span class="line">        <span class="built_in">fprintf</span>(fpo, <span class="string">&quot;%d&quot;</span>,sum);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">timeval</span> <span class="title">end</span>;</span></span><br><span class="line">    gettimeofday(&amp;end, <span class="literal">NULL</span>);</span><br><span class="line">    ULLINT timer = <span class="number">1000000</span> * (end.tv_sec-start.tv_sec)+end.tv_usec-start.tv_usec;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\nTime used: %llu us\n&quot;</span>,timer);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="多线程求和器"><a class="markdownIt-Anchor" href="#多线程求和器"></a> 多线程求和器</h3>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">//  main.c</span></span><br><span class="line"><span class="comment">//  multisum</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//  Created by miracleyoo on 2018/7/28.</span></span><br><span class="line"><span class="comment">//  Copyright © 2018年 miracleyoo. All rights reserved.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/time.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ULLINT unsigned long long</span></span><br><span class="line"></span><br><span class="line"><span class="type">time_t</span> t_start,t_end;</span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="type">pthread_mutex_t</span> testlock;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> part_res[<span class="number">100</span>] = &#123;<span class="number">0</span>&#125;;</span><br><span class="line"><span class="type">int</span> M=<span class="number">0</span>,N=<span class="number">0</span>,cmplen=<span class="number">0</span>,sum=<span class="number">0</span>;</span><br><span class="line"><span class="type">int</span> count=<span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">partSum</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">int</span> start_numC,cmplenC,resC;</span><br><span class="line">    <span class="type">int</span> i=count;</span><br><span class="line">    count++;</span><br><span class="line">    start_numC = i*cmplen+<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">if</span>(i==N<span class="number">-1</span>)&#123;</span><br><span class="line">        cmplenC = M-cmplen*i;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span>&#123;</span><br><span class="line">        cmplenC = cmplen;</span><br><span class="line">    &#125;</span><br><span class="line">    resC = (<span class="number">2</span>*start_numC+cmplenC<span class="number">-1</span>)*cmplenC/<span class="number">2</span>;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;==&gt; Now child process (i:%d) is running, the partly result is: %d\n&quot;</span>,i,resC);</span><br><span class="line">    pthread_mutex_lock(&amp;testlock);</span><br><span class="line">    sum+=resC;</span><br><span class="line">    pthread_mutex_unlock(&amp;testlock);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">const</span> <span class="type">char</span> * argv[])</span> &#123;</span><br><span class="line">    </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">timeval</span> <span class="title">start</span>;</span></span><br><span class="line">    gettimeofday(&amp;start,<span class="literal">NULL</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// insert code here....</span></span><br><span class="line">    <span class="type">int</span> i=<span class="number">0</span>;</span><br><span class="line">    <span class="comment">/* 读取文件 */</span></span><br><span class="line">    FILE *fp = <span class="literal">NULL</span>;</span><br><span class="line">    <span class="type">char</span> buff[<span class="number">2</span>][<span class="number">255</span>];</span><br><span class="line">    <span class="type">char</span> * Ms, * Ns;</span><br><span class="line">    fp = fopen(<span class="string">&quot;input.txt&quot;</span>, <span class="string">&quot;r+&quot;</span>);</span><br><span class="line">    <span class="built_in">fscanf</span>(fp,<span class="string">&quot;%s&quot;</span>,buff[<span class="number">0</span>]);</span><br><span class="line">    <span class="built_in">fscanf</span>(fp,<span class="string">&quot;%s&quot;</span>,buff[<span class="number">1</span>]);</span><br><span class="line">    </span><br><span class="line">    Ns = strtok(buff[<span class="number">0</span>], <span class="string">&quot;=&quot;</span>);</span><br><span class="line">    Ns = strtok(<span class="literal">NULL</span>, <span class="string">&quot;=&quot;</span>);</span><br><span class="line">    N = atoi(Ns);</span><br><span class="line">    </span><br><span class="line">    Ms = strtok(buff[<span class="number">1</span>], <span class="string">&quot;=&quot;</span>);</span><br><span class="line">    Ms = strtok(<span class="literal">NULL</span>, <span class="string">&quot;=&quot;</span>);</span><br><span class="line">    M = atoi(Ms);</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;==&gt; Multi-Thread summation program running...\n\n&quot;</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;==&gt; M:%d,N:%d\n&quot;</span>,M,N);</span><br><span class="line"></span><br><span class="line">    cmplen = M/N;</span><br><span class="line">    pthread_mutex_init(&amp;testlock, <span class="literal">NULL</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/*创建子线程*/</span></span><br><span class="line">    <span class="type">int</span> ret_thrd[N],ret;</span><br><span class="line">    <span class="type">pthread_t</span> thread[N];</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">0</span>;i&lt;N;i++)&#123;</span><br><span class="line">        ret_thrd[i] = pthread_create(&amp;thread[i], <span class="literal">NULL</span>, (<span class="type">void</span> *)&amp;partSum, (<span class="type">void</span> *)<span class="literal">NULL</span>);<span class="comment">//, (void *)&amp;i);</span></span><br><span class="line">        <span class="keyword">if</span> (ret_thrd[i] != <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;==&gt; Thread %d built failed!\n&quot;</span>,i);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span>&#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;==&gt; Thread %d built successfully!\n&quot;</span>,i);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">0</span>;i&lt;N;i++)&#123;</span><br><span class="line">        ret = pthread_join(thread[i], <span class="literal">NULL</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Sum: %d\n&quot;</span>,sum);</span><br><span class="line">    FILE *fpo = <span class="literal">NULL</span>;</span><br><span class="line">    fpo = fopen(<span class="string">&quot;output.txt&quot;</span>, <span class="string">&quot;w+&quot;</span>);</span><br><span class="line">    <span class="built_in">fprintf</span>(fpo, <span class="string">&quot;%d&quot;</span>,sum);</span><br><span class="line"></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">timeval</span> <span class="title">end</span>;</span></span><br><span class="line">    gettimeofday(&amp;end, <span class="literal">NULL</span>);</span><br><span class="line">    ULLINT timer = <span class="number">1000000</span> * (end.tv_sec-start.tv_sec)+end.tv_usec-start.tv_usec;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\nTime used: %llu us\n&quot;</span>,timer);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>linux</tag>
        <tag>multi-thread</tag>
        <tag>xcode</tag>
        <tag>multi-process</tag>
        <tag>C-lang</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch利用Tensorboardx进行网络结构可视化</title>
    <url>/2018/08/18/tensorboardx-net-visualization/</url>
    <content><![CDATA[<p>之前提到过利用<code>python-graphviz</code>进行自动网络可视化，尽管其较为适合展示，但是Tensorboard生成的网络结构图有着可折叠、便于调试的优点，那Pytorch可以使用这项功能吗？</p>
<p>答案是肯定的，tensorboardx提供了这项支持。</p>
<span id="more"></span>
<p>首先提供相关资源：</p>
<h2 id="资源与下载"><a class="markdownIt-Anchor" href="#资源与下载"></a> 资源与下载</h2>
<ol>
<li>
<p>tensorboardx的安装：<code>pip install tensorboardx</code></p>
</li>
<li>
<p>tensorboardx画网络图的实例：<a href="https://github.com/lanpa/tensorboardX/blob/master/examples/demo_graph.py">实例</a></p>
</li>
<li>
<p>结果展示：</p>
<p><img data-src="006tNbRwgy1fuemv60tllj30ba0isn4w.jpg" alt="image-20180818175931766"></p>
</li>
</ol>
<h2 id="基础操作"><a class="markdownIt-Anchor" href="#基础操作"></a> 基础操作</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dummy_input = Variable(torch.rand(<span class="number">13</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>))</span><br><span class="line">model = Net1()</span><br><span class="line"><span class="keyword">with</span> SummaryWriter(comment=<span class="string">&#x27;Net1&#x27;</span>) <span class="keyword">as</span> w:</span><br><span class="line">    w.add_graph(model, (dummy_input, ))</span><br></pre></td></tr></table></figure>
<h2 id="warning"><a class="markdownIt-Anchor" href="#warning"></a> WARNING</h2>
<p>如果需要可视化网络结构图，一定要让这一步操作放在把net加载为CUDA模型之前进行！</p>
]]></content>
      <tags>
        <tag>machine-learning</tag>
        <tag>pytorch</tag>
        <tag>visualization</tag>
      </tags>
  </entry>
  <entry>
    <title>TensorFlow Higher-Level APIs的使用</title>
    <url>/2019/01/05/tf-high-level-api/</url>
    <content><![CDATA[<h2 id="estimator"><a class="markdownIt-Anchor" href="#estimator"></a> <a href="https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator">Estimator</a>, <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/learn/Experiment">Experiment</a>, and <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/data/Dataset">Dataset</a>的关系</h2>
<p><img data-src="1*zoNZvvuJb06yAghetc6BfQ.png" alt="Overview of the Experiment, Estimator and DataSet framework and how they interact. (These components will be explained in the following sections)"></p>
<span id="more"></span>
<h2 id="estimator定义"><a class="markdownIt-Anchor" href="#estimator定义"></a> Estimator定义</h2>
<p>The <a href="https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator"><strong>Estimator</strong></a> class represents a model, as well as how this model should be trained and evaluated. We can create an estimator as follows:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">return</span> tf.estimator.Estimator(</span><br><span class="line">    model_fn=model_fn,  <span class="comment"># First-class function</span></span><br><span class="line">    params=params,  <span class="comment"># HParams</span></span><br><span class="line">    config=run_config  <span class="comment"># RunConfig</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="参数解释"><a class="markdownIt-Anchor" href="#参数解释"></a> 参数解释</h3>
<p>To create the Estimator we need to pass in a model function, a collection of parameters and some configuration.</p>
<ul>
<li>The <strong>parameters</strong> should be a collection of the model’s hyperparameters. This can be a dictionary, but we will represent it in this example as an <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/training/HParams">HParams</a> object, which acts as a <a href="https://docs.python.org/2/library/collections.html#collections.namedtuple">namedtuple</a>.</li>
<li>The <strong>configuration</strong> specifies how the <strong>training and evaluation</strong> are run, and where to store the results. This configuration will be represented by a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/learn/RunConfig">RunConfig</a> object, which communicates everything the Estimator needs to know about the environment in which the model will be run.</li>
<li>The <strong>model function</strong> is a Python function, which builds the model given the input. (More on this later)</li>
</ul>
<h4 id="model-function"><a class="markdownIt-Anchor" href="#model-function"></a> Model function</h4>
<p>The model function is a Python function which is passed as a <a href="https://en.wikipedia.org/wiki/First-class_function">first-class function</a> to the Estimator. We’ll see later that TensorFlow uses first-class functions in other places. The benefit of representing the model as a function is that the model can be recreated over and over by instantiating the function. The model can be recreated during the training with different input, for example, to run validation tests during training.</p>
<p>The model function takes the <strong>input features</strong> as parameters and the corresponding <strong>labels</strong> as tensors. It also takes a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/learn/ModeKeys"><strong>mode</strong></a> that signals if the model is training, evaluating or performing inference. The last parameter to the model function should be a collection of <strong>hyperparameters</strong>, which are the same as those passed to the Estimator. This model function should return an <a href="https://www.tensorflow.org/api_docs/python/tf/estimator/EstimatorSpec"><strong>EstimatorSpec</strong></a> object which will define the complete model.</p>
<p>The EstimatorSpec takes in the prediction, loss, training and evaluation <a href="https://www.tensorflow.org/api_docs/python/tf/Operation">Operations</a> so it defines the full model graph used for training, evaluation, and inference. Because the EstimatorSpec just takes in regular TensorFlow Operations, we can use frameworks like <a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim">TF-Slim</a> to define our model.</p>
<h2 id="estimator创建方式"><a class="markdownIt-Anchor" href="#estimator创建方式"></a> Estimator创建方式</h2>
<ol>
<li>预创建的 Estimator</li>
<li>自定义 Estimator</li>
<li>从 Keras 模型创建 Estimator</li>
</ol>
<h3 id="3从-keras-模型创建-estimator的例子"><a class="markdownIt-Anchor" href="#3从-keras-模型创建-estimator的例子"></a> 3从 Keras 模型创建 Estimator的例子：</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Instantiate a Keras inception v3 model.</span></span><br><span class="line">keras_inception_v3 = tf.keras.applications.inception_v3.InceptionV3(weights=<span class="literal">None</span>)</span><br><span class="line"><span class="comment"># Compile model with the optimizer, loss, and metrics you&#x27;d like to train with.</span></span><br><span class="line">keras_inception_v3.<span class="built_in">compile</span>(optimizer=tf.keras.optimizers.SGD(lr=<span class="number">0.0001</span>, momentum=<span class="number">0.9</span>),</span><br><span class="line">                          loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">                          metric=<span class="string">&#x27;accuracy&#x27;</span>)</span><br><span class="line"><span class="comment"># Create an Estimator from the compiled Keras model. Note the initial model</span></span><br><span class="line"><span class="comment"># state of the keras model is preserved in the created Estimator.</span></span><br><span class="line">est_inception_v3 = tf.keras.estimator.model_to_estimator(keras_model=keras_inception_v3)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Treat the derived Estimator as you would with any other Estimator.</span></span><br><span class="line"><span class="comment"># First, recover the input name(s) of Keras model, so we can use them as the</span></span><br><span class="line"><span class="comment"># feature column name(s) of the Estimator input function:</span></span><br><span class="line">keras_inception_v3.input_names  <span class="comment"># print out: [&#x27;input_1&#x27;]</span></span><br><span class="line"><span class="comment"># Once we have the input name(s), we can create the input function, for example,</span></span><br><span class="line"><span class="comment"># for input(s) in the format of numpy ndarray:</span></span><br><span class="line">train_input_fn = tf.estimator.inputs.numpy_input_fn(</span><br><span class="line">    x=&#123;<span class="string">&quot;input_1&quot;</span>: train_data&#125;,</span><br><span class="line">    y=train_labels,</span><br><span class="line">    num_epochs=<span class="number">1</span>,</span><br><span class="line">    shuffle=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># To train, we call Estimator&#x27;s train function:</span></span><br><span class="line">est_inception_v3.train(input_fn=train_input_fn, steps=<span class="number">2000</span>)</span><br></pre></td></tr></table></figure>
<h3 id="这样做的好处"><a class="markdownIt-Anchor" href="#这样做的好处"></a> 这样做的好处</h3>
<p>Keras 模型本身容易建立，导出到Estimator后又可以利用 Estimator 的优势，例如分布式训练。</p>
<h2 id="estimator-的优势"><a class="markdownIt-Anchor" href="#estimator-的优势"></a> Estimator 的优势</h2>
<h3 id="从意义角度"><a class="markdownIt-Anchor" href="#从意义角度"></a> 从意义角度</h3>
<ul>
<li>环境适配性好。可以在本地主机、分布式多服务器环境中运行基于 Estimator 的模型，而无需更改模型。此外，可以在 CPU、GPU 或 TPU 上运行基于 Estimator 的模型，而无需重新编码模型。</li>
<li>简化了在模型开发者之间共享实现的过程。</li>
<li>采用 Estimator 创建模型通常比采用低阶 TensorFlow API 更简单。</li>
<li>其本身在 <a href="https://www.tensorflow.org/api_docs/python/tf/layers?hl=zh-cn"><code>tf.layers</code></a> 之上构建而成，可以简化自定义过程。</li>
<li>Estimator 会自动构建图。</li>
<li>Estimator 提供安全的分布式训练循环，可以控制如何以及何时：
<ul>
<li>构建图</li>
<li>初始化变量</li>
<li>开始排队</li>
<li>处理异常</li>
<li>创建检查点文件并从故障中恢复</li>
<li>保存 TensorBoard 的摘要</li>
</ul>
</li>
</ul>
<h3 id="从使用角度"><a class="markdownIt-Anchor" href="#从使用角度"></a> 从使用角度</h3>
<ul>
<li><strong>学习流程</strong>：Estimator 封装了对机器学习不同阶段的控制，用户无需不断的为新机器学习任务重复编写训练、评估、预测的代码。可以专注于对网络结构的控制。</li>
<li><strong>网络结构</strong>：Estimator 的网络结构是在 model_fn 中独立定义的，用户创建的任何网络结构都可以在 Estimator 的控制下进行机器学习。这可以允许用户很方便的使用别人定义好的 model_fn。</li>
<li><strong>数据导入</strong>：Estimator 的数据导入也是由 input_fn 独立定义的。例如，用户可以非常方便的只通过改变 input_fn 的定义，来使用相同的网络结构学习不同的数据。</li>
</ul>
<p>使用 Estimator 编写应用时，您必须将数据输入管道从模型中分离出来。这种分离简化了不同数据集的实验流程。</p>
<h2 id="预创建的-estimator-程序的结构"><a class="markdownIt-Anchor" href="#预创建的-estimator-程序的结构"></a> 预创建的 Estimator 程序的结构</h2>
<p>依赖预创建的 Estimator 的 TensorFlow 程序通常包含下列四个步骤：</p>
<ol>
<li>
<p><strong>编写一个或多个数据集导入函数。</strong> 例如，您可以创建一个函数来导入训练集，并创建另一个函数来导入测试集。每个数据集导入函数都必须返回两个对象：</p>
<ul>
<li>一个字典，其中键是特征名称，值是包含相应特征数据的张量（或 SparseTensor）</li>
<li>一个包含一个或多个标签的张量</li>
</ul>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">input_fn</span>(<span class="params">dataset</span>):</span><br><span class="line">   ...  <span class="comment"># manipulate dataset, extracting the feature dict and the label</span></span><br><span class="line">   <span class="keyword">return</span> feature_dict, label</span><br></pre></td></tr></table></figure>
<ol start="2">
<li><strong>定义特征列。</strong> 每个 <a href="https://www.tensorflow.org/api_docs/python/tf/feature_column?hl=zh-cn"><code>tf.feature_column</code></a> 都标识了特征名称、特征类型和任何输入预处理操作。例如，以下代码段创建了三个存储整数或浮点数据的特征列。前两个特征列仅标识了特征的名称和类型。第三个特征列还指定了一个 lambda，该程序将调用此 lambda 来调节原始数据：</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Define three numeric feature columns.</span></span><br><span class="line">population = tf.feature_column.numeric_column(<span class="string">&#x27;population&#x27;</span>)</span><br><span class="line">crime_rate = tf.feature_column.numeric_column(<span class="string">&#x27;crime_rate&#x27;</span>)</span><br><span class="line">median_education = tf.feature_column.numeric_column(<span class="string">&#x27;median_education&#x27;</span>,</span><br><span class="line">                    normalizer_fn=<span class="keyword">lambda</span> x: x - global_education_mean)</span><br></pre></td></tr></table></figure>
<ol start="3">
<li><strong>实例化相关的预创建的 Estimator。</strong> 例如，下面是对名为 <code>LinearClassifier</code> 的预创建 Estimator 进行实例化的示例代码：</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Instantiate an estimator, passing the feature columns.</span></span><br><span class="line">estimator = tf.estimator.LinearClassifier(</span><br><span class="line">    feature_columns=[population, crime_rate, median_education],</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
<ol start="4">
<li>**调用训练、评估或推理方法。**例如，所有 Estimator 都提供训练模型的 <code>train</code> 方法。</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># my_training_set is the function created in Step 1 estimator.train(input_fn=my_training_set, steps=2000)</span></span><br></pre></td></tr></table></figure>
<h2 id="experiment"><a class="markdownIt-Anchor" href="#experiment"></a> Experiment</h2>
<p>The <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/learn/Experiment"><strong>Experiment</strong></a> class defines how to train a model and integrates nicely with the Estimator. We can create an experiment as follows:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">experiment = tf.contrib.learn.Experiment(</span><br><span class="line">    estimator=estimator,  <span class="comment"># Estimator</span></span><br><span class="line">    train_input_fn=train_input_fn,  <span class="comment"># First-class function</span></span><br><span class="line">    eval_input_fn=eval_input_fn,  <span class="comment"># First-class function</span></span><br><span class="line">    train_steps=params.train_steps,  <span class="comment"># Minibatch steps</span></span><br><span class="line">    min_eval_frequency=params.min_eval_frequency,  <span class="comment"># Eval frequency</span></span><br><span class="line">    train_monitors=[train_input_hook],  <span class="comment"># Hooks for training</span></span><br><span class="line">    eval_hooks=[eval_input_hook],  <span class="comment"># Hooks for evaluation</span></span><br><span class="line">    eval_steps=<span class="literal">None</span>  <span class="comment"># Use evaluation feeder until its empty</span></span><br><span class="line">)</span><br><span class="line">view raw</span><br></pre></td></tr></table></figure>
<p>The Experiment takes as input:</p>
<ul>
<li>An <strong>estimator</strong> (for example the one we defined above).</li>
<li><strong>Train and evaluation data</strong> as a <a href="https://en.wikipedia.org/wiki/First-class_function">first-class function</a>. The same concept as the model function explained earlier is used here. By passing in a function instead of operation, the input graph can be recreated if needed. We’ll talk more about this later.</li>
<li><a href="https://www.tensorflow.org/api_guides/python/train#Training_Hooks"><strong>Training and Evaluating hooks</strong></a>. These hooks can be used to save or monitor specific things, or to set up certain operations in the Graph or Session. For example, we will be passing in operations to help initialize the data loaders (again, more later).</li>
<li>Various parameters describing how long to train for and when to evaluate.</li>
</ul>
<p>Once we have defined the experiment, we can run it to train and evaluate the model with <a href="http://tf.contrib.learn.learn_runner.run/">learn_runner.run</a> as follows:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">learn_runner.run(</span><br><span class="line">    experiment_fn=experiment_fn,  <span class="comment"># First-class function</span></span><br><span class="line">    run_config=run_config,  <span class="comment"># RunConfig</span></span><br><span class="line">    schedule=<span class="string">&quot;train_and_evaluate&quot;</span>,  <span class="comment"># What to run</span></span><br><span class="line">    hparams=params  <span class="comment"># HParams</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>Like the model function and the data functions, the learn runner takes in the function that creates the experiment as a parameter.</p>
<h3 id="dataset"><a class="markdownIt-Anchor" href="#dataset"></a> Dataset</h3>
<p>We’ll be using the <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/data/Dataset"><strong>Dataset</strong></a> class and the corresponding <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/data/Iterator"><strong>Iterator</strong></a> to represent our training and evaluation data, and to create data feeders that iterate over the data during training. In this example, we will use the <a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/tutorials/mnist">MNIST</a> data that’s available in Tensorflow, and build a Dataset wrapper around it. For example, we will represent the training input data as:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Define the training inputs</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_train_inputs</span>(<span class="params">batch_size, mnist_data</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Return the input function to get the training data.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        batch_size (int): Batch size of training iterator that is returned</span></span><br><span class="line"><span class="string">                          by the input function.</span></span><br><span class="line"><span class="string">        mnist_data (Object): Object holding the loaded mnist data.</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        (Input function, IteratorInitializerHook):</span></span><br><span class="line"><span class="string">            - Function that returns (features, labels) when called.</span></span><br><span class="line"><span class="string">            - Hook to initialise input iterator.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    iterator_initializer_hook = IteratorInitializerHook()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train_inputs</span>():</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Returns training set as Operations.</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            (features, labels) Operations that iterate over the dataset</span></span><br><span class="line"><span class="string">            on every evaluation</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">&#x27;Training_data&#x27;</span>):</span><br><span class="line">            <span class="comment"># Get Mnist data</span></span><br><span class="line">            images = mnist_data.train.images.reshape([-<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>])</span><br><span class="line">            labels = mnist_data.train.labels</span><br><span class="line">            <span class="comment"># Define placeholders</span></span><br><span class="line">            images_placeholder = tf.placeholder(</span><br><span class="line">                images.dtype, images.shape)</span><br><span class="line">            labels_placeholder = tf.placeholder(</span><br><span class="line">                labels.dtype, labels.shape)</span><br><span class="line">            <span class="comment"># Build dataset iterator</span></span><br><span class="line">            dataset = tf.contrib.data.Dataset.from_tensor_slices(</span><br><span class="line">                (images_placeholder, labels_placeholder))</span><br><span class="line">            dataset = dataset.repeat(<span class="literal">None</span>)  <span class="comment"># Infinite iterations</span></span><br><span class="line">            dataset = dataset.shuffle(buffer_size=<span class="number">10000</span>)</span><br><span class="line">            dataset = dataset.batch(batch_size)</span><br><span class="line">            iterator = dataset.make_initializable_iterator()</span><br><span class="line">            next_example, next_label = iterator.get_next()</span><br><span class="line">            <span class="comment"># Set runhook to initialize iterator</span></span><br><span class="line">            iterator_initializer_hook.iterator_initializer_func = \</span><br><span class="line">                <span class="keyword">lambda</span> sess: sess.run(</span><br><span class="line">                    iterator.initializer,</span><br><span class="line">                    feed_dict=&#123;images_placeholder: images,</span><br><span class="line">                               labels_placeholder: labels&#125;)</span><br><span class="line">            <span class="comment"># Return batched (features, labels)</span></span><br><span class="line">            <span class="keyword">return</span> next_example, next_label</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Return function and hook</span></span><br><span class="line">    <span class="keyword">return</span> train_inputs, iterator_initializer_hook</span><br></pre></td></tr></table></figure>
<p>Calling this <em>get_train_inputs</em> will return a <a href="https://en.wikipedia.org/wiki/First-class_function">first-class function</a> that creates the data loading operations in a TensorFlow graph, together with a Hook to initialize the iterator.</p>
<p>The MNIST data used in this example is initially represented as a <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html">Numpy array</a>. We create a <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder">placeholder</a> tensor that gets the data fed in; we use a placeholder in order to avoid copying the data. Next, we create a sliced dataset with the help of <em>from_tensor_slices.</em> We will make sure that this dataset runs for an infinite amount of epochs (the experiment can take care of limiting the number of epochs), and that the data gets shuffled and put into batches of the required size.</p>
<p>To iterate over the data we need to create an iterator from the dataset. Because we are using a placeholder we need to initialize the placeholder in the relevant session with the NumPy data. We can do this by creating an <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/data/Dataset#make_initializable_iterator">initializable iterator</a>. We will create a custom defined _IteratorInitializerHook _object to initialize the iterator when the graph is created:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">IteratorInitializerHook</span>(tf.train.SessionRunHook):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Hook to initialise data iterator after Session is created.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(IteratorInitializerHook, self).__init__()</span><br><span class="line">        self.iterator_initializer_func = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">after_create_session</span>(<span class="params">self, session, coord</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Initialise the iterator after the session has been created.&quot;&quot;&quot;</span></span><br><span class="line">        self.iterator_initializer_func(session)</span><br></pre></td></tr></table></figure>
<p>The <em>IteratorInitializerHook</em> inherits from <a href="https://www.tensorflow.org/api_docs/python/tf/train/SessionRunHook"><strong>SessionRunHook</strong></a>. This hook will call <em>after_create_session</em> as soon as the relevant session is created, and initialize the placeholder with the right data. This hook is returned by our <em>get_train_inputs</em> function and will be passed to the Experiment object upon creation.</p>
<p>The data loading operations returned by the <em>train_inputs</em> function are TensorFlow <a href="https://www.tensorflow.org/api_docs/python/tf/Operation">operations</a> that will return a new batch every time they are evaluated.</p>
<h2 id="引用"><a class="markdownIt-Anchor" href="#引用"></a> 引用</h2>
<ol>
<li><a href="https://medium.com/onfido-tech/higher-level-apis-in-tensorflow-67bfb602e6c0">Higher-Level APIs in TensorFlow</a></li>
<li><a href="https://www.tensorflow.org/guide/estimators?hl=zh-cn">TensorFlow Estimator</a></li>
<li><a href="https://juejin.im/post/59b4cc816fb9a00a6974c5a3">如何使用TensorFlow中的高级API：Estimator、Experiment和Dataset</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/33681224">TensorFlow高层API：Custom Estimator建立CNN+RNN</a></li>
<li>There is a paper called <a href="https://terrytangyuan.github.io/data/papers/tf-estimators-kdd-paper.pdf">“TensorFlow Estimators: Managing Simplicity vs. Flexibility in High-Level Machine Learning Frameworks”</a> describing the high level-design of the Estimator framework.</li>
<li><a href="https://www.tensorflow.org/versions/r1.3/programmers_guide/datasets">TensorFlow has more documentation on using the Dataset API</a>.</li>
<li>There are 2 versions of the Estimator class. We are using the one at <a href="https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator">tf.estimator.Estimator</a> in this example, but there is also an older unstable version at <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/learn/Estimator">tf.contrib.learn.Estimator</a>.</li>
<li>There are also 2 versions of the RunConfig class. While we are using the one at <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/learn/RunConfig">tf.contrib.learn.RunConfig</a> there is also a version at <a href="https://www.tensorflow.org/api_docs/python/tf/estimator/RunConfig">tf.estimator.RunConfig</a>. I couldn’t get the latter one to work with the Experiment framework so I stuck with the tf.contrib version.</li>
<li>While we didn’t use them in this example, the Estimator framework defines predefined estimators for typical models such as <a href="https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier">classifiers</a> and <a href="https://www.tensorflow.org/api_docs/python/tf/estimator/DNNRegressor">regressors</a>. These predefined estimators are easy to use and come with a <a href="https://www.tensorflow.org/extend/estimators">detailed tutorial</a>.</li>
<li>TensorFlow also defines an abstraction for the “head” of a model, the part that sits on top of the architecture and defines the loss, evaluation and training operations. This head will take care of things like defining the model function, and all the required Operations. You can find a version at <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/learn/Head">tf.contrib.learn.Head</a>. There is also a <a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/estimator/canned/head.py">prototype version</a> in the newer estimator framework. We decided not to use it in this example due to its development being quite unstable.</li>
<li>This blog uses the TensorFlow <a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim">slim</a> framework to define the architecture of the model. Slim is a lightweight library for defining complex models in tensorflow. They also define <a href="https://github.com/tensorflow/models/tree/master/slim">pre-defined architectures and pre-trained models</a>.</li>
</ol>
<h2 id="示例代码"><a class="markdownIt-Anchor" href="#示例代码"></a> 示例代码</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;Script to illustrate usage of tf.estimator.Estimator in TF v1.3&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data <span class="keyword">as</span> mnist_data</span><br><span class="line"><span class="keyword">from</span> tensorflow.contrib <span class="keyword">import</span> slim</span><br><span class="line"><span class="keyword">from</span> tensorflow.contrib.learn <span class="keyword">import</span> ModeKeys</span><br><span class="line"><span class="keyword">from</span> tensorflow.contrib.learn <span class="keyword">import</span> learn_runner</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Show debugging output</span></span><br><span class="line">tf.logging.set_verbosity(tf.logging.DEBUG)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set default flags for the output directories</span></span><br><span class="line">FLAGS = tf.app.flags.FLAGS</span><br><span class="line">tf.app.flags.DEFINE_string(</span><br><span class="line">    flag_name=<span class="string">&#x27;model_dir&#x27;</span>, default_value=<span class="string">&#x27;./mnist_training&#x27;</span>,</span><br><span class="line">    docstring=<span class="string">&#x27;Output directory for model and training stats.&#x27;</span>)</span><br><span class="line">tf.app.flags.DEFINE_string(</span><br><span class="line">    flag_name=<span class="string">&#x27;data_dir&#x27;</span>, default_value=<span class="string">&#x27;./mnist_data&#x27;</span>,</span><br><span class="line">    docstring=<span class="string">&#x27;Directory to download the data to.&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define and run experiment ###############################</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run_experiment</span>(<span class="params">argv=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Run the training experiment.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Define model parameters</span></span><br><span class="line">    params = tf.contrib.training.HParams(</span><br><span class="line">        learning_rate=<span class="number">0.002</span>,</span><br><span class="line">        n_classes=<span class="number">10</span>,</span><br><span class="line">        train_steps=<span class="number">5000</span>,</span><br><span class="line">        min_eval_frequency=<span class="number">100</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Set the run_config and the directory to save the model and stats</span></span><br><span class="line">    run_config = tf.contrib.learn.RunConfig()</span><br><span class="line">    run_config = run_config.replace(model_dir=FLAGS.model_dir)</span><br><span class="line"></span><br><span class="line">    learn_runner.run(</span><br><span class="line">        experiment_fn=experiment_fn,  <span class="comment"># First-class function</span></span><br><span class="line">        run_config=run_config,  <span class="comment"># RunConfig</span></span><br><span class="line">        schedule=<span class="string">&quot;train_and_evaluate&quot;</span>,  <span class="comment"># What to run</span></span><br><span class="line">        hparams=params  <span class="comment"># HParams</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">experiment_fn</span>(<span class="params">run_config, params</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Create an experiment to train and evaluate the model.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        run_config (RunConfig): Configuration for Estimator run.</span></span><br><span class="line"><span class="string">        params (HParam): Hyperparameters</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        (Experiment) Experiment for training the mnist model.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># You can change a subset of the run_config properties as</span></span><br><span class="line">    run_config = run_config.replace(</span><br><span class="line">        save_checkpoints_steps=params.min_eval_frequency)</span><br><span class="line">    <span class="comment"># Define the mnist classifier</span></span><br><span class="line">    estimator = get_estimator(run_config, params)</span><br><span class="line">    <span class="comment"># Setup data loaders</span></span><br><span class="line">    mnist = mnist_data.read_data_sets(FLAGS.data_dir, one_hot=<span class="literal">False</span>)</span><br><span class="line">    train_input_fn, train_input_hook = get_train_inputs(</span><br><span class="line">        batch_size=<span class="number">128</span>, mnist_data=mnist)</span><br><span class="line">    eval_input_fn, eval_input_hook = get_test_inputs(</span><br><span class="line">        batch_size=<span class="number">128</span>, mnist_data=mnist)</span><br><span class="line">    <span class="comment"># Define the experiment</span></span><br><span class="line">    experiment = tf.contrib.learn.Experiment(</span><br><span class="line">        estimator=estimator,  <span class="comment"># Estimator</span></span><br><span class="line">        train_input_fn=train_input_fn,  <span class="comment"># First-class function</span></span><br><span class="line">        eval_input_fn=eval_input_fn,  <span class="comment"># First-class function</span></span><br><span class="line">        train_steps=params.train_steps,  <span class="comment"># Minibatch steps</span></span><br><span class="line">        min_eval_frequency=params.min_eval_frequency,  <span class="comment"># Eval frequency</span></span><br><span class="line">        train_monitors=[train_input_hook],  <span class="comment"># Hooks for training</span></span><br><span class="line">        eval_hooks=[eval_input_hook],  <span class="comment"># Hooks for evaluation</span></span><br><span class="line">        eval_steps=<span class="literal">None</span>  <span class="comment"># Use evaluation feeder until its empty</span></span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> experiment</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define model ############################################</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_estimator</span>(<span class="params">run_config, params</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Return the model as a Tensorflow Estimator object.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">         run_config (RunConfig): Configuration for Estimator run.</span></span><br><span class="line"><span class="string">         params (HParams): hyperparameters.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> tf.estimator.Estimator(</span><br><span class="line">        model_fn=model_fn,  <span class="comment"># First-class function</span></span><br><span class="line">        params=params,  <span class="comment"># HParams</span></span><br><span class="line">        config=run_config  <span class="comment"># RunConfig</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">model_fn</span>(<span class="params">features, labels, mode, params</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Model function used in the estimator.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        features (Tensor): Input features to the model.</span></span><br><span class="line"><span class="string">        labels (Tensor): Labels tensor for training and evaluation.</span></span><br><span class="line"><span class="string">        mode (ModeKeys): Specifies if training, evaluation or prediction.</span></span><br><span class="line"><span class="string">        params (HParams): hyperparameters.</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        (EstimatorSpec): Model to be run by Estimator.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    is_training = mode == ModeKeys.TRAIN</span><br><span class="line">    <span class="comment"># Define model&#x27;s architecture</span></span><br><span class="line">    logits = architecture(features, is_training=is_training)</span><br><span class="line">    predictions = tf.argmax(logits, axis=-<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># Loss, training and eval operations are not needed during inference.</span></span><br><span class="line">    loss = <span class="literal">None</span></span><br><span class="line">    train_op = <span class="literal">None</span></span><br><span class="line">    eval_metric_ops = &#123;&#125;</span><br><span class="line">    <span class="keyword">if</span> mode != ModeKeys.INFER:</span><br><span class="line">        loss = tf.losses.sparse_softmax_cross_entropy(</span><br><span class="line">            labels=tf.cast(labels, tf.int32),</span><br><span class="line">            logits=logits)</span><br><span class="line">        train_op = get_train_op_fn(loss, params)</span><br><span class="line">        eval_metric_ops = get_eval_metric_ops(labels, predictions)</span><br><span class="line">    <span class="keyword">return</span> tf.estimator.EstimatorSpec(</span><br><span class="line">        mode=mode,</span><br><span class="line">        predictions=predictions,</span><br><span class="line">        loss=loss,</span><br><span class="line">        train_op=train_op,</span><br><span class="line">        eval_metric_ops=eval_metric_ops</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_train_op_fn</span>(<span class="params">loss, params</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Get the training Op.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">         loss (Tensor): Scalar Tensor that represents the loss function.</span></span><br><span class="line"><span class="string">         params (HParams): Hyperparameters (needs to have `learning_rate`)</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        Training Op</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> tf.contrib.layers.optimize_loss(</span><br><span class="line">        loss=loss,</span><br><span class="line">        global_step=tf.contrib.framework.get_global_step(),</span><br><span class="line">        optimizer=tf.train.AdamOptimizer,</span><br><span class="line">        learning_rate=params.learning_rate</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_eval_metric_ops</span>(<span class="params">labels, predictions</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Return a dict of the evaluation Ops.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        labels (Tensor): Labels tensor for training and evaluation.</span></span><br><span class="line"><span class="string">        predictions (Tensor): Predictions Tensor.</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        Dict of metric results keyed by name.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&#x27;Accuracy&#x27;</span>: tf.metrics.accuracy(</span><br><span class="line">            labels=labels,</span><br><span class="line">            predictions=predictions,</span><br><span class="line">            name=<span class="string">&#x27;accuracy&#x27;</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">architecture</span>(<span class="params">inputs, is_training, scope=<span class="string">&#x27;MnistConvNet&#x27;</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Return the output operation following the network architecture.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        inputs (Tensor): Input Tensor</span></span><br><span class="line"><span class="string">        is_training (bool): True iff in training mode</span></span><br><span class="line"><span class="string">        scope (str): Name of the scope of the architecture</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">         Logits output Op for the network.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(scope):</span><br><span class="line">        <span class="keyword">with</span> slim.arg_scope(</span><br><span class="line">                [slim.conv2d, slim.fully_connected],</span><br><span class="line">                weights_initializer=tf.contrib.layers.xavier_initializer()):</span><br><span class="line">            net = slim.conv2d(inputs, <span class="number">20</span>, [<span class="number">5</span>, <span class="number">5</span>], padding=<span class="string">&#x27;VALID&#x27;</span>,</span><br><span class="line">                              scope=<span class="string">&#x27;conv1&#x27;</span>)</span><br><span class="line">            net = slim.max_pool2d(net, <span class="number">2</span>, stride=<span class="number">2</span>, scope=<span class="string">&#x27;pool2&#x27;</span>)</span><br><span class="line">            net = slim.conv2d(net, <span class="number">40</span>, [<span class="number">5</span>, <span class="number">5</span>], padding=<span class="string">&#x27;VALID&#x27;</span>,</span><br><span class="line">                              scope=<span class="string">&#x27;conv3&#x27;</span>)</span><br><span class="line">            net = slim.max_pool2d(net, <span class="number">2</span>, stride=<span class="number">2</span>, scope=<span class="string">&#x27;pool4&#x27;</span>)</span><br><span class="line">            net = tf.reshape(net, [-<span class="number">1</span>, <span class="number">4</span> * <span class="number">4</span> * <span class="number">40</span>])</span><br><span class="line">            net = slim.fully_connected(net, <span class="number">256</span>, scope=<span class="string">&#x27;fn5&#x27;</span>)</span><br><span class="line">            net = slim.dropout(net, is_training=is_training,</span><br><span class="line">                               scope=<span class="string">&#x27;dropout5&#x27;</span>)</span><br><span class="line">            net = slim.fully_connected(net, <span class="number">256</span>, scope=<span class="string">&#x27;fn6&#x27;</span>)</span><br><span class="line">            net = slim.dropout(net, is_training=is_training,</span><br><span class="line">                               scope=<span class="string">&#x27;dropout6&#x27;</span>)</span><br><span class="line">            net = slim.fully_connected(net, <span class="number">10</span>, scope=<span class="string">&#x27;output&#x27;</span>,</span><br><span class="line">                                       activation_fn=<span class="literal">None</span>)</span><br><span class="line">        <span class="keyword">return</span> net</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define data loaders #####################################</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">IteratorInitializerHook</span>(tf.train.SessionRunHook):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Hook to initialise data iterator after Session is created.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(IteratorInitializerHook, self).__init__()</span><br><span class="line">        self.iterator_initializer_func = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">after_create_session</span>(<span class="params">self, session, coord</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Initialise the iterator after the session has been created.&quot;&quot;&quot;</span></span><br><span class="line">        self.iterator_initializer_func(session)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define the training inputs</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_train_inputs</span>(<span class="params">batch_size, mnist_data</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Return the input function to get the training data.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        batch_size (int): Batch size of training iterator that is returned</span></span><br><span class="line"><span class="string">                          by the input function.</span></span><br><span class="line"><span class="string">        mnist_data (Object): Object holding the loaded mnist data.</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        (Input function, IteratorInitializerHook):</span></span><br><span class="line"><span class="string">            - Function that returns (features, labels) when called.</span></span><br><span class="line"><span class="string">            - Hook to initialise input iterator.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    iterator_initializer_hook = IteratorInitializerHook()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train_inputs</span>():</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Returns training set as Operations.</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            (features, labels) Operations that iterate over the dataset</span></span><br><span class="line"><span class="string">            on every evaluation</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">&#x27;Training_data&#x27;</span>):</span><br><span class="line">            <span class="comment"># Get Mnist data</span></span><br><span class="line">            images = mnist_data.train.images.reshape([-<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>])</span><br><span class="line">            labels = mnist_data.train.labels</span><br><span class="line">            <span class="comment"># Define placeholders</span></span><br><span class="line">            images_placeholder = tf.placeholder(</span><br><span class="line">                images.dtype, images.shape)</span><br><span class="line">            labels_placeholder = tf.placeholder(</span><br><span class="line">                labels.dtype, labels.shape)</span><br><span class="line">            <span class="comment"># Build dataset iterator</span></span><br><span class="line">            dataset = tf.contrib.data.Dataset.from_tensor_slices(</span><br><span class="line">                (images_placeholder, labels_placeholder))</span><br><span class="line">            dataset = dataset.repeat(<span class="literal">None</span>)  <span class="comment"># Infinite iterations</span></span><br><span class="line">            dataset = dataset.shuffle(buffer_size=<span class="number">10000</span>)</span><br><span class="line">            dataset = dataset.batch(batch_size)</span><br><span class="line">            iterator = dataset.make_initializable_iterator()</span><br><span class="line">            next_example, next_label = iterator.get_next()</span><br><span class="line">            <span class="comment"># Set runhook to initialize iterator</span></span><br><span class="line">            iterator_initializer_hook.iterator_initializer_func = \</span><br><span class="line">                <span class="keyword">lambda</span> sess: sess.run(</span><br><span class="line">                    iterator.initializer,</span><br><span class="line">                    feed_dict=&#123;images_placeholder: images,</span><br><span class="line">                               labels_placeholder: labels&#125;)</span><br><span class="line">            <span class="comment"># Return batched (features, labels)</span></span><br><span class="line">            <span class="keyword">return</span> next_example, next_label</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Return function and hook</span></span><br><span class="line">    <span class="keyword">return</span> train_inputs, iterator_initializer_hook</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_test_inputs</span>(<span class="params">batch_size, mnist_data</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Return the input function to get the test data.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        batch_size (int): Batch size of training iterator that is returned</span></span><br><span class="line"><span class="string">                          by the input function.</span></span><br><span class="line"><span class="string">        mnist_data (Object): Object holding the loaded mnist data.</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        (Input function, IteratorInitializerHook):</span></span><br><span class="line"><span class="string">            - Function that returns (features, labels) when called.</span></span><br><span class="line"><span class="string">            - Hook to initialise input iterator.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    iterator_initializer_hook = IteratorInitializerHook()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_inputs</span>():</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Returns training set as Operations.</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            (features, labels) Operations that iterate over the dataset</span></span><br><span class="line"><span class="string">            on every evaluation</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">&#x27;Test_data&#x27;</span>):</span><br><span class="line">            <span class="comment"># Get Mnist data</span></span><br><span class="line">            images = mnist_data.test.images.reshape([-<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>])</span><br><span class="line">            labels = mnist_data.test.labels</span><br><span class="line">            <span class="comment"># Define placeholders</span></span><br><span class="line">            images_placeholder = tf.placeholder(</span><br><span class="line">                images.dtype, images.shape)</span><br><span class="line">            labels_placeholder = tf.placeholder(</span><br><span class="line">                labels.dtype, labels.shape)</span><br><span class="line">            <span class="comment"># Build dataset iterator</span></span><br><span class="line">            dataset = tf.contrib.data.Dataset.from_tensor_slices(</span><br><span class="line">                (images_placeholder, labels_placeholder))</span><br><span class="line">            dataset = dataset.batch(batch_size)</span><br><span class="line">            iterator = dataset.make_initializable_iterator()</span><br><span class="line">            next_example, next_label = iterator.get_next()</span><br><span class="line">            <span class="comment"># Set runhook to initialize iterator</span></span><br><span class="line">            iterator_initializer_hook.iterator_initializer_func = \</span><br><span class="line">                <span class="keyword">lambda</span> sess: sess.run(</span><br><span class="line">                    iterator.initializer,</span><br><span class="line">                    feed_dict=&#123;images_placeholder: images,</span><br><span class="line">                               labels_placeholder: labels&#125;)</span><br><span class="line">            <span class="keyword">return</span> next_example, next_label</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Return function and hook</span></span><br><span class="line">    <span class="keyword">return</span> test_inputs, iterator_initializer_hook</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Run script ##############################################</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    tf.app.run(</span><br><span class="line">        main=run_experiment</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>machine-learning</tag>
        <tag>deep-learning</tag>
        <tag>tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title>新浪微博图床失效应对方法</title>
    <url>/2022/11/18/sina-img-recover/</url>
    <content><![CDATA[<p>浏览之前的笔记时发现Markdown中所有上传至新浪图床上的内容都无法显示了，说实话还是很急的，毕竟内容比较多。首先明确一点，虽然你无法访问这些图了，但它们还在新浪服务器上，只是需要换一个口进去。</p>
然后在网上转了一圈，有不少人提这是因为防盗链问题之类，加
<meta name="referrer" content="no-referrer">
<p>保平安。但问题是我是Markdown，加这个根本无从谈起。网上一些迁移脚本试了一下也并没有效果，因为下载不下来就是下载不下来嘛。</p>
<span id="more"></span>
<p>最后在<a href="https://www.31du.cn/blog/sinaimgurl.html">这里</a>发现了答案：</p>
<blockquote>
<p>因为<strong>wx1/2/3/4</strong>、<strong>ww1/2/3/4</strong> 与 <strong>ws1/2/3/4</strong> 为前缀的节点目前都被限制了，而 <strong>tva1/2/3/4</strong> 为前缀的节点目前仍可顺利打开。那么<strong>只要把网址前缀中的 wx、ww 与 ws 都改成 tva 系列应该就可以暂时继续使用微博图床的外链图片了</strong>。</p>
</blockquote>
<p>如果在Typora里，只需要正则匹配一下<code>ws\d</code>替换为<code>tva1</code>即可，然后在<code>格式-图像-移动所有图片到...</code>选项中将这些图片全部拉到本地即可。如果需要批量处理，可以参考这个<a href="https://github.com/wangshub/markdown-img-backup">脚本</a>，但需要修改一下，把上述替换加进代码中去。</p>
]]></content>
      <tags>
        <tag>web</tag>
        <tag>tech</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenCV与Qt不兼容问题</title>
    <url>/2022/11/22/opencv-qt-comp/</url>
    <content><![CDATA[<p>今天测试WSL2时，发现OpenCV弹窗显示图片一直会报错，所以就试着解决了一下。</p>
<p>报的错是：<code>QObject::moveToThread:&lt;XXXX&gt; Current thread is not the object's thread &lt;XXXX&gt;</code>，且是一大堆错连着。</p>
<span id="more"></span>
<p>Google了一会儿，发现很多人指出是安装的qtpy和OpenCV存在兼容性问题，只要将OpenCV Downgrade一下就好了。具体的命令是：</p>
<p><code>pip install opencv-python==4.1.2.30</code></p>
<p>这个版本是确认可用的，你也可以试试其附近的版本。</p>
<p>我用的测试代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> qtpy</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(cv2.__version__)</span><br><span class="line"><span class="built_in">print</span>(qtpy.__version__)</span><br><span class="line">img=cv2.imread(<span class="string">&#x27;~/workdir/output.png&#x27;</span>)</span><br><span class="line">cv2.imshow(<span class="string">&#x27;test&#x27;</span>, img)</span><br><span class="line">cv2.waitKey(<span class="number">1</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p>如果跑完不报错，问题就解决了。</p>
]]></content>
      <tags>
        <tag>python</tag>
        <tag>opencv</tag>
        <tag>qt</tag>
      </tags>
  </entry>
  <entry>
    <title>SLURM集群中多次登录时保存的Tmux Session不见/消失/时隐时现/随机出现的问题</title>
    <url>/2022/11/17/slurm-tmux/</url>
    <content><![CDATA[<p>先说结论，不少Slurm集群使用了两到多个login node来缓解入口机器的压力，均衡负载。这些node每个实际上都可以被看做是一个独立的服务器，只是共享了文件系统和其他一些服务。而Tmux是依赖于node，即这里是login node的。如果换了node，自然也就找不到你之前detach后存档的tmux窗口了。</p>
<span id="more"></span>
<p>不幸的是，你能登录到哪个node不说是完全随机的，但是由系统根据负载动态分配的，所以说到底你并无法控制你ssh到cluster后被自动分配到了哪个主机。当然，你可以通过<code>hostname -s</code>或<code>cat /etc/hostname</code>来获知你当前的主机名，以判断你之前save的tmux session是不是在相同的node上。</p>
<p>至于解决方案，有三种：</p>
<ol type="1">
<li><p>如果你的SLURM集群支持集群内部node相互ssh，那问题就好办了，直接ssh过去就好了。例如，如果你已知自己的tmux session建立在<code>login2</code> node上，而经过上一步的check hostname，你得知当前的主机名称是<code>login1</code>，那解决方案就简单直接了：<code>ssh login2</code>或<code>ssh -Y login2</code>. 来源：<a href="https://docs.ycrc.yale.edu/clusters-at-yale/guides/tmux/">Link</a></p>
<blockquote>
<p>注意：如果你登录server时候用的是pub和private key file认证，那么很有可能你无法直接在多个login node中跳转。若想做到这点，需要你将自己的private key上传到server，并使用<code>ssh -i &lt;your/id_rsa.pub&gt; loginN</code> 命令登录。</p>
</blockquote></li>
<li><p>如果很遗憾，由于安全设定原因，你无法在cluster内从一个node ssh到另一个，那其实解决方案就比较脏了，建议多次登录，开多个tab登录，使用多个可能的机器登录，挑选被分配到<code>login2</code> node的那个session使用吧。据我的经验来看，如果一个机器登不上<code>login2</code>，比起在同一个机器上继续尝试，使用另一台机器试试成功概率更大。当然这也许有点玄学成分了。</p></li>
<li><p>参考这篇文章，他们的大致做法是每次启动tmux时写一个文件保存当前login node，然后你本地登录的时候对此进行解析，如果不在一个node上就重新来。但看下来他们需要不同的login node有一个专属的名字，可以直接ssh到特定login node。<a href="https://sumner.verhaaklab.com/slurm/how_to_interactive_via_tmux/">Webpage Link</a>，以及<a href="https://github.com/TheJacksonLaboratory/sumnerdocs/tree/master/docs/confs/bin">GitHub Link</a>。</p></li>
</ol>
<p>小Tips：如果可能，把tmux放login1上，一般负载没那么高的时候经验来看更倾向于被分配到第一个login node。</p>
]]></content>
      <tags>
        <tag>linux</tag>
        <tag>server</tag>
        <tag>slurm</tag>
      </tags>
  </entry>
  <entry>
    <title>WSL的克隆，WSL1与WSL2的克隆共存</title>
    <url>/2022/11/24/wsl-clone/</url>
    <content><![CDATA[<p><strong>前言</strong>：WSL1和WSL2各有各的特点。WSL2支持GPU和外接USB硬件设备访问，效率也更高；但一旦涉及到Windows内部的文件系统访问，那只能说是慢的不能行，尤其是运行涉及到大量文件操作的脚本时。但是我用WSL很久了，也有了不少个性化设置，安装了很多Library。如果重头再来一遍，耗时耗力且可能某些内容与之前的环境不兼容。于是想法来了：能不能直接把已有的WSL克隆一份，并升级为WSL2，或者相反？</p>
<span id="more"></span>
<h2 id="具体操作">具体操作</h2>
<ol type="1">
<li><p>导出已有的WSL Distribution到一个tar压缩包。</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">wsl <span class="literal">--export</span> &lt;distribution name&gt; &lt;export file name&gt;</span><br></pre></td></tr></table></figure>
<p>例如如果你安装的是Ubuntu，想把它导出到当前目录，文件名为<code>ubuntu.tar</code>，则：</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">wsl <span class="literal">--export</span> Ubuntu ubuntu.tar</span><br></pre></td></tr></table></figure></li>
<li><p>导出之后，自然就是导入了。选好导入后的压缩包准备解压的位置，然后：</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">wsl <span class="literal">--import</span> &lt;new distribution name&gt; &lt;install location&gt; &lt;export file name&gt;</span><br></pre></td></tr></table></figure>
<p>如果你想给新的系统命名为<code>Ubuntu-WSL2</code>,新WSL位置放<code>.\Ubuntu-WSL2</code>，则：</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">wsl <span class="literal">--import</span> Ubuntu<span class="literal">-WSL2</span> .\Ubuntu<span class="literal">-WSL2</span> ubuntu.tar</span><br></pre></td></tr></table></figure>
<p>值得一提的是，如果你想把新的克隆版也装到类似原本WSL的安装位置，这个位置在：</p>
<p><code>**%USERPROFILE%\AppData\Local\Packages\&lt;distribution package name&gt;\LocalState\ext4.vhdx**</code></p>
<p>以Ubuntu为例，这个目录是：<code>%USERPROFILE%\AppData\Local\Packages\CanonicalGroupLimited.UbuntuonWindows_79rhkp1fndgsc\LocalState\ext4.vhdx</code></p></li>
<li><p>导入完之后，必须要先运行一次，以把新的系统写入Windows Terminal的配置文件中。</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">wsl <span class="literal">-d</span> &lt;new distribution name&gt;</span><br></pre></td></tr></table></figure>
<p>如：</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">wsl <span class="literal">-d</span> Ubuntu<span class="literal">-WSL2</span></span><br></pre></td></tr></table></figure>
<p><img data-src="image-20221124151115574.png" alt="image-20221124151115574" style="zoom:50%;"></p>
<p>我这里是把WSL2作为Main，克隆后输出的WSL1，所以图示如上。</p></li>
<li><p>如果你的目的只是单纯的克隆一下WSL，那到第三步其实已经完成了。但如果你还想更改WSL版本，那么：</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">wsl <span class="literal">--set-version</span> &lt;new distribution name&gt; <span class="number">2</span></span><br></pre></td></tr></table></figure>
<p>这里的<code>2</code>代表WSL2，如果你原本的WSL是WSL2，希望把克隆后的WSL版本降至<code>1</code>，那么把这里的<code>2</code>替换为<code>1</code>即可。如：</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">wsl <span class="literal">--set-version</span> Ubuntu<span class="literal">-WSL1</span> <span class="number">1</span></span><br></pre></td></tr></table></figure></li>
<li><p>此时你会注意到，虽然登录进去了，但是你的user是root，不再是之前你自己的用户名。当然这个不需要慌，很容易就改了。</p>
<p>只需要在<code>/etc/wsl.conf</code>文件中加上这样两行即可：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[user]</span><br><span class="line">default=&lt;YOUR_PREVIOUS_USERNAME&gt;</span><br></pre></td></tr></table></figure>
<p>如果没有这个文件，创建一个该文件即可。</p>
<p>做完这步之后，你需要彻底关闭该WSL，重新进入后生效。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wsl --terminate Ubuntu-WSL1</span><br></pre></td></tr></table></figure>
<p>另外，如果你不想要更改默认用户，但想要某次以该用户进入WSL，可以使用以下命令：</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">wsl <span class="literal">-d</span> Ubuntu<span class="literal">-WSL1</span> <span class="literal">-u</span> &lt;YOUR_PREVIOUS_USERNAME&gt;</span><br></pre></td></tr></table></figure></li>
<li><p>最后，如果你想查看确认当前安装的所有WSL系统版本：</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">wsl <span class="literal">-l</span> <span class="literal">-v</span></span><br></pre></td></tr></table></figure>
<p>有类似如下这两项说明已经成功：</p>
<p><img data-src="image-20221124152610692.png" alt="image-20221124152610692" style="zoom:50%;"></p></li>
</ol>
<h2 id="reference">Reference</h2>
<ul>
<li><a href="https://endjin.com/blog/2021/11/setting-up-multiple-wsl-distribution-instances">Setting up multiple WSL distribution instances</a></li>
</ul>
]]></content>
      <tags>
        <tag>tech</tag>
        <tag>wsl</tag>
      </tags>
  </entry>
  <entry>
    <title>GNN-based Human Pose Estimation (HPE) 论文总结</title>
    <url>/2023/02/19/gnn-hpe/</url>
    <content><![CDATA[<h2 id="dgcn-dynamic-graph-convolutional-network-for-efficient-multi-person-pose-estimation"><a class="markdownIt-Anchor" href="#dgcn-dynamic-graph-convolutional-network-for-efficient-multi-person-pose-estimation"></a> DGCN: Dynamic Graph Convolutional Network for Efficient Multi-Person Pose Estimation</h2>
<img data-src="image-20221219151203243.png" alt="image-20221219151203243" style="zoom:50%;">
<img data-src="image-20221219154249782.png" alt="image-20221219154249782" style="zoom:50%;">
<h3 id="summary"><a class="markdownIt-Anchor" href="#summary"></a> Summary</h3>
<ul>
<li>Multi-person.</li>
<li>Image-based. Graph is just used in their DGCM module.</li>
<li>Bottom-Up.</li>
</ul>
<span id="more"></span>
<ul>
<li>
<p>Basic Hypothesis:</p>
<blockquote>
<p>Existing bottom-up methods mainly define relations by empirically picking out edges from this graph, while omitting edges that may contain useful semantic relations.</p>
</blockquote>
<p>But actually OpenPose is using the similar idea: “Redundant PAF connections”. The difference is that OpenPose redundant connections are still empirical, while in this paper, they take into account all possible connections between two arbitrary joints, instead of limited amount.</p>
</li>
<li>
<p>Core idea: 本文是一篇基于RGB图片的Bottom-up 2D HPE文章。文中Graph是作为其核心模块DGCM的一部分出现的，且并没有使用GNN。这里的Graph是用来建模joints之间关系的，即摆脱了传统的基于经验的骨骼链接，也不是单纯的基于dataset计算的软性链接，而是将软性链接的值当做伯努利分布中的概率来用，每次随机筛出来几个可能的邻接矩阵来用。本文中所谓Graph的使用其实完全可以被transformer代替，本质上是在建模关节点之间的关联性。</p>
</li>
<li>
<p>Graph:</p>
<ul>
<li>Node: Human Joints。</li>
<li>Node Value: 无。</li>
<li>Edge: Joints间的全连接。</li>
<li>Edge Value: 两个joints之间的相关性。</li>
<li>Output: 一个joints间的邻接矩阵。</li>
<li>Usage: 用于生成带有随机性的、基于soft adjacency matrix的人类关节点关联矩阵。</li>
</ul>
</li>
</ul>
<h3 id="points"><a class="markdownIt-Anchor" href="#points"></a> Points</h3>
<ul>
<li>
<blockquote>
<p>Bottom-up pose estimation methods try to learn two kinds of heatmaps from the deep neural network, including keypoint heatmaps and relation heatmaps.</p>
</blockquote>
</li>
<li>
<p>Soft Adjacency Matrix:</p>
<ul>
<li>基于全部训练集中任意两个joints之间的距离（normalized by scale factor s）的倒数构建软邻接矩阵。</li>
<li>由于任意一个点到期自身的距离是0，相应的邻接矩阵值设为1。</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>A</mi><mi>s</mi><mrow><mi>i</mi><mi>j</mi></mrow></msubsup><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><mi>γ</mi><mfrac><mn>1</mn><msubsup><mi>M</mi><mi>d</mi><mrow><mi>i</mi><mi>j</mi></mrow></msubsup></mfrac><mo stretchy="false">)</mo><mo separator="true">,</mo><msubsup><mi>A</mi><mi>s</mi><mrow><mi>i</mi><mi>i</mi></mrow></msubsup><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">A_{s}^{ij}=\sigma(\gamma\frac{1}{M_d^{ij}}), A_s^{ii}=1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.071664em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.5665079999999998em;vertical-align:-0.7213999999999998em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.52166em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9547714285714286em;"><span style="top:-2.1527714285714286em;margin-left:-0.10903em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">d</span></span></span><span style="top:-2.9836857142857145em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3472285714285714em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7213999999999998em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">s</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>。</li>
</ul>
</li>
<li>
<p>Dynamic Adjacency Matrix：</p>
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>A</mi><mi>d</mi><mrow><mi>i</mi><mi>j</mi></mrow></msubsup><mo>∼</mo><mi>B</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><msubsup><mi>A</mi><mi>s</mi><mrow><mi>i</mi><mi>j</mi></mrow></msubsup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">A_d^{ij}\sim B(x,A_s^{ij})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2438799999999999em;vertical-align:-0.3013079999999999em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.942572em;"><span style="top:-2.3986920000000005em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span><span style="top:-3.1809080000000005em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3013079999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0746639999999998em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">s</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>，x是数量，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>A</mi><mi>s</mi><mrow><mi>i</mi><mi>j</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">A_s^{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.071664em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">s</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span>是概率，B是伯努利分布。</li>
<li>这里的伯努利分布（01分布）实质上就是把软邻接矩阵的值变成了概率。A^(i,j)值越大，概率越大，取1的可能性越大。就这样筛选几次，得到几个可能的邻接矩阵。</li>
</ul>
</li>
<li>
<p>文中使用了金字塔式多尺度feature map，理由是人的大小远近不一样，多尺度的feature更有适应性。</p>
</li>
<li>
<p>由于邻接矩阵里面每个joint和它自己的relation-term永远是1，就相当于加了一个skip connection一样，不用担心每个joint只被其邻居决定。</p>
</li>
<li>
<p>除了这里提到的动态邻接矩阵，还有一个learnable <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mo>×</mo><mi>K</mi></mrow><annotation encoding="application/x-tex">K\times K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span>的weights，共同起作用。</p>
</li>
</ul>
<h2 id="learning-dynamics-via-graph-neural-networks-for-human-pose-estimation-and-tracking"><a class="markdownIt-Anchor" href="#learning-dynamics-via-graph-neural-networks-for-human-pose-estimation-and-tracking"></a> Learning Dynamics via Graph Neural Networks for Human Pose Estimation and Tracking</h2>
<img data-src="image-20221219160516007.png" alt="image-20221219160516007" style="zoom:50%;">
<h3 id="summary-2"><a class="markdownIt-Anchor" href="#summary-2"></a> Summary</h3>
<ul>
<li>
<p>Multi-person 2D HPE.</p>
</li>
<li>
<p>Top-Down.</p>
</li>
<li>
<p>Frame-based.</p>
</li>
<li>
<p>Pipeline:</p>
<ul>
<li>Current Frame 2D HRNet Branch: Crop Human -&gt; Rescale -&gt; HRNet -&gt; HeatMap-F -&gt; Argmax -&gt; Joints-F</li>
<li>Historical tracklets GNN Branch: Build Joints based on (Tracklets’ (0~t-1) joints’ + current frames’ all pixels’)(Visual Features, Joint Locations, Joint Type) -&gt; Connect edges in time and space -&gt; GNN -&gt; HeatMap-G -&gt; Joints-G</li>
<li>Merging: Hungarian(Joints-F, Joints-G) -&gt; If no matching, new ID, output Joints-G; If matched, output argmax(HeatMap-F, HeatMap-G)</li>
</ul>
</li>
<li>
<p>本文是一个Tow-Down的、基于帧序列（视频）的、2D Multi-Human HPE+Human Tracking的工作。它先用传统的剪裁预测方式预测每帧的所有可能人的可能joints，然后再将每帧每人的每个joint都通过MLP转换为一个个node的feature map，连接这些node，过一个GNN，最后得到最终预测。</p>
</li>
<li>
<p>Graph：</p>
<ul>
<li>Node: 已经被追踪的人的<strong>所有历史joints</strong>(FIFO内的)及当前Frame的<strong>所有像素</strong>。</li>
<li>Node Value: 一个基于HRNet输出feature、2D相对位置、joint类型softmax的综合feature map，综合方式是分别过MLP后average。</li>
<li>Edge: 帧内和帧间分别全连接。</li>
<li>Edge Value: 无。</li>
<li>Output: 对于每个此前追踪过的人，输出对其每个关节点在当前帧位置的预测。由于当前帧全图像素都是nodes，所以对于每种joint type，其实输出的相当于一个HeatMap。</li>
<li>Usage: 通过分析过往最终过的人的历史joints location，以及当前帧的visual feature，预测这些人的每个joint在当前帧的位置。</li>
</ul>
</li>
</ul>
<h3 id="question"><a class="markdownIt-Anchor" href="#question"></a> Question</h3>
<ul>
<li>
<p>怎么做的tracking？</p>
<ul>
<li>又是匈牙利算法。GNN基于tracklets预测的结果和基于当前帧HRNet预测出来的结果进行matching。其中使用的相似度是基于关键点的位置计算出来的。</li>
</ul>
</li>
<li>
<p>GNN 基于tracklets历史预测的poses和当前帧通过HRNet预测的Pose是如何结合（Aggregate and Merge）的？</p>
<ul>
<li>先匹配，匹配上的就对heatmap做平均然后argmax。</li>
<li>没匹配上的就给一个新ID，直接argmax。</li>
<li>对匹配上的人，如果FIFO已经满了，就踢一个加新的；反之直接加了。</li>
</ul>
<blockquote>
<p>For all the matched poses, the joint heatmaps of the two poses are first aligned according to their centers and then merged together by averaging the heatmaps.</p>
</blockquote>
</li>
<li>
<p>GNN的edge怎么定义的？</p>
<ul>
<li>Edge有两种，一种是同一帧中joints之间的链接，一种是每个joint与上一帧中所有joints的联系（包括当前帧的nodes）。</li>
<li>没有具体说edge的值（attr），应该是没有用。</li>
</ul>
</li>
</ul>
<h3 id="points-2"><a class="markdownIt-Anchor" href="#points-2"></a> Points</h3>
<ul>
<li>
<p>每个tracklet都是一个unique的被记录在案的人。</p>
</li>
<li>
<p>对于每个tracklet，都会分别被过一遍一个GNN进行预测。注意，GNN这里也可以理解做是Top-Down的，对于每个历史上记录在案的人，都分别过一遍GNN预测在当前帧这个人每个关节点的位置。</p>
</li>
<li>
<p>GNN的nodes包含某个历史tracklets（追踪的关键点）中的所有joints以及当前帧的所有像素点。</p>
</li>
<li>
<p>当前帧*(t)<em>的每个像素组成的node都与tracklets FIFO中最后一帧</em>(t-1)*的检测结果中的每个joint相连。</p>
<img data-src="image-20221220121801045.png" alt="image-20221220121801045" style="zoom:50%;">
</li>
<li>
<p>之所以要对Visual Features (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">v_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>), Joint Locations(<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">p_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>), Joint Type(<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>c</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">c_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>)向量分别做MLP，是因为它们的维度不同，且node的channel不能有多维。</p>
</li>
<li>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>J</mi><mi>k</mi></msub><mo>=</mo><mi>P</mi><mi>o</mi><mi>o</mi><mi>l</mi><mi>i</mi><mi>n</mi><mi>g</mi><mo stretchy="false">(</mo><mi>M</mi><mi>L</mi><msub><mi>P</mi><mrow><mi>v</mi><mi>i</mi><mi>s</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>v</mi><mi>k</mi></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>M</mi><mi>L</mi><msub><mi>P</mi><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>p</mi><mi>k</mi></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>M</mi><mi>L</mi><msub><mi>P</mi><mrow><mi>t</mi><mi>y</mi><mi>p</mi><mi>e</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>c</mi><mi>k</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">J_k=Pooling(MLP_{vis}(v_k), MLP_{pos}(p_k), MLP_{type}(c_k))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.09618em;">J</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.09618em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal">o</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal">L</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal">L</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal">L</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.28055599999999997em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span></span></span></span> 为每个node的值。这里的pooling是average pooling。</p>
</li>
<li>
<p>对于<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">p_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>而言，全部帧的这个location都以FIFO中最后一帧*(t-1)*中人物中心点为基准进行normalization，当前帧这些nodes也不例外。</p>
</li>
<li>
<p>注意，当前帧*(t)*全像素组成的这些nodes里面，在算<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>J</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">J_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.09618em;">J</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.09618em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>时候不加<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>c</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">c_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>分支，即不用joint type，因为joint type是要predict的东西。</p>
</li>
<li>
<p>最终预测出来的东西是一个Prob，它包含了当前帧t所有像素点可能为某个joint type的概率（classification）。</p>
</li>
<li>
<p>对于每个tracklets，都有一个FIFO队列保存K个过去位置。</p>
</li>
</ul>
<h3 id="comments"><a class="markdownIt-Anchor" href="#comments"></a> Comments</h3>
<ul>
<li>非常新颖的使用GNN的方法。用多个方面的features分别过MLP通过average pooling的方法作为node的值，既可以确保这些feature的维度不match不成问题，也可以有效降低channel number，降低cost。最重要的是，对于某些node，你甚至可以移除某些features而不影响整体维度，比如对当前frame像素nodes不添加不存在的类别features。</li>
<li>同时也非常暴力，直接在帧内、帧间分别用全连接，且当前frame直接把全部像素点位置都变成node，这是一个巨大的开销，并不优雅，也不符合GNN的内含逻辑。</li>
<li>位置norm方法值得学习。</li>
<li>我们的项目可能也可以用上匈牙利匹配，但是匹配的是时间上的cluster，而匹配的变量可能是cluster的平均方向向量等。</li>
</ul>
<h2 id="context-modeling-in-3d-human-pose-estimation-a-unified-perspective"><a class="markdownIt-Anchor" href="#context-modeling-in-3d-human-pose-estimation-a-unified-perspective"></a> Context Modeling in 3D Human Pose Estimation: A Unified Perspective</h2>
<p><img data-src="image-20221221105021381.png" alt="image-20221221105021381"></p>
<h3 id="summary-3"><a class="markdownIt-Anchor" href="#summary-3"></a> Summary</h3>
<ul>
<li>Single image-based.</li>
<li>2D -&gt; 3D lifting.</li>
<li>Top-Down.</li>
<li>核心操作是一套Attention。首先他们预测出2D Pose，然后将这些Pose投影到3D空间，再用一套Encoder-Decoder网络来预测3D Heatmap。具体来说，每个voxel预测J个值，代表它是某个joint的可能性。而其中关键的Attention部分分为两部分，全局Attention和关节对Attention。前者预测某个voxel <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span></span></span></span> 含某个joint <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>u</mi></mrow><annotation encoding="application/x-tex">u</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">u</span></span></span></span>的概率，后者预测当另一个voxel <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> 包含joint <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi></mrow><annotation encoding="application/x-tex">v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span></span> 时，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>u</mi><mo separator="true">,</mo><mi>v</mi></mrow><annotation encoding="application/x-tex">u,v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">u</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span></span> 间的关联性。这个关联性来自于训练集上的prior，主要成分是所有物理（经验）肢体连接的距离平均值和标准差，这个关联性高时说明 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>u</mi><mo separator="true">,</mo><mi>v</mi></mrow><annotation encoding="application/x-tex">u,v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">u</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span></span> 在当前voxel <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo separator="true">,</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">q, k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> 中时大概率符合prior中的预测，反之说明这对joints连接的肢体可能过长/短了，所以当前分布可能性很小。</li>
<li>Graph:
<ul>
<li>Node: 所有的voxels。</li>
<li>Node Value: 来自于2D坐标投影的features。</li>
<li>Edge: Voxel间的连接。</li>
<li>Edge Value: Voxel间的关联性（Pairiwise-Attention）。</li>
<li>Output: 每个3D voxel包含某个joint的概率。</li>
<li>Usage: 用于从2D预测升维到3D。</li>
<li>Note: 这里所谓的GNN其实就是ContextPose (Attentions)的一种特例。</li>
</ul>
</li>
</ul>
<h3 id="points-3"><a class="markdownIt-Anchor" href="#points-3"></a> Points</h3>
<ul>
<li>Pairwise-Attention（关节对Attention）的公式是：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>q</mi><mo separator="true">,</mo><mi>k</mi><mo separator="true">,</mo><msub><mi>e</mi><mrow><mi>u</mi><mo separator="true">,</mo><mi>v</mi></mrow></msub><mo stretchy="false">)</mo><mo>∝</mo><mi>e</mi><mi>x</mi><mi>p</mi><mo stretchy="false">(</mo><mo>−</mo><mfrac><mrow><mo stretchy="false">(</mo><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mi>q</mi><mo>−</mo><mi>k</mi><mi mathvariant="normal">∣</mi><msub><mi mathvariant="normal">∣</mi><mn>2</mn></msub><mo>−</mo><msub><mi>μ</mi><mrow><mi>u</mi><mo separator="true">,</mo><mi>v</mi></mrow></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><mrow><mn>2</mn><mi>α</mi><msubsup><mi>σ</mi><mrow><mi>u</mi><mo separator="true">,</mo><mi>v</mi></mrow><mn>2</mn></msubsup><mo>+</mo><mi>ϵ</mi></mrow></mfrac><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(q,k,e_{u,v}) \propto exp(-\frac{(||q-k||_2-\mu_{u,v})^2}{2\alpha\sigma^2_{u,v}+\epsilon})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">u</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∝</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.77366em;vertical-align:-0.64242em;"></span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord">−</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.13124em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mathnormal mtight" style="margin-right:0.0037em;">α</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7463142857142857em;"><span style="top:-2.214em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">u</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.42488571428571426em;"><span></span></span></span></span></span></span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">ϵ</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.50732em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">∣</span><span class="mord mtight">∣</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mord mtight">∣</span><span class="mord mtight"><span class="mord mtight">∣</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mord mathnormal mtight">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285716em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">u</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2818857142857143em;"><span></span></span></span></span></span></span><span class="mclose mtight"><span class="mclose mtight">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913142857142857em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.64242em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span></span></span></li>
<li>PA被normalized了，具体公式是：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">Σ</mi><mrow><mi>k</mi><mo>∈</mo><mi mathvariant="normal">Ω</mi></mrow></msub><msub><mi>G</mi><mi>v</mi></msub><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>v</mi><mo separator="true">,</mo><mi>k</mi></mrow></msub><mo stretchy="false">)</mo><mo>⋅</mo><mi>P</mi><mo stretchy="false">(</mo><mi>q</mi><mo separator="true">,</mo><mi>k</mi><mo separator="true">,</mo><msub><mi>e</mi><mrow><mi>u</mi><mo separator="true">,</mo><mi>v</mi></mrow></msub><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\Sigma_{k\in\Omega}G_v(x_{v,k}) \cdot P(q,k,e_{u,v})=1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord">Σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999985em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">∈</span><span class="mord mtight">Ω</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.17737em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">u</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>, 意味着如果voxel <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span></span></span></span> 包含关节 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>u</mi></mrow><annotation encoding="application/x-tex">u</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">u</span></span></span></span>，那么所有可能包含关节 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi></mrow><annotation encoding="application/x-tex">v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span></span> 的voxel <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> 它本身的概率乘以它满足 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>u</mi><mo separator="true">,</mo><mi>v</mi></mrow><annotation encoding="application/x-tex">u,v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">u</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span></span> 两个关节点物理距离prior的概率和为1。</li>
</ul>
<h2 id="optimizing-network-structure-for-3d-human-pose-estimation"><a class="markdownIt-Anchor" href="#optimizing-network-structure-for-3d-human-pose-estimation"></a> Optimizing Network Structure for 3D Human Pose Estimation</h2>
<p><img data-src="image-20221221122107913.png" alt="image-20221221122107913"></p>
<img data-src="image-20221221122050872.png" alt="image-20221221122050872" style="zoom:50%;">
<h3 id="summary-4"><a class="markdownIt-Anchor" href="#summary-4"></a> Summary</h3>
<ul>
<li>
<p>本文提出了一种统一模型，它可以将2D-&gt;3D Human Pose Lifting的诸多方法（FCN，GNN，LCN）写入一个统一公式中，并取得更优的效果。</p>
</li>
<li>
<p>相比于普通GCN，其特点在于：</p>
<ul>
<li>普通GCN对于所有的node，做Linear的时候都用的共享的weights。</li>
<li>而在LCN中，计算每个输入node对输出node的贡献时所用的weights，都分别训练，不共享参数。</li>
</ul>
<img data-src="image-20221221135856400.png" alt="image-20221221135856400" style="zoom:50%;">
</li>
<li>
<p>Graph:</p>
<ul>
<li>Node: J个人类Joints。</li>
<li>Node Value: 2D坐标的features。</li>
<li>Edge: Joints间的连接。</li>
<li>Edge Value: Joints间的关联性（邻接矩阵）。</li>
<li>Output: 每个Joint的3D坐标。</li>
<li>Usage: 用于从2D预测升维到3D。</li>
</ul>
</li>
</ul>
<h2 id="adaptive-hypergraph-neural-network-for-multi-person-pose-estimation"><a class="markdownIt-Anchor" href="#adaptive-hypergraph-neural-network-for-multi-person-pose-estimation"></a> Adaptive Hypergraph Neural Network for Multi-Person Pose Estimation</h2>
<p><img data-src="image-20221220191107517.png" alt="image-20221220191107517"></p>
<h3 id="summary-5"><a class="markdownIt-Anchor" href="#summary-5"></a> Summary</h3>
<ul>
<li>
<p>Image-based.</p>
</li>
<li>
<p>Multi-human 2D HPE.</p>
</li>
<li>
<p>Top-Down.</p>
</li>
<li>
<p>文中提出了一种“<strong>超边</strong>”(Hyperedge)，这种边不是物理的边，也不是非物理但连接两个顶点的边，而是连接了多个顶点、有着类似<strong>区分body part</strong>作用的“大边”。这种超边的分配由训练好的网络负责，生成的依据是图中的语义关系。比如如果人在拉伸右腿，那右手和右脚踝就会被分配到一个超边中，因为它们有着紧密的语义联系。</p>
<img data-src="image-20221220191125713.png" alt="image-20221220191125713" style="zoom:50%;">
</li>
<li>
<p>本文做的是Top-Down的单张图片2D多人HPE。其核心贡献在于提出了“超边”这种由图片语义得来、可连接两个到多个joints的广义边，从而可以更好地应对一些非典型动作的图片。</p>
</li>
<li>
<p>Graph:</p>
<ul>
<li>Node: Human Joints.</li>
<li>Node Value: d dimension feature.</li>
<li>Edge: m条，为hyperedges。</li>
<li>Edge Value: 每条超边链接的joints以及链接的紧密程度。</li>
<li>Output: 一个<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi><mo>×</mo><mi>m</mi></mrow><annotation encoding="application/x-tex">J\times m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.09618em;">J</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">m</span></span></span></span>的矩阵，m是超边的数量，J是关键点的数量。代表着联系的紧密程度。</li>
<li>Usage: 根据图片信息更好的建立人类关键点间的高维语义联系。</li>
</ul>
</li>
</ul>
<h3 id="questions"><a class="markdownIt-Anchor" href="#questions"></a> Questions</h3>
<ul>
<li>Adaptive hypergraph矩阵可以包含可变数量的边。这个是怎么处理的？</li>
<li>这个矩阵是如何训练的？输入是什么？</li>
</ul>
<h3 id="points-4"><a class="markdownIt-Anchor" href="#points-4"></a> Points</h3>
<ul>
<li>对于一层GCN而言，它的forward公式是<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>H</mi><mrow><mo stretchy="false">(</mo><mi>l</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msup><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><mover accent="true"><mi>A</mi><mo>~</mo></mover><msup><mi>H</mi><mrow><mo stretchy="false">(</mo><mi>l</mi><mo stretchy="false">)</mo></mrow></msup><msup><mi>W</mi><mrow><mo stretchy="false">(</mo><mi>W</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">H^{(l+1)}=\sigma (\tilde{A}H^{(l)}W^{(W+1)})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8879999999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1701899999999998em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9201899999999998em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">A</span></span></span><span style="top:-3.6023300000000003em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.11110999999999999em;"><span class="mord">~</span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">W</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>，这里的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>σ</mi></mrow><annotation encoding="application/x-tex">\sigma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span></span></span></span>代表激活函数，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>A</mi><mo>~</mo></mover></mrow><annotation encoding="application/x-tex">\tilde{A}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9201899999999998em;vertical-align:0em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9201899999999998em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">A</span></span></span><span style="top:-3.6023300000000003em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.11110999999999999em;"><span class="mord">~</span></span></span></span></span></span></span></span></span></span>代表被normalized邻接矩阵，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi></mrow><annotation encoding="application/x-tex">W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span></span></span></span>是这层GCN的parameter。<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi></mrow><annotation encoding="application/x-tex">H</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span></span></span></span>是feature map，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi></mrow><annotation encoding="application/x-tex">l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span></span></span></span>这里代表第<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi></mrow><annotation encoding="application/x-tex">l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span></span></span></span>层GCN。正常情况下，这个步骤整体都被打包进<code>pyg.GCN</code> module一起做了，但这里我们刚好有现成的邻接矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">A</span></span></span></span>，就不用专门再去构造graph，弄一个专门的<code>edge_index</code>矩阵了，因为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">A</span></span></span></span>就是了。</li>
</ul>
<h2 id="learning-skeletal-graph-neural-networks-for-hard-3d-pose-estimation"><a class="markdownIt-Anchor" href="#learning-skeletal-graph-neural-networks-for-hard-3d-pose-estimation"></a> Learning Skeletal Graph Neural Networks for Hard 3D Pose Estimation</h2>
<p><img data-src="image-20221221141417256.png" alt="image-20221221141417256"></p>
<h3 id="summary-6"><a class="markdownIt-Anchor" href="#summary-6"></a> Summary</h3>
<ul>
<li>
<p>本文提出了一种针对不同距离（hop）的nodes使用不同Aggregation层级的GCN，保证了不同距离的node得以被区分对待，降低远距离node带来的噪音。同时，它还结合了经验人类skeleton和动态可学习skeleton的优点，用同步的两个branch分别运算，进一步提升了基于video的2D-&gt;3D HPE Lifting的质量。</p>
</li>
<li>
<p>Graph:</p>
<ul>
<li>
<p>Node: J个人类Joints。</p>
</li>
<li>
<p>Node Value: 2D坐标的features。</p>
</li>
<li>
<p>Edge: Joints间的连接。分为两部分，一部分是物理连接，一部分是动态可学习的连接。</p>
</li>
<li>
<p>Edge Value: Joints间的关联性（邻接矩阵）。</p>
</li>
<li>
<p>Output: 每个Joint的3D坐标。</p>
</li>
<li>
<p>Usage: 用于从2D预测升维到3D。</p>
<blockquote>
<p>Given 2D keypoints <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>∈</mo><msup><mi>R</mi><mrow><mi>N</mi><mo>×</mo><mn>2</mn></mrow></msup></mrow><annotation encoding="application/x-tex">X ∈ R^{N\times 2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mbin mtight">×</span><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span>, with N nodes, the model outputs better 3D positions <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi><mo>∈</mo><msup><mi>R</mi><mrow><mi>N</mi><mo>×</mo><mn>3</mn></mrow></msup></mrow><annotation encoding="application/x-tex">Y ∈ R^{N\times 3}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mbin mtight">×</span><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span></span>.</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<h3 id="points-5"><a class="markdownIt-Anchor" href="#points-5"></a> Points</h3>
<ul>
<li>
<p>决定文中设计思路的几个重要观察：</p>
<ol>
<li>Joints Graph中距离遥远的node虽然有时也会提供有价值的信息，但也导入了许多不相干的噪音。</li>
<li>动态Joints Graph的构建很有效，但在不同的动作中joints间的关联性变化很大。所以虽然动态图在表征不同的动作时候很直观，如果只给定单张图，它也很容易受到outlier的影响。所以文中引入了TCN让信息在时间轴上流动。</li>
</ol>
</li>
<li>
<p>实际设计上，基本是一层D-HCSF一层TCN这样串联。</p>
<img data-src="image-20221221150901507.png" alt="image-20221221150901507" style="zoom:50%;">
</li>
<li>
<p>Zoom in，看HCSF层，他们的核心思想是对近程和远程的node区分对待，分不同的层级对待。对于离自己近的node，用类似skip connection的连接直连最后；而离得远的nodes则先分组aggregate几次后再连到主bus上。</p>
</li>
<li>
<p>Dynamic Hierarchical Channel-Squeezing Fusion (D-HCSF) 层的思想：结合了固定skeleton和动态学习skeleton的长处。蓝色是固定分支，橙色是动态。</p>
<img data-src="GNN-based HPE/image-20221221150056706.png" alt="image-20221221150056706" style="zoom:50%;">
</li>
</ul>
]]></content>
      <tags>
        <tag>machine-learning</tag>
        <tag>deep-learning</tag>
        <tag>paper</tag>
        <tag>CV</tag>
      </tags>
  </entry>
  <entry>
    <title>SMPL 完全攻略 -- 从定义到文章到部署</title>
    <url>/2023/01/21/smpl-all/</url>
    <content><![CDATA[<h2 id="overview">Overview</h2>
<ul>
<li>SMPL主要含有两组参数，一组是人物的体态信息β，一组是人物的姿态信息θ。</li>
<li>SMPL本身是“相对的”，其只包含人物本身的信息，而不包含任何与环境、相机视角、位置等信息。另外，其mesh点记录的值是相对于模板人类模型标准值的。</li>
<li>SMPL不包含手、脸和衣服，但后续的其他文章逐渐完善了相应参数。</li>
</ul>
<span id="more"></span>
<ul>
<li>SMPLX中的参数某种程度上包含了肌肉随动作（Pose）变化的信息。他们采用了铰链模型，并搭配PCA方法分析主要关联项，得到了当人体从静态到某个特定Pose时哪些肌肉会发生形变以及如何形变的信息，而其NB也主要NB在这里。有了这些关联模型，人体运动时重建的mesh就不是那种被奇怪地拉伸的mesh了，而是更加符合人体肌肉运动规律的mesh。</li>
<li>他们使用的训练数据是4维扫描，即<code>3D Mesh + Time</code>的扫描。他们也正是通过分析关节点和mesh随着时间的变化，才分析得到了Pose和Mesh变形之间的相关性。</li>
<li>在构建MONO/SMPL+H时，由于手非常复杂且容易被遮挡，另外在全身扫描时手部分辨率也很有限，所以他们特意为了手部额外采集了一个数据集，含有各种人物、姿态和遮挡。</li>
</ul>
<h2 id="名称辨析">名称辨析</h2>
<ul>
<li><code>SMPL</code>: A Skinned Multi-Person Linear Model。人体模型。</li>
<li><code>MONO</code>: A hand Model with Articulated and Non-rigid defOrmations。手部模型。</li>
<li><code>SMPL+H</code>: A fully articulated body and Hand model。手部模型+人体模型。</li>
<li><code>SMPL-X</code>: SMPL eXpressive，是一个含有姿态、表情、手部动作的人体模型。</li>
<li><code>SMPLify-X</code>：<code>SMPL-X</code>原文中提到的用于拟合SMPL-X模型的一种方法。具体操作是先预测2D Joints，再用Optimization的方法拟合3D模型使得投影与2D Joints尽可能重合。</li>
<li><code>SMPLify</code>：<code>SMPLify-X</code>的前辈。方法类似，但是效果和速度差一点。</li>
</ul>
<h2 id="d模型制作和运用中常用术语">3D模型制作和运用中常用术语</h2>
<p>该节摘自<a href="https://zhuanlan.zhihu.com/p/256358005">SMPL论文解读和相关基础知识介绍</a></p>
<blockquote>
<ul>
<li>顶点（vertex）：动画模型可以看成多个小三角形（四边形）组成，每个小三角形就可以看成一个顶点。顶点越多，动画模型越精细。</li>
<li>骨骼点：人体的一些关节点，类似于人体姿态估计的关键点。每个骨骼点都由一个三元组作为参数去控制（可以查看欧拉角，四元数相关概念）</li>
<li>骨骼蒙皮（Rig）：建立骨骼点和顶点的关联关系。每个骨骼点会关联许多顶点，并且每一个顶点权重不一样。通过这种关联关系，就可以通过控制骨骼点的旋转向量来控制整个人运动。</li>
<li>纹理贴图：动画人体模型的表面纹理，即衣服裤子这些。</li>
<li>BlendShape：控制动画角色运动有两种，一种是上面说的利用Rig，还有一种是利用BlendShape。比如：生成一种笑脸和正常脸，那么通过BlendShape就可以自动生成二者过渡的动画。这种方式相比于利用Rig，可以不定义骨骼点，比较方便。</li>
<li>蒙皮：将模型从一个姿态转变为另一个姿态，使用的转换矩阵叫做蒙皮矩阵。（Linear Blend Skinning算法）</li>
<li>顶点权重(vertex weights)：用于变形网格mesh</li>
<li>uv map：将3D多边形网格展开到2D平面得到 UV图像</li>
<li>texture map：将3D多边形网格表面的纹理展开到2D平面，得到纹理图像</li>
<li>拓扑(topology)：重新拓扑是将高分辨率模型转换为可用于动画的较小模型的过程。两个mesh拓扑结构相同是指两个mesh上面任一个三角面片的三个顶点的ID是一样的（如某一个三角面片三个顶点是2,5,8；另一个mesh上也必有一个2,5,8组成的三角面片）</li>
<li>linear blend skinning algorithm</li>
</ul>
<p>每个关节的数据结构包含：关节名字、骨骼中其父节点的索引、关节的绑定姿势之逆变换（蒙皮网格顶点绑定至骨骼时，关节的位置、定向及缩放）</p>
</blockquote>
<h2 id="三种类型的smpl文章应用">三种类型的SMPL文章/应用</h2>
<ol type="1">
<li>提出SMPL这种模型本身的定义的文章。这些文章使用大量不同动作的3D人体扫描构筑了一个平均人类模型（Male，Female，Neutral），且定义了当人物的形体和动作发生特定变化时表皮的相应变形方式。文中的“训练”指的是训练这些运动/形态参数与实际表皮形变的函数映射。</li>
<li>使用单张/多张不同角度照片来推理相应人物的SMPL模型位置。如SMPLify和SMPL-X。SMPLify-X（用于拟合SMPL-X模型的方法）的pipeline是：
<ol type="1">
<li>先自下而上用OpenPose预测人体2D关键点。</li>
<li>然后再结合各种Prior（身体姿态、手部姿态、身体形状、面部姿态、面部表情、极端弯曲）和各种Loss Punishment（2D与3D在平面投影的Loss，身体Parts互相穿透的Loss）去让3D的模型拟合这些关键点。</li>
<li>用了Optimization算法直接去拟合的3D模型参数，这个步骤没有使用深度学习。相反，使用的是Limited-memory BFGS optimizer (L-BFGS)的强化Wolfe line search（SMPL-X）、Chumpy+OpenDR（SMPLify）。</li>
</ol></li>
<li>端到端的深度学习文章。这些文章都是在SMPL-X发表之后涌现出来的。文章中不再使用Optimization-based methods，而是转而使用SMPLify-X来通过照片或多角度照片生成Ground Truth，制造完数据集后直接使用DL进行预测。</li>
</ol>
<h2 id="smpl">SMPL</h2>
<ul>
<li><p>SMPL一文与从图片/视频/XXXX预测人体形态没有任何关系，它的贡献单纯是提出了一个更好的人体模型，而这个模型可以很好地建模人的体态和姿势，同时肌肉/蒙皮形状会随着人的运动而相应变化，从而达到拟真的效果，而不会出现滑稽的拉伸形变。</p></li>
<li><p>SMPL提出的人体模型的输入是由两部分组成的：</p>
<ul>
<li>β：一个10维vector</li>
<li>θ：一个3(K+1)维vector，K是骨架节点数，这里是23。加的1是人体中心。</li>
</ul></li>
<li><p>SMPL的输出是N个顶点的坐标，维度为3N。N: 顶点数，6890。</p></li>
<li><p>SMPL人类模型是可微分的，也就是说，如果你有了人物的3D扫描，想用一个deep learning model来预测这个扫描，你可以直接输入图片/视频/XXXX，中间输出是<span class="math inline">\(\beta+\theta\)</span>，然后最终输出N个顶点的位置，而这N个顶点你是可以直接去和GT做L1 loss的，因为可微也就意味着可以auto backward。</p></li>
<li><p><span class="math inline">\(\beta\)</span>的十个参数物理意义：</p>
<blockquote>
<p>0 代表整个人体的胖瘦和大小，初始为0的情况下，正数变瘦小，负数变大胖（±5） 1 侧面压缩拉伸，正数压缩 2 正数变胖大 3 负数肚子变大很多，人体缩小 4 代表 chest、hip、abdomen的大小，初始为0的情况下，正数变大，负数变小（±5） 5 负数表示大肚子+整体变瘦 6 正数表示肚子变得特别大的情况下，其他部位非常瘦小 7 正数表示身体被纵向挤压 8 正数表示横向表胖 9 正数表示肩膀变宽</p>
</blockquote></li>
<li><p>论文核心图的解释：</p>
<figure>
<img data-src="image-20221118192351294.png" alt="image-20221118192351294"><figcaption aria-hidden="true">image-20221118192351294</figcaption>
</figure>
<ul>
<li>(a)是平均人体模型，男女各一个，后续的演算都是基于标准平均人体模型的</li>
<li>(b)是加入了人物体态参数的结果</li>
<li>(c)是加入了特定动作发生时肌肉/蒙皮变形补偿后的结果。注意此时只是对即将发生的动作进行补偿，但还没有真正apply动作。</li>
<li>(d)是实际让人物摆出了相应动作的结果</li>
</ul></li>
<li><p>再回到上图的一些重要符号表达，</p>
<ul>
<li><p><span class="math inline">\(\bar{T}\)</span>: 3N维vector，由N个串联的顶点表示的初始状态下的平均模型。这里的3并不是xyz 3D坐标，而是每个关节点相对于其父关节的轴角旋转量。这里的坐标以父节点为原点。</p>
<blockquote>
<p><span class="math inline">\(\omega\)</span> denotes the axis-angle representation of the relative rotation of part k with respect to its parent in the kinematic tree</p>
</blockquote></li>
<li><p><span class="math inline">\(\mathcal{W}\)</span> : <span class="math inline">\(4\times 3N\)</span>维，其实应该是<span class="math inline">\(K\times 3N\)</span>维才对，但为了和现存渲染引擎同步，这里取每个顶点最多被附近4个关节点的运动影响。<span class="math inline">\(\mathcal{W}\)</span>是LBS/QBS混合权重矩阵。由于顶点和其附近的关节点存在相关性，这个相关性是每个顶点对应多个关节点，且权重不一。这里就需要这样一个矩阵来记录这种相互关系，即关节点对顶点的影响权重 (第几个顶点受哪些关节点的影响且权重分别为多少)。</p></li>
<li><p><span class="math inline">\(J\)</span> : 用于补偿joint position因为目标人物体态变化产生的位移。它通过表皮的形状位置来推测新的joints位置。</p></li>
<li><p><span class="math inline">\(B_S(\overrightarrow{\beta})\)</span>里面的这个<span class="math inline">\(B_S\)</span>的作用是把已经经过PCA筛选压缩过的10个参数恢复到正常的3N维度，即对于每个顶点，应当向哪个方向变化来适应这个人的体态。这里恢复出来的值也是相对于平均模型的。</p></li>
<li><p><span class="math inline">\(B_S(\overrightarrow{\theta})\)</span>同理，由于我们输入的pose <span class="math inline">\(\overrightarrow{\theta}\)</span> 也只有3(K+1)维度，而想要对因为人体做出特定动作产生的形变进行补偿，也需要一个3N维度的值来对每个顶点分别建模补偿。</p></li>
</ul></li>
<li><p>而关于训练，训练过程中对于形态和姿势的训练时分开进行的。前者在一个<code>Multi-Shape Dataset</code>上训练完成，而后者在一个<code>Multi-Pose Dataset</code>上训练完成，二者是相互独立的。</p></li>
<li><p>模型训练主要训练的是这些参数：形态的<span class="math inline">\(\bar{T}, \mathcal{S}\)</span>和姿势的参数<span class="math inline">\(\mathcal{J},\mathcal{W},\mathcal{P}\)</span>。除去上面介绍过的<span class="math inline">\(\bar{T},\mathcal{W}\)</span>，其他几位的介绍如下</p>
<ul>
<li><span class="math inline">\(\mathcal{J}\)</span>: <span class="math inline">\(3N\times 3K\)</span>，将rest vertices转换成rest joints 的矩阵。</li>
<li><span class="math inline">\(\mathcal{P}\)</span>: 矩阵形状为<span class="math inline">\(3N\times 9K\)</span>，这里之所以K前面系数是9，是因为使用时把关节点的坐标从3D空间坐标处理成了其相对于根节点的旋转矩阵，而3D旋转矩阵有9个参数。<span class="math inline">\(\mathcal{P}\)</span>是这所有27*9=207个 pose blend shapes 组成的矩阵。因此，pose blend shape 函数BP(θ→;P) 完全被矩阵 P 定义。</li>
</ul></li>
</ul>
<h2 id="模型本身使用说明">模型本身使用说明</h2>
<ul>
<li>模型本身在Python中的使用是相当简单直接的：<code>Load Model -&gt; Assign β&amp;θ -&gt;Dump</code></li>
<li>Dump出来的pkl模型可以直接在Blender/Unity等软件中读取，应用到SMPL模型中。</li>
</ul>
<h2 id="smpl-x">SMPL-X</h2>
<ol type="1">
<li>SMPL-X其实是一个大杂烩，它结合了基本姿态用的SMPL模型，手部姿态的MANO模型和面部特征的FLAME模型。</li>
<li>SMPL-X模型本身分别在多个数据集上训练：
<ol type="1">
<li><span class="math inline">\(\{S\}\)</span>：形状空间参数（shape space parameters），在3800个A-pose捕捉不同性别的变化的数据集上训练</li>
<li><span class="math inline">\(\{W，P，J\}\)</span> ：身体姿态空间参数（body pose space parameters），在1786个不同姿态的数据集上训练</li>
<li>MANO：姿态空间及姿态相关混合形状（pose space and pose corrective blendshapes），1500 手部扫描数据</li>
<li>FLAME：表情空间<span class="math inline">\(\{\varepsilon\}\)</span>（expression space），3800 头部高精度扫描数据上训练</li>
</ol></li>
<li>SMPL-X区分了男女模型，用了一个性别分类器。</li>
<li>Pipeline（上文有提）：
<ol type="1">
<li>先自下而上用OpenPose预测人体2D关键点。</li>
<li>然后再结合各种Prior（身体姿态、手部姿态、身体形状、面部姿态、面部表情、极端弯曲）和各种Loss Punishment（2D与3D在平面投影的Loss，身体Parts互相穿透的Loss）去让3D的模型拟合这些关键点。</li>
<li>用了Optimization算法直接去拟合的3D模型参数，这个步骤没有使用深度学习。相反，使用的是Limited-memory BFGS optimizer (L-BFGS)的强化Wolfe line search（SMPL-X）、Chumpy+OpenDR（SMPLify）。</li>
</ol></li>
<li>既可以用于从2D joints coordinates得到SMPL-X，也可以通过3D joints coordinates得到，如论文“<em>I2l-meshnet: Image-to-lixel prediction network for accurate 3d human pose and mesh estimation from a single rgb image</em>” 中，作者就通过SMPLify-X得到了H3M数据集的SMPL版本。</li>
</ol>
<h2 id="已有数据集转化">已有数据集转化</h2>
<ul>
<li>带有图片和2D Human Joints Label的数据集：使用<a href="https://github.com/JiangWenPL/multiperson/tree/master/misc/smplify-x">SMPLify-X</a>，或<a href="https://github.com/facebookresearch/eft">EFT</a>。</li>
<li>带有图片和3D Human Joints Label的数据集：使用<a href="https://github.com/JiangWenPL/multiperson">multiperson</a>库中的<a href="https://github.com/JiangWenPL/multiperson/tree/master/misc/smplify-x">SMPLify-X-for-3D</a>工具.</li>
<li>带有图片和多视角2D Human Joints Label的数据集：使用SMPLify</li>
<li>只有图片：使用<a href="https://github.com/facebookresearch/eft">EFT</a>。</li>
</ul>
<h2 id="动作的生产转化导入">动作的生产/转化/导入</h2>
<ul>
<li>我们已经将相关github repo打包成了docker，可以直接一键部署使用。具体链接和详细教程后续整理后更新。</li>
</ul>
<h2 id="other-papers">Other Papers</h2>
<p>在看完上面几篇最重要的鼻祖论文之后，下面是几篇最近的使用了SMPL系统的文章，通过对他们的分析可以对SMPL的应用有一个更好的理解。</p>
<h3 id="object-occluded-human-shape-and-pose-estimation-from-a-single-color-image">Object-Occluded Human Shape and Pose Estimation from a Single Color Image</h3>
<p><img data-src="image-20221129172810204.png" alt="image-20221129172810204" style="zoom:50%;"></p>
<ul>
<li><p>数据采集：</p>
<ul>
<li>他们先用Mask-RCNN和Alphapose来预测人体Mask及2D Joints。</li>
<li>对于不准确的label，他们手动矫正。</li>
<li>最后用SMPLify-X中的多视角方法得到GT。</li>
<li>得到GT后，他们把这个3D SMPL模型朝着图像平面投影，若投影不在Mask覆盖范围内（即被遮挡），那就给涂黑（-0.5），反之，用表面xyz构建3通道UV Map。</li>
</ul></li>
<li><p>数据处理：</p>
<ul>
<li>文中预测的基本单位是顶点（即表面上的全部点）而非骨骼、joints。</li>
<li>UV Map看上去是彩色的，这个颜色其实意味着UV Map有三个通道，而这三个通道是相应每个点所对应的x、y、z坐标值。</li>
<li>其中，对于未被遮挡的点（Mask点亮的点），把xy给norm到<span class="math inline">\([-0.5,0.5]\)</span>即可；而对被遮挡的点，其xyz是<span class="math inline">\([-0.5,-0.5,-0.5]\)</span>，即全黑（以-0.5为黑）。</li>
</ul></li>
<li><p>Pipeline：</p>
<ol type="1">
<li>Pipeline分为两部分，Train和Predict。</li>
<li>Train会先训练一个UV Map Inpainting Network。把之前处理过的、过了norm且遮挡部分给涂黑的UV Map给送到一个网络里，试图输出被涂黑区域得以被重新预测的UV Map。这就把3D SMPL HPE转成了一个image inpainting问题，即填补空缺部分图像。</li>
<li>Predict过程中，会先预测Mask，然后直接concatenate共同作为输入。</li>
<li>然后RGB Image预测全体UV Map时候用的是另一个完全不同于训练时UV Map Inpainting Network的branch，但是在这个branch里，Inpainting Branch的高维度feature被拿了进来作为constrain。这里说的不清楚，应该是把这个feature map concatenate到RGB image过了Encoder之后的feature map上作为prior。需要参考代码理解。</li>
</ol></li>
<li><p>Points：</p>
<ul>
<li><p>UV Map Inpainting Sub-Network的Loss由三部分构成：</p>
<ol type="1">
<li><p>首先是预测的UV Map和GT UV Map的L1 Loss。</p></li>
<li><p>然后是一个挺有趣的term，用于保证人体的每个部位预测出的UV Map是平滑的：对每个点计算一个它与其下方和右方点的差的绝对值。然后通过最小化这个值，保证预测的UV Map的平滑性。<span class="math inline">\(L_{tv}=\sum_{k}\sum_{(i,j)\in R_k}(|P_{i+1,j}-P_{i,j}|+|P_{i,j+1}-P_{i,j}|)\)</span>。其中<span class="math inline">\(R_k\)</span>是第k个身体部位对应的区域。</p></li>
<li><p>最后是关于人体各部位交界处的点。这些点在多个部位的UV Map上都有坐标。这个loss term旨在计算这些点在所有UV Map上的均值与GT的L1 Loss，以保证交界点处的值也平滑。</p></li>
<li><p>他们把3D点投影成2D时用了weak perspective projection弱透视投影。</p></li>
<li><p>速度相较于基于优化的SMPLify-X快得多，从30s降低到了13ms。</p></li>
<li><p>他们也用了已有的数据集+Occlusion的方式在多个数据集上得到了结果，加遮挡的方式值得学习。</p>
<p><img data-src="image-20221129175700470.png" alt="image-20221129175700470" style="zoom:50%;"></p></li>
</ol></li>
</ul></li>
</ul>
<h2 id="monocular-one-stage-regression-of-multiple-3d-people">Monocular, One-stage, Regression of Multiple 3D People</h2>
<ul>
<li><p>Idea: 本文的中心思想是用单张图像解析生成图中的多人SMPL模型。</p></li>
<li><p>Questions:</p>
<ol type="1">
<li>2D label的数据集可以通过EFT（Exemplar Fine-Tuning for 3D Human Model Fitting Towards In-the-Wild 3D Human Pose Estimation）生成，但那些只有3D joints coordinates但没有SMPL的数据集是怎么用上的？</li>
</ol></li>
<li><p>Pipeline:</p>
<ul>
<li>首先过一个Backbone提取feature map。</li>
<li>然后这个feature map被送到三个branch中，它们分别用来预测：
<ol type="1">
<li>人体中心位置的热力图<span class="math inline">\(C_m\in R^{1\times H \times W}\)</span>。它预测的是2D的人体中心位置。</li>
<li>相机参数map <span class="math inline">\(A_m\)</span>。这里的<span class="math inline">\(A_m\)</span>形状是<span class="math inline">\(R^{3\times W\times H}\)</span>，它的意义是：如果图片上某个pixel是某个人体中心的话，对应的这个人的相关相机参数。每个pixel预测的相机参数含有三个值，分别是<span class="math inline">\((s, t_x, t_y)\)</span>。<span class="math inline">\(s\)</span>是scale，包含了人的body size和depth。而<span class="math inline">\(t_x\)</span>和<span class="math inline">\(t_y\)</span>则是投影相对图片中心在x和y方向上的移动距离。<span class="math inline">\(t_x, t_y \in (-1,1)\)</span>，被normalized过。</li>
<li>SMPL map <span class="math inline">\(S_m\)</span>。这个和<span class="math inline">\(A_m\)</span>类似，也是假定每个pixel上都有一个可能的人体中心，然后这个人对应的SMPL参数。形状为<span class="math inline">\(R^{142\times H\times W}\)</span>。对于每个pixel，其中10个参数是shape，132个是pose。</li>
</ol></li>
<li>上面整个过程可以概括为：知道人大致在哪-&gt;知道这个位置的人的位移和scaling-&gt;知道这个人的形状和pose。</li>
</ul></li>
<li><p>Points:</p>
<ul>
<li><p>Collision-aware representation: 基于中心的方法往往使用的是bbox的中心，而这个中心在人体中并没有实际意义，且容易落到人体外部。本文选择了计算未被遮挡的人体躯干的几个点的均值作为中心点。如果躯干点都被遮挡了，就计算全部可见joints的中心点。</p>
<blockquote>
<p>We define the body center as the center of visible torso joints (neck, left/right shoulders, pelvis, and left/right hips).</p>
</blockquote></li>
<li><p>Multiple-human same-center情况的处理：使用类似于正正离子相互排斥的概念，让相近的两个人体中心尽可能远离彼此。</p></li>
</ul></li>
</ul>
<h2 id="exemplar-fine-tuning-for-3d-human-model-fitting-towards-in-the-wild-3d-human-pose-estimation">Exemplar Fine-Tuning for 3D Human Model Fitting Towards In-the-Wild 3D Human Pose Estimation</h2>
<ul>
<li><p>Idea: 3D HPE的野外数据和2D不同，很难取得。本文旨在利用已有的大规模2D数据集，通过高质量的优化匹配得到对应的3D labels，进而辅助训练。</p></li>
<li><p>Questions:</p>
<ol type="1">
<li>本文拟合的是SMPL还是3D骨架
<ul>
<li>拟合的是SMPL，3D坐标是SMPL pose parameter <span class="math inline">\(\theta\)</span> 的计算后的结果。</li>
</ul></li>
<li>本文与SMPLify-X有何不同
<ul>
<li>SMPLify-X只是一种单纯的fitting-based method，而本文则是结合了fitting和regression二者。</li>
</ul></li>
<li>有哪些文章使用了其公开的3D SMPL数据labels</li>
<li><strong>prior terms到底长什么样？怎么用到计算循环中的？</strong></li>
</ol></li>
<li><p>Pipeline：EFT方法是优化方法与回归方法的结合。具体操作是先正常训练一个神经网络，让它从2D坐标和输入图像预测对应的3D坐标。回归方法到这里就结束了，但EFT这才刚刚开始。EFT针对每一个图片实例，再得到神经网络的预测结果后，再以这个结果作为起点放到fitting method中去进一步优化，并且设定了一个限制就是新的优化后的神经网络权重<span class="math inline">\(w\)</span>与训练好的最佳权重<span class="math inline">\(w^*\)</span>之间差距不能太大。值得注意的是，这个优化后的权重<span class="math inline">\(w^+\)</span>仅服务于这一张图，用完就扔了。</p></li>
<li><p>Points：</p>
<ul>
<li><p>从2D坐标得到3D位置有两种做法：基于优化（fitting）的方法和基于回归（regression）的方法。前者通过构建多个Loss惩罚项、结合多种prior来逐步得到最能满足限制条件的3D坐标，而后者则直接通过深度网络来一步到位预测。</p></li>
<li><p>而本文提出的EFT则是结合了上面两种方法的方法。</p>
<figure>
<img data-src="image-20221205130430922.png" alt="image-20221205130430922"><figcaption aria-hidden="true">image-20221205130430922</figcaption>
</figure>
<p>上面三组公式分别是优化法、回归法，及EFT的公式。</p>
<p><span class="math inline">\(\Theta\)</span>代表SMPL模型的全部参数，其中，<span class="math inline">\(\theta,\beta\)</span>分别代表pose（以铰链夹角的形式展现）和shape参数。<span class="math inline">\(J\)</span>是3D location，<span class="math inline">\(\hat{J}\)</span>是2D location，<span class="math inline">\(\pi\)</span>是Projection matrix，用于把3D坐标投影到图像的2D平面，<span class="math inline">\(M\)</span>用于把SMPL参数转换为absolute 3D坐标。<span class="math inline">\(L_{pose}、L_{shape}\)</span>分别是pose、shape的prior。<span class="math inline">\(\Phi\)</span>是神经网络,<span class="math inline">\(w\)</span>是神经网络的权重。<span class="math inline">\(I\)</span>是输入图片。其中，<span class="math inline">\(\Theta{w}=\Phi_w(I)\)</span></p></li>
<li><p>优化方法的Loss包含三部分：</p>
<ol type="1">
<li>2D Loss</li>
<li>Pose Prior</li>
<li>Shape Prior</li>
</ol></li>
<li><p>回归方法的Loss包含三部分：</p>
<ol type="1">
<li><p>2D Loss</p></li>
<li><p>3D Loss</p></li>
<li><p>SMPL Loss</p></li>
</ol></li>
<li><p>EFT方法的Loss包含三部分：</p>
<ol type="1">
<li>2D Loss</li>
<li>进一步优化（fitting）后的神经网络参数与预训练网络的神经网络参数的差距Loss</li>
<li>Shape Prior</li>
</ol></li>
<li><p>EFT中有个参数<span class="math inline">\(\gamma\)</span>，这个参数决定了优化后的神经网络参数<span class="math inline">\(w\)</span>与预训练的<span class="math inline">\(w^*\)</span>的相似程度。如果<span class="math inline">\(\gamma\)</span>很大，那么基本这个优化步骤就没用了，因为<span class="math inline">\(w\)</span>不敢跑远，结果将会和神经网络直接预测出来的结果类似。再fitting-based method中，也有这个<span class="math inline">\(\gamma\)</span>，作用相似，如果太大的话，得到的结果将会是pose prior的平均pose。</p></li>
<li><p>与纯优化方案不同，这里EFT优化的不是<span class="math inline">\(\Theta, \pi\)</span>，而是神经网络的参数<span class="math inline">\(w\)</span>。</p></li>
<li><p>EFT中没有使用pose prior，因为它假定了神经网络已经隐式地编码了prior。</p></li>
<li><p>文章中帮我们跑了这些数据集（2D joints -&gt; SMPL）：<code>COCO, MPII, LSPet, PoseTrack, and OCHuman</code> datasets。</p></li>
<li><p>值得一提的是，由于优化方案有最低可见joints限制，所以不符合要求的人物labels已经被删掉了，所以得到的3D标签并非与原来的一一对应。</p></li>
</ul></li>
</ul>
<h2 id="问题">问题</h2>
<ul>
<li>已有的SMPL数据集都是怎么来的，他们是：
<ul>
<li>仿真</li>
<li>3D扫描</li>
<li>采集RGB的图片，同时通过mocap得到pose（2D/3D），结合SMPLify-X/<a href="https://files.is.tue.mpg.de/black/papers/MoSh.pdf">MoSh</a>/<a href="https://amass.is.tue.mpg.de/">Mosh++</a>得到SMPL-X模型GT。这里mocap可以是使用marker的，也可以是不使用marker的multi-view vision-based mocap system。</li>
<li>录多角度/单角度Video，全程逐帧应用SMPL预测，得到GT。过程中需要先用openpose预测得到2D坐标。</li>
</ul></li>
<li>最重要的几个SMPL数据集？
<ol type="1">
<li>AMASS，这个数据集是个整合数据集，把一大堆mocap数据集都给整合进来了，然后用他们自己的Mosh++跑出来SMPL，如果有手部mocap的还会把手部的mesh也进行分别优化。</li>
</ol></li>
</ul>
<h2 id="实践操作">实践/操作</h2>
<ul>
<li><p>首先，SMPL有一系列论文，其为：</p>
<ul>
<li><p>SMPL：最开始的一篇</p></li>
<li><p>SMPL+H：加了手部参数的SMPL</p></li>
<li><p>SMPLX：加了面部和手部参数的SMPL</p>
<blockquote>
<p>A new, unified, 3D model of the human body, SMPL-X, that extends SMPL with fully articulated hands and an expressive face.</p>
</blockquote></li>
</ul></li>
</ul>
<h2 id="reference">Reference</h2>
<h3 id="papers">Papers</h3>
<ol type="1">
<li><a href="https://smpl.is.tue.mpg.de/">SMPL</a>: <a href="https://smpl.is.tue.mpg.de/download.php">Code</a></li>
<li><a href="https://smpl-x.is.tue.mpg.de/index.html">SMPL-X</a>: <a href="https://github.com/vchoutas/smplx">Original</a>, <a href="https://github.com/vchoutas/smplify-x">Multi-View</a></li>
<li><a href="https://mano.is.tue.mpg.de/">Embodied Hands (MANO)</a></li>
<li><a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Zhang_Object-Occluded_Human_Shape_and_Pose_Estimation_From_a_Single_Color_CVPR_2020_paper.pdf">Object-Occluded Human Shape and Pose Estimation from a Single Color Image</a></li>
</ol>
<h3 id="blogs">Blogs</h3>
<ol type="1">
<li><a href="https://zhuanlan.zhihu.com/p/256358005">SMPL论文解读和相关基础知识介绍</a></li>
<li><a href="https://www.zhihu.com/question/292017089">想弄懂SMPL模型该如何学习</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/419779571">SMPL-X论文学习笔记</a></li>
</ol>
]]></content>
      <tags>
        <tag>python</tag>
        <tag>machine-learning</tag>
        <tag>CV</tag>
        <tag>SMPL</tag>
      </tags>
  </entry>
  <entry>
    <title>blender-syn-data-gen-tutorial</title>
    <url>/2021/11/27/blender-syn-data-gen-tutorial/</url>
    <content><![CDATA[<h1 id="blender-tutorial-on-generating-synthetic-data">Blender Tutorial on Generating Synthetic Data</h1>
<h2 id="how-to-make-an-ok-mmd-video">How to make an OK MMD video</h2>
<ul>
<li>MikuMikuDance (MMD) is a simple and powerful tool, as we used in the previous paper. However, users cannot easily inject scripts to access the inner variables. Also, with respect to the rendering, it has a physical limitation of 60 FPS, which restricts the direct simulation of DVS sensors. Lastly, there are many processes in the simulation loop where manual adjustment is forced, which limit the scalability. Therefore, we choose another route that concentrates on Blender and tries to rule out manual participation to the largest extent.</li>
</ul>
<span id="more"></span>
<ul>
<li><p>First, as the <code>.vmd</code> files distributed on the internet usually only contain the joints' movement and no mesh physics included, we will have a hard time dealing with the clothes materials, and physics in Blender, as Blender doesn't automatically use a preset for these factors like MMD. Therefore, we'd better take care of them in advance in MMD.</p></li>
<li><p>Here we are going to use a “successor” software of MMD, which is called MikuMikuMotion (MMM). Import your <code>.pmx</code> and <code>.vmd</code> files into MMM, and bake the physical mesh movement to a separate <code>.vmd</code> file. Turn the <code>Always</code> button on in the <code>Physics</code> Tab to make sure you calculate the physics for each frame, then click <code>Record</code> to bake your movement when everything is ready.</p>
<p><img data-src="image-20220714212046705.png" alt="image-20220714212046705" style="zoom:50%;"></p></li>
<li><p>Then dump your recorded motion to another <code>.vmd</code> file:</p>
<p><img data-src="image-20220714212445071.png" alt="image-20220714212445071" style="zoom:50%;"></p></li>
<li><p>Ok, then let's switch to Blender.</p></li>
<li><p>You have to install a plugin <a href="https://github.com/powroupi/blender_mmd_tools">mmd_tools</a> for Blender at first. It will help you to import your <code>.pmx</code> model files and <code>.vmd</code> motion files, as Blender doesn't support these file types natively. If you install it successfully, you will be able to see a panel like this on your sidebar:</p>
<p><img data-src="image-20220714215023678.png" alt="image-20220714215023678" style="zoom:50%;"></p></li>
<li><p>Click <code>Import</code>, then you could import your model that is used for recording in MMM to Blender. Then, make sure you clicked and selected the model that you just imported, and click the <code>Import</code> button under the tab <code>Motion</code> to import the baked <code>.vmd</code> motion file you get from MMM.</p></li>
<li><p>After that, you may notice that the skin color of your model looks magenta, then you have to follow the following step to repair that:</p>
<p><img data-src="image-20220714215437237.png" alt="image-20220714215437237" style="zoom:60%;"></p></li>
<li><p>If you also have a camera's trajectory, please click on the camera in the explorer and click <code>Motion-&gt;Import</code> in <code>MMD</code> side panel to select your <code>.vmd</code> camera motion file and import it.</p>
<p><img data-src="image-20220715103036422.png" alt="image-20220715103036422" style="zoom:50%;"></p></li>
<li><p>Then, it's time to set the lighting. Well, honestly speaking, I don't really care too much about lighting, as the requirement of generating synthetic data is not that high, so let's simply light everything up.</p>
<p><img data-src="image-20220714220719987.png" alt="image-20220714220719987" style="zoom:50%;"></p></li>
<li><p>We are almost there, and next, setting the output parameters: Remember to change your resolution, and set your output path as well as the file format. Here the resolution 346x260 is the resolution for event camera DAVIS346, which is the camera we are currently using.</p>
<p><img data-src="image-20220714221006003.png" alt="image-20220714221006003" style="zoom:50%;"></p></li>
<li><p>Next, let's set some render properties: For the render engine, you can use either <code>Eevee</code> or <code>Cycles</code>, but if you choose <code>Cycles</code>, remember to turn on the <code>GPU</code> rendering option under it to speed up. Also, if you want the background of your video to be pure white/transparent/other pure color, please check the <code>Tranparent</code> in <code>Film</code> section. Moreover, make sure to change the <code>View Transform</code> from <code>Filmic</code> to <code>Standard</code>, the color looks more <em>Real</em> that way.</p>
<p><img data-src="image-20220714222126060.png" alt="image-20220714222126060" style="zoom:50%;"></p></li>
<li><p>Lastly, continuing from the last point, if you want to have a pure color background, then you have to add a <em>Background</em> here: Go to the <code>Compositing</code> Tab on the top bar, then add an <code>Alpha Over</code> node and drag it between the existing two nodes. Connect it as the figure shows, then set the first <code>Image</code> with the pure color you desire. All set. (Notice, if there is nothing in this board, click the <code>Use Nodes</code> on the inner menu row, near the <code>Add</code> and <code>Nodes</code> to show the basic panels.)</p>
<p><img data-src="image-20220714222651269.png" alt="image-20220714222651269" style="zoom:50%;"></p></li>
<li><p>Now everything is prepared, let's render the frame/video. Click on the <code>Render</code> menu, then choose render frame/video, you can then find your video in the output folder you set before.</p>
<p><img data-src="image-20220714223147763.png" alt="image-20220714223147763" style="zoom:50%;"></p></li>
</ul>
<h2 id="generate-mask-video">Generate Mask Video</h2>
<ul>
<li><p>One more thing, if you want to dump the human mask, simple change the wires in <code>Composition</code> Panel is fine.</p>
<figure>
<img data-src="image-20220714223747030.png" alt="image-20220714223747030"><figcaption aria-hidden="true">image-20220714223747030</figcaption>
</figure></li>
</ul>
<h2 id="generate-depth-video">Generate Depth Video</h2>
<ul>
<li><p>If you even want to have the depth video, it's still easy enough: add another node in <code>Compositing</code> Tab to map a certain range of depth to <code>[0,1]</code>.</p>
<p><img data-src="image-20220714225113714.png" alt="image-20220714225113714" style="zoom:50%;"></p></li>
<li><p>You need to tweak this range carefully based on your model's actual moving range.</p></li>
</ul>
<h2 id="better-lighting-settings-like-default-material-preview">Better Lighting Settings (Like Default Material Preview)</h2>
<ul>
<li><p>You may notice that the default material preview looks great, but it's not easy to imitate that effect. Here let's take a step to try to reach a similar level of the effect by applying skybox texture.</p></li>
<li><p>In the beginning, you should understand what <code>Skybox</code> is used for. Skybox is used as a sort of <strong>Directional Colored Lighting</strong> in all directions. Imagine that you are surrounded by a certain environment, and the objects in each direction could reflect the light of their own color. This is what the sky box is used for. Compared to the <code>Sky box</code>, actually, it's more like a <code>sky sphere</code>, which is a sphere around you. You could control the <code>Strength</code> of the sky box, just like you modify the lighting strength.</p></li>
<li><p>First, let's enable a built-in plugin called <code>Node Wrangler</code> which could enable us to quickly add texture-related pipelines. Go to <code>Edit-&gt;Preference-&gt;Add-ons</code>.</p>
<p><img data-src="image-20220715154232096.png" alt="image-20220715154232096" style="zoom:50%;"></p></li>
<li><p>Modify the <code>Shader Editor</code> and switch the <code>Object</code> to <code>World</code> on its right. Also, make sure you turned <code>Use Nodes</code> option on. Then you'll be able to modify the environmental settings, like the sky box around the world. This is an informative figure. You should first select the <code>Node Groupe</code> which contains <code>Background</code> output port.</p>
<p><img data-src="image-20220715155114990.png" alt="image-20220715155114990" style="zoom:50%;"></p></li>
<li><p>Then, press <code>CTRL+T</code> to instantiate the three boxes on its left together. Next, connect the <code>General</code> option to <code>Vector</code>, and set your sky boxes' rotation angles. Usually, if you don't know how to rotate and just want to rotate like you could do in <code>Material Preview</code> mode, please make sure that you only rotate on the Z axis.</p></li>
<li><p>Then, it's time to load your actual sky box file. Go to your installation directory of Blender, and go to <code>&lt;Blender Installation Folder&gt;\2.93\datafiles\studiolights\world</code> directory, you can find all the default sky boxes Blender uses in its <code>Material Preview</code> mode. For me, the installation folder is at <code>C:\Program Files\Blender Foundation\Blender 2.93</code>, which is the default location.</p></li>
<li><p>Lastly, if you want to change the lighting strength, make sure to modify the <code>Strength</code> option in the <code>Node Group</code> box. Here I set it to 2.</p></li>
<li><p>Still, you may need to have a default sunlighting for a better 3D effect.</p></li>
<li><p>Done!</p></li>
</ul>
<h2 id="script-your-operations-and-repeat">Script Your Operations and Repeat!</h2>
<ul>
<li><p>Blender has a wonderful feature: it will record and tell you the python command equivalent for all the operations you take! Therefore, if you have done a pipeline correctly, you could simply copy all these commands and make them into a script easily. You could found the console here:</p>
<p><img data-src="image-20220714233705944.png" alt="image-20220714233705944" style="zoom:50%;"></p></li>
<li><p>You can even select multiple lines and copy them into corresponding python code blocks, which is an amazing function.</p></li>
</ul>
]]></content>
      <tags>
        <tag>blender</tag>
        <tag>MMD</tag>
        <tag>data-generation</tag>
      </tags>
  </entry>
  <entry>
    <title>3D Multi-Person Pose Estimation (HPE) Reviews</title>
    <url>/2023/04/02/3d-multi-hpe-review/</url>
    <content><![CDATA[<h2 id="taxonomy"><a class="markdownIt-Anchor" href="#taxonomy"></a> Taxonomy</h2>
<ul>
<li>By method: Top-Down; Bottom-Up</li>
<li>By time dimension: Frame; Time Sequence</li>
<li>By input type: Monocular; Multi-View</li>
<li>By human number: Single; Multiple</li>
<li>By output type: Skeleton; Mesh (SMPL, SCAPE, DensePose)</li>
</ul>
<span id="more"></span>
<p><img data-src="image-20221212154341647.png" alt="image-20221212154341647"></p>
<h2 id="possible-self-supervision-methods"><a class="markdownIt-Anchor" href="#possible-self-supervision-methods"></a> Possible Self-Supervision Methods</h2>
<ol>
<li>Do an “event inpainting”, and try to predict the missing events.</li>
<li>Same as the point 1, but predict the number of events missing instead.</li>
<li>Set a certain area (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><msub><mi>x</mi><mn>0</mn></msub><mo>:</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>y</mi><mn>0</mn></msub><mo>:</mo><msub><mi>y</mi><mn>1</mn></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[x_0:x_1,y_0:y_1]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span>) in <code>xy</code> plane all to 0, given a small piece <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><msub><mi>x</mi><mn>0</mn></msub><mo>:</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>y</mi><mn>0</mn></msub><mo>:</mo><msub><mi>y</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>t</mi><mn>0</mn></msub><mo>:</mo><msub><mi>t</mi><mn>1</mn></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[x_0:x_1,y_0:y_1, t_0:t_1]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.80952em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span>, and try to predict the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">t_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76508em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li>
<li>Given a subgraph of events in the human body, try to predict the following events that are generated by the same part.</li>
<li>Randomly set some nodes’ <code>y</code>(which part in the human body, which human id, …) to 0, and let the network refill.</li>
<li>Predict the position of the future event for a certain part based on the “optical flow/motion vector” generated.</li>
</ol>
<h2 id="major-points-from-papers"><a class="markdownIt-Anchor" href="#major-points-from-papers"></a> Major Points from Papers</h2>
<ul>
<li>In order to be flexible enough, researchers choose to predict pixel-based camera-centered coordinates instead of calibrated absolute coordinates. In this way, they can bypass the camera’s intrinsic and extrinsic issues and not be bound to a single type of hardware. Also, they can work on any images without knowing the parameters of the camera. In most cases, we also don’t need the absolute coordinates.</li>
<li>To make the system support multi-person, one common way is to have a two-step structure and use a pretrained bounding box detection network in the first stage. This could be hard for us since our input feature (TORE) is far different from the RGB images and definitely need to fine-tune.</li>
<li>Instead of Single-Image-based methods, more papers focus on video-based 3D MHPE nowadays.</li>
</ul>
<h2 id="common-points-among-all-hpe-papers"><a class="markdownIt-Anchor" href="#common-points-among-all-hpe-papers"></a> Common Points Among All HPE Papers</h2>
<ul>
<li>
<p>For 2D pose estimation, the following are common tricks:</p>
<ul>
<li>
<p>Multi-tasking <code>※ Highly possible to be applied in our work, but the task need to be carefully designed based on the graph's characteristics.</code></p>
<ul>
<li>Jointly do 2D/3D pose estimation. <code>※ Possible</code></li>
<li>Human activity recognition. <code>※ Not applicable</code></li>
<li>Human part segmentation. <code>※ Maybe, but need a pipeline to generate human part label</code></li>
</ul>
</li>
<li>
<p>Teacher-student/Distill/Quantification -&gt; small nets <code>※ This may not work here, as GNN itself is small and efficient enough.</code></p>
</li>
<li>
<p>Refinement blocks <code>※ We can definitely use the though of refinement</code></p>
</li>
<li>
<p>Hourglass scheme <code>※ We can try to build a similar structure in GNN</code></p>
</li>
<li>
<p>Multi-stage network</p>
</li>
</ul>
<img data-src="image-20221212162944138.png" alt="image-20221212162944138" style="zoom:50%;">
</li>
<li>
<p>For 3D HPE, the following frameworks are frequently used:</p>
<ul>
<li>Image -&gt; Heatmap -&gt; Joints Coordinates</li>
<li>Image -&gt; 2D Pose -&gt; 3D</li>
<li>Image -&gt; 2D Pose, + Image -&gt; 3D</li>
</ul>
<img data-src="image-20221212163200109.png" alt="image-20221212163200109" style="zoom:50%;">
</li>
<li>
<p>For SMPL, here is the common pipeline:</p>
<img data-src="image-20221212163427300.png" alt="image-20221212163427300" style="zoom:50%;">
</li>
</ul>
<h2 id="camera-distance-aware-top-down-approach-for-3d-multi-person-pose-estimation-from-a-single-rgb-image"><a class="markdownIt-Anchor" href="#camera-distance-aware-top-down-approach-for-3d-multi-person-pose-estimation-from-a-single-rgb-image"></a> Camera Distance-aware Top-down Approach for 3D Multi-person Pose Estimation from a Single RGB Image</h2>
<p><img data-src="image-20220927122328357.png" alt="image-20220927122328357"></p>
<h3 id="points"><a class="markdownIt-Anchor" href="#points"></a> Points</h3>
<ul>
<li>
<p>They construct the system based on the top-down approach that consists of DetectNet, RootNet, and PoseNet.</p>
</li>
<li>
<p>They include some intrinsic matrix parameters in their input (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><msqrt><mrow><msub><mi>α</mi><mi>x</mi></msub><msub><mi>α</mi><mi>y</mi></msub><mfrac><msub><mi>A</mi><mrow><mi>r</mi><mi>e</mi><mi>a</mi><mi>l</mi></mrow></msub><msub><mi>A</mi><mrow><mi>i</mi><mi>m</mi><mi>g</mi></mrow></msub></mfrac></mrow></msqrt></mrow><annotation encoding="application/x-tex">k=\sqrt{\alpha_x\alpha_y\frac{A_{real}}{A_{img}}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.84em;vertical-align:-0.6790645em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1609355000000001em;"><span class="svg-align" style="top:-3.8em;"><span class="pstrut" style="height:3.8em;"></span><span class="mord" style="padding-left:1em;"><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.894191em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2818857142857143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.41586em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5423199999999999em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span><span style="top:-3.1209355em;"><span class="pstrut" style="height:3.8em;"></span><span class="hide-tail" style="min-width:1.02em;height:1.8800000000000001em;"><svg width="400em" height="1.8800000000000001em" viewbox="0 0 400000 1944" preserveaspectratio="xMinYMin slice"><path d="M983 90
l0 -0
c4,-6.7,10,-10,18,-10 H400000v40
H1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7
s-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744
c-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30
c26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722
c56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5
c53.7,-170.3,84.5,-266.8,92.5,-289.5z
M1001 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.6790645em;"><span></span></span></span></span></span></span></span></span>, where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">\alpha s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mord mathnormal">s</span></span></span></span> are from camera intrinsic). <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mrow><mi>r</mi><mi>e</mi><mi>a</mi><mi>l</mi></mrow></msub></mrow><annotation encoding="application/x-tex">A_{real}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is an estimated fixed number (2000mm x 2000mm) to indicate an approximate “human bounding box” size in <strong>real life</strong>. <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mrow><mi>i</mi><mi>m</mi><mi>g</mi></mrow></msub></mrow><annotation encoding="application/x-tex">A_{img}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> is the predicted bounding box size on the image in pixels.</p>
</li>
<li>
<p>What they do is not directly predicted the actual depth <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Z</mi></mrow><annotation encoding="application/x-tex">Z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span></span></span></span>, instead, they predict a correction factor based on the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> mentioned above. In this way, they take the information from the image and intrinsic directly into the pipeline, which eases the model’s job and makes the pipeline more flexible.</p>
<img data-src="image-20220927131536292.png" alt="image-20220927131536292" style="zoom:50%;">
</li>
<li>
<p>The PostNet is a standard one, just <code>RestNet+TransConvs-&gt;Heat Maps-&gt;Argmax-&gt;Coordinates</code> pipeline.</p>
</li>
<li>
<p>Even if you input a random image from an unknown hardware (whose intrinsic is unknown), their system can still provide an overlay-able prediction with a given (random) <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mi>x</mi></msub></mrow><annotation encoding="application/x-tex">\alpha_x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mi>y</mi></msub></mrow><annotation encoding="application/x-tex">\alpha_y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>.</p>
</li>
<li>
<p>For both predicted root coordinates by RootNet or the pose coordinates by PoseNet, the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">x</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span> coordinates are directly in the image plane, with a unit of the pixel.</p>
</li>
<li>
<p>The z coordinates predicted in the PoseNet are relative coordinates to the human center. And the final prediction is this relative z value + predicted <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mrow><mi>r</mi><mi>o</mi><mi>o</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">z_{root}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>. That’s the reason that even <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span> is wrong, the predicted 3D coordinates could still align.</p>
</li>
</ul>
<h2 id="single-shot-multi-person-3d-pose-estimation-from-monocular-rgb"><a class="markdownIt-Anchor" href="#single-shot-multi-person-3d-pose-estimation-from-monocular-rgb"></a> Single-Shot Multi-Person 3D Pose Estimation From Monocular RGB</h2>
<h3 id="points-2"><a class="markdownIt-Anchor" href="#points-2"></a> Points</h3>
<ul>
<li>It proposed a new dataset MuPoTs-3D, which is the first large-scale multi-person 3D HPE dataset with occlusion.</li>
<li>They didn’t use a marker-based MoCap system as that don’t works. So they merely employ purely multi-view marker-less motion capture to create the 20 sequences of MuPoTs3D. Here is the <a href="https://captury.com/">system</a> they used.</li>
<li>They did data augmentation with background and clothing replacement, as well as rotation and scaling.</li>
<li>Bottom-Up method. Predicting all the joints at first, then assemble them.</li>
</ul>
<h3 id="questions"><a class="markdownIt-Anchor" href="#questions"></a> Questions</h3>
<ul>
<li>Not very clear how they do the assembling of joints.</li>
</ul>
<h2 id="monocular-3d-multi-person-pose-estimation-by-integrating-top-down-and-bottom-up-networks"><a class="markdownIt-Anchor" href="#monocular-3d-multi-person-pose-estimation-by-integrating-top-down-and-bottom-up-networks"></a> Monocular 3D Multi-Person Pose Estimation by Integrating Top-Down and Bottom-Up Networks</h2>
<h3 id="points-3"><a class="markdownIt-Anchor" href="#points-3"></a> Points</h3>
<ul>
<li>
<p>This paper integrates both top-down and bottom-up methods to bypass the inherent disadvantages for both schemes. They do the bbox detection at first, and then predict the relative 3D poses and IDs of joints for each joints in the cropped image, then combine these image pieces to a complete channel. This heat map channel is concatenated to original input to serve as the input of the bottom-up methods. Then the bottom-up branch predict 4 maps:</p>
<ol>
<li>A 2D pose map.</li>
<li>A relative joint depth map.</li>
<li>A human root depth map.</li>
<li>A human ID map.</li>
</ol>
<p><img data-src="image-20220928124207020.png" alt="image-20220928124207020"></p>
</li>
<li>
<p>Graph Neural Network (GNN) is applied to do pose refinement in the top-down branch. This could help fix the incomplete pose caused by occlusion or partially out-of bbox body parts.</p>
</li>
<li>
<p>Two TCNs are used to estimate both person-centric 3D pose and camera-centric root depth based on a given sequence of 2D poses similar to [6].</p>
</li>
</ul>
<h2 id="graph-based-3d-multi-person-pose-estimation-using-multi-view-images"><a class="markdownIt-Anchor" href="#graph-based-3d-multi-person-pose-estimation-using-multi-view-images"></a> Graph-Based 3D Multi-Person Pose Estimation Using Multi-View Images</h2>
<h3 id="general"><a class="markdownIt-Anchor" href="#general"></a> General</h3>
<ul>
<li>Single-view 3D pose estimation approaches:
<ol>
<li>2D pose -&gt; 3D pose.</li>
<li>Jointly learning 2D and 3D poses.</li>
<li>Directly regressing 3D poses.</li>
</ol>
</li>
<li>Multi-view 3D pose estimation approaches:
<ol>
<li>2D -&gt; 3D: estimate 2D joints of the same person in each view through monocular pose estimator, then lift the matched 2D single view poses to 3D locations. This 2D to 3D process could be done by triangulation, single-person 3D PSM, or 1x1 Conv</li>
<li>Direct 3D pose estimation.</li>
</ol>
</li>
</ul>
<h3 id="points-4"><a class="markdownIt-Anchor" href="#points-4"></a> Points</h3>
<ul>
<li>They used the graphs for two parts: estimate the human center coordinates, and the whole body pose.</li>
<li>They take human structural prior to achieve better performance.</li>
</ul>
<h2 id="recent-advances-of-monocular-2d-and-3d-human-pose-estimation-a-deep-learning-perspective"><a class="markdownIt-Anchor" href="#recent-advances-of-monocular-2d-and-3d-human-pose-estimation-a-deep-learning-perspective"></a> Recent Advances of Monocular 2D and 3D Human Pose Estimation: A Deep Learning Perspective</h2>
<img data-src="image-20220929103125994.png" alt="image-20220929103125994" style="zoom:30%;">
<img data-src="image-20220929103235556.png" alt="image-20220929103235556" style="zoom:50%;">
<p><img data-src="image-20220929103344466.png" alt="image-20220929103344466"></p>
<h2 id="openpose-realtime-multi-person-2d-pose-estimation-using-part-affinity-fields"><a class="markdownIt-Anchor" href="#openpose-realtime-multi-person-2d-pose-estimation-using-part-affinity-fields"></a> OpenPose: Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields</h2>
<img data-src="image-20220930122642807.png" alt="image-20220930122642807" style="zoom:50%;">
<h3 id="questions-2"><a class="markdownIt-Anchor" href="#questions-2"></a> Questions</h3>
<ul>
<li>
<p>如何把预测的某个关节点的confidence map中含有的多个Local Maxima代表的多个不同人的同一个关节点区分开？</p>
<ul>
<li>使用了NMS（Non-Maximum Suppression）算法。直接得到discreet的关节点candidates。</li>
</ul>
</li>
<li>
<p>得到的这些不同人的关节点如何重新match到一起，形成一副副骨架？</p>
<ul>
<li>
<p>首先，对于已知会有连接的两个joints（如左手手腕和左手手肘），假设它们对应的confidence map中分别得到了<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><msub><mi>J</mi><mn>1</mn></msub></msub></mrow><annotation encoding="application/x-tex">N_{J_1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.93343em;vertical-align:-0.2501em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.09618em;">J</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:-0.09618em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><msub><mi>J</mi><mn>2</mn></msub></msub></mrow><annotation encoding="application/x-tex">N_{J_2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.93343em;vertical-align:-0.2501em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.09618em;">J</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:-0.09618em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span></span></span></span>个候补点，那么对于每组可能的组合<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo separator="true">,</mo><mi>B</mi></mrow><annotation encoding="application/x-tex">A,B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">A</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span>（共<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><msub><mi>J</mi><mn>1</mn></msub></msub><mo>∗</mo><msub><mi>N</mi><msub><mi>J</mi><mn>2</mn></msub></msub></mrow><annotation encoding="application/x-tex">N_{J_1}*N_{J_2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.93343em;vertical-align:-0.2501em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.09618em;">J</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:-0.09618em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.93343em;vertical-align:-0.2501em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.09618em;">J</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:-0.09618em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span></span></span></span>个），分别计算一下沿着<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mrow><mi>A</mi><mi>B</mi></mrow><mo stretchy="true">→</mo></mover></mrow><annotation encoding="application/x-tex">\overrightarrow{AB}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.20533em;vertical-align:0em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.20533em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span><span class="svg-align" style="top:-3.6833299999999998em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="height:0.522em;min-width:0.888em;"><svg width="400em" height="0.522em" viewbox="0 0 400000 522" preserveaspectratio="xMaxYMin slice"><path d="M0 241v40h399891c-47.3 35.3-84 78-110 128
-16.7 32-27.7 63.7-33 95 0 1.3-.2 2.7-.5 4-.3 1.3-.5 2.3-.5 3 0 7.3 6.7 11 20
 11 8 0 13.2-.8 15.5-2.5 2.3-1.7 4.2-5.5 5.5-11.5 2-13.3 5.7-27 11-41 14.7-44.7
 39-84.5 73-119.5s73.7-60.2 119-75.5c6-2 9-5.7 9-11s-3-9-9-11c-45.3-15.3-85
-40.5-119-75.5s-58.3-74.8-73-119.5c-4.7-14-8.3-27.3-11-40-1.3-6.7-3.2-10.8-5.5
-12.5-2.3-1.7-7.5-2.5-15.5-2.5-14 0-21 3.7-21 11 0 2 2 10.3 6 25 20.7 83.3 67
 151.7 139 205zm0 0v40h399900v-40z"/></svg></span></span></span></span></span></span></span></span></span>方向PAF的积分。实际操作上，用的是AB点之间等距取样的几个点的PAF值的和。</p>
</li>
<li>
<p>然后对这<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><msub><mi>J</mi><mn>1</mn></msub></msub></mrow><annotation encoding="application/x-tex">N_{J_1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.93343em;vertical-align:-0.2501em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.09618em;">J</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:-0.09618em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span></span></span></span>个<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>J</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">J_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.09618em;">J</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.09618em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>类型点和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><msub><mi>J</mi><mn>2</mn></msub></msub></mrow><annotation encoding="application/x-tex">N_{J_2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.93343em;vertical-align:-0.2501em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.09618em;">J</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:-0.09618em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span></span></span></span>个<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>J</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">J_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.09618em;">J</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.09618em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>类型点做一个bipartite matching，简单说就是对于两组点，尝试在这两组点中建立尽可能多的匹配，每个匹配对应一条图上的边，edge的value就是由上一步定义的PAF积分计算得到。任意一个点最多匹配另一组中的一个点。目标是让这些匹配得到的边的值的和最大。这是一个NP-Hard问题，具体匹配由匈牙利算法执行。</p>
<img data-src="image-20221213233302649.png" alt="image-20221213233302649" style="zoom:80%;">
<p>这里的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>E</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">E_c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>就是所有边值的和，m和n分别是两组关节点组<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>D</mi><msub><mi>j</mi><mn>1</mn></msub></msub></mrow><annotation encoding="application/x-tex">D_{j_1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:-0.05724em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>D</mi><msub><mi>j</mi><mn>2</mn></msub></msub></mrow><annotation encoding="application/x-tex">D_{j_2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:-0.05724em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>中的点，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>E</mi><mrow><mi>m</mi><mi>n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">E_{mn}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是上面提到的mn两点间的PAF积分值。<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>z</mi><mrow><msub><mi>j</mi><mn>1</mn></msub><msub><mi>j</mi><mn>2</mn></msub></mrow><mrow><mi>m</mi><mi>n</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">z_{j_1j_2}^{mn}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.059164em;vertical-align:-0.394772em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-2.441336em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:-0.05724em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:-0.05724em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.394772em;"><span></span></span></span></span></span></span></span></span></span>代表分别属于<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>J</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">J_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.09618em;">J</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.09618em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>J</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">J_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.09618em;">J</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.09618em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>两组点中的m和n点是否相连。如果是，值为1；反之为0。尝试最大化这个<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>E</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">E_c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。</p>
</li>
</ul>
</li>
<li>
<p>PAF的GT怎么得到的？</p>
<ul>
<li>
<p>给定两个相连的关节点，连线。以这个连线为等分线沿线的垂直方向做一个矩形。</p>
</li>
<li>
<p>在这个矩形内的就是<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mrow><mi>A</mi><mi>B</mi></mrow><mo stretchy="true">→</mo></mover></mrow><annotation encoding="application/x-tex">\overrightarrow{AB}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.20533em;vertical-align:0em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.20533em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span><span class="svg-align" style="top:-3.6833299999999998em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="height:0.522em;min-width:0.888em;"><svg width="400em" height="0.522em" viewbox="0 0 400000 522" preserveaspectratio="xMaxYMin slice"><path d="M0 241v40h399891c-47.3 35.3-84 78-110 128
-16.7 32-27.7 63.7-33 95 0 1.3-.2 2.7-.5 4-.3 1.3-.5 2.3-.5 3 0 7.3 6.7 11 20
 11 8 0 13.2-.8 15.5-2.5 2.3-1.7 4.2-5.5 5.5-11.5 2-13.3 5.7-27 11-41 14.7-44.7
 39-84.5 73-119.5s73.7-60.2 119-75.5c6-2 9-5.7 9-11s-3-9-9-11c-45.3-15.3-85
-40.5-119-75.5s-58.3-74.8-73-119.5c-4.7-14-8.3-27.3-11-40-1.3-6.7-3.2-10.8-5.5
-12.5-2.3-1.7-7.5-2.5-15.5-2.5-14 0-21 3.7-21 11 0 2 2 10.3 6 25 20.7 83.3 67
 151.7 139 205zm0 0v40h399900v-40z"/></svg></span></span></span></span></span></span></span></span></span>单位向量，反之为0。</p>
</li>
<li>
<p>如果图中有多个人，且多个人的同一个部位出现在了同一个点上，则其对应多个单位向量，最终的值是这些单位向量向量和的均值:</p>
<img data-src="image-20221214000402136.png" alt="image-20221214000402136" style="zoom:50%;">
<p>值得注意的是，对于每种肢体（不是关节点），对所有同种肢体只生成一张PAF map。由于某个2D点可能同时在多个人的这个肢体上（Occlusion），所以对于map上某个特定点的PAF值，是在这个点上所有可能在的人的该肢体的单位向量的向量和的均值。</p>
</li>
</ul>
</li>
<li>
<p>如果某个部位缺失了怎么办？</p>
<ul>
<li>缺失了就缺失了。本文会依次匹配所有PAF中含有的端点对，如果某个部分没了，那就单纯把这部分移除就好了。</li>
</ul>
</li>
</ul>
<h3 id="points-5"><a class="markdownIt-Anchor" href="#points-5"></a> Points</h3>
<ul>
<li>
<p>PAF是一系列单位向量，它们分布在每个肢体上（两个有联系的joints），方向是肢体的指向。</p>
</li>
<li>
<p>整个模型是顺序的，先predict-refine PAF（前一半蓝色区域的网络），然后再predict-refine关键点（后一半橙色区域的网络）。前半和后半的第一个block是预测，后面全部都是refine阶段。之所以先PAF再KP是因为如果先预测KP可以用它来帮助预测PAF（知道了线端自然可以得到一些关于端点的信息），而如果反过来先预测端点，因为端点只是一个个独立的点，并不知道相互间的连接方法，所以对预测PAF结果并无帮助。</p>
</li>
<li>
<p>由于有的数据集并不会标出来所有的人，所以有时候即使网络预测出来了没有label的人，也会被loss所惩罚。他们的做法是加一个mask，让没有label的点不参与loss计算。</p>
</li>
<li>
<p>每个阶段都会单独计算L2 Loss并加起来。</p>
</li>
<li>
<p>在对各个部位NMS出来的一大堆可能的散点进行匹配的时候，文中做了几个关键的条件放松来加速运算：</p>
<ul>
<li>
<p>本来这是一个全连接图预测问题，即人体中的每个点都应该和其他所有点进行matching。</p>
</li>
<li>
<p>第一个放松点是只根据先验知识采用最少量但最make sense的连接数（如头和脖子，手腕和手肘，脚踝和膝盖等），且仅对这些连接进行计算匹配。在这时其实人体骨骼模型已经成了一个spanning tree skeleton了。值得注意的是，他们最后还是加入了一些冗余匹配对，如耳朵和肩膀、手腕和肩膀等。这些冗余可以保证在拥挤的场景中更不容易出错。</p>
</li>
<li>
<p>第二个放松点是把本来是一个树状的、但连续的匹配问题（如本来应该匹配手腕-手肘-肩膀-脖子-……），但这里将其转换为了这些joints间的两两匹配问题（如手腕-手肘，手肘-肩膀，肩膀-脖子，……）。这是因为相邻关节的树模型已经被PAF充分model了，所以不需要。</p>
<p><img data-src="image-20221214002603030.png" alt="image-20221214002603030"></p>
</li>
</ul>
</li>
<li>
<p>在生成某个关节点的confidence map的GT时，先找出每个人对应的关节点p，然后以p为中心通过高斯模糊扩散开来。在合并多个人这个关节的扩散形成的blob时，若有交叉，取交叉二者/N者的最大值。不用average的原因是average可能会让多个blob变成一个，如图：</p>
<img data-src="image-20221214003719893.png" alt="image-20221214003719893" style="zoom:50%;">
</li>
<li>
<p>有趣的是，本文除了做HPE，还可以做车辆关键点检测和脚的关键点检测，非常牛。</p>
</li>
</ul>
]]></content>
      <tags>
        <tag>machine-learning</tag>
        <tag>deep-learning</tag>
        <tag>paper</tag>
        <tag>HPE</tag>
      </tags>
  </entry>
  <entry>
    <title>Point Cloud Clustering 聚类方法论文总结</title>
    <url>/2023/03/27/point-cloud-clustering-paper/</url>
    <content><![CDATA[<h2 id="基本操作"><a class="markdownIt-Anchor" href="#基本操作"></a> 基本操作</h2>
<ol>
<li>降噪</li>
<li>点云聚类（DBSCAN）</li>
<li>追踪（Tracking）</li>
<li>ID（Identification）</li>
</ol>
<span id="more"></span>
<h2 id="real-time-people-tracking-and-identification-from-sparse-mm-wave-radar-point-clouds"><a class="markdownIt-Anchor" href="#real-time-people-tracking-and-identification-from-sparse-mm-wave-radar-point-clouds"></a> Real-time People Tracking and Identification from Sparse mm-Wave Radar Point-clouds</h2>
<p><img data-src="image-20221216011045607.png" alt="image-20221216011045607"></p>
<p><img data-src="image-20221216011117452.png" alt="image-20221216011117452"></p>
<h3 id="question"><a class="markdownIt-Anchor" href="#question"></a> Question</h3>
<ul>
<li>
<p>怎么做的tracking？</p>
<ul>
<li>
<p>使用了converted-measurements Kalman filter (CM-KF) 方法预测目标人物位置、速度、Extension（？）。</p>
</li>
<li>
<p>用了NN-JPDA（nearest-neighbors joint probabilistic data association）算法计算轨迹。</p>
<blockquote>
<p>The MTT association between new observations and trajectories is achieved using an approximation of the nearest-neighbors joint probabilistic data association (NN-JPDA) algorithm</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<h3 id="radar-part"><a class="markdownIt-Anchor" href="#radar-part"></a> Radar Part</h3>
<p><strong>※ 本文含有大量关于使用FMCW雷达采集和处理数据的细节，完全可以用作相关参考。</strong></p>
<ul>
<li>
<p>首先，雷达用的是MIMO雷达（multiple-input multiple-output)。</p>
</li>
<li>
<p>发射器3个，接收器4个，等效为一个发射器12个接收器。</p>
</li>
<li>
<p>发射信号被分布在两个空间走向上，分别是经(Azimuth, AZ)和纬(Elevation, EL)。两个方向上的信号以时分复用的方式交替发射，以取得两个方向上的角度，用以计算Point Cloud中每个点的空间位置。</p>
</li>
<li>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi><mo separator="true">,</mo><mi>ϕ</mi></mrow><annotation encoding="application/x-tex">\theta, \phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">ϕ</span></span></span></span>分别是一个反射点在 AZ 和 EL 方向上的角度，R是反射点相对雷达的距离。xyz可以只靠<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo separator="true">,</mo><mi>θ</mi><mo separator="true">,</mo><mi>ϕ</mi></mrow><annotation encoding="application/x-tex">R,\theta,\phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">ϕ</span></span></span></span>来计算出来。</p>
<img data-src="image-20221216143959204.png" alt="image-20221216143959204" style="zoom:50%;">
</li>
</ul>
<h3 id="points"><a class="markdownIt-Anchor" href="#points"></a> Points</h3>
<ul>
<li>
<p>本文中，并没有针对可变数量的人物进行适配。仅仅支持或3人或8人。所谓的ID只是一个N分类CNN罢了。</p>
<blockquote>
<p>Identification: a deep NN classifier is applied to a temporal sequence of K subsequent point-clouds associated with each trajectory, with the objective of discerning among a set of Q pre-defined subject identities.</p>
</blockquote>
</li>
<li>
<p>聚类还是DBSCAN方法。</p>
</li>
</ul>
<h2 id="human-tracking-and-identification-through-a-millimeter-wave-radar"><a class="markdownIt-Anchor" href="#human-tracking-and-identification-through-a-millimeter-wave-radar"></a> Human tracking and identification through a millimeter wave radar</h2>
<h3 id="questions"><a class="markdownIt-Anchor" href="#questions"></a> Questions</h3>
<ul>
<li>
<p>遮挡情况怎么办，多个人离得近有重合时候怎么办？</p>
<ul>
<li>凉拌，论文避开了这个问题没说。</li>
</ul>
</li>
<li>
<p>mmWave Radar的具体参数？</p>
<ul>
<li>频段为77–81 GHz。</li>
<li>Bandwidth是 4 GHz。</li>
<li>The Chirp Cycle Time 𝑇𝑐 是 162.14 μs。</li>
<li>Frequency Slope 是 70 GHz∕ms。</li>
<li>Range resolution （距离分辨率）是 4.4 cm。</li>
<li>Maximum unambiguous range （最大有效工作距离）是 5 m。</li>
<li>可分辨的最大径向速度是 2 m∕s。</li>
<li>速度分辨率是 0.26 m∕s。</li>
<li>128 chirps 每帧。</li>
<li>每秒33帧。</li>
</ul>
</li>
<li>
<p>怎么做的human track？</p>
<ul>
<li>这个过程是逐帧的。每当有新的人被检出，或是有被检出的人无法与之前帧的任何一个之前记录在案的人匹配成功，则添加一个新的track record</li>
<li>帧间目标匹配用的是匈牙利算法做的。</li>
<li>若有某个之前检出并记录过的人物在从某帧开始的连续D帧都没再出现过，则删除这个人。</li>
<li>最后，用Kalman Filter来预测和纠正轨迹。</li>
</ul>
<img data-src="image-20221216095831664.png" alt="image-20221216095831664" style="zoom:50%;">
</li>
<li>
<p>Detection &amp; Association 步骤中，匈牙利算法匹配已知人物和新一帧中的所有检出人物时，具体的匹配对象是什么（已知人物是一种什么形态被存贮记录的）？</p>
<ul>
<li>
<p>无论是track record中记录的人还是新一帧检测出来的人，其实际representation形式都是在x和y方向上的位置和速度。</p>
<blockquote>
<p>For each track we maintain a state which consists of location and velocity along the x and y axes. For each track the initial state consists of the first detection location and velocity.</p>
</blockquote>
</li>
</ul>
</li>
<li>
<p>Kalman Filter的具体作用？</p>
<ol>
<li>
<p>降噪。纠正传感器噪声。</p>
</li>
<li>
<p>当目标物体有几帧缺失时，补全。</p>
</li>
<li>
<p>在本文中Kalman Filter是在track prediction部分使用的。它每次会结合过去对当前帧结果（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover accent="true"><mi>x</mi><mo>^</mo></mover><mi>t</mi></msup><mo separator="true">,</mo><msup><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>t</mi></msup><mo separator="true">,</mo><msubsup><mover accent="true"><mi>v</mi><mo>^</mo></mover><mi>x</mi><mi>t</mi></msubsup><mo separator="true">,</mo><msubsup><mover accent="true"><mi>v</mi><mo>^</mo></mover><mi>y</mi><mi>t</mi></msubsup></mrow><annotation encoding="application/x-tex">\hat{x}^t,\hat{y}^t,\hat{v}_x^t,\hat{v}_y^t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.176664em;vertical-align:-0.383108em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">x</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.22222em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.22222em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4530000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.22222em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4530000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span></span></span></span>）的预测和当前的实际CNN Output（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>x</mi><mi>t</mi></msup><mo separator="true">,</mo><msup><mi>y</mi><mi>t</mi></msup><mo separator="true">,</mo><msubsup><mi>v</mi><mi>x</mi><mi>t</mi></msubsup><mo separator="true">,</mo><msubsup><mi>v</mi><mi>y</mi><mi>t</mi></msubsup></mrow><annotation encoding="application/x-tex">x^t,y^t,v^t_x,v^t_y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.176664em;vertical-align:-0.383108em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span></span></span></span>）得到一个新的综合了二者的结果（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover accent="true"><mi>x</mi><mo>˚</mo></mover><mi>t</mi></msup><mo separator="true">,</mo><msup><mover accent="true"><mi>y</mi><mo>˚</mo></mover><mi>t</mi></msup><mo separator="true">,</mo><msubsup><mover accent="true"><mi>v</mi><mo>˚</mo></mover><mi>x</mi><mi>t</mi></msubsup><mo separator="true">,</mo><msubsup><mover accent="true"><mi>v</mi><mo>˚</mo></mover><mi>y</mi><mi>t</mi></msubsup></mrow><annotation encoding="application/x-tex">\mathring{x}^{t},\mathring{y}^{t},\mathring{v}^{t}_x,\mathring{v}^{t}_y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.176664em;vertical-align:-0.383108em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">x</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.34722em;"><span class="mord">˚</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.31944em;"><span class="mord">˚</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.34722em;"><span class="mord">˚</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4530000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.34722em;"><span class="mord">˚</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4530000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span></span></span></span>），并以此为基础预测下一帧的结果（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover accent="true"><mi>x</mi><mo>^</mo></mover><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msup><mo separator="true">,</mo><msup><mover accent="true"><mi>y</mi><mo>^</mo></mover><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msup><mo separator="true">,</mo><msubsup><mover accent="true"><mi>v</mi><mo>^</mo></mover><mi>x</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo separator="true">,</mo><msubsup><mover accent="true"><mi>v</mi><mo>^</mo></mover><mi>y</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msubsup></mrow><annotation encoding="application/x-tex">\hat{x}^{t+1},\hat{y}^{t+1},\hat{v}^{t+1}_x,\hat{v}^{t+1}_y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.197216em;vertical-align:-0.383108em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">x</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.22222em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.22222em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4530000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.22222em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4530000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span></span></span></span>）。</p>
</li>
<li>
<p>具体可参考<a href="https://sikasjc.github.io/2018/05/08/kalman_filter/">Kalman Filter 卡尔曼滤波</a>，如下图，橙色是基于之前结果对小车当前相对距离的预测，紫色是对当前距离的观测，二者都有误差且服从正态分布，绿色则是综合了预测和观测的分布。</p>
<p><img data-src="image-20221216134555511.png" alt="image-20221216134555511"></p>
</li>
</ol>
</li>
<li>
<p>User Identification具体怎么做的？</p>
<ul>
<li>
<p>首先让人失望的是，还是softmax+classification-based方法，还是fixed number of human。</p>
</li>
<li>
<p>然后具体的做法是：</p>
<ol>
<li>先是正常的sliding windows聚合2s以内的所有点，步长为0.5s。</li>
<li>对于所有人，先使用一个大小相同的bbox圈起来这个人的所有点。</li>
<li>然后做Voxel Grid，有点像pooling操作，聚合成一个个空间块。</li>
<li>Flatten这些voxel grid到一维，输入一个classifier（BiLSTM+MLP）过softmax出每个人的概率。</li>
</ol>
<img data-src="image-20221216110618763.png" alt="image-20221216110618763" style="zoom:50%;">
</li>
</ul>
</li>
<li>
<p>mmWave信号是如何转换成3D点云的？</p>
<ol>
<li>首先FMCW雷达先记录所有的反射。</li>
<li>然后通过range-FFT之后移除clutter。</li>
<li>最后在估算完速度和角度之后生成point cloud。</li>
</ol>
</li>
<li>
<p>怎么做到的区分未训练的闯入者和每个训练对象的？</p>
<ul>
<li>在softmax loss分类，还加了一个center loss，旨在让来自同一个人的samples的intra-class distance最小，拥有相似的中心点，聚集在一起。</li>
<li>一旦来了新的人，他的sample feature中心点会远离前面的所有人，就会被区分开。</li>
<li>值得注意的是，这个所谓的相似的中心点并不是根据同一个人的features自然聚合训练出来的，而是通过对每个人类别label过一个embedding得到的。这个embedding会和每个该类的人的输出feature map做loss。</li>
<li>具体说道怎么根据这个embedding区分，那就是对每个人物bbox内得到的feature map，分别和每个已知人的bbox逐点算距离，距离太大就算闯入者，反之如果有一个还算小，那就是这类了。</li>
</ul>
</li>
</ul>
<h3 id="points-2"><a class="markdownIt-Anchor" href="#points-2"></a> Points</h3>
<ul>
<li>
<p>用的VICON Mocap System。</p>
</li>
<li>
<p>他们在论文中指出mmWave雷达很能穿，泡沫、塑料、木材、甚至铝对点云密度造成的影响都小于1%。</p>
<ul>
<li>用的材料是统一的3mm厚<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><msup><mn>0</mn><mn>5</mn></msup><mi>m</mi><msup><mi>m</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">10^5mm^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">5</span></span></span></span></span></span></span></span><span class="mord mathnormal">m</span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>大小的板子。约为1.5张A4纸大。</li>
<li>问题是，他们直接把材料怼到雷达脸上测的（1cm away from the sensor），为了防止radar signal transmitted in the line-of-sight condition。算是又避开了一个重要问题。估计在可视范围内放obstacles会出问题。</li>
<li>这种程度的穿透其实只在sensor有用，比如可以装配到屏幕、家具下面，而对应用端意义有限，即没法真的在日常空间中穿透物体。</li>
</ul>
</li>
<li>
<p>Clustering用的是DBScan，参数<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi><mo>=</mo><mn>0.05</mn><mo separator="true">,</mo><mi>α</mi><mo>=</mo><mn>0.25</mn><mo separator="true">,</mo><mi>M</mi><mi>i</mi><mi>n</mi><mi>P</mi><mi>t</mi><mi>s</mi><mo>=</mo><mn>20</mn></mrow><annotation encoding="application/x-tex">\epsilon=0.05, \alpha=0.25, MinPts=20</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">ϵ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8388800000000001em;vertical-align:-0.19444em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">5</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">2</span><span class="mord">5</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal">t</span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord">0</span></span></span></span></p>
<blockquote>
<p>DBScan has two parameters, namely Eps which indicates the maximum distance of two points in the same cluster and MinPts which indicates the minimum point number in a cluster to cope with noise points. In practice, we choose 0.05 as Eps and 20 as MinPts. 𝛼 was set to 0.25 in the customized distance function.</p>
</blockquote>
</li>
</ul>
<h3 id="about-fmcw-radar"><a class="markdownIt-Anchor" href="#about-fmcw-radar"></a> About FMCW Radar</h3>
<ul>
<li>
<p>步骤：</p>
<ol>
<li>range-FFT: 用来算目标物体距离。</li>
<li>Clutter Removal: 去掉静态物体。具体做法是对于每个range bin，对于每个天线，减去其均值。理由没看懂。(?)</li>
</ol>
<blockquote>
<p>As we are interested in identifying people moving in the scene, the background, corresponding to stationary objects, needs to be removed before performing Doppler FFT. This is performed by subtracting a mean for each range bin per antenna across the chirps in a frame. With this step in the processing pipeline, the millimeter wave radar is able to generate a point cloud which does not contain static obstacles. However, this does not guarantee that the point cloud does not contain noise. While the users move in the scene, parts of the background objects are occluded and the reflections from these areas changes over time, leading to noise in the radar point cloud.</p>
</blockquote>
<ol start="3">
<li>
<p>Doppler-FFT: 用来算目标物体速度。这一步前必须先把静态物体移除到位。</p>
</li>
<li>
<p>Angle Estimation：用天线组合来算目标物体相对雷达角度。</p>
</li>
</ol>
</li>
<li>
<p>很好奇究竟是如何从距离速度和角度还原出来如此高精度的3D空间坐标信息的。(?)</p>
</li>
</ul>
<h3 id="improvable-points"><a class="markdownIt-Anchor" href="#improvable-points"></a> Improvable Points</h3>
<ul>
<li>首先，这是针对特定人群的训练。无法泛化，训练集里面有谁谁才能用。</li>
<li>其次，他们算center loss时候只考虑了类内区别最小，没考虑让类间不同最大。</li>
<li>没有考虑人们距离太近时候的点云重合混杂问题，避而不谈。</li>
</ul>
]]></content>
      <tags>
        <tag>machine-learning</tag>
        <tag>deep-learning</tag>
        <tag>paper</tag>
        <tag>clustering</tag>
        <tag>point-cloud</tag>
      </tags>
  </entry>
  <entry>
    <title>MMD模型导入Blender后应用动捕BVH文件</title>
    <url>/2022/09/16/mmd-blender-bvh/</url>
    <content><![CDATA[<p>如果你手里有一个MMD模型(<code>.pmx</code>)，并且想在Blender将任务骨骼与某个动捕文件（<code>.bvh</code>）同步，即应用已有的动捕数据到mmd模型中，那么下面的教程可以帮到你。</p>
<span id="more"></span>
<h2 id="插件准备">插件准备</h2>
<ul>
<li><a href="https://github.com/absolute-quantum/cats-blender-plugin">CATS</a>
<ul>
<li>读入<code>.pmx</code>文件（读入时候应该做了自动scaling，如果用<a href="https://github.com/powroupi/blender_mmd_tools">mmd_tools</a>读入则会默认大10倍）</li>
<li>修正模型和材料（包括常见的紫色眼睛皮肤问题）</li>
<li>重命名日文的骨骼、材料、mesh等到英文（在后面map动捕文件的各个骨骼到模型骨架时非常重要）</li>
<li>精简骨骼（比如无效的外骨骼等会被优化，内部骨骼也会被简化为动捕等常用的骨骼形式，取消IK骨等）</li>
<li>注意：不需要另行安装<code>mmd_tools</code>，CATS会默认pre-install。</li>
</ul></li>
<li><a href="https://www.rokoko.com/integrations/3d-character-animation-in-blender#Section-integrations-download-links">Rokoko</a>：
<ul>
<li>作用：map动捕文件的各个骨骼到模型骨架</li>
<li>自动侦测骨骼间的对应关系，基本一键匹配后都是对的，即使名称什么有着较大区别也OK。</li>
<li>一旦你自己做过了一次匹配，这组mapping就会被它自动记录，后续相似的模型都可以直接一键。</li>
<li>如果不放心，或是某组匹配很常用想记录，可以直接export对应关系。</li>
</ul></li>
</ul>
<h2 id="模型导入与处理">模型导入与处理</h2>
<ul>
<li><p>首先是用<code>CATS</code>插件导入<code>.pmx</code>模型。这一步没什么问题，也不需要特别的操作，只管导入即可。如果右边的panel被隐藏了，显示的快捷键是<code>N</code>。</p>
<figure>
<img data-src="image-20220803233840197.png" alt="image-20220803233840197"><figcaption aria-hidden="true">image-20220803233840197</figcaption>
</figure></li>
<li><p>修正模型。刚导入的时候人物可能有各种小问题，但只要经过修正就都OK了。这个步骤是真的完完全全的“一键”操作，真的只用点一下<code>Fix Model</code>就好了。</p>
<p><img data-src="image-20220803234114008.png" alt="image-20220803234114008" style="zoom: 67%;"></p></li>
<li><p>修正完成后，请一定记得点一下<code>Start Pose Mode</code>，否则如果后面直接把<code>.bvh</code>文件应用过来，你会发现一些常见的诡异问题，如：手指尖、身上的一些饰物被留在了原地不动，只有身体其他部分在动，导致剧烈变形（这是由于手指/其他位置可能在模型中有多块骨头控制，而<code>.bvh</code>文件中对应位置只有更少的骨骼数，这就导致了某些骨骼没有得到mapping）；亦或是身体骨骼连接比较奇怪，如果旋转某块骨头就会连带其他一些意想不到的部位转动…… Anyway，解法就是简单的点一下<code>Start Pose Mode</code>，程序帮忙进行了一个骨骼和mesh间的绑定修正。这之后即使你再点击<code>Stop Pose Mode</code>也不会有问题，可方向用。</p></li>
<li><p>处理好之后的模型如图：</p>
<p><img data-src="image-20220803234942232.png" alt="image-20220803234942232" style="zoom:67%;"></p></li>
</ul>
<h2 id="与动捕文件匹配">与动捕文件匹配</h2>
<p>动捕文件直接导入后会默认出现一个骨架，这个骨架往往很大，所以你可能看不见它，此时需要缩小view很多倍才能看到全貌。我们的任务就是让这个骨架和修正后的人物模型骨架相匹配。</p>
<ul>
<li><p>导入<code>.bvh</code>文件。如果你知道其正常的缩放比例，如0.1或0.01，可以在load的时候选择。如果想后面看着动态调节，可以在导入并选中动捕骨骼后按下快捷键<code>S</code>，只需要移动鼠标即可进行等比例缩放。如果想缩放某个特定坐标轴，按下<code>S</code>后再单独按<code>X</code>, <code>Y</code>, 或<code>Z</code>即可。</p>
<p><img data-src="image-20220803235859075.png" alt="image-20220803235859075" style="zoom:50%;"></p></li>
<li><p>导入成功后，你将得到一个类似这样的结果：</p>
<p><img data-src="image-20220804000011284.png" alt="image-20220804000011284" style="zoom:50%;"></p></li>
<li><p>下一步，让动捕骨骼处于放松（Rest）状态，即T字状态。有两种方式：</p>
<ol type="1">
<li><p>直接点击骨骼Panel的<code>Rest Position</code>即可。好处是方便，坏处是一旦点了这个你就无法在此基础上进行调整。</p>
<p><img data-src="image-20220804000607036.png" alt="image-20220804000607036" style="zoom:50%;"></p></li>
<li><p>删除动捕骨骼的所有变形。注意这个是Temporary的，只要你不打帧上去，这个并不会影响你这一帧的实际位置，所以不用慌。</p>
<p><img data-src="image-20220804001114077.png" alt="image-20220804001114077" style="zoom:50%;"></p>
<p>操作步骤：选择动捕骨骼-&gt;选择Pose Mode-&gt;按下<code>A</code>键全选动捕骨骼-&gt;在下拉菜单<code>Pose</code>中清楚全部Transform。完成后，你将得到一个T字动捕骨骼。</p>
<p><img data-src="image-20220804001253169.png" alt="image-20220804001253169" style="zoom:50%;"></p></li>
</ol></li>
<li><p>然后分两种情况：如果人物的默认放松姿态也是T字，那么就可以直接进入下一步。否则，进行如下操作：先缩放动捕骨骼到和人基本重合的size，然后分别调整左右大臂的旋转角度，使得动捕骨骼和人物骨骼的手臂平行或重合。这一步是为了保证二者在这个用于对齐的帧有着相似的骨骼形态。注意：不能调整人物的大臂来贴合动捕文件，这个即使调了也无效。</p></li>
<li><p>骨骼匹配：</p>
<p><img data-src="image-20220804002622271.png" alt="image-20220804002622271" style="zoom:40%;"></p>
<ol type="1">
<li><p>打开<code>Rokoko</code> Panel，在<code>Retargeting</code>选项卡里选择动作的源和目标。这里源就是动捕文件，目标就是模型的骨骼。</p></li>
<li><p>点击<code>Rebuild Bone List</code>进行骨骼匹配。注意这里如果有些骨骼互相没有匹配好，需要手动匹配。方法是切换到<code>Pose Mode</code>后点选目标骨骼，确认其名称，然后填写到Panel对应的下方映射表格中。</p></li>
<li><p>骨骼匹配完成后，记着点击<code>Use Pose</code>栏的<code>Current</code>选项，表示用于对齐的是当前动捕骨骼的状态，而非Rest状态。</p></li>
<li><p>最后，点击<code>Retarget Animation</code>，All Set。</p>
<p><img data-src="image-20220804004103963.png" alt="image-20220804004103963" style="zoom:50%;"></p></li>
</ol></li>
</ul>
<h2 id="常见问题">常见问题</h2>
<ul>
<li><p>如果<code>.bvh</code>文件比较“飘”，脚不在地上，且偏离O点太远，我们可以做的是，先在<code>Object Mode</code>下平移动捕骨骼到合适的中心位置，然后按下<code>Shift+C</code>将cursor重置与O点，接下来选择<code>Set Origin to 3D Cursor</code>把动捕骨骼的中心点设定到坐标原点。在做完这一步之后再执行上面的<code>Retarget Animation</code>。</p>
<figure>
<img data-src="image-20220804012518890.png" alt="image-20220804012518890"><figcaption aria-hidden="true">image-20220804012518890</figcaption>
</figure></li>
</ul>
<h2 id="reference">Reference</h2>
<ul>
<li><a href="https://www.youtube.com/watch?v=Nyxeb48mUfs&amp;ab_channel=CGDive">Retargeting using Rokoko (COMPLETE guide) - Blender 2.8, 2.9, 3.0</a>：最重要的一个参考，本教程大部分来源于此。</li>
<li><a href="https://github.com/Rokoko/rokoko-studio-live-blender">Rokoko官方Wiki</a></li>
<li><a href="https://sites.google.com/a/cgspeed.com/cgspeed/motion-capture/the-3dsmax-friendly-bvh-release-of-cmus-motion-capture-database?authuser=0">CMU Bvh动捕数据集</a></li>
<li><a href="https://blog.csdn.net/linjf520/article/details/121696940">Key 3D Rigging Terms to Get You Moving - 关于 3D Rigging 的一些术语</a></li>
<li><a href="https://www.bilibili.com/read/cv15281069/">MMD to Blender 教程，快来动手制作你的 MMD 吧~（材质篇） - 哔哩哔哩</a></li>
<li><a href="https://www.bilibili.com/read/cv9778708/">【MMD/Blender】联动渲染基础教程 - 哔哩哔哩</a></li>
<li><a href="https://www.bilibili.com/read/cv10390257/">Blender 2D 渲染材质分享及经验总结 - 哔哩哔哩</a></li>
<li><a href="https://blender.stackexchange.com/questions/53886/move-3d-cursor-back-to-center-hotkey">Move 3D cursor back to center hotkey?</a></li>
<li><a href="https://www.youtube.com/watch?v=_ojeeuNtJM8&amp;t=96s&amp;ab_channel=Chris%27Tutorials">How to Quickly Set Object Origin in Blender 2.9 (Tutorial)</a></li>
</ul>
]]></content>
      <tags>
        <tag>blender</tag>
        <tag>MMD</tag>
        <tag>modeling</tag>
      </tags>
  </entry>
  <entry>
    <title>Spiking Neural Network (SNN) 学习笔记</title>
    <url>/2023/04/22/snn-notes/</url>
    <content><![CDATA[<h2 id="points"><a class="markdownIt-Anchor" href="#points"></a> Points</h2>
<ul>
<li>
<p>Input:</p>
<ul>
<li>One counter-intuitive fact is that almost all the mainstream SNN frameworks’ input shape is not a series of 1-D spike signals. Actually, the input shape is pretty much like other ANNs, but with an additional <code>T</code> time dimension. Here is the common input shape: <code>T x N x C x H x W</code>, where <code>T</code> means time, <code>N</code> means batch size, <code>C</code> means channel number, and <code>H, W</code> stands for the input image size. Except for the first two dimensions (<code>T, N</code>), the rest of the dimensions are quite flexible and can be modified as needed, and we can simplify the input shape as <code>T x N x X</code>.</li>
<li>For the Loihi SNN hardware platform, the input size is a bit different, but it’s a simple permutation: <code>N x X x T</code>.</li>
</ul>
</li>
</ul>
<span id="more"></span>
<ul>
<li>
<p>Another counter-intuitive side of SNN is, SNN is usually not used solely. Here, I mean people don’t solely use SNN neurons to build their entire model. The neuron-alone model can be potentially more efficient, but it is not good at capturing local and global patterns, and features. Instead, neurons here are only treated as a substitute for <strong>activation functions</strong> in ANNs.</p>
</li>
<li>
<p>Characteristics of SNN:</p>
<ul>
<li>
<p><strong>Generative Property of SNN</strong>: Generative, as its name shows, for a trained SNN, for an output neuron of a certain output class, if we scale the values of all the input neurons connected to this neuron and rearrange them properly, we can get a general pattern image of this class. This pattern could be clear and distinctive, or blurry and non-distinguishable, which reflects how well this class is trained. Like the image below, the last one is worse compared to the first three. This property will be used for demonstrating the results.</p>
<img data-src="image-20220707185619913.png" alt="image-20220707185619913" style="zoom:50%;">
</li>
<li>
<p><strong>Variable Threshold</strong>: Each pattern (e.g., in MNIST, the different number) has a different number of activations. For example, the number 1 has less activation (white pixels in the 28x28 image) than the number 8, generally speaking. Therefore, those classes with more activation will overshadow all the other classes with less activation. To avoid this kind of inter-class imbalance, we need to set a different threshold for each class, which is calculated based on the number of activation each class contains.</p>
</li>
<li>
<p><strong>Lateral Inhibition</strong>: Many different neurons in the same layer could get excited at different time stamps, however, when one neuron gets excited, this mechanism (lateral inhibition) will reduce the activity and inhibit other neurons in the same layer to get excited. This property is also called <em>Winner-Takes-All(WTA)</em>. In biology, the neuron gets excited first and lowers down the membrane potential of other neurons in the same layer.</p>
</li>
</ul>
</li>
</ul>
<h2 id="how-to-rewrite-an-ann-to-snn"><a class="markdownIt-Anchor" href="#how-to-rewrite-an-ann-to-snn"></a> How to Rewrite an ANN to SNN</h2>
<ul>
<li>
<p>First, select a proper neuron type (let’s call it Nx), and replace all the activation functions in your original ANN model with Nx.</p>
<blockquote>
<p>The literature <code>[P1]</code> provides a theoretical basis for analyzing the conversion of ANN to SNN. The theory shows that the IF neuron in SNN is an unbiased estimator of the ReLU activation function over time.</p>
</blockquote>
</li>
<li>
<p>Then, remove all batch normalization layers.</p>
</li>
<li>
<p>If you plan to eventually deploy the model to the Loihi platform, you should set all the <code>bias</code> items in related layers to False, like <code>Conv</code> and <code>Linear</code>. This is because <code>bias</code> is not supported in Loihi.</p>
</li>
</ul>
<h2 id="stdp"><a class="markdownIt-Anchor" href="#stdp"></a> STDP</h2>
<ul>
<li>
<p>The algorithm that is commonly used in neuron training is called Spike Time Dependent Plasticity (STDP, 突触时间依赖可塑性)。</p>
</li>
<li>
<p>STDP can only be applied to the training of neurons (SNN layers), but not other ANN layers used in the same network.</p>
</li>
<li>
<p>STDP is actually a biological process used by the brain to modify its neural connections (synapses). Since the unmatched learning efficiency of the brain has been appreciated for decades, this rule was incorporated in ANNs to train a neural network. Modeling of weights is based on the following two rules -</p>
<ul>
<li>Any synapse that contributes to the firing of a post-synaptic neuron should be made strong i.e its value should be increased.</li>
<li>Synapses that don’t contribute to the firing of a post-synaptic neuron should be diminished i.e its value should be decreased.</li>
</ul>
<p>Here is an explanation of how this algorithm works:</p>
<p>Consider the scenario depicted in this figure</p>
<p><a href="https://github.com/Shikhargupta/Spiking-Neural-Network/blob/master/images/spikes.jpg"><img data-src="spikes.jpg" alt="img"></a></p>
<p>Four neurons connect to a single neuron by synapse. Each pre-synaptic neuron is firing at its own rate and the spikes are sent forward by the corresponding synapse. The intensity of the spike translated to the post-synaptic neuron depends upon the strength of the connecting synapse. Now, because of the input spikes membrane potential of the post-synaptic neuron increases and sends out a spike after crossing the threshold. At the time when the post-synaptic neuron spikes, we’ll monitor which all pre-synaptic neurons helped it to fire. This could be done by observing which pre-synaptic neurons sent out spikes before post-synaptic neurons spiked. This way they helped in the post-synaptic spike by increasing the membrane potential and hence the corresponding synapse is strengthened. The factor by which the weight of the synapse is increased is inversely proportional to the time difference between post-synaptic and pre-synaptic spikes given by this graph</p>
<p><a href="https://github.com/Shikhargupta/Spiking-Neural-Network/blob/master/images/stdp_curve.jpg"><img data-src="stdp_curve.jpg" alt="img" style="zoom:20%;"></a></p>
</li>
</ul>
<h2 id="parameters"><a class="markdownIt-Anchor" href="#parameters"></a> Parameters</h2>
<p>Building a Spiking Neural Network from scratch is not an easy job. There are several parameters that need to be tuned and taken care of. Combinations of so many parameters make it worse. Some of the major parameters that play an important role in the dynamics of a network are -</p>
<ul>
<li>Learning Rate</li>
<li>Threshold Potential</li>
<li>Weight Initialization</li>
<li>Number of Spikes Per Sample</li>
<li>Range of Weights</li>
</ul>
<h2 id="frequently-used-activation-layersneurons"><a class="markdownIt-Anchor" href="#frequently-used-activation-layersneurons"></a> Frequently-used Activation Layers/Neurons</h2>
<ul>
<li>IF stands for Integrate-and-Fire. It is a simple model in which a neuron integrates incoming inputs over time and generates a spike when the membrane potential reaches a threshold value.</li>
<li>LIF stands for Leaky Integrate-and-Fire. It is an extension of the IF model that takes into account the leakage of charge through the neuron membrane over time. This model is widely used in SNNs due to its simplicity and efficiency.</li>
<li>PLIF stands for Poisson Leaky Integrate-and-Fire. It is a model that takes into account the stochastic nature of synaptic inputs in biological neurons. In this model, synaptic inputs are modeled as a Poisson process, and the membrane potential of the neuron is determined by the integration of these inputs over time, taking into account the leakage of charge through the membrane.</li>
</ul>
<h2 id="transform-traditional-rgb-images-to-events"><a class="markdownIt-Anchor" href="#transform-traditional-rgb-images-to-events"></a> Transform Traditional RGB Images to Events</h2>
<ul>
<li>Methods:
<ol>
<li>Show images on a paper/monitor, and then turn on/off the light.</li>
<li>Show images on a paper/monitor, and move the image/camera/sensor horizontally to keep the depth the same.</li>
<li>Show images on a paper/monitor, and rotate the camera.</li>
</ol>
</li>
<li><a href="https://www.frontiersin.org/articles/10.3389/fnins.2015.00437/full">Converting Static Image Datasets to Spiking Neuromorphic Datasets Using Saccades</a>: The original paper proposed for generating N-MNIST (Event camera version MNIST). It is collected by using an actual DVS to capture the MNIST images shown on a monitor, which slightly rotates the DVS to generate brightness change.</li>
<li>For normal RGB images, we can also generate <em>spikes</em> for a certain period of time based on a certain distribution (e.g., Poisson Distribution) of pixel positions with a fixed frequency.</li>
</ul>
<h2 id="specialized-hardware"><a class="markdownIt-Anchor" href="#specialized-hardware"></a> Specialized Hardware</h2>
<ul>
<li><strong>Intel Loihi 2</strong>: A hardware device designed for neuromorphic computation.
<ul>
<li>Asynchronous neurons applied.</li>
<li>Come with a new software platform, Lava.</li>
<li>Lava is <strong>NOT</strong> compatible with other platforms like PyTorch. Conversion needed.</li>
<li><a href="https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html">Official Site</a></li>
<li><a href="https://www.intel.com/content/www/us/en/research/neuromorphic-computing-loihi-2-technology-brief.html">Specification</a>.</li>
<li><a href="https://github.com/lava-nc/lava/issues/153">Pit Holes</a></li>
</ul>
</li>
</ul>
<h2 id="spikingjelly"><a class="markdownIt-Anchor" href="#spikingjelly"></a> spikingjelly</h2>
<ul>
<li>
<p><a href="https://spikingjelly.readthedocs.io/zh_CN/latest/activation_based/basic_concept.html">Link</a></p>
</li>
<li>
<p>Different from what I expected to be the input (a series of 1-D features along the time axis), the input shape of spikingjelly is very much like a normal input shape (<code>N x C x H x W</code>, or even <code>T x N x C x H x W</code>).</p>
</li>
<li>
<p>The training strategy is not any different from other Pytorch models.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">optimizer.zero_grad()</span><br><span class="line">y = net(x)</span><br><span class="line">loss = criterion(y, label)</span><br><span class="line">loss.backward()</span><br><span class="line">optimizer.step()</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>To transform a CNN-based model to an SNN model, just remove all the activation layers and replace them with any neurons you like (e.g., LIF).</p>
</li>
<li>
<p>An SNN neuron layer, actually, can be seen as an array of neurons that has the same shape as your input. Let’s call it a sub-neuron. Each sub-neuron works separately, and neighboring neurons don’t share anything with them. In the entire training/prediction process, each sub-neuron can be seen as an RNN. The spatial understanding and local feature capture ability are brought by normal CNN layers like <code>Conv2d</code>.</p>
</li>
<li>
<p>You can select each neuron’s step mode from single-step to <code>multi-step</code>. The first one doesn’t take care of the time axis and you have to manually manage the behavior along the time axis, and the latter simply can be seen as a wrapper of standard loop-based stepping on a time series.</p>
</li>
<li>
<p>SpikingJelly supports both Gradient descent and STDP training scheme. Actually, you can even merge these two training strategies, train neuron layers using STDP and train other CNN layers using GD. <a href="https://spikingjelly.readthedocs.io/zh_CN/latest/activation_based_en/stdp.html">Link</a></p>
</li>
<li>
<p>It supports direct conversion to the Intel Loihi platform (<a href="https://spikingjelly.readthedocs.io/zh_CN/latest/activation_based_en/lava_exchange.html">Link</a>). You can even train an ANN at first and convert it to SNN with a bunch of patterns. (<a href="https://spikingjelly.readthedocs.io/zh_CN/latest/activation_based_en/ann2snn.html">Link</a>)</p>
</li>
</ul>
<h2 id="helpful-softwarepackages"><a class="markdownIt-Anchor" href="#helpful-softwarepackages"></a> Helpful Software/Packages</h2>
<ul>
<li>
<p><code>AWESOME</code>: <a href="https://github.com/realamirhe/awesome-computational-neuro-science">Computational Neuro Science</a></p>
</li>
<li>
<p><code>FRAMEWORK</code> <a href="https://spikingjelly.readthedocs.io/zh_CN/latest/index.html">惊蛰 Spiking Jelly</a>: A PyTorch-based SNN framework.</p>
</li>
<li>
<p><code>LIBRARY</code> <a href="https://github.com/neuromorphs/tonic">Tonic</a>: A tool to facilitate the download, manipulation and loading of event-based/spike-based data. It’s like PyTorch Vision but for neuromorphic data.</p>
</li>
<li>
<p><code>PACKAGE</code> <a href="https://github.com/BindsNET/bindsnet">BindsNET</a> is a Python package used for simulating spiking neural networks (SNNs) on CPUs or GPUs using PyTorch Tensor functionality. Similar to Spiking Jelly and need more comparison. This package is developed by Hava’s group, so potentially easier to deploy.</p>
</li>
</ul>
<h2 id="references"><a class="markdownIt-Anchor" href="#references"></a> References</h2>
<h3 id="papers"><a class="markdownIt-Anchor" href="#papers"></a> Papers</h3>
<ol>
<li>Rueckauer B, Lungu I-A, Hu Y, Pfeiffer M and Liu S-C (2017) Conversion of Continuous-Valued Deep Networks to Efficient Event-Driven Networks for Image Classification. Front. Neurosci. 11:682.</li>
</ol>
<h3 id="blogs"><a class="markdownIt-Anchor" href="#blogs"></a> Blogs</h3>
<ol>
<li><a href="https://github.com/realamirhe/awesome-computational-neuro-science/blob/master/tutorials.md">Realamirhe’s Tutorial on ANN&amp;SNN</a></li>
<li><a href="https://github.com/Shikhargupta/Spiking-Neural-Network">Spiking-Neural-Network</a>: A python implementation of hardware efficient spiking neural network. It contains a good introduction to SNN.</li>
<li><a href="https://spikingjelly.readthedocs.io/zh_CN/latest/index.html">惊蛰 Spiking Jelly</a>: General tutorial is also provided.</li>
</ol>
]]></content>
      <tags>
        <tag>deep-learning</tag>
        <tag>SNN</tag>
      </tags>
  </entry>
  <entry>
    <title>DVS Domain Adaption Note</title>
    <url>/2023/04/19/dvs-da-paper/</url>
    <content><![CDATA[<h2 id="unsupervised-domain-adaption-algorithms">Unsupervised Domain Adaption Algorithms</h2>
<ul>
<li>GRL: Gradient Reversal Layer。 目标是让两个domain的distribution在feature extractor眼中无法区分（即match两个domain使其分布趋同）。</li>
<li>MMD：Minimize the Maximum Mean Discrepancy between the target and source domain。最小化两个域之间的最大平均差异。作者提出了一个metric来衡量域间差异，通过加loss来抑制这个差异，最终达到让网络最终层输出与域无关的稳定feature。</li>
<li>AFN：比较玄学。他们说之所以在target domain上表现不好是因为目标向量的norm相比源域的更小。所以它们就逐渐提高深度embedding的L2 norms来解决这个问题。</li>
</ul>
<span id="more"></span>
<ul>
<li>Rotation：作者添加了一个额外的自监督任务，即预测图片的绝对旋转角度。因为它同时接受源域和目标域的输入，所以理论上会学的更倾向于用共通的参数。甚至还有人扩展了这个方法，让网络直接去预测paired多模态图片的相对旋转角度。</li>
<li>Entropy：Grandvalet提出了一种表征目标域不确定性的方法，通过加一个正则项来帮助减缓domain shift的影响。</li>
</ul>
<h2 id="n-rod-a-neuromorphic-dataset-for-synthetic-to-real-domain-adaptation">N-ROD: a Neuromorphic Dataset for Synthetic-to-Real Domain Adaptation</h2>
<ul>
<li><p>CVPRW, 2021, <a href="https://n-rod-dataset.github.io/home/">Site</a></p></li>
<li><p>核心思想就是用已有的上面提到的各种UDA方法来减轻Synthetic和Real Event Data的domain shift。</p></li>
<li><p>Pipeline也非常直接，就是给RGB和Event frame分别整一个Feature Extractor，然后让Synthetic的rgb和events feature concat到一起，real的concat到一起，送入一个通用的Domain Adaptation Block(DABlock)作为一个branch，另一个branch做预测。</p>
<p><img data-src="dvs-da-paper/image-20230422182441632.png" alt="image-20230422182441632" style="zoom:50%;"></p></li>
<li><p>训练的时候他们用了RGB和Event Frames，但测试的时候只用Event Frames。</p></li>
<li><p>值得一提的是，既然能用这种架构，说明上面那些UDA方法都可以被归纳为一个auxiliary head来进行plug-and-play。</p></li>
<li><p>另外，他们提供了一个<a href="https://polimi365-my.sharepoint.com/personal/10425666_polimi_it/_layouts/15/onedrive.aspx?ga=1">数据集</a>，包含有相同目标的real和syn版本。</p></li>
</ul>
<h2 id="bridging-the-gap-between-events-and-frames-through-unsupervised-domain-adaptation">Bridging the Gap Between Events and Frames Through Unsupervised Domain Adaptation</h2>
<ul>
<li><p>IEEE ROBOTICS AND AUTOMATION LETTERS, 2022</p></li>
<li><p>感性的认知上，这篇文章主要的手法是循环式Loss，类似cycle gan；主要的逻辑是style transfer。</p></li>
<li><p>核心优点有两个：</p>
<ol type="1">
<li>不使用视频生成events，而是从单个image直接生成。</li>
<li>不需要paired data。</li>
</ol></li>
<li><p>缺点：</p>
<ol type="1">
<li>高度依赖所参考的events frame的参数，如dvs相机的ego motion speed，events frame的accumulation方法和参数（如时间）</li>
<li>有前提假设：环境亮度恒定，且events frame的采样时间短。</li>
</ol></li>
<li><p>不被拒稿的创新点：</p>
<ol type="1">
<li><p>首先是整体流程相对新颖，他们通过先生成optical flow，再结合frame图像的gradient和time difference生成events的。</p>
<p><img data-src="dvs-da-paper/image-20230419112731101.png" alt="image-20230419112731101" style="zoom:50%;"></p></li>
<li><p>把events frame和rgb image之间的domain adaption转化成了一个style transfer问题。events frame只需要贡献style feature就好，而rgb image则基于这个style，它自己的feature map，以及它自己的gradient输出相应的events frame。最后的loss计算也非常有style transfer的味道：</p>
<ul>
<li>计算原始rgb image和最终生成的events frame的feature map二者对应的content feature的Loss。</li>
<li>计算原始event frame和最终生成的events frame的feature map二者对应的style feature的Loss。</li>
</ul></li>
<li><p>通过上述手段，相当于作者强制让event feature extractor和rgb frame feature extractor输出的content feature达成一致，从而做到让RGB frame干的活（task，这里是目标检测）同样的events frame出来的feature也能干。</p></li>
<li><p>虽然作者说他的</p></li>
<li><p>作者大量使用了Loss，尤其是Adversarial Loss来enforce每个环节生成的内容都足够符合目标域的distribution。</p>
<p>以下是主Loss：</p>
<ol type="1">
<li>原始rgb image的feature map做输入，在task（这里是object Detection）上面的loss。</li>
<li>最终生成的events frame的feature map做输入，在task上面的loss。</li>
</ol>
<p>循环（Cycle）Loss：</p>
<ol type="1">
<li>Content部分：让生成的events frame的feature map与最初rgb image的feature map做L1 Loss</li>
<li>Style部分：让生成的events frame的style feature map和最初events frame的feature map做L1 Loss</li>
</ol>
<p>对抗Loss：</p>
<ol type="1">
<li><p>首先是最开始rgb image和event frame生成的两个feature map，训练一个PatchGAN Discriminator来尽可能区分二者，同时加一个generator loss到主loss。</p>
<p><img data-src="dvs-da-paper/image-20230419135409950.png" alt="image-20230419135409950" style="zoom:33%;"></p></li>
<li><p>对生成的events frame和原始的events frame也做一个GAN，尽可能让Discriminator无法区分出来生成的和真实的。</p>
<p><img data-src="dvs-da-paper/image-20230419135721458.png" alt="image-20230419135721458" style="zoom:33%;"></p></li>
</ol></li>
<li><p>作者不但在深度学习pipeline上做的很好，还充分利用了events 生成的物理知识，通过结合image gradient、optical flow、event trigger mechanism等，在整体流程中把物理prior完美融入。</p></li>
</ol></li>
<li><p>核心idea是把event features拆分成两部分，一部分是内容，另一部分是运动特征。通过这种方式，他们可以很高效的让events和images的潜在空间（latent space）进行匹配。他们使用了一个生成式事件模型。</p></li>
<li><p>虽然说的是直接生成events，实际上生成的是accumulated events frame。</p></li>
<li><p>注意他的<span class="math inline">\(R_{ref}\)</span>并非一个深度学习block，而是一个使用了原图gradient和pseudo flow的内积操作！</p></li>
<li><p>同样值得一提的是，他们在pseudo flow generation部分并没有加额外的supervision！之所以即使这样还能生成挺好的pseudo flow，是因为如果想用image gradient和这里生成的东西内积后得到events，根据公式这个feature map必须是flow：</p>
<p><img data-src="dvs-da-paper/image-20230419163354478.png" alt="image-20230419163354478" style="zoom:33%;"></p></li>
<li><p>虽然左下角那个content feature没用到，但同样的events feature extractor，再最右边生成的feature map则被用来做了content reference。</p>
<p><img data-src="dvs-da-paper/image-20230419115118001.png" alt="image-20230419115118001" style="zoom:50%;"></p></li>
<li><p>作者怎么控制的events feature extractor出来的两个feature map分别代表content和style？</p>
<ul>
<li>通过他定义的各种GAN Loss和Cycle Loss教这两个feature map做人。</li>
</ul></li>
<li><p>他们做的augmentation也挺有趣，基本是这样的：先正常预测到pseudo flow为止，然后适当随机给预测的全局flow加一个bias，预测出events后再次生成pseudo flow，进行cycle loss。目的是确保events frame feature extractor输出的两个feature map分别表征内容和style（motion）。</p>
<p><img data-src="dvs-da-paper/image-20230419165600573.png" alt="image-20230419165600573" style="zoom:50%;"></p></li>
</ul>
<h2 id="object-tracking-by-jointly-exploiting-frame-and-event-domain">Object Tracking by Jointly Exploiting Frame and Event Domain</h2>
<ul>
<li><p>ICCV, 2021</p></li>
<li><p>目标问题：Object Tracking。</p></li>
<li><p>Modality：DVS+RGB。本文研究的不是domain shift而是domain fusion，或者说，如何用DVS信息来提高RGB表现。</p></li>
<li><p>Pipeline理解：</p>
<ul>
<li>首先，每个rgb frame会对应好几个events frame。</li>
<li>events frame们先每个单独进行feature extraction，self-attention，然后结果被element-wise add到一起。</li>
<li>rgb frame则直接过一系列的feature extraction blocks，直接得到feature map。</li>
<li>这两者的feature map被送到CDMS block中做cross-attention互相融合，然后过adaptive weighting module被分别赋予不同的权重，最后加到一起得到一个统一的feature map。</li>
<li>上述过程中，无论是rgb还是events frame，都有深浅两个branch，浅的那个就是early exit。最终会得到两个feature map，一个是<span class="math inline">\(K_l\)</span>，一个是<span class="math inline">\(K_h\)</span>。</li>
<li>后面其实就没什么好说的了，就是单纯把这两个feature map放到classifier和Bbox regressor里面就好了。</li>
</ul>
<p><img data-src="dvs-da-paper/image-20230419174703447.png" alt="image-20230419174703447" style="zoom:33%;"></p>
<p><img data-src="dvs-da-paper/image-20230419174720669.png" alt="image-20230419174720669" style="zoom: 33%;"></p></li>
</ul>
<h2 id="multi-domain-collaborative-feature-representation-for-robust-visual-object-tracking">Multi-domain collaborative feature representation for robust visual object tracking</h2>
<ul>
<li>The Visual Computer， 2021</li>
<li>目标问题：Object Tracking</li>
<li>Pipeline：
<ul>
<li>整体思路是比较典中典的N路并行多模态运算啦。
<ol type="1">
<li>第一路：一个SNN feature extractor，输入是raw events（根据shape推算，其实应该是time voxel）。</li>
<li>第二路：accumulate events into event count frames, 然后和RGB图concat。之后过一个feature extractor。</li>
<li>第三路：RGB-only feature extractor。</li>
</ol></li>
<li>最后把三路结果concat起来，过一些block，得到tracking result。</li>
</ul></li>
<li>有点意思的是，他们的SNN branch是直接用的pretrain model然后给freeze起来用了。模型来自于“Eventbased angular velocity regression with spiking networks”。</li>
</ul>
]]></content>
      <tags>
        <tag>paper</tag>
        <tag>DVS</tag>
        <tag>domain-adaption</tag>
      </tags>
  </entry>
  <entry>
    <title>mmWave Radar Fusion 论文总结</title>
    <url>/2023/03/09/mmwave-radar-fusion-paper/</url>
    <content><![CDATA[<h2 id="immfusion-robust-mmwave-rgb-fusion-for-3d-human-body-reconstruction-in-all-weather-conditions"><a class="markdownIt-Anchor" href="#immfusion-robust-mmwave-rgb-fusion-for-3d-human-body-reconstruction-in-all-weather-conditions"></a> ImmFusion: Robust mmWave-RGB Fusion for 3D Human Body Reconstruction in All Weather Conditions</h2>
<ul>
<li>2022, Arxiv</li>
<li>Question: How to merge mmWave radar with RGB frames to do 3D human mesh reconstruction?</li>
<li>Spec: Single person, 3D mesh, RGB + mmWave Radar.</li>
<li>Features: Robust in extreme weather/conditions like rain, smoke, low light, and occlusion.</li>
</ul>
<span id="more"></span>
<h3 id="points"><a class="markdownIt-Anchor" href="#points"></a> Points</h3>
<ul>
<li>
<p>Merging scheme: Using three branches: Image branch, radar point cloud branch, and a fusion branch. All three branches are concatenated and sent to a transformer. A human template is also concatenated as “positional encoding” (actually it’s more like prior knowledge encoding.)</p>
<p><img data-src="image-20230329171848182-1682213515149-69.png" alt="image-20230329171848182"></p>
</li>
<li>
<p>Previous fusion methods:</p>
<ol>
<li>Point-level fusion method: Concatenate image features or projected RGB pixels to the point clouds as extended features of the point-based model.
<ul>
<li>This fusion strategy is not suitable for mmWave-RGB fusion due to the sparsity and noise of radar points.</li>
<li>Undesirable issues like <strong>randomly missing</strong> and <strong>temporally flicking</strong> would lead to fetching fewer or even wrong image features.</li>
</ul>
</li>
<li>DeepFusion: Treat image features as K and V, answering Qs from mmWave point cloud features.</li>
<li>TokenFusion: Do feature extraction and go through the transformer separately for both image and radar features. Fusion happens in the last stage.</li>
</ol>
</li>
<li>
<p>They perform positional encoding by attaching the 3D coordinates of each joint and vertex in a <strong>human template</strong> mesh to the global vector.</p>
</li>
<li>
<p>Raw radar side input has a shape of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1024</mn><mo>×</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">1024\times 3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mord">0</span><span class="mord">2</span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span></span></span></span>, which means 1024 mmWave radar point cloud in the cropped body region. Here it’s not clear how can this dimension keeps the same among all samples, but there should be a sampling mechanism to always sample 1024 points exactly.</p>
</li>
<li>
<p>Image feature part, they use HRNet to extract the feature of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>224</mn><mo>×</mo><mn>224</mn></mrow><annotation encoding="application/x-tex">224\times 224</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">2</span><span class="mord">2</span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord">2</span><span class="mord">4</span></span></span></span> cropped body region.</p>
</li>
<li>
<p>They use <code>PointNet++</code> to process raw radar point clouds, and the length of the resulting feature map (<code>L</code>) represents the number of seed points sampled by the Farthest Point Sample (FPS).</p>
</li>
<li>
<p>Results:</p>
<p><img data-src="image-20230329183402590-1682213515151-78.png" alt="image-20230329183402590"></p>
</li>
</ul>
<h2 id="mmwave-radar-and-vision-fusion-for-object-detection-in-autonomous-driving-a-review"><a class="markdownIt-Anchor" href="#mmwave-radar-and-vision-fusion-for-object-detection-in-autonomous-driving-a-review"></a> MmWave Radar and Vision Fusion for Object Detection in Autonomous Driving: A Review</h2>
<ul>
<li>2022, Sensors (MDPI)</li>
<li>This paper discussed various fusion methods used by previous mmWave + Vision sensor papers.</li>
</ul>
<h3 id="fusion-methods"><a class="markdownIt-Anchor" href="#fusion-methods"></a> Fusion Methods</h3>
<img data-src="image-20230329190214285-1682213515150-70.png" alt="image-20230329190214285" style="zoom:50%;">
<ol>
<li>
<p>Data Level</p>
<ul>
<li>Mature, but not the mainstream method.</li>
<li>Basically, using radar to detect the ROI, and crop the visual frame accordingly.</li>
<li>The size of the initial ROI is determined by the distance between the obstacle and mmWave radar.</li>
<li>Radar’s information loss is significant.</li>
</ul>
<img data-src="image-20230329193957860-1682213515150-72.png" alt="image-20230329193957860" style="zoom:50%;">
</li>
<li>
<p>Decision Level</p>
<ul>
<li>This is the mainstream fusion scheme at present.</li>
<li>The basic guideline is to process radar and vision data separately in parallel, let them do the final prediction also separately, and only fuse the predicted results.</li>
<li>Radar detection results generate a list of objects and contain information such as the distance, azimuth angle, and relative velocity of the detected objects.</li>
<li>The fusion method can be divided into Bayesian theory-based, Kalman Filter-based, Dempster Shafer Theory-based, and Radar Validation-based.</li>
</ul>
<img data-src="image-20230329200724366-1682213515150-71.png" alt="image-20230329200724366" style="zoom:50%;">
</li>
<li>
<p>Feature Level</p>
<ul>
<li>This is a relatively new strategy.</li>
<li>The core idea is to extract the feature from both sensors, fuse them, and do the prediction.</li>
<li>The fusion methods are usually concatenation, point-wise addition, or spatial attention fusion.</li>
<li>Note that the goal of fusion here is to compile an RGB image-like feature map, and the object detection module here can be any traditional CV object detection algorithm.</li>
<li>Radar feature extraction mostly adopts the method of converting radar points to the image plane to generate a radar image. The purpose of radar feature extraction is to transform radar information into imagelike matrix information. Each radar-generated feature map’s channel represents a physical quantity such as distance, longitudinal speed, lateral speed, and so on.</li>
</ul>
<img data-src="image-20230329201007298-1682213515150-73.png" alt="image-20230329201007298" style="zoom:50%;">
</li>
</ol>
<h3 id="future-trend"><a class="markdownIt-Anchor" href="#future-trend"></a> Future Trend</h3>
<ul>
<li>3D Object detection. The existing Radar-Vision fusion works are mainly 2D object detection, and 3D detection results are far worse.</li>
<li>Integrate new sensors.</li>
<li>Better ways of sensing information fusion (multi-modal fusion).
<ul>
<li>Better ways to deal with sparseness brought by radar.</li>
<li>More efficient multi-sensor fusing methods.</li>
</ul>
</li>
</ul>
<h3 id="calibration"><a class="markdownIt-Anchor" href="#calibration"></a> Calibration</h3>
<ul>
<li>Coordinate transformation method: Radar and camera are placed in the same coordinate. Using the camera and radar’s absolute coordinates, perform a linear transformation to calibrate.</li>
<li>Sensor verification method: Radar proposes a target list at first, and then verifies and matches using vision information.</li>
<li>Vision-based method: Propose candidate areas for moving targets using the camera, and match radar results to it.</li>
</ul>
<h2 id="spatial-attention-fusion-for-obstacle-detection-using-mmwave-radar-and-vision-sensor"><a class="markdownIt-Anchor" href="#spatial-attention-fusion-for-obstacle-detection-using-mmwave-radar-and-vision-sensor"></a> Spatial Attention Fusion for Obstacle Detection Using MmWave Radar and Vision Sensor</h2>
<ul>
<li>2020, Sensors (MDPI)</li>
<li>Core Contribution: Proposed a novel attention-based radar-vision fusion mechanism to do obstacle detection.</li>
<li>Taxonomy: Feature level fusion. (Attached is another taxonomy.)</li>
</ul>
<img data-src="image-20230330151749489-1682213515150-74.png" alt="image-20230330151749489" style="zoom:50%;">
<h3 id="points-2"><a class="markdownIt-Anchor" href="#points-2"></a> Points</h3>
<ul>
<li>
<p>Network structure: The feature extractor part is not anything new, it is a combination of modified ResNet and RetinaNet. The fusion mechanism is the part where it has the edge on.</p>
<img data-src="image-20230330151909029-1682213515150-76.png" alt="image-20230330151909029" style="zoom:50%;">
</li>
<li>
<p>The core mechanism: SAF, aims to predict an attention map generated by radar feature, and point-wise multiply this attention map by the feature extracted from vision features.</p>
</li>
</ul>
<img data-src="image-20230330151942545-1682213515150-77.png" alt="image-20230330151942545" style="zoom:50%;">
<ul>
<li>
<p>The “radar image” they used is transformed from radar points, which is shown as follows:</p>
<ul>
<li>They calculate the extrinsic matrix of the radar and front camera separately, transforming the radar point cloud into camera coordinates.</li>
<li>They calculate the pixel value of the radar image using depth <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">d</span></span></span></span>, longitudinal velocity <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>x</mi></msub></mrow><annotation encoding="application/x-tex">v_x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and lateral velocity <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>y</mi></msub></mrow><annotation encoding="application/x-tex">v_y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>. The <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span></span> here is a linear transformation for these three variables.</li>
<li>Lastly, since each pixel covers a too-small area of the image, they render a solid circle around each radar point. The value within the circle is the same, and the circle’s radius is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span>.</li>
<li>If there there are two radar points whose distance is less than <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>r</mi></mrow><annotation encoding="application/x-tex">2r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span>, in the intersection area, use the value of the nearer one (the one with a smaller <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">d</span></span></span></span>).</li>
</ul>
<img data-src="image-20230330174231545-1682213515150-75.png" alt="image-20230330174231545" style="zoom:50%;">
</li>
</ul>
<h2 id="tools"><a class="markdownIt-Anchor" href="#tools"></a> Tools</h2>
<ul>
<li><a href="https://github.com/radar-lab/ti_mmwave_rospkg">ROsPKG</a>: Turn raw radar data to point clouds.</li>
<li><a href="https://github.com/nesl/RadHAR">RadHAR</a>: Point Cloud Data collection and pre-processing (<a href="https://github.com/nesl/RadHAR/blob/master/DataPreprocessing/voxels.py">Voxel Generation</a>) examples can be found here. This is from a paper: <a href="https://dl.acm.org/citation.cfm?id=3356768"><em>RadHAR: Human Activity Recognition from Point Clouds Generated through a Millimeter-wave Radar</em></a></li>
<li>Point Cloud-related questions on TI: <a href="https://e2e.ti.com/support/sensors-group/sensors/f/sensors-forum/1049628/dca1000evm-point-cloud-data">Link</a> (They used IWR 1843 BOOST &amp; DCA 1000 EVM)</li>
</ul>
]]></content>
      <tags>
        <tag>deep-learning</tag>
        <tag>paper</tag>
        <tag>mmwave-radar</tag>
        <tag>domain-fusion</tag>
      </tags>
  </entry>
  <entry>
    <title>qDVS 论文笔记</title>
    <url>/2023/01/28/gert-qdvs-paper/</url>
    <content><![CDATA[<p><strong>Paper's full name</strong>: A 256x256 6.3pJ/pixel-event Query-driven Dynamic Vision Sensor with Energy-conserving Row-parallel Event Scanning, <a href="https://ieeexplore.ieee.org/document/9431446">Link</a></p>
<h2 id="idea">Idea</h2>
<p>This paper proposed a novel query-driven DVS (qDVS) hardware. This new hardware combines the advantages of APS and DVS, following a fixed scanning rate to inquire <strong>all</strong> pixels whether are good to fire an event. The output of qDVS is event <strong>frames</strong>. Pixels here are responsible for fewer functions, they only need to tell whether they are good to shoot and the polarity, as their address is fixed on the generated event frames. As each pixel has fewer functions, they are able to be made smaller, which results in an overall higher pixel density. Also, since the output of qDVS is already framed, machine learning researchers don't need to do accumulation themselves and hence optimized the processing pipeline.</p>
<span id="more"></span>
<h2 id="questions">Questions</h2>
<ul>
<li>They used a fixed scanning rate to interact with all pixels, but how to change this rate to better accommodate different information densities?
<ul>
<li>Change the external clock rate. (Not sure)</li>
</ul></li>
<li>What is the "fill factor" in DVS?</li>
<li>Although qDVS can directly output event frames, as qDVS works at a very high clock rate according to the paper, each frame should not contain enough events for a prediction. For problems like human pose estimation, using these frames will definitely cause a severe missing torso problem, as humans don't move all his/her body parts all the time.
<ul>
<li>Not clearly mentioned in the paper. This problem may not be solved in their paper originally.</li>
<li>Maybe accumulation is also used?</li>
</ul></li>
<li>Why the dynamic range is clearly lower (68dB) than other DVS cameras like Prophesee (124dB) and DAVIS346 (120dB)? Even the RGB camera has a higher dynamic range (FLIR BlackFly, 74.35dB). This means the qDVS camera doesn't have an advantage over other RGB cameras in low-lighting conditions.
<ul>
<li>An inference is stated in <em>Hardware Design Consideration</em> Point 6.</li>
</ul></li>
<li>Will the reset process eliminate the accumulated voltage change if this change is not big enough to trigger an event?</li>
</ul>
<figure>
<img data-src="kuben1-027-large.gif" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<h2 id="points">Points</h2>
<ol type="1">
<li>This is a hardware paper regarding a novel query-driven DVS sensing approach (qDVS).</li>
<li>It aims to boost the achievable pixel density and energy efficiency.</li>
<li>Combines complementary advantages of RGB + DVS.</li>
<li>Spec: 256 x 256, 33% fill factor, 10% temporal contrast sensitivity.</li>
<li>Peak rate: 0.5mW, 1.2V, 80Meps, 6.3pJ/pixel-event.</li>
<li>Comparison between chips:</li>
</ol>
<ul>
<li>Traditional CMOS/APS: High pixel density, use frame scanning at a <strong>fixed clock rate</strong>, causes constant data rate and <strong>power independent of information content</strong>.</li>
<li>Typical DVS: Saves energy by more efficient visual event coding. <strong>Low pixel density</strong>, inefficient implementation, caused extra area and power overhead to continuously monitor for events and handle requests and acknowledge handshaking with each pixel. This leads to substantial <strong>static power</strong>.</li>
<li>qDVS: Uses a <strong>clocked time-division multiplexing</strong> to <strong>periodically scan</strong> the array, querying each pixel to check whether the brightness change has passed a threshold. This scanning time interval is way smaller than the APS rate.</li>
</ul>
<ol start="7" type="1">
<li>gDVS achieves 2x greater pixel density, 20x greater energy efficiency than state-of-the-art.</li>
<li>qDVS is more suitable for deep learning since it directly outputs frames of events and does not require accumulation of events in the buffer memory, to reconstruct frames or dynamic clustering algorithms to identify object boundaries, in order to track them.</li>
</ol>
<h2 id="hardware-design-consideration">Hardware Design Consideration</h2>
<ol type="1">
<li><p>In qDVS, the <span class="math inline">\(V_{IN}\)</span> is defined by both <span class="math inline">\(C_{PH}\)</span> and <span class="math inline">\(C_{REF}\)</span>, where <span class="math inline">\(\Delta V_{IN} = \frac{C_{PH}}{C_{PH}+C_{REF}}\cdot\Delta V_{PH} + \frac{C_{REF}}{C_{PH}+C_{REF}}\cdot\Delta V_{REF} \space\space\space\space\space (1)\)</span>.</p></li>
<li><p>If <span class="math inline">\(\Delta V_{IN}&gt;+\epsilon\)</span>, output an ON event, if <span class="math inline">\(\Delta V_{IN}&lt;-\epsilon\)</span>, output an OFF event.</p></li>
<li><p>The photodiode generates output <span class="math inline">\(V_{PH}\)</span> in a <strong>logarithmic</strong> way to the brightness. This is the reason that there is a <span class="math inline">\(log\)</span> applied to the brightness in DVS.</p></li>
<li><p>Capacitors work as <strong>differentiators</strong>, turning the variation of electric potential into electric potential current <span class="math inline">\(Q=It=C\Delta U\)</span>, <span class="math inline">\(I=C\frac{dU}{dt}\)</span>. Therefore, when the brightness on this photodiode doesn't change, no potential is generated after the capacitor <span class="math inline">\(C_{PH}\)</span>.</p></li>
<li><p>As the threshold for generating an ON/OFF event is <strong>fixed</strong> and based on <span class="math inline">\(\Delta V_{IN}\)</span>, while <span class="math inline">\(\Delta V_{IN}\)</span> is decided by two factors <span class="math inline">\(\Delta V_{IN}\)</span> and <span class="math inline">\(\Delta V_{REF}\)</span> together, if we want to make the system easier to shoot events, then it's better to use a larger <span class="math inline">\(\Delta V_{REF}\)</span>. In this way, a smaller <span class="math inline">\(\Delta V_{IN}\)</span> is able to trigger an event. Otherwise, if the <span class="math inline">\(\Delta V_{REF}\)</span> is set smaller, a larger <span class="math inline">\(\Delta V_{IN}\)</span> in required for shooting an event, which leads to a higher requirement of input brightness change.</p></li>
<li><p>As formula (1) shows, <span class="math inline">\(\Delta V_{PH}\)</span> cannot contribute more than <span class="math inline">\(1\times \Delta V_{PH}\)</span> as <span class="math inline">\(C_{REF}\)</span> is not negative. There is <strong>no amplifier</strong> applied after <span class="math inline">\(V_{PH}\)</span> to enlarge this value. This is called passive coupling, while in a regular DVS camera, an active amplifier is applied after the photodiode, making a relatively smaller change of potential becomes larger. This is why qDVS has a much smaller dynamic range.</p></li>
<li><p>Illumination intensity change sensitivity (Hardness to trigger an event) is determined by <span class="math inline">\(C_{REF}\)</span>, while the dynamic range (to which absolute brightness range events can still be effectively triggered) is determined by coupling amplification of input <span class="math inline">\(\Delta V_{PH}\)</span>.</p></li>
<li><p>As qDVS is a frame scan-based design, there is no need to <strong>report the row and column address</strong> for each event, which alleviates the energy consumption by acquiring these addresses, resulting in a higher information density with a fixed bus bandwidth.</p></li>
<li><p>The queries are processed in a <strong>row-parallel, column-serial</strong> scanned output pattern. (How does this row parallel happen? Not clear in the paper. My guess is that it is using clocked time division multiplexing technique here for rows.)</p></li>
<li><p>Column readout performs thresholding comparison of the pixel photodiode voltage, using <strong>bipolar voltage modulation</strong> of <span class="math inline">\(V_{REF}(V_{UP} \space and \space V_{DN})\)</span>, to detect ON and OFF temporal change events in intensity.</p></li>
<li><p>A Gm-boosted high-gain cascode amplifier (Gain &gt; 90dB) provides a <strong>voltage clamp</strong> on the sense line to mitigate capacitive loading on the sense line and eliminate CV2 losses incurred in APS and DDS readout.</p></li>
<li><p>A dynamic comparator eliminates static power losses in event generation. This is the key reason that it is more energy efficient than regular DVS. (?What does dynamic comparator means? How different from the regular DVS?)</p></li>
</ol>
<figure>
<img data-src="kuben2-027-large.gif" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
]]></content>
      <tags>
        <tag>paper</tag>
        <tag>DVS</tag>
      </tags>
  </entry>
  <entry>
    <title>记一个不常见SLURM Device Busy BUG</title>
    <url>/2022/06/11/slurm-resource-busy-bug-report/</url>
    <content><![CDATA[<h2 id="运行环境">运行环境</h2>
<ul>
<li>SLURM 深度学习集群。</li>
<li>系统：Ubuntu 20.04.5 LTS</li>
<li>造成BUG的程序：深度学习训练代码。</li>
<li>具体造成BUG的库：python的<code>multiprocessing</code>。</li>
</ul>
<span id="more"></span>
<h2 id="现象">现象</h2>
<ul>
<li><p>训练了几十个epoch都没有问题，突然狂报这个错：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">OSError: [Errno 16] Device or resource busy: <span class="string">&#x27;.nfsf7f2453cdbd6a8c40001fce6&#x27;</span></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;/work/&lt;USER&gt;/anaconda3/envs/ROMP/lib/python3.9/multiprocessing/util.py&quot;</span>, line 300, <span class="keyword">in</span> _run_finalizers</span><br><span class="line">    finalizer()</span><br><span class="line">  File <span class="string">&quot;/work/&lt;USER&gt;/anaconda3/envs/ROMP/lib/python3.9/multiprocessing/util.py&quot;</span>, line 224, <span class="keyword">in</span> __call__</span><br><span class="line">    res = self._callback(*self._args, **self._kwargs)</span><br><span class="line">  File <span class="string">&quot;/work/&lt;USER&gt;/anaconda3/envs/ROMP/lib/python3.9/multiprocessing/util.py&quot;</span>, line 133, <span class="keyword">in</span> _remove_temp_dir</span><br><span class="line">    rmtree(tempdir)</span><br><span class="line">  File <span class="string">&quot;/work/&lt;USER&gt;/anaconda3/envs/ROMP/lib/python3.9/shutil.py&quot;</span>, line 734, <span class="keyword">in</span> rmtree</span><br><span class="line">    _rmtree_safe_fd(fd, path, onerror)</span><br><span class="line">  File <span class="string">&quot;/work/&lt;USER&gt;/anaconda3/envs/ROMP/lib/python3.9/shutil.py&quot;</span>, line 690, <span class="keyword">in</span> _rmtree_safe_fd</span><br><span class="line">    onerror(os.unlink, fullname, sys.exc_info())</span><br><span class="line">  File <span class="string">&quot;/work/&lt;USER&gt;/anaconda3/envs/ROMP/lib/python3.9/shutil.py&quot;</span>, line 688, <span class="keyword">in</span> _rmtree_safe_fd</span><br><span class="line">    os.unlink(entry.name, dir_fd=topfd)</span><br></pre></td></tr></table></figure></li>
<li><p><code>.nfs&lt;xxxxxxxxxx&gt;</code>后面的这一串符号会不断变化，其他报错信息基本稳定。</p></li>
</ul>
<h2 id="解决">解决</h2>
<ul>
<li><p>经过查询得到，OSError [Errno 16] Device or resource busy 往往是某个资源正在被其他程序访问。然而这里的“资源”都是<code>multiprocessing</code>库用来在进程间交流信息的临时文件。</p></li>
<li><p>当该错误和<code>.nfs&lt;xxxxxxx&gt;</code>一起出现时，表明该资源位于一个网络位置上。这里是因为集群的储存都是以挂载的网络位置方式进行的。</p></li>
<li><p>经过一番Google，最初认为可能原因和某几个帖子一样，是disk quota已经用光了，所以会无法新建文件等，所以我先删除了一波东西，然而error依旧，且往各个位置下载大文件也并不会报类似的错误，所以暂时认为不是这个原因。</p></li>
<li><p>最终解决方案是，因为这些文件都是临时文件，所以问题一定是出在了储存临时文件的位置处，大概率是集群本身的问题（集群还是挺经常出各种奇怪问题的），所以只需要在程序开始处重新指定临时文件存储目录即可。</p></li>
<li><p>值得注意的是，跑代码需要在GPU node上跑，每个node都有自己的临时文件文件夹（估计是为了加速，把cache存到离本机最近的物理储存位置），所以更改的目标位置可以就设为<code>/tmp</code>。</p></li>
<li><p>具体代码如下（Python）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tempfile</span><br><span class="line">tempfile.tempdir = <span class="string">&#x27;/tmp&#x27;</span></span><br></pre></td></tr></table></figure>
<p>注意需要将这两行代码放到程序入口文件的最上方。如果你的暂存文件夹本来就是<code>/tmp</code>，换成任意一个你喜欢的路径即可。</p></li>
</ul>
]]></content>
      <tags>
        <tag>python</tag>
        <tag>linux</tag>
        <tag>server</tag>
        <tag>slurm</tag>
        <tag>bug-report</tag>
      </tags>
  </entry>
</search>
