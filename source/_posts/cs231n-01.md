---
title: CS231N 第一课
tags:
  - machine-learning
  - CV
date: 2018-03-28 16:32:37
---


# [CS231N](http://cs231n.stanford.edu) 第一课

## History

* 在深度学习没有出现之前，处理图片的一个重要技术是分割图片。当时最好的算法有[Normalized Cut](http://blog.sina.com.cn/s/blog_49b5f5080100lrxm.html)等。
* [SIFT（Scale-invariant feature transform）](https://blog.csdn.net/abcjennifer/article/details/7639681)：一种检测局部特征的算法，该算法通过求一幅图中的特征点（interest points,or corner points）及其有关scale 和 orientation 的描述子得到特征并进行图像特征点匹配，获得了良好效果，主要可以应用与物体检测。通过提取一些不会根据拍摄者的角度、远近变化的特征来确定目标。
* 当前SIFT仍在某些领域无法被深度学习取代，如照相机中的拍摄全景图时，各个图片的拼接就是用的SIFT。
* 人脸检测技术在很早之前（几十年前）就已经有了，而且运算速度飞快，运用于早期的相机中。
* [Faster RCNN（Regions with CNN Features）](https://zhuanlan.zhihu.com/p/24916624) ：适用于[目标检测](https://blog.csdn.net/xyy19920105/article/details/50817725) 。
* [ImageNet](http://www.image-net.org)：李菲菲组织的图片识别竞赛，在2012年被Hinton直接把准确率上升了10%。

## Image Classification

* 图像分类是计算机视觉的核心。生活中的绝大部分物体大致可以被分为1w类左右。定义分类本身是困难而容易产生歧义的，关键在于如何定义标准。

* 神经网络其实是很容易被欺骗的，比如通过改变少数个像素，便可以使得一个训练好的神经网络把猫的图像以高置信度判断为狗。

* Semantic Gap：语义鸿沟。在一算计看来一个图片就是

* 计算机视觉中很难解决的问题：光照、变形、遮挡、背景嘈杂（背景和主物体特征相似）、同一个类别中有较大差异的个体（猫种类有很多种类的猫）、两个类之间差异小（狗和狼长的很相似）

* 数据驱动的方法：

  1. 采集一个包括图片和相应标签的数据集
  2. 用机器学习的方法训练一个图片分类器
  3. 使用一个测试集评估这个分类器

* 一个经典的图像分类的数据集：CIFAR-10数据集：共有10个类别，50000个训练图像和10000个测试图像

* 第一个分类器：最近邻分类器（Nearest Neighbor Classifier）：寻找训练集中和测试图像最为相似的图像，并依据它们的labels来判断该图像的label。

* 对于所有的机器学习模型，都有两种方法：

  1. 非参数化方法：并不会把训练集转化为参数，如NNC
  2. 参数化方法：模型大小和训练数据量无关，如SVN，测试时性能更好

* 近似最近邻法（Approximate Nearest Neighbor）：有一套库FLANN，现在已经被集成到OPENCV中

* 超参数：不是被数据驱动的参数，是不会再训练中被改变的

  {% asset_img L1L2-Distance.png L1L2-Distance%}

* [交叉验证（Cross Validation）](https://blog.csdn.net/holybin/article/details/27185659) ：交叉验证（Cross Validation）是用来验证分类器的性能一种统计分析方法，基本思想是把在某种意义下将原始数据（dataset）进行分组，一部分做为训练集（training set），另一部分做为验证集（validation set），首先用训练集对分类器进行训练，在利用验证集来测试训练得到的模型（model），以此来做为评价分类器的性能指标。

* 之所以叫模式识别，是因为在各层网络中，每层都会开始学习到一些特征，或称模式，比如第一层可能学习的是人的眼、嘴，后面的层学习到了人脸的轮廓。

  ​